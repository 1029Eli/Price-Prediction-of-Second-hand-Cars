{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uDa32elhSuIa",
   "metadata": {
    "id": "uDa32elhSuIa"
   },
   "source": [
    "# 项目介绍 - 二手车价格预测\n",
    "二手车价格收到多种因素影响，在现有的数据集下，我们如何通过机器学习的方式去预测它的价格呢？以二手车市场为背景，要求预测二手汽车的交易价格，这是一个典型的回归问题  \n",
    "内容一：完成数据理解，对原始数据进行数据分析及可视化  \n",
    "内容二：特征工程，构建样本和特征，利用常规机器学习算法进行价格预测  \n",
    "内容三：加入神经网络等深度学习框架模型，进行价格预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "OU1COzokToyu",
   "metadata": {
    "executionInfo": {
     "elapsed": 6344,
     "status": "ok",
     "timestamp": 1750592343212,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "OU1COzokToyu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torchsummary import summary\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dd9e35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in d:\\anaconda\\envs\\recbole\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baxSDf1S_be",
   "metadata": {
    "id": "9baxSDf1S_be"
   },
   "source": [
    "# 1. Read and Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DFKNKXHlSxs7",
   "metadata": {
    "id": "DFKNKXHlSxs7"
   },
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "train_data = pd.read_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/used_car_train_data.csv', sep=\"\\s+\")\n",
    "test_data = pd.read_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/used_car_testA_20200313.csv', sep=\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vLpEycpvy_V2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750469653411,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "vLpEycpvy_V2",
    "outputId": "384bccbb-1aea-422e-e785-5274ce7afde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (150000, 31)\n",
      "TestA data shape: (50000, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape:',train_data.shape)\n",
    "print('TestA data shape:',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c1fba-da69-4bc5-ba1b-d6bde3f09442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1750469654412,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "cf5c1fba-da69-4bc5-ba1b-d6bde3f09442",
    "outputId": "1c8f5749-b3bd-4e6e-e68a-0228ca3ed6c3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5d7f021b-5637-4593-8c6d-45802f2c2292\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264777</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d7f021b-5637-4593-8c6d-45802f2c2292')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5d7f021b-5637-4593-8c6d-45802f2c2292 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5d7f021b-5637-4593-8c6d-45802f2c2292');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-cff68756-3a60-4baa-abc0-8b7c17078c23\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff68756-3a60-4baa-abc0-8b7c17078c23')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-cff68756-3a60-4baa-abc0-8b7c17078c23 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType gearbox power  \\\n",
       "0       0     736  20040402   30.0    6.0       1.0       0.0     0.0    60   \n",
       "1       1    2262  20030301   40.0    1.0       2.0       0.0     0.0     0   \n",
       "2       2   14874  20040403  115.0   15.0       1.0       0.0     0.0   163   \n",
       "3       3   71865  19960908  109.0   10.0       0.0       0.0     1.0   193   \n",
       "4       4  111080  20120103  110.0    5.0       1.0       0.0     0.0    68   \n",
       "\n",
       "  kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n",
       "0      12.5  ...  0.235676  0.101988  0.129549  0.022816  0.097462 -2.881803   \n",
       "1      15.0  ...  0.264777  0.121004  0.135731  0.026597  0.020582 -4.900482   \n",
       "2      12.5  ...  0.251410  0.114912  0.165147  0.062173  0.027075 -4.846749   \n",
       "3      15.0  ...  0.274293  0.110300  0.121964  0.033395  0.000000 -4.509599   \n",
       "4       5.0  ...  0.228036  0.073205  0.091880  0.078819  0.121534 -1.896240   \n",
       "\n",
       "       v_11      v_12      v_13      v_14  \n",
       "0  2.804097 -2.420821  0.795292  0.914762  \n",
       "1  2.096338 -1.030483 -1.722674  0.245522  \n",
       "2  1.803559  1.565330 -0.832687 -0.229963  \n",
       "3  1.285940 -0.501868 -2.438353 -0.478699  \n",
       "4  0.910783  0.931110  2.834518  1.923482  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w9wS15jU5omC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1750469655796,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "w9wS15jU5omC",
    "outputId": "9af16b2c-f162-482b-a0da-00c90b95e96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   SaleID             150000 non-null  int64  \n",
      " 1   name               150000 non-null  int64  \n",
      " 2   regDate            150000 non-null  int64  \n",
      " 3   model              150000 non-null  float64\n",
      " 4   brand              150000 non-null  float64\n",
      " 5   bodyType           150000 non-null  float64\n",
      " 6   fuelType           150000 non-null  float64\n",
      " 7   gearbox            150000 non-null  object \n",
      " 8   power              150000 non-null  object \n",
      " 9   kilometer          150000 non-null  object \n",
      " 10  notRepairedDamage  150000 non-null  object \n",
      " 11  regionCode         150000 non-null  int64  \n",
      " 12  seller             150000 non-null  int64  \n",
      " 13  offerType          150000 non-null  float64\n",
      " 14  creatDate          150000 non-null  float64\n",
      " 15  price              150000 non-null  float64\n",
      " 16  v_0                150000 non-null  float64\n",
      " 17  v_1                150000 non-null  float64\n",
      " 18  v_2                150000 non-null  float64\n",
      " 19  v_3                150000 non-null  float64\n",
      " 20  v_4                150000 non-null  float64\n",
      " 21  v_5                150000 non-null  float64\n",
      " 22  v_6                150000 non-null  float64\n",
      " 23  v_7                150000 non-null  float64\n",
      " 24  v_8                150000 non-null  float64\n",
      " 25  v_9                150000 non-null  float64\n",
      " 26  v_10               150000 non-null  float64\n",
      " 27  v_11               150000 non-null  float64\n",
      " 28  v_12               148531 non-null  float64\n",
      " 29  v_13               146417 non-null  float64\n",
      " 30  v_14               135884 non-null  float64\n",
      "dtypes: float64(22), int64(5), object(4)\n",
      "memory usage: 35.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8NHXFo3Y4zJI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1750469658072,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "8NHXFo3Y4zJI",
    "outputId": "4bd5062f-395c-4180-a9b6-3f636d223b4a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a4a705b0-d79b-4c3f-a6d8-d2584ae3ea7f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>regionCode</th>\n",
       "      <th>seller</th>\n",
       "      <th>offerType</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>148531.000000</td>\n",
       "      <td>146417.000000</td>\n",
       "      <td>135884.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74999.500000</td>\n",
       "      <td>68349.172873</td>\n",
       "      <td>2.003417e+07</td>\n",
       "      <td>47.128953</td>\n",
       "      <td>8.052527</td>\n",
       "      <td>1.870747</td>\n",
       "      <td>1.394827</td>\n",
       "      <td>1.997783e+05</td>\n",
       "      <td>2.841478e+05</td>\n",
       "      <td>1.415701e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246643</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.174574</td>\n",
       "      <td>0.296920</td>\n",
       "      <td>0.406928</td>\n",
       "      <td>-0.164371</td>\n",
       "      <td>-0.446352</td>\n",
       "      <td>-0.085471</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43301.414527</td>\n",
       "      <td>61103.875095</td>\n",
       "      <td>5.364988e+04</td>\n",
       "      <td>49.535881</td>\n",
       "      <td>7.864603</td>\n",
       "      <td>5.221312</td>\n",
       "      <td>15.676749</td>\n",
       "      <td>1.985073e+06</td>\n",
       "      <td>2.376421e+06</td>\n",
       "      <td>5.151321e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116636</td>\n",
       "      <td>0.133581</td>\n",
       "      <td>0.927042</td>\n",
       "      <td>1.773396</td>\n",
       "      <td>1.962003</td>\n",
       "      <td>3.758661</td>\n",
       "      <td>2.002930</td>\n",
       "      <td>2.257730</td>\n",
       "      <td>1.267140</td>\n",
       "      <td>1.050417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.991000e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.273510</td>\n",
       "      <td>-8.206004</td>\n",
       "      <td>-8.399672</td>\n",
       "      <td>-9.168192</td>\n",
       "      <td>-9.404106</td>\n",
       "      <td>-9.639552</td>\n",
       "      <td>-6.113291</td>\n",
       "      <td>-6.546556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37499.750000</td>\n",
       "      <td>11156.000000</td>\n",
       "      <td>1.999091e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.390000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241064</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.055272</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>-3.666042</td>\n",
       "      <td>-2.026105</td>\n",
       "      <td>-1.745234</td>\n",
       "      <td>-0.999703</td>\n",
       "      <td>-0.426907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74999.500000</td>\n",
       "      <td>51638.000000</td>\n",
       "      <td>2.003091e+07</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.010000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256928</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.090081</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.063335</td>\n",
       "      <td>1.240603</td>\n",
       "      <td>-0.457218</td>\n",
       "      <td>-0.160305</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.155026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112499.250000</td>\n",
       "      <td>118841.250000</td>\n",
       "      <td>2.007111e+07</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.719000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265170</td>\n",
       "      <td>0.104255</td>\n",
       "      <td>0.120590</td>\n",
       "      <td>0.081996</td>\n",
       "      <td>0.094738</td>\n",
       "      <td>2.691063</td>\n",
       "      <td>1.115744</td>\n",
       "      <td>1.572130</td>\n",
       "      <td>0.929041</td>\n",
       "      <td>0.700543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>149999.000000</td>\n",
       "      <td>196812.000000</td>\n",
       "      <td>2.015121e+07</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401999</td>\n",
       "      <td>1.387847</td>\n",
       "      <td>12.357011</td>\n",
       "      <td>18.819042</td>\n",
       "      <td>18.801218</td>\n",
       "      <td>18.802072</td>\n",
       "      <td>13.562011</td>\n",
       "      <td>11.147669</td>\n",
       "      <td>8.658418</td>\n",
       "      <td>2.743993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4a705b0-d79b-4c3f-a6d8-d2584ae3ea7f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a4a705b0-d79b-4c3f-a6d8-d2584ae3ea7f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a4a705b0-d79b-4c3f-a6d8-d2584ae3ea7f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-00e01889-d84a-4245-aded-a03d2dfb5765\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00e01889-d84a-4245-aded-a03d2dfb5765')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-00e01889-d84a-4245-aded-a03d2dfb5765 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              SaleID           name       regDate          model  \\\n",
       "count  150000.000000  150000.000000  1.500000e+05  150000.000000   \n",
       "mean    74999.500000   68349.172873  2.003417e+07      47.128953   \n",
       "std     43301.414527   61103.875095  5.364988e+04      49.535881   \n",
       "min         0.000000       0.000000  1.991000e+07       0.000000   \n",
       "25%     37499.750000   11156.000000  1.999091e+07      10.000000   \n",
       "50%     74999.500000   51638.000000  2.003091e+07      30.000000   \n",
       "75%    112499.250000  118841.250000  2.007111e+07      66.000000   \n",
       "max    149999.000000  196812.000000  2.015121e+07     247.000000   \n",
       "\n",
       "               brand       bodyType       fuelType    regionCode  \\\n",
       "count  150000.000000  150000.000000  150000.000000  1.500000e+05   \n",
       "mean        8.052527       1.870747       1.394827  1.997783e+05   \n",
       "std         7.864603       5.221312      15.676749  1.985073e+06   \n",
       "min         0.000000       0.000000       0.000000  0.000000e+00   \n",
       "25%         1.000000       0.000000       0.000000  7.390000e+02   \n",
       "50%         6.000000       1.000000       0.000000  2.010000e+03   \n",
       "75%        13.000000       3.000000       1.000000  3.719000e+03   \n",
       "max        39.000000     999.000000    3500.000000  2.016041e+07   \n",
       "\n",
       "             seller     offerType  ...            v_5            v_6  \\\n",
       "count  1.500000e+05  1.500000e+05  ...  150000.000000  150000.000000   \n",
       "mean   2.841478e+05  1.415701e+06  ...       0.246643       0.062381   \n",
       "std    2.376421e+06  5.151321e+06  ...       0.116636       0.133581   \n",
       "min    0.000000e+00  0.000000e+00  ...       0.000000       0.000000   \n",
       "25%    0.000000e+00  0.000000e+00  ...       0.241064       0.000161   \n",
       "50%    0.000000e+00  0.000000e+00  ...       0.256928       0.001547   \n",
       "75%    0.000000e+00  0.000000e+00  ...       0.265170       0.104255   \n",
       "max    2.016041e+07  2.016041e+07  ...       1.401999       1.387847   \n",
       "\n",
       "                 v_7            v_8            v_9           v_10  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.174574       0.296920       0.406928      -0.164371   \n",
       "std         0.927042       1.773396       1.962003       3.758661   \n",
       "min        -0.273510      -8.206004      -8.399672      -9.168192   \n",
       "25%         0.055272       0.036050       0.035225      -3.666042   \n",
       "50%         0.090081       0.058523       0.063335       1.240603   \n",
       "75%         0.120590       0.081996       0.094738       2.691063   \n",
       "max        12.357011      18.819042      18.801218      18.802072   \n",
       "\n",
       "                v_11           v_12           v_13           v_14  \n",
       "count  150000.000000  148531.000000  146417.000000  135884.000000  \n",
       "mean       -0.446352      -0.085471       0.022190       0.008456  \n",
       "std         2.002930       2.257730       1.267140       1.050417  \n",
       "min        -9.404106      -9.639552      -6.113291      -6.546556  \n",
       "25%        -2.026105      -1.745234      -0.999703      -0.426907  \n",
       "50%        -0.457218      -0.160305       0.008602       0.155026  \n",
       "75%         1.115744       1.572130       0.929041       0.700543  \n",
       "max        13.562011      11.147669       8.658418       2.743993  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-zVsifma5_vW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1750469659350,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "-zVsifma5_vW",
    "outputId": "9d7f305e-bc42-42d4-8cd9-4d2c4d2286b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   SaleID             50000 non-null  int64  \n",
      " 1   name               50000 non-null  int64  \n",
      " 2   regDate            50000 non-null  int64  \n",
      " 3   model              50000 non-null  float64\n",
      " 4   brand              50000 non-null  int64  \n",
      " 5   bodyType           50000 non-null  float64\n",
      " 6   fuelType           50000 non-null  float64\n",
      " 7   gearbox            50000 non-null  object \n",
      " 8   power              50000 non-null  object \n",
      " 9   kilometer          50000 non-null  object \n",
      " 10  notRepairedDamage  50000 non-null  object \n",
      " 11  regionCode         50000 non-null  int64  \n",
      " 12  seller             50000 non-null  float64\n",
      " 13  offerType          50000 non-null  float64\n",
      " 14  creatDate          50000 non-null  float64\n",
      " 15  v_0                50000 non-null  float64\n",
      " 16  v_1                50000 non-null  float64\n",
      " 17  v_2                50000 non-null  float64\n",
      " 18  v_3                50000 non-null  float64\n",
      " 19  v_4                50000 non-null  float64\n",
      " 20  v_5                50000 non-null  float64\n",
      " 21  v_6                50000 non-null  float64\n",
      " 22  v_7                50000 non-null  float64\n",
      " 23  v_8                50000 non-null  float64\n",
      " 24  v_9                50000 non-null  float64\n",
      " 25  v_10               50000 non-null  float64\n",
      " 26  v_11               50000 non-null  float64\n",
      " 27  v_12               49548 non-null  float64\n",
      " 28  v_13               48880 non-null  float64\n",
      " 29  v_14               45356 non-null  float64\n",
      "dtypes: float64(21), int64(5), object(4)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwnII9h06D3N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1750469661224,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "xwnII9h06D3N",
    "outputId": "197894af-391a-404e-c4ac-5fe7167e34a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8ab5973a-a5cd-44d0-9355-08e0436d5da6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>regionCode</th>\n",
       "      <th>seller</th>\n",
       "      <th>offerType</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>49548.000000</td>\n",
       "      <td>48880.000000</td>\n",
       "      <td>45356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>174999.500000</td>\n",
       "      <td>68542.223280</td>\n",
       "      <td>2.003393e+07</td>\n",
       "      <td>46.844520</td>\n",
       "      <td>8.056240</td>\n",
       "      <td>1.82978</td>\n",
       "      <td>1.310420</td>\n",
       "      <td>1.846027e+05</td>\n",
       "      <td>2.693423e+05</td>\n",
       "      <td>1.420901e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245942</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>0.278298</td>\n",
       "      <td>0.394680</td>\n",
       "      <td>-0.180498</td>\n",
       "      <td>-0.441886</td>\n",
       "      <td>-0.093695</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14433.901067</td>\n",
       "      <td>61052.808133</td>\n",
       "      <td>5.368870e+04</td>\n",
       "      <td>49.469548</td>\n",
       "      <td>7.819477</td>\n",
       "      <td>4.38703</td>\n",
       "      <td>11.319999</td>\n",
       "      <td>1.907934e+06</td>\n",
       "      <td>2.314646e+06</td>\n",
       "      <td>5.160173e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113548</td>\n",
       "      <td>0.132116</td>\n",
       "      <td>0.889236</td>\n",
       "      <td>1.705061</td>\n",
       "      <td>1.904670</td>\n",
       "      <td>3.749435</td>\n",
       "      <td>2.011260</td>\n",
       "      <td>2.264558</td>\n",
       "      <td>1.262383</td>\n",
       "      <td>1.039922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.991000e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.137733e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.481381</td>\n",
       "      <td>-8.088973</td>\n",
       "      <td>-9.160049</td>\n",
       "      <td>-8.916949</td>\n",
       "      <td>-8.249206</td>\n",
       "      <td>-5.881834</td>\n",
       "      <td>-6.112667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>162499.750000</td>\n",
       "      <td>11203.500000</td>\n",
       "      <td>1.999091e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241186</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.055647</td>\n",
       "      <td>0.035926</td>\n",
       "      <td>0.034963</td>\n",
       "      <td>-3.656769</td>\n",
       "      <td>-2.033607</td>\n",
       "      <td>-1.744112</td>\n",
       "      <td>-0.999841</td>\n",
       "      <td>-0.428772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>174999.500000</td>\n",
       "      <td>52248.500000</td>\n",
       "      <td>2.003091e+07</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.025000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257005</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.090068</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.063502</td>\n",
       "      <td>1.208642</td>\n",
       "      <td>-0.447549</td>\n",
       "      <td>-0.165747</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.152347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>187499.250000</td>\n",
       "      <td>118856.500000</td>\n",
       "      <td>2.007110e+07</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.739000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265163</td>\n",
       "      <td>0.104231</td>\n",
       "      <td>0.120749</td>\n",
       "      <td>0.081606</td>\n",
       "      <td>0.094614</td>\n",
       "      <td>2.675705</td>\n",
       "      <td>1.136973</td>\n",
       "      <td>1.567727</td>\n",
       "      <td>0.924715</td>\n",
       "      <td>0.702953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>199999.000000</td>\n",
       "      <td>196805.000000</td>\n",
       "      <td>2.015121e+07</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>2.016041e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339804</td>\n",
       "      <td>1.332522</td>\n",
       "      <td>12.338872</td>\n",
       "      <td>18.761276</td>\n",
       "      <td>18.811053</td>\n",
       "      <td>18.856218</td>\n",
       "      <td>12.950498</td>\n",
       "      <td>7.430223</td>\n",
       "      <td>5.228962</td>\n",
       "      <td>2.624622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ab5973a-a5cd-44d0-9355-08e0436d5da6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8ab5973a-a5cd-44d0-9355-08e0436d5da6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8ab5973a-a5cd-44d0-9355-08e0436d5da6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4467c934-b358-4dad-86c8-cf2a85c9e855\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4467c934-b358-4dad-86c8-cf2a85c9e855')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4467c934-b358-4dad-86c8-cf2a85c9e855 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              SaleID           name       regDate         model         brand  \\\n",
       "count   50000.000000   50000.000000  5.000000e+04  50000.000000  50000.000000   \n",
       "mean   174999.500000   68542.223280  2.003393e+07     46.844520      8.056240   \n",
       "std     14433.901067   61052.808133  5.368870e+04     49.469548      7.819477   \n",
       "min    150000.000000       0.000000  1.991000e+07      0.000000      0.000000   \n",
       "25%    162499.750000   11203.500000  1.999091e+07     10.000000      1.000000   \n",
       "50%    174999.500000   52248.500000  2.003091e+07     29.000000      6.000000   \n",
       "75%    187499.250000  118856.500000  2.007110e+07     65.000000     13.000000   \n",
       "max    199999.000000  196805.000000  2.015121e+07    246.000000     39.000000   \n",
       "\n",
       "          bodyType      fuelType    regionCode        seller     offerType  \\\n",
       "count  50000.00000  50000.000000  5.000000e+04  5.000000e+04  5.000000e+04   \n",
       "mean       1.82978      1.310420  1.846027e+05  2.693423e+05  1.420901e+06   \n",
       "std        4.38703     11.319999  1.907934e+06  2.314646e+06  5.160173e+06   \n",
       "min        0.00000      0.000000  0.000000e+00  0.000000e+00 -4.137733e+00   \n",
       "25%        0.00000      0.000000  7.500000e+02  0.000000e+00  0.000000e+00   \n",
       "50%        1.00000      0.000000  2.025000e+03  0.000000e+00  0.000000e+00   \n",
       "75%        3.00000      1.000000  3.739000e+03  0.000000e+00  0.000000e+00   \n",
       "max      500.00000    610.000000  2.016041e+07  2.016041e+07  2.016041e+07   \n",
       "\n",
       "       ...           v_5           v_6           v_7           v_8  \\\n",
       "count  ...  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean   ...      0.245942      0.062157      0.167631      0.278298   \n",
       "std    ...      0.113548      0.132116      0.889236      1.705061   \n",
       "min    ...      0.000000      0.000000      0.000000     -7.481381   \n",
       "25%    ...      0.241186      0.000157      0.055647      0.035926   \n",
       "50%    ...      0.257005      0.005279      0.090068      0.058519   \n",
       "75%    ...      0.265163      0.104231      0.120749      0.081606   \n",
       "max    ...      1.339804      1.332522     12.338872     18.761276   \n",
       "\n",
       "                v_9          v_10          v_11          v_12          v_13  \\\n",
       "count  50000.000000  50000.000000  50000.000000  49548.000000  48880.000000   \n",
       "mean       0.394680     -0.180498     -0.441886     -0.093695      0.018620   \n",
       "std        1.904670      3.749435      2.011260      2.264558      1.262383   \n",
       "min       -8.088973     -9.160049     -8.916949     -8.249206     -5.881834   \n",
       "25%        0.034963     -3.656769     -2.033607     -1.744112     -0.999841   \n",
       "50%        0.063502      1.208642     -0.447549     -0.165747      0.009142   \n",
       "75%        0.094614      2.675705      1.136973      1.567727      0.924715   \n",
       "max       18.811053     18.856218     12.950498      7.430223      5.228962   \n",
       "\n",
       "               v_14  \n",
       "count  45356.000000  \n",
       "mean       0.010720  \n",
       "std        1.039922  \n",
       "min       -6.112667  \n",
       "25%       -0.428772  \n",
       "50%        0.152347  \n",
       "75%        0.702953  \n",
       "max        2.624622  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P8F_m7X-BeZu",
   "metadata": {
    "id": "P8F_m7X-BeZu"
   },
   "source": [
    "## 1.1查看数据缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j0HFQoOE_TNV",
   "metadata": {
    "id": "j0HFQoOE_TNV"
   },
   "source": [
    "### 1.1.1 train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zwqm6FQzwnZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1750469663325,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "zwqm6FQzwnZi",
    "outputId": "a911503f-cb36-4b43-af4a-e68d0dbe8d96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SaleID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regDate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilometer</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionCode</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seller</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offerType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatDate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_12</th>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_13</th>\n",
       "      <td>3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_14</th>\n",
       "      <td>14116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "SaleID                   0\n",
       "name                     0\n",
       "regDate                  0\n",
       "model                    0\n",
       "brand                    0\n",
       "bodyType                 0\n",
       "fuelType                 0\n",
       "gearbox                  0\n",
       "power                    0\n",
       "kilometer                0\n",
       "notRepairedDamage        0\n",
       "regionCode               0\n",
       "seller                   0\n",
       "offerType                0\n",
       "creatDate                0\n",
       "price                    0\n",
       "v_0                      0\n",
       "v_1                      0\n",
       "v_2                      0\n",
       "v_3                      0\n",
       "v_4                      0\n",
       "v_5                      0\n",
       "v_6                      0\n",
       "v_7                      0\n",
       "v_8                      0\n",
       "v_9                      0\n",
       "v_10                     0\n",
       "v_11                     0\n",
       "v_12                  1469\n",
       "v_13                  3583\n",
       "v_14                 14116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6jgWzJbSw1Ai",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "executionInfo": {
     "elapsed": 7470,
     "status": "ok",
     "timestamp": 1750469673385,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "6jgWzJbSw1Ai",
    "outputId": "d0d24d25-02f6-4164-de4c-7fcb54be0893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化缺失分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(train_data.isnull(), cbar=False, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nqneq0t9_cz5",
   "metadata": {
    "id": "nqneq0t9_cz5"
   },
   "source": [
    "### 1.1.2 test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Ubmz6VYw4GR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1750469676076,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "0Ubmz6VYw4GR",
    "outputId": "ef44c607-6cfc-4777-d180-71d980e40f72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SaleID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regDate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilometer</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regionCode</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seller</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offerType</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatDate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_12</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_13</th>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_14</th>\n",
       "      <td>4644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "SaleID                  0\n",
       "name                    0\n",
       "regDate                 0\n",
       "model                   0\n",
       "brand                   0\n",
       "bodyType                0\n",
       "fuelType                0\n",
       "gearbox                 0\n",
       "power                   0\n",
       "kilometer               0\n",
       "notRepairedDamage       0\n",
       "regionCode              0\n",
       "seller                  0\n",
       "offerType               0\n",
       "creatDate               0\n",
       "v_0                     0\n",
       "v_1                     0\n",
       "v_2                     0\n",
       "v_3                     0\n",
       "v_4                     0\n",
       "v_5                     0\n",
       "v_6                     0\n",
       "v_7                     0\n",
       "v_8                     0\n",
       "v_9                     0\n",
       "v_10                    0\n",
       "v_11                    0\n",
       "v_12                  452\n",
       "v_13                 1120\n",
       "v_14                 4644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5-g-CfffxPmN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "executionInfo": {
     "elapsed": 2541,
     "status": "ok",
     "timestamp": 1750296003124,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "5-g-CfffxPmN",
    "outputId": "2d322b70-50d3-43bd-a779-d011988e492f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化缺失分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(test_data.isnull(), cbar=False, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R5knYs5exqCx",
   "metadata": {
    "id": "R5knYs5exqCx"
   },
   "source": [
    "## 1.2 数据类别和异常值检查\n",
    "+ 除gearbox, power, kilometer和notRepairedDamage为object外, 其他都为数值类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sExlU9gvyLBo",
   "metadata": {
    "id": "sExlU9gvyLBo"
   },
   "source": [
    "### 1.2.1 train dataset - 数据类别检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zgg0QwE9xtx9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1750469686565,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "zgg0QwE9xtx9",
    "outputId": "cc30810d-395b-4752-b14a-6a1487fa9cd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>105715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>17558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>12611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4273 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "notRepairedDamage\n",
       "0.0     105715\n",
       "-        17558\n",
       "1.0      12611\n",
       "0         3586\n",
       "70          56\n",
       "         ...  \n",
       "1283         1\n",
       "4490         1\n",
       "4300         1\n",
       "4293         1\n",
       "4825         1\n",
       "Name: count, Length: 4273, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PWLUUmT5zNt1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750469689423,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "PWLUUmT5zNt1",
    "outputId": "4af16a15-10d8-474d-ea1f-e4a316b94c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异常值数量: 14116\n"
     ]
    }
   ],
   "source": [
    "mask = ~train_data['notRepairedDamage'].isin([\"0.0\", \"1.0\", '-'])\n",
    "abnormal_count = mask.sum()\n",
    "print(f\"异常值数量: {abnormal_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0HaCsqjO0JOI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1750469690773,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "0HaCsqjO0JOI",
    "outputId": "9da35cb4-673b-4714-f83c-b54b97581261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 <class 'str'>\n",
      "- <class 'str'>\n",
      "1.0 <class 'str'>\n",
      "0 <class 'str'>\n",
      "4825 <class 'str'>\n",
      "1326 <class 'str'>\n",
      "6792 <class 'str'>\n",
      "5765 <class 'str'>\n",
      "1141 <class 'str'>\n",
      "5084 <class 'str'>\n",
      "1465 <class 'str'>\n",
      "5313 <class 'str'>\n",
      "665 <class 'str'>\n",
      "1225 <class 'str'>\n",
      "560 <class 'str'>\n",
      "4293 <class 'str'>\n",
      "556 <class 'str'>\n",
      "6409 <class 'str'>\n",
      "2578 <class 'str'>\n",
      "2679 <class 'str'>\n",
      "2754 <class 'str'>\n",
      "6244 <class 'str'>\n",
      "1543 <class 'str'>\n",
      "2049 <class 'str'>\n",
      "5997 <class 'str'>\n",
      "78 <class 'str'>\n",
      "125 <class 'str'>\n",
      "1496 <class 'str'>\n",
      "1411 <class 'str'>\n",
      "200 <class 'str'>\n",
      "874 <class 'str'>\n",
      "2062 <class 'str'>\n",
      "336 <class 'str'>\n",
      "754 <class 'str'>\n",
      "3103 <class 'str'>\n",
      "3815 <class 'str'>\n",
      "446 <class 'str'>\n",
      "762 <class 'str'>\n",
      "3124 <class 'str'>\n",
      "4987 <class 'str'>\n",
      "2468 <class 'str'>\n",
      "1319 <class 'str'>\n",
      "2007 <class 'str'>\n",
      "3972 <class 'str'>\n",
      "486 <class 'str'>\n",
      "5435 <class 'str'>\n",
      "3235 <class 'str'>\n",
      "4975 <class 'str'>\n",
      "5806 <class 'str'>\n",
      "398 <class 'str'>\n",
      "6111 <class 'str'>\n",
      "2870 <class 'str'>\n",
      "2557 <class 'str'>\n",
      "107 <class 'str'>\n",
      "310 <class 'str'>\n",
      "617 <class 'str'>\n",
      "1832 <class 'str'>\n",
      "261 <class 'str'>\n",
      "1970 <class 'str'>\n",
      "4705 <class 'str'>\n",
      "790 <class 'str'>\n",
      "423 <class 'str'>\n",
      "4349 <class 'str'>\n",
      "1383 <class 'str'>\n",
      "2613 <class 'str'>\n",
      "913 <class 'str'>\n",
      "2707 <class 'str'>\n",
      "3670 <class 'str'>\n",
      "4051 <class 'str'>\n",
      "6075 <class 'str'>\n",
      "2143 <class 'str'>\n",
      "635 <class 'str'>\n",
      "290 <class 'str'>\n",
      "647 <class 'str'>\n",
      "650 <class 'str'>\n",
      "369 <class 'str'>\n",
      "4816 <class 'str'>\n",
      "6185 <class 'str'>\n",
      "2860 <class 'str'>\n",
      "1801 <class 'str'>\n",
      "941 <class 'str'>\n",
      "6586 <class 'str'>\n",
      "1565 <class 'str'>\n",
      "5158 <class 'str'>\n",
      "5361 <class 'str'>\n",
      "2594 <class 'str'>\n",
      "6656 <class 'str'>\n",
      "329 <class 'str'>\n",
      "2038 <class 'str'>\n",
      "1688 <class 'str'>\n",
      "5181 <class 'str'>\n",
      "890 <class 'str'>\n",
      "6840 <class 'str'>\n",
      "5410 <class 'str'>\n",
      "1826 <class 'str'>\n",
      "1456 <class 'str'>\n",
      "2509 <class 'str'>\n",
      "1140 <class 'str'>\n",
      "1975 <class 'str'>\n",
      "1070 <class 'str'>\n",
      "728 <class 'str'>\n",
      "1946 <class 'str'>\n",
      "771 <class 'str'>\n",
      "501 <class 'str'>\n",
      "3936 <class 'str'>\n",
      "3335 <class 'str'>\n",
      "2182 <class 'str'>\n",
      "2529 <class 'str'>\n",
      "593 <class 'str'>\n",
      "6508 <class 'str'>\n",
      "2821 <class 'str'>\n",
      "3104 <class 'str'>\n",
      "3516 <class 'str'>\n",
      "255 <class 'str'>\n",
      "4456 <class 'str'>\n",
      "7341 <class 'str'>\n",
      "2831 <class 'str'>\n",
      "1248 <class 'str'>\n",
      "2522 <class 'str'>\n",
      "3431 <class 'str'>\n",
      "2605 <class 'str'>\n",
      "763 <class 'str'>\n",
      "3384 <class 'str'>\n",
      "5097 <class 'str'>\n",
      "1858 <class 'str'>\n",
      "3425 <class 'str'>\n",
      "2724 <class 'str'>\n",
      "605 <class 'str'>\n",
      "451 <class 'str'>\n",
      "3451 <class 'str'>\n",
      "3395 <class 'str'>\n",
      "3904 <class 'str'>\n",
      "3918 <class 'str'>\n",
      "4606 <class 'str'>\n",
      "738 <class 'str'>\n",
      "13 <class 'str'>\n",
      "218 <class 'str'>\n",
      "72 <class 'str'>\n",
      "3419 <class 'str'>\n",
      "1765 <class 'str'>\n",
      "4881 <class 'str'>\n",
      "4861 <class 'str'>\n",
      "443 <class 'str'>\n",
      "1192 <class 'str'>\n",
      "7910 <class 'str'>\n",
      "2099 <class 'str'>\n",
      "611 <class 'str'>\n",
      "656 <class 'str'>\n",
      "1653 <class 'str'>\n",
      "3938 <class 'str'>\n",
      "2947 <class 'str'>\n",
      "6433 <class 'str'>\n",
      "2615 <class 'str'>\n",
      "5936 <class 'str'>\n",
      "4023 <class 'str'>\n",
      "241 <class 'str'>\n",
      "4277 <class 'str'>\n",
      "5484 <class 'str'>\n",
      "666 <class 'str'>\n",
      "2620 <class 'str'>\n",
      "538 <class 'str'>\n",
      "1066 <class 'str'>\n",
      "4198 <class 'str'>\n",
      "3697 <class 'str'>\n",
      "3545 <class 'str'>\n",
      "1152 <class 'str'>\n",
      "403 <class 'str'>\n",
      "2850 <class 'str'>\n",
      "827 <class 'str'>\n",
      "449 <class 'str'>\n",
      "243 <class 'str'>\n",
      "3797 <class 'str'>\n",
      "282 <class 'str'>\n",
      "2061 <class 'str'>\n",
      "3297 <class 'str'>\n",
      "2854 <class 'str'>\n",
      "5616 <class 'str'>\n",
      "2670 <class 'str'>\n",
      "701 <class 'str'>\n",
      "4870 <class 'str'>\n",
      "1275 <class 'str'>\n",
      "6735 <class 'str'>\n",
      "527 <class 'str'>\n",
      "182 <class 'str'>\n",
      "450 <class 'str'>\n",
      "413 <class 'str'>\n",
      "4951 <class 'str'>\n",
      "2320 <class 'str'>\n",
      "1312 <class 'str'>\n",
      "5794 <class 'str'>\n",
      "2526 <class 'str'>\n",
      "196 <class 'str'>\n",
      "1189 <class 'str'>\n",
      "4056 <class 'str'>\n",
      "188 <class 'str'>\n",
      "998 <class 'str'>\n",
      "2166 <class 'str'>\n",
      "4584 <class 'str'>\n",
      "3758 <class 'str'>\n",
      "1343 <class 'str'>\n",
      "911 <class 'str'>\n",
      "903 <class 'str'>\n",
      "2090 <class 'str'>\n",
      "1897 <class 'str'>\n",
      "1530 <class 'str'>\n",
      "1142 <class 'str'>\n",
      "2298 <class 'str'>\n",
      "3392 <class 'str'>\n",
      "1740 <class 'str'>\n",
      "5742 <class 'str'>\n",
      "4516 <class 'str'>\n",
      "4135 <class 'str'>\n",
      "1155 <class 'str'>\n",
      "1641 <class 'str'>\n",
      "3533 <class 'str'>\n",
      "267 <class 'str'>\n",
      "2727 <class 'str'>\n",
      "715 <class 'str'>\n",
      "5909 <class 'str'>\n",
      "2423 <class 'str'>\n",
      "3084 <class 'str'>\n",
      "4754 <class 'str'>\n",
      "5695 <class 'str'>\n",
      "961 <class 'str'>\n",
      "582 <class 'str'>\n",
      "1296 <class 'str'>\n",
      "2248 <class 'str'>\n",
      "1792 <class 'str'>\n",
      "2600 <class 'str'>\n",
      "1896 <class 'str'>\n",
      "390 <class 'str'>\n",
      "837 <class 'str'>\n",
      "5864 <class 'str'>\n",
      "482 <class 'str'>\n",
      "3948 <class 'str'>\n",
      "1570 <class 'str'>\n",
      "4128 <class 'str'>\n",
      "2178 <class 'str'>\n",
      "1453 <class 'str'>\n",
      "1533 <class 'str'>\n",
      "1504 <class 'str'>\n",
      "568 <class 'str'>\n",
      "3521 <class 'str'>\n",
      "3463 <class 'str'>\n",
      "4060 <class 'str'>\n",
      "4814 <class 'str'>\n",
      "2199 <class 'str'>\n",
      "1987 <class 'str'>\n",
      "126 <class 'str'>\n",
      "2499 <class 'str'>\n",
      "2849 <class 'str'>\n",
      "189 <class 'str'>\n",
      "906 <class 'str'>\n",
      "641 <class 'str'>\n",
      "3477 <class 'str'>\n",
      "2914 <class 'str'>\n",
      "545 <class 'str'>\n",
      "1279 <class 'str'>\n",
      "987 <class 'str'>\n",
      "2956 <class 'str'>\n",
      "4829 <class 'str'>\n",
      "2603 <class 'str'>\n",
      "5434 <class 'str'>\n",
      "1187 <class 'str'>\n",
      "2853 <class 'str'>\n",
      "1435 <class 'str'>\n",
      "2420 <class 'str'>\n",
      "7114 <class 'str'>\n",
      "5872 <class 'str'>\n",
      "2130 <class 'str'>\n",
      "663 <class 'str'>\n",
      "784 <class 'str'>\n",
      "3108 <class 'str'>\n",
      "2497 <class 'str'>\n",
      "297 <class 'str'>\n",
      "429 <class 'str'>\n",
      "3136 <class 'str'>\n",
      "7908 <class 'str'>\n",
      "1886 <class 'str'>\n",
      "70 <class 'str'>\n",
      "1505 <class 'str'>\n",
      "3341 <class 'str'>\n",
      "3386 <class 'str'>\n",
      "4096 <class 'str'>\n",
      "1621 <class 'str'>\n",
      "1813 <class 'str'>\n",
      "1154 <class 'str'>\n",
      "4290 <class 'str'>\n",
      "3689 <class 'str'>\n",
      "1014 <class 'str'>\n",
      "468 <class 'str'>\n",
      "6820 <class 'str'>\n",
      "1883 <class 'str'>\n",
      "167 <class 'str'>\n",
      "2485 <class 'str'>\n",
      "607 <class 'str'>\n",
      "1399 <class 'str'>\n",
      "2264 <class 'str'>\n",
      "1700 <class 'str'>\n",
      "3785 <class 'str'>\n",
      "2711 <class 'str'>\n",
      "467 <class 'str'>\n",
      "2196 <class 'str'>\n",
      "5783 <class 'str'>\n",
      "428 <class 'str'>\n",
      "759 <class 'str'>\n",
      "1357 <class 'str'>\n",
      "1104 <class 'str'>\n",
      "3517 <class 'str'>\n",
      "4336 <class 'str'>\n",
      "2120 <class 'str'>\n",
      "36 <class 'str'>\n",
      "295 <class 'str'>\n",
      "1930 <class 'str'>\n",
      "1704 <class 'str'>\n",
      "4535 <class 'str'>\n",
      "1015 <class 'str'>\n",
      "6466 <class 'str'>\n",
      "1151 <class 'str'>\n",
      "1895 <class 'str'>\n",
      "6337 <class 'str'>\n",
      "3275 <class 'str'>\n",
      "1481 <class 'str'>\n",
      "1032 <class 'str'>\n",
      "3611 <class 'str'>\n",
      "5509 <class 'str'>\n",
      "23 <class 'str'>\n",
      "32 <class 'str'>\n",
      "5678 <class 'str'>\n",
      "34 <class 'str'>\n",
      "2705 <class 'str'>\n",
      "749 <class 'str'>\n",
      "4148 <class 'str'>\n",
      "7272 <class 'str'>\n",
      "2552 <class 'str'>\n",
      "1508 <class 'str'>\n",
      "1919 <class 'str'>\n",
      "3239 <class 'str'>\n",
      "5848 <class 'str'>\n",
      "16 <class 'str'>\n",
      "1642 <class 'str'>\n",
      "831 <class 'str'>\n",
      "1563 <class 'str'>\n",
      "6038 <class 'str'>\n",
      "6002 <class 'str'>\n",
      "259 <class 'str'>\n",
      "606 <class 'str'>\n",
      "3585 <class 'str'>\n",
      "2064 <class 'str'>\n",
      "474 <class 'str'>\n",
      "3686 <class 'str'>\n",
      "3985 <class 'str'>\n",
      "140 <class 'str'>\n",
      "85 <class 'str'>\n",
      "6085 <class 'str'>\n",
      "113 <class 'str'>\n",
      "2065 <class 'str'>\n",
      "2163 <class 'str'>\n",
      "2342 <class 'str'>\n",
      "3041 <class 'str'>\n",
      "3829 <class 'str'>\n",
      "2208 <class 'str'>\n",
      "2869 <class 'str'>\n",
      "46 <class 'str'>\n",
      "969 <class 'str'>\n",
      "1974 <class 'str'>\n",
      "2036 <class 'str'>\n",
      "4179 <class 'str'>\n",
      "4052 <class 'str'>\n",
      "2127 <class 'str'>\n",
      "4808 <class 'str'>\n",
      "2154 <class 'str'>\n",
      "3873 <class 'str'>\n",
      "5109 <class 'str'>\n",
      "3426 <class 'str'>\n",
      "6920 <class 'str'>\n",
      "2591 <class 'str'>\n",
      "2077 <class 'str'>\n",
      "2813 <class 'str'>\n",
      "1609 <class 'str'>\n",
      "4207 <class 'str'>\n",
      "378 <class 'str'>\n",
      "350 <class 'str'>\n",
      "1833 <class 'str'>\n",
      "1148 <class 'str'>\n",
      "3871 <class 'str'>\n",
      "662 <class 'str'>\n",
      "706 <class 'str'>\n",
      "3568 <class 'str'>\n",
      "4357 <class 'str'>\n",
      "2563 <class 'str'>\n",
      "373 <class 'str'>\n",
      "3673 <class 'str'>\n",
      "2054 <class 'str'>\n",
      "2310 <class 'str'>\n",
      "7387 <class 'str'>\n",
      "2715 <class 'str'>\n",
      "1964 <class 'str'>\n",
      "5731 <class 'str'>\n",
      "1713 <class 'str'>\n",
      "5011 <class 'str'>\n",
      "192 <class 'str'>\n",
      "1766 <class 'str'>\n",
      "4381 <class 'str'>\n",
      "128 <class 'str'>\n",
      "787 <class 'str'>\n",
      "1045 <class 'str'>\n",
      "4676 <class 'str'>\n",
      "256 <class 'str'>\n",
      "1244 <class 'str'>\n",
      "1620 <class 'str'>\n",
      "5757 <class 'str'>\n",
      "2722 <class 'str'>\n",
      "341 <class 'str'>\n",
      "6303 <class 'str'>\n",
      "2017 <class 'str'>\n",
      "225 <class 'str'>\n",
      "1506 <class 'str'>\n",
      "1992 <class 'str'>\n",
      "7773 <class 'str'>\n",
      "1451 <class 'str'>\n",
      "3586 <class 'str'>\n",
      "5502 <class 'str'>\n",
      "5133 <class 'str'>\n",
      "3003 <class 'str'>\n",
      "1827 <class 'str'>\n",
      "3894 <class 'str'>\n",
      "4528 <class 'str'>\n",
      "3301 <class 'str'>\n",
      "153 <class 'str'>\n",
      "3068 <class 'str'>\n",
      "1382 <class 'str'>\n",
      "3244 <class 'str'>\n",
      "263 <class 'str'>\n",
      "769 <class 'str'>\n",
      "2111 <class 'str'>\n",
      "6381 <class 'str'>\n",
      "2664 <class 'str'>\n",
      "3866 <class 'str'>\n",
      "573 <class 'str'>\n",
      "2796 <class 'str'>\n",
      "3040 <class 'str'>\n",
      "1190 <class 'str'>\n",
      "580 <class 'str'>\n",
      "4970 <class 'str'>\n",
      "2346 <class 'str'>\n",
      "5367 <class 'str'>\n",
      "3028 <class 'str'>\n",
      "1757 <class 'str'>\n",
      "1058 <class 'str'>\n",
      "1603 <class 'str'>\n",
      "4607 <class 'str'>\n",
      "2215 <class 'str'>\n",
      "4225 <class 'str'>\n",
      "2763 <class 'str'>\n",
      "76 <class 'str'>\n",
      "1212 <class 'str'>\n",
      "1785 <class 'str'>\n",
      "4523 <class 'str'>\n",
      "2949 <class 'str'>\n",
      "4510 <class 'str'>\n",
      "3979 <class 'str'>\n",
      "957 <class 'str'>\n",
      "6057 <class 'str'>\n",
      "2589 <class 'str'>\n",
      "4133 <class 'str'>\n",
      "2533 <class 'str'>\n",
      "3803 <class 'str'>\n",
      "91 <class 'str'>\n",
      "3754 <class 'str'>\n",
      "1551 <class 'str'>\n",
      "4218 <class 'str'>\n",
      "1466 <class 'str'>\n",
      "3140 <class 'str'>\n",
      "3515 <class 'str'>\n",
      "813 <class 'str'>\n",
      "21 <class 'str'>\n",
      "5025 <class 'str'>\n",
      "3111 <class 'str'>\n",
      "1196 <class 'str'>\n",
      "1106 <class 'str'>\n",
      "5623 <class 'str'>\n",
      "7120 <class 'str'>\n",
      "7965 <class 'str'>\n",
      "1401 <class 'str'>\n",
      "1947 <class 'str'>\n",
      "1040 <class 'str'>\n",
      "304 <class 'str'>\n",
      "4506 <class 'str'>\n",
      "555 <class 'str'>\n",
      "3219 <class 'str'>\n",
      "3999 <class 'str'>\n",
      "695 <class 'str'>\n",
      "6307 <class 'str'>\n",
      "7339 <class 'str'>\n",
      "2824 <class 'str'>\n",
      "2424 <class 'str'>\n",
      "2525 <class 'str'>\n",
      "6264 <class 'str'>\n",
      "6946 <class 'str'>\n",
      "1476 <class 'str'>\n",
      "509 <class 'str'>\n",
      "6566 <class 'str'>\n",
      "3109 <class 'str'>\n",
      "3160 <class 'str'>\n",
      "308 <class 'str'>\n",
      "1373 <class 'str'>\n",
      "7223 <class 'str'>\n",
      "1945 <class 'str'>\n",
      "272 <class 'str'>\n",
      "2966 <class 'str'>\n",
      "5978 <class 'str'>\n",
      "52 <class 'str'>\n",
      "238 <class 'str'>\n",
      "2475 <class 'str'>\n",
      "3942 <class 'str'>\n",
      "248 <class 'str'>\n",
      "1835 <class 'str'>\n",
      "1198 <class 'str'>\n",
      "2059 <class 'str'>\n",
      "3704 <class 'str'>\n",
      "755 <class 'str'>\n",
      "725 <class 'str'>\n",
      "1658 <class 'str'>\n",
      "3891 <class 'str'>\n",
      "2961 <class 'str'>\n",
      "143 <class 'str'>\n",
      "415 <class 'str'>\n",
      "3630 <class 'str'>\n",
      "3362 <class 'str'>\n",
      "2194 <class 'str'>\n",
      "3067 <class 'str'>\n",
      "2073 <class 'str'>\n",
      "5733 <class 'str'>\n",
      "3077 <class 'str'>\n",
      "2418 <class 'str'>\n",
      "3211 <class 'str'>\n",
      "4630 <class 'str'>\n",
      "3857 <class 'str'>\n",
      "4178 <class 'str'>\n",
      "544 <class 'str'>\n",
      "1018 <class 'str'>\n",
      "3563 <class 'str'>\n",
      "644 <class 'str'>\n",
      "1375 <class 'str'>\n",
      "2349 <class 'str'>\n",
      "3810 <class 'str'>\n",
      "3088 <class 'str'>\n",
      "447 <class 'str'>\n",
      "3597 <class 'str'>\n",
      "3246 <class 'str'>\n",
      "4119 <class 'str'>\n",
      "2767 <class 'str'>\n",
      "4378 <class 'str'>\n",
      "933 <class 'str'>\n",
      "2725 <class 'str'>\n",
      "4307 <class 'str'>\n",
      "4786 <class 'str'>\n",
      "3519 <class 'str'>\n",
      "1578 <class 'str'>\n",
      "1920 <class 'str'>\n",
      "1120 <class 'str'>\n",
      "1281 <class 'str'>\n",
      "3083 <class 'str'>\n",
      "397 <class 'str'>\n",
      "6939 <class 'str'>\n",
      "176 <class 'str'>\n",
      "6455 <class 'str'>\n",
      "1763 <class 'str'>\n",
      "5282 <class 'str'>\n",
      "2224 <class 'str'>\n",
      "4350 <class 'str'>\n",
      "2932 <class 'str'>\n",
      "552 <class 'str'>\n",
      "6472 <class 'str'>\n",
      "2922 <class 'str'>\n",
      "497 <class 'str'>\n",
      "109 <class 'str'>\n",
      "943 <class 'str'>\n",
      "4451 <class 'str'>\n",
      "3911 <class 'str'>\n",
      "2730 <class 'str'>\n",
      "4845 <class 'str'>\n",
      "4097 <class 'str'>\n",
      "764 <class 'str'>\n",
      "5334 <class 'str'>\n",
      "5504 <class 'str'>\n",
      "1958 <class 'str'>\n",
      "1673 <class 'str'>\n",
      "654 <class 'str'>\n",
      "66 <class 'str'>\n",
      "910 <class 'str'>\n",
      "2797 <class 'str'>\n",
      "2541 <class 'str'>\n",
      "1694 <class 'str'>\n",
      "5662 <class 'str'>\n",
      "3643 <class 'str'>\n",
      "1211 <class 'str'>\n",
      "4192 <class 'str'>\n",
      "6476 <class 'str'>\n",
      "3434 <class 'str'>\n",
      "5433 <class 'str'>\n",
      "172 <class 'str'>\n",
      "2618 <class 'str'>\n",
      "796 <class 'str'>\n",
      "3852 <class 'str'>\n",
      "2630 <class 'str'>\n",
      "339 <class 'str'>\n",
      "2583 <class 'str'>\n",
      "4770 <class 'str'>\n",
      "694 <class 'str'>\n",
      "944 <class 'str'>\n",
      "2045 <class 'str'>\n",
      "2417 <class 'str'>\n",
      "3042 <class 'str'>\n",
      "2202 <class 'str'>\n",
      "1871 <class 'str'>\n",
      "5187 <class 'str'>\n",
      "4406 <class 'str'>\n",
      "485 <class 'str'>\n",
      "6235 <class 'str'>\n",
      "847 <class 'str'>\n",
      "3494 <class 'str'>\n",
      "2297 <class 'str'>\n",
      "1519 <class 'str'>\n",
      "3888 <class 'str'>\n",
      "690 <class 'str'>\n",
      "3582 <class 'str'>\n",
      "5056 <class 'str'>\n",
      "2093 <class 'str'>\n",
      "597 <class 'str'>\n",
      "2241 <class 'str'>\n",
      "6283 <class 'str'>\n",
      "729 <class 'str'>\n",
      "2301 <class 'str'>\n",
      "3055 <class 'str'>\n",
      "905 <class 'str'>\n",
      "97 <class 'str'>\n",
      "3393 <class 'str'>\n",
      "952 <class 'str'>\n",
      "1553 <class 'str'>\n",
      "3464 <class 'str'>\n",
      "4997 <class 'str'>\n",
      "4883 <class 'str'>\n",
      "4161 <class 'str'>\n",
      "4840 <class 'str'>\n",
      "1501 <class 'str'>\n",
      "4763 <class 'str'>\n",
      "4723 <class 'str'>\n",
      "147 <class 'str'>\n",
      "4182 <class 'str'>\n",
      "782 <class 'str'>\n",
      "3955 <class 'str'>\n",
      "2986 <class 'str'>\n",
      "6110 <class 'str'>\n",
      "249 <class 'str'>\n",
      "1670 <class 'str'>\n",
      "6276 <class 'str'>\n",
      "2726 <class 'str'>\n",
      "3325 <class 'str'>\n",
      "590 <class 'str'>\n",
      "1350 <class 'str'>\n",
      "6163 <class 'str'>\n",
      "2872 <class 'str'>\n",
      "772 <class 'str'>\n",
      "2002 <class 'str'>\n",
      "417 <class 'str'>\n",
      "3086 <class 'str'>\n",
      "2503 <class 'str'>\n",
      "1121 <class 'str'>\n",
      "7730 <class 'str'>\n",
      "1083 <class 'str'>\n",
      "2102 <class 'str'>\n",
      "101 <class 'str'>\n",
      "1000 <class 'str'>\n",
      "2005 <class 'str'>\n",
      "1145 <class 'str'>\n",
      "6384 <class 'str'>\n",
      "4944 <class 'str'>\n",
      "1347 <class 'str'>\n",
      "146 <class 'str'>\n",
      "1002 <class 'str'>\n",
      "3823 <class 'str'>\n",
      "5029 <class 'str'>\n",
      "3766 <class 'str'>\n",
      "4019 <class 'str'>\n",
      "5121 <class 'str'>\n",
      "454 <class 'str'>\n",
      "1157 <class 'str'>\n",
      "3962 <class 'str'>\n",
      "4937 <class 'str'>\n",
      "3006 <class 'str'>\n",
      "1293 <class 'str'>\n",
      "1998 <class 'str'>\n",
      "4509 <class 'str'>\n",
      "3822 <class 'str'>\n",
      "6114 <class 'str'>\n",
      "1807 <class 'str'>\n",
      "6113 <class 'str'>\n",
      "4764 <class 'str'>\n",
      "2261 <class 'str'>\n",
      "2280 <class 'str'>\n",
      "1768 <class 'str'>\n",
      "3161 <class 'str'>\n",
      "770 <class 'str'>\n",
      "1796 <class 'str'>\n",
      "199 <class 'str'>\n",
      "434 <class 'str'>\n",
      "2333 <class 'str'>\n",
      "3383 <class 'str'>\n",
      "1268 <class 'str'>\n",
      "1336 <class 'str'>\n",
      "4459 <class 'str'>\n",
      "7048 <class 'str'>\n",
      "1302 <class 'str'>\n",
      "1298 <class 'str'>\n",
      "726 <class 'str'>\n",
      "1009 <class 'str'>\n",
      "328 <class 'str'>\n",
      "2801 <class 'str'>\n",
      "812 <class 'str'>\n",
      "3649 <class 'str'>\n",
      "896 <class 'str'>\n",
      "1878 <class 'str'>\n",
      "7846 <class 'str'>\n",
      "1109 <class 'str'>\n",
      "5213 <class 'str'>\n",
      "3454 <class 'str'>\n",
      "1989 <class 'str'>\n",
      "4765 <class 'str'>\n",
      "1590 <class 'str'>\n",
      "2537 <class 'str'>\n",
      "4824 <class 'str'>\n",
      "7460 <class 'str'>\n",
      "5474 <class 'str'>\n",
      "7061 <class 'str'>\n",
      "2272 <class 'str'>\n",
      "4577 <class 'str'>\n",
      "1171 <class 'str'>\n",
      "601 <class 'str'>\n",
      "2394 <class 'str'>\n",
      "1304 <class 'str'>\n",
      "2026 <class 'str'>\n",
      "3705 <class 'str'>\n",
      "3191 <class 'str'>\n",
      "2560 <class 'str'>\n",
      "3655 <class 'str'>\n",
      "3672 <class 'str'>\n",
      "638 <class 'str'>\n",
      "7841 <class 'str'>\n",
      "352 <class 'str'>\n",
      "3674 <class 'str'>\n",
      "108 <class 'str'>\n",
      "2352 <class 'str'>\n",
      "2484 <class 'str'>\n",
      "5358 <class 'str'>\n",
      "3120 <class 'str'>\n",
      "1096 <class 'str'>\n",
      "2369 <class 'str'>\n",
      "2345 <class 'str'>\n",
      "6279 <class 'str'>\n",
      "481 <class 'str'>\n",
      "2205 <class 'str'>\n",
      "2190 <class 'str'>\n",
      "1098 <class 'str'>\n",
      "542 <class 'str'>\n",
      "4568 <class 'str'>\n",
      "5627 <class 'str'>\n",
      "948 <class 'str'>\n",
      "5515 <class 'str'>\n",
      "927 <class 'str'>\n",
      "951 <class 'str'>\n",
      "1638 <class 'str'>\n",
      "71 <class 'str'>\n",
      "668 <class 'str'>\n",
      "2546 <class 'str'>\n",
      "6165 <class 'str'>\n",
      "11 <class 'str'>\n",
      "360 <class 'str'>\n",
      "3190 <class 'str'>\n",
      "385 <class 'str'>\n",
      "709 <class 'str'>\n",
      "3273 <class 'str'>\n",
      "4468 <class 'str'>\n",
      "252 <class 'str'>\n",
      "4502 <class 'str'>\n",
      "7011 <class 'str'>\n",
      "305 <class 'str'>\n",
      "1127 <class 'str'>\n",
      "5551 <class 'str'>\n",
      "1968 <class 'str'>\n",
      "2289 <class 'str'>\n",
      "1741 <class 'str'>\n",
      "2029 <class 'str'>\n",
      "869 <class 'str'>\n",
      "1027 <class 'str'>\n",
      "1755 <class 'str'>\n",
      "1253 <class 'str'>\n",
      "828 <class 'str'>\n",
      "3461 <class 'str'>\n",
      "2243 <class 'str'>\n",
      "3727 <class 'str'>\n",
      "317 <class 'str'>\n",
      "4617 <class 'str'>\n",
      "1924 <class 'str'>\n",
      "1287 <class 'str'>\n",
      "59 <class 'str'>\n",
      "222 <class 'str'>\n",
      "519 <class 'str'>\n",
      "1610 <class 'str'>\n",
      "1318 <class 'str'>\n",
      "1803 <class 'str'>\n",
      "4566 <class 'str'>\n",
      "337 <class 'str'>\n",
      "2857 <class 'str'>\n",
      "4690 <class 'str'>\n",
      "1062 <class 'str'>\n",
      "3457 <class 'str'>\n",
      "2024 <class 'str'>\n",
      "792 <class 'str'>\n",
      "3000 <class 'str'>\n",
      "1128 <class 'str'>\n",
      "2037 <class 'str'>\n",
      "2951 <class 'str'>\n",
      "685 <class 'str'>\n",
      "2055 <class 'str'>\n",
      "8 <class 'str'>\n",
      "3794 <class 'str'>\n",
      "6976 <class 'str'>\n",
      "1436 <class 'str'>\n",
      "7349 <class 'str'>\n",
      "5126 <class 'str'>\n",
      "5322 <class 'str'>\n",
      "2318 <class 'str'>\n",
      "929 <class 'str'>\n",
      "1277 <class 'str'>\n",
      "1778 <class 'str'>\n",
      "6836 <class 'str'>\n",
      "5112 <class 'str'>\n",
      "1492 <class 'str'>\n",
      "577 <class 'str'>\n",
      "2441 <class 'str'>\n",
      "3864 <class 'str'>\n",
      "3318 <class 'str'>\n",
      "2800 <class 'str'>\n",
      "504 <class 'str'>\n",
      "2283 <class 'str'>\n",
      "528 <class 'str'>\n",
      "2011 <class 'str'>\n",
      "1051 <class 'str'>\n",
      "1180 <class 'str'>\n",
      "5799 <class 'str'>\n",
      "416 <class 'str'>\n",
      "3832 <class 'str'>\n",
      "4463 <class 'str'>\n",
      "4348 <class 'str'>\n",
      "3127 <class 'str'>\n",
      "2434 <class 'str'>\n",
      "5901 <class 'str'>\n",
      "3839 <class 'str'>\n",
      "2244 <class 'str'>\n",
      "1223 <class 'str'>\n",
      "5108 <class 'str'>\n",
      "2625 <class 'str'>\n",
      "17 <class 'str'>\n",
      "752 <class 'str'>\n",
      "3699 <class 'str'>\n",
      "6135 <class 'str'>\n",
      "2644 <class 'str'>\n",
      "858 <class 'str'>\n",
      "4491 <class 'str'>\n",
      "2263 <class 'str'>\n",
      "2251 <class 'str'>\n",
      "2833 <class 'str'>\n",
      "4054 <class 'str'>\n",
      "3095 <class 'str'>\n",
      "904 <class 'str'>\n",
      "250 <class 'str'>\n",
      "2710 <class 'str'>\n",
      "4771 <class 'str'>\n",
      "3475 <class 'str'>\n",
      "5942 <class 'str'>\n",
      "1598 <class 'str'>\n",
      "300 <class 'str'>\n",
      "5535 <class 'str'>\n",
      "1049 <class 'str'>\n",
      "3992 <class 'str'>\n",
      "3676 <class 'str'>\n",
      "258 <class 'str'>\n",
      "5231 <class 'str'>\n",
      "1544 <class 'str'>\n",
      "358 <class 'str'>\n",
      "3330 <class 'str'>\n",
      "2083 <class 'str'>\n",
      "4531 <class 'str'>\n",
      "7421 <class 'str'>\n",
      "3007 <class 'str'>\n",
      "326 <class 'str'>\n",
      "851 <class 'str'>\n",
      "5950 <class 'str'>\n",
      "2777 <class 'str'>\n",
      "642 <class 'str'>\n",
      "3844 <class 'str'>\n",
      "1950 <class 'str'>\n",
      "448 <class 'str'>\n",
      "4493 <class 'str'>\n",
      "5379 <class 'str'>\n",
      "5447 <class 'str'>\n",
      "1979 <class 'str'>\n",
      "6962 <class 'str'>\n",
      "3149 <class 'str'>\n",
      "1222 <class 'str'>\n",
      "4026 <class 'str'>\n",
      "2232 <class 'str'>\n",
      "3986 <class 'str'>\n",
      "5743 <class 'str'>\n",
      "1903 <class 'str'>\n",
      "1831 <class 'str'>\n",
      "2275 <class 'str'>\n",
      "3925 <class 'str'>\n",
      "213 <class 'str'>\n",
      "207 <class 'str'>\n",
      "4080 <class 'str'>\n",
      "1004 <class 'str'>\n",
      "239 <class 'str'>\n",
      "2571 <class 'str'>\n",
      "2476 <class 'str'>\n",
      "1911 <class 'str'>\n",
      "1036 <class 'str'>\n",
      "757 <class 'str'>\n",
      "1052 <class 'str'>\n",
      "919 <class 'str'>\n",
      "3453 <class 'str'>\n",
      "3122 <class 'str'>\n",
      "4116 <class 'str'>\n",
      "1113 <class 'str'>\n",
      "1269 <class 'str'>\n",
      "6608 <class 'str'>\n",
      "375 <class 'str'>\n",
      "2712 <class 'str'>\n",
      "4250 <class 'str'>\n",
      "4570 <class 'str'>\n",
      "3400 <class 'str'>\n",
      "1089 <class 'str'>\n",
      "2156 <class 'str'>\n",
      "1943 <class 'str'>\n",
      "3849 <class 'str'>\n",
      "1527 <class 'str'>\n",
      "2170 <class 'str'>\n",
      "4802 <class 'str'>\n",
      "4730 <class 'str'>\n",
      "4704 <class 'str'>\n",
      "1078 <class 'str'>\n",
      "2577 <class 'str'>\n",
      "2864 <class 'str'>\n",
      "389 <class 'str'>\n",
      "3750 <class 'str'>\n",
      "60 <class 'str'>\n",
      "1340 <class 'str'>\n",
      "6 <class 'str'>\n",
      "718 <class 'str'>\n",
      "214 <class 'str'>\n",
      "806 <class 'str'>\n",
      "3650 <class 'str'>\n",
      "1299 <class 'str'>\n",
      "5780 <class 'str'>\n",
      "2772 <class 'str'>\n",
      "4029 <class 'str'>\n",
      "5821 <class 'str'>\n",
      "7563 <class 'str'>\n",
      "2927 <class 'str'>\n",
      "461 <class 'str'>\n",
      "6129 <class 'str'>\n",
      "93 <class 'str'>\n",
      "3142 <class 'str'>\n",
      "1748 <class 'str'>\n",
      "264 <class 'str'>\n",
      "6120 <class 'str'>\n",
      "2483 <class 'str'>\n",
      "766 <class 'str'>\n",
      "2840 <class 'str'>\n",
      "1632 <class 'str'>\n",
      "4008 <class 'str'>\n",
      "1445 <class 'str'>\n",
      "1799 <class 'str'>\n",
      "1556 <class 'str'>\n",
      "3569 <class 'str'>\n",
      "2520 <class 'str'>\n",
      "5552 <class 'str'>\n",
      "2646 <class 'str'>\n",
      "24 <class 'str'>\n",
      "4751 <class 'str'>\n",
      "1851 <class 'str'>\n",
      "3761 <class 'str'>\n",
      "5609 <class 'str'>\n",
      "2407 <class 'str'>\n",
      "5595 <class 'str'>\n",
      "6929 <class 'str'>\n",
      "4286 <class 'str'>\n",
      "4455 <class 'str'>\n",
      "6548 <class 'str'>\n",
      "465 <class 'str'>\n",
      "4954 <class 'str'>\n",
      "3309 <class 'str'>\n",
      "4352 <class 'str'>\n",
      "5233 <class 'str'>\n",
      "2683 <class 'str'>\n",
      "2572 <class 'str'>\n",
      "3467 <class 'str'>\n",
      "4822 <class 'str'>\n",
      "1439 <class 'str'>\n",
      "4212 <class 'str'>\n",
      "6087 <class 'str'>\n",
      "6239 <class 'str'>\n",
      "394 <class 'str'>\n",
      "689 <class 'str'>\n",
      "359 <class 'str'>\n",
      "47 <class 'str'>\n",
      "440 <class 'str'>\n",
      "2998 <class 'str'>\n",
      "4066 <class 'str'>\n",
      "3290 <class 'str'>\n",
      "3128 <class 'str'>\n",
      "5096 <class 'str'>\n",
      "489 <class 'str'>\n",
      "2401 <class 'str'>\n",
      "5357 <class 'str'>\n",
      "4947 <class 'str'>\n",
      "3495 <class 'str'>\n",
      "6533 <class 'str'>\n",
      "934 <class 'str'>\n",
      "3027 <class 'str'>\n",
      "1261 <class 'str'>\n",
      "3370 <class 'str'>\n",
      "2728 <class 'str'>\n",
      "193 <class 'str'>\n",
      "4213 <class 'str'>\n",
      "1272 <class 'str'>\n",
      "7871 <class 'str'>\n",
      "5120 <class 'str'>\n",
      "2720 <class 'str'>\n",
      "2012 <class 'str'>\n",
      "1038 <class 'str'>\n",
      "2501 <class 'str'>\n",
      "457 <class 'str'>\n",
      "1484 <class 'str'>\n",
      "4699 <class 'str'>\n",
      "6019 <class 'str'>\n",
      "3081 <class 'str'>\n",
      "2035 <class 'str'>\n",
      "8040 <class 'str'>\n",
      "645 <class 'str'>\n",
      "1564 <class 'str'>\n",
      "4561 <class 'str'>\n",
      "1349 <class 'str'>\n",
      "6579 <class 'str'>\n",
      "856 <class 'str'>\n",
      "323 <class 'str'>\n",
      "1042 <class 'str'>\n",
      "4613 <class 'str'>\n",
      "1637 <class 'str'>\n",
      "1276 <class 'str'>\n",
      "1538 <class 'str'>\n",
      "1580 <class 'str'>\n",
      "7396 <class 'str'>\n",
      "102 <class 'str'>\n",
      "994 <class 'str'>\n",
      "2528 <class 'str'>\n",
      "4186 <class 'str'>\n",
      "4464 <class 'str'>\n",
      "1021 <class 'str'>\n",
      "2564 <class 'str'>\n",
      "2403 <class 'str'>\n",
      "2975 <class 'str'>\n",
      "1775 <class 'str'>\n",
      "6411 <class 'str'>\n",
      "3958 <class 'str'>\n",
      "891 <class 'str'>\n",
      "3375 <class 'str'>\n",
      "166 <class 'str'>\n",
      "3603 <class 'str'>\n",
      "4137 <class 'str'>\n",
      "1292 <class 'str'>\n",
      "3146 <class 'str'>\n",
      "1526 <class 'str'>\n",
      "1828 <class 'str'>\n",
      "2067 <class 'str'>\n",
      "3527 <class 'str'>\n",
      "5188 <class 'str'>\n",
      "3024 <class 'str'>\n",
      "2626 <class 'str'>\n",
      "1703 <class 'str'>\n",
      "1513 <class 'str'>\n",
      "7399 <class 'str'>\n",
      "1973 <class 'str'>\n",
      "1428 <class 'str'>\n",
      "921 <class 'str'>\n",
      "1447 <class 'str'>\n",
      "2842 <class 'str'>\n",
      "4107 <class 'str'>\n",
      "4191 <class 'str'>\n",
      "2060 <class 'str'>\n",
      "2650 <class 'str'>\n",
      "233 <class 'str'>\n",
      "6361 <class 'str'>\n",
      "98 <class 'str'>\n",
      "5417 <class 'str'>\n",
      "2491 <class 'str'>\n",
      "3912 <class 'str'>\n",
      "4889 <class 'str'>\n",
      "2245 <class 'str'>\n",
      "1727 <class 'str'>\n",
      "4418 <class 'str'>\n",
      "1231 <class 'str'>\n",
      "1159 <class 'str'>\n",
      "3821 <class 'str'>\n",
      "3661 <class 'str'>\n",
      "4791 <class 'str'>\n",
      "2830 <class 'str'>\n",
      "3021 <class 'str'>\n",
      "2255 <class 'str'>\n",
      "3550 <class 'str'>\n",
      "558 <class 'str'>\n",
      "4518 <class 'str'>\n",
      "2132 <class 'str'>\n",
      "681 <class 'str'>\n",
      "5327 <class 'str'>\n",
      "6489 <class 'str'>\n",
      "2379 <class 'str'>\n",
      "4045 <class 'str'>\n",
      "1191 <class 'str'>\n",
      "145 <class 'str'>\n",
      "6328 <class 'str'>\n",
      "1589 <class 'str'>\n",
      "2146 <class 'str'>\n",
      "7631 <class 'str'>\n",
      "4291 <class 'str'>\n",
      "3465 <class 'str'>\n",
      "5421 <class 'str'>\n",
      "1338 <class 'str'>\n",
      "2072 <class 'str'>\n",
      "5557 <class 'str'>\n",
      "1256 <class 'str'>\n",
      "2389 <class 'str'>\n",
      "2100 <class 'str'>\n",
      "1691 <class 'str'>\n",
      "6251 <class 'str'>\n",
      "420 <class 'str'>\n",
      "57 <class 'str'>\n",
      "3192 <class 'str'>\n",
      "1301 <class 'str'>\n",
      "5420 <class 'str'>\n",
      "3736 <class 'str'>\n",
      "118 <class 'str'>\n",
      "4333 <class 'str'>\n",
      "318 <class 'str'>\n",
      "2217 <class 'str'>\n",
      "3283 <class 'str'>\n",
      "2299 <class 'str'>\n",
      "5240 <class 'str'>\n",
      "737 <class 'str'>\n",
      "3652 <class 'str'>\n",
      "1953 <class 'str'>\n",
      "4571 <class 'str'>\n",
      "309 <class 'str'>\n",
      "4955 <class 'str'>\n",
      "2923 <class 'str'>\n",
      "2602 <class 'str'>\n",
      "1458 <class 'str'>\n",
      "2311 <class 'str'>\n",
      "5296 <class 'str'>\n",
      "1814 <class 'str'>\n",
      "2466 <class 'str'>\n",
      "1825 <class 'str'>\n",
      "3085 <class 'str'>\n",
      "5658 <class 'str'>\n",
      "2482 <class 'str'>\n",
      "411 <class 'str'>\n",
      "1404 <class 'str'>\n",
      "1115 <class 'str'>\n",
      "1854 <class 'str'>\n",
      "4499 <class 'str'>\n",
      "6011 <class 'str'>\n",
      "3836 <class 'str'>\n",
      "278 <class 'str'>\n",
      "4073 <class 'str'>\n",
      "5988 <class 'str'>\n",
      "4261 <class 'str'>\n",
      "292 <class 'str'>\n",
      "4874 <class 'str'>\n",
      "4391 <class 'str'>\n",
      "1168 <class 'str'>\n",
      "4326 <class 'str'>\n",
      "262 <class 'str'>\n",
      "2962 <class 'str'>\n",
      "7765 <class 'str'>\n",
      "2147 <class 'str'>\n",
      "5814 <class 'str'>\n",
      "2978 <class 'str'>\n",
      "3270 <class 'str'>\n",
      "77 <class 'str'>\n",
      "3624 <class 'str'>\n",
      "1197 <class 'str'>\n",
      "116 <class 'str'>\n",
      "2651 <class 'str'>\n",
      "2400 <class 'str'>\n",
      "3780 <class 'str'>\n",
      "2274 <class 'str'>\n",
      "1478 <class 'str'>\n",
      "5219 <class 'str'>\n",
      "1929 <class 'str'>\n",
      "3862 <class 'str'>\n",
      "4639 <class 'str'>\n",
      "7720 <class 'str'>\n",
      "1846 <class 'str'>\n",
      "4134 <class 'str'>\n",
      "3601 <class 'str'>\n",
      "1790 <class 'str'>\n",
      "710 <class 'str'>\n",
      "217 <class 'str'>\n",
      "7594 <class 'str'>\n",
      "3057 <class 'str'>\n",
      "6527 <class 'str'>\n",
      "3254 <class 'str'>\n",
      "5647 <class 'str'>\n",
      "4846 <class 'str'>\n",
      "1980 <class 'str'>\n",
      "2791 <class 'str'>\n",
      "2596 <class 'str'>\n",
      "1860 <class 'str'>\n",
      "3638 <class 'str'>\n",
      "2032 <class 'str'>\n",
      "2201 <class 'str'>\n",
      "3023 <class 'str'>\n",
      "2027 <class 'str'>\n",
      "700 <class 'str'>\n",
      "4928 <class 'str'>\n",
      "4040 <class 'str'>\n",
      "1353 <class 'str'>\n",
      "4727 <class 'str'>\n",
      "2504 <class 'str'>\n",
      "136 <class 'str'>\n",
      "3730 <class 'str'>\n",
      "3576 <class 'str'>\n",
      "3547 <class 'str'>\n",
      "86 <class 'str'>\n",
      "3429 <class 'str'>\n",
      "2267 <class 'str'>\n",
      "2160 <class 'str'>\n",
      "1718 <class 'str'>\n",
      "631 <class 'str'>\n",
      "3274 <class 'str'>\n",
      "1368 <class 'str'>\n",
      "1454 <class 'str'>\n",
      "4438 <class 'str'>\n",
      "2458 <class 'str'>\n",
      "1962 <class 'str'>\n",
      "7427 <class 'str'>\n",
      "3359 <class 'str'>\n",
      "1208 <class 'str'>\n",
      "5652 <class 'str'>\n",
      "1676 <class 'str'>\n",
      "5862 <class 'str'>\n",
      "3690 <class 'str'>\n",
      "4024 <class 'str'>\n",
      "1123 <class 'str'>\n",
      "914 <class 'str'>\n",
      "2848 <class 'str'>\n",
      "2357 <class 'str'>\n",
      "3558 <class 'str'>\n",
      "280 <class 'str'>\n",
      "3929 <class 'str'>\n",
      "621 <class 'str'>\n",
      "7099 <class 'str'>\n",
      "7515 <class 'str'>\n",
      "1331 <class 'str'>\n",
      "2051 <class 'str'>\n",
      "478 <class 'str'>\n",
      "3817 <class 'str'>\n",
      "5558 <class 'str'>\n",
      "765 <class 'str'>\n",
      "6774 <class 'str'>\n",
      "571 <class 'str'>\n",
      "1687 <class 'str'>\n",
      "3194 <class 'str'>\n",
      "4866 <class 'str'>\n",
      "2531 <class 'str'>\n",
      "1899 <class 'str'>\n",
      "740 <class 'str'>\n",
      "1308 <class 'str'>\n",
      "7153 <class 'str'>\n",
      "1880 <class 'str'>\n",
      "6282 <class 'str'>\n",
      "19 <class 'str'>\n",
      "3181 <class 'str'>\n",
      "68 <class 'str'>\n",
      "2103 <class 'str'>\n",
      "1558 <class 'str'>\n",
      "2247 <class 'str'>\n",
      "5283 <class 'str'>\n",
      "3437 <class 'str'>\n",
      "1857 <class 'str'>\n",
      "4 <class 'str'>\n",
      "367 <class 'str'>\n",
      "800 <class 'str'>\n",
      "5342 <class 'str'>\n",
      "2943 <class 'str'>\n",
      "1937 <class 'str'>\n",
      "2315 <class 'str'>\n",
      "3369 <class 'str'>\n",
      "614 <class 'str'>\n",
      "2290 <class 'str'>\n",
      "6273 <class 'str'>\n",
      "2452 <class 'str'>\n",
      "3607 <class 'str'>\n",
      "2629 <class 'str'>\n",
      "517 <class 'str'>\n",
      "963 <class 'str'>\n",
      "2786 <class 'str'>\n",
      "2861 <class 'str'>\n",
      "1329 <class 'str'>\n",
      "637 <class 'str'>\n",
      "2487 <class 'str'>\n",
      "7184 <class 'str'>\n",
      "1440 <class 'str'>\n",
      "3310 <class 'str'>\n",
      "155 <class 'str'>\n",
      "406 <class 'str'>\n",
      "2338 <class 'str'>\n",
      "1259 <class 'str'>\n",
      "6973 <class 'str'>\n",
      "2384 <class 'str'>\n",
      "1007 <class 'str'>\n",
      "2042 <class 'str'>\n",
      "2323 <class 'str'>\n",
      "4196 <class 'str'>\n",
      "58 <class 'str'>\n",
      "3507 <class 'str'>\n",
      "1607 <class 'str'>\n",
      "5090 <class 'str'>\n",
      "4457 <class 'str'>\n",
      "3074 <class 'str'>\n",
      "1611 <class 'str'>\n",
      "1012 <class 'str'>\n",
      "4220 <class 'str'>\n",
      "1252 <class 'str'>\n",
      "1690 <class 'str'>\n",
      "2494 <class 'str'>\n",
      "1041 <class 'str'>\n",
      "3742 <class 'str'>\n",
      "3394 <class 'str'>\n",
      "4309 <class 'str'>\n",
      "5274 <class 'str'>\n",
      "1839 <class 'str'>\n",
      "6376 <class 'str'>\n",
      "734 <class 'str'>\n",
      "714 <class 'str'>\n",
      "1075 <class 'str'>\n",
      "65 <class 'str'>\n",
      "5278 <class 'str'>\n",
      "3747 <class 'str'>\n",
      "3450 <class 'str'>\n",
      "6571 <class 'str'>\n",
      "2303 <class 'str'>\n",
      "210 <class 'str'>\n",
      "2260 <class 'str'>\n",
      "5585 <class 'str'>\n",
      "551 <class 'str'>\n",
      "1599 <class 'str'>\n",
      "3339 <class 'str'>\n",
      "376 <class 'str'>\n",
      "1480 <class 'str'>\n",
      "7680 <class 'str'>\n",
      "3613 <class 'str'>\n",
      "3487 <class 'str'>\n",
      "2047 <class 'str'>\n",
      "3577 <class 'str'>\n",
      "491 <class 'str'>\n",
      "667 <class 'str'>\n",
      "3070 <class 'str'>\n",
      "2599 <class 'str'>\n",
      "3574 <class 'str'>\n",
      "1546 <class 'str'>\n",
      "1076 <class 'str'>\n",
      "2354 <class 'str'>\n",
      "1053 <class 'str'>\n",
      "5239 <class 'str'>\n",
      "3544 <class 'str'>\n",
      "7929 <class 'str'>\n",
      "4028 <class 'str'>\n",
      "1430 <class 'str'>\n",
      "2799 <class 'str'>\n",
      "2446 <class 'str'>\n",
      "149 <class 'str'>\n",
      "2162 <class 'str'>\n",
      "2514 <class 'str'>\n",
      "2174 <class 'str'>\n",
      "3965 <class 'str'>\n",
      "4035 <class 'str'>\n",
      "6182 <class 'str'>\n",
      "3170 <class 'str'>\n",
      "742 <class 'str'>\n",
      "1203 <class 'str'>\n",
      "4110 <class 'str'>\n",
      "2122 <class 'str'>\n",
      "2107 <class 'str'>\n",
      "3825 <class 'str'>\n",
      "3557 <class 'str'>\n",
      "5752 <class 'str'>\n",
      "4500 <class 'str'>\n",
      "1377 <class 'str'>\n",
      "4268 <class 'str'>\n",
      "4654 <class 'str'>\n",
      "2108 <class 'str'>\n",
      "4946 <class 'str'>\n",
      "61 <class 'str'>\n",
      "7045 <class 'str'>\n",
      "791 <class 'str'>\n",
      "703 <class 'str'>\n",
      "1907 <class 'str'>\n",
      "1797 <class 'str'>\n",
      "5293 <class 'str'>\n",
      "604 <class 'str'>\n",
      "4948 <class 'str'>\n",
      "4768 <class 'str'>\n",
      "3879 <class 'str'>\n",
      "1356 <class 'str'>\n",
      "3723 <class 'str'>\n",
      "2110 <class 'str'>\n",
      "2789 <class 'str'>\n",
      "4208 <class 'str'>\n",
      "1819 <class 'str'>\n",
      "5214 <class 'str'>\n",
      "414 <class 'str'>\n",
      "2187 <class 'str'>\n",
      "245 <class 'str'>\n",
      "7283 <class 'str'>\n",
      "4170 <class 'str'>\n",
      "1887 <class 'str'>\n",
      "3087 <class 'str'>\n",
      "1425 <class 'str'>\n",
      "1132 <class 'str'>\n",
      "895 <class 'str'>\n",
      "2013 <class 'str'>\n",
      "236 <class 'str'>\n",
      "1085 <class 'str'>\n",
      "4553 <class 'str'>\n",
      "1875 <class 'str'>\n",
      "1865 <class 'str'>\n",
      "4474 <class 'str'>\n",
      "1006 <class 'str'>\n",
      "5728 <class 'str'>\n",
      "368 <class 'str'>\n",
      "565 <class 'str'>\n",
      "2875 <class 'str'>\n",
      "4400 <class 'str'>\n",
      "4688 <class 'str'>\n",
      "926 <class 'str'>\n",
      "3213 <class 'str'>\n",
      "3212 <class 'str'>\n",
      "2046 <class 'str'>\n",
      "1379 <class 'str'>\n",
      "1594 <class 'str'>\n",
      "43 <class 'str'>\n",
      "724 <class 'str'>\n",
      "2642 <class 'str'>\n",
      "3311 <class 'str'>\n",
      "4907 <class 'str'>\n",
      "4144 <class 'str'>\n",
      "2871 <class 'str'>\n",
      "5018 <class 'str'>\n",
      "4836 <class 'str'>\n",
      "148 <class 'str'>\n",
      "3828 <class 'str'>\n",
      "883 <class 'str'>\n",
      "3102 <class 'str'>\n",
      "1010 <class 'str'>\n",
      "5871 <class 'str'>\n",
      "1294 <class 'str'>\n",
      "4431 <class 'str'>\n",
      "817 <class 'str'>\n",
      "458 <class 'str'>\n",
      "5839 <class 'str'>\n",
      "4033 <class 'str'>\n",
      "1354 <class 'str'>\n",
      "5563 <class 'str'>\n",
      "6760 <class 'str'>\n",
      "4949 <class 'str'>\n",
      "628 <class 'str'>\n",
      "3026 <class 'str'>\n",
      "5947 <class 'str'>\n",
      "15 <class 'str'>\n",
      "3892 <class 'str'>\n",
      "1539 <class 'str'>\n",
      "3583 <class 'str'>\n",
      "1471 <class 'str'>\n",
      "2088 <class 'str'>\n",
      "889 <class 'str'>\n",
      "191 <class 'str'>\n",
      "2287 <class 'str'>\n",
      "6196 <class 'str'>\n",
      "5966 <class 'str'>\n",
      "3719 <class 'str'>\n",
      "7226 <class 'str'>\n",
      "2609 <class 'str'>\n",
      "181 <class 'str'>\n",
      "313 <class 'str'>\n",
      "53 <class 'str'>\n",
      "2502 <class 'str'>\n",
      "1960 <class 'str'>\n",
      "269 <class 'str'>\n",
      "41 <class 'str'>\n",
      "579 <class 'str'>\n",
      "3388 <class 'str'>\n",
      "720 <class 'str'>\n",
      "716 <class 'str'>\n",
      "5269 <class 'str'>\n",
      "942 <class 'str'>\n",
      "6385 <class 'str'>\n",
      "2124 <class 'str'>\n",
      "4386 <class 'str'>\n",
      "3503 <class 'str'>\n",
      "4682 <class 'str'>\n",
      "1369 <class 'str'>\n",
      "5247 <class 'str'>\n",
      "3523 <class 'str'>\n",
      "382 <class 'str'>\n",
      "111 <class 'str'>\n",
      "170 <class 'str'>\n",
      "6364 <class 'str'>\n",
      "3470 <class 'str'>\n",
      "6357 <class 'str'>\n",
      "2884 <class 'str'>\n",
      "3757 <class 'str'>\n",
      "2882 <class 'str'>\n",
      "163 <class 'str'>\n",
      "4355 <class 'str'>\n",
      "3080 <class 'str'>\n",
      "5779 <class 'str'>\n",
      "3304 <class 'str'>\n",
      "2809 <class 'str'>\n",
      "6888 <class 'str'>\n",
      "5874 <class 'str'>\n",
      "674 <class 'str'>\n",
      "811 <class 'str'>\n",
      "1928 <class 'str'>\n",
      "2348 <class 'str'>\n",
      "6497 <class 'str'>\n",
      "276 <class 'str'>\n",
      "4887 <class 'str'>\n",
      "285 <class 'str'>\n",
      "4174 <class 'str'>\n",
      "5184 <class 'str'>\n",
      "3069 <class 'str'>\n",
      "5238 <class 'str'>\n",
      "4677 <class 'str'>\n",
      "1736 <class 'str'>\n",
      "6721 <class 'str'>\n",
      "730 <class 'str'>\n",
      "4532 <class 'str'>\n",
      "2568 <class 'str'>\n",
      "2519 <class 'str'>\n",
      "2717 <class 'str'>\n",
      "4536 <class 'str'>\n",
      "332 <class 'str'>\n",
      "2574 <class 'str'>\n",
      "2910 <class 'str'>\n",
      "536 <class 'str'>\n",
      "1784 <class 'str'>\n",
      "5083 <class 'str'>\n",
      "711 <class 'str'>\n",
      "2397 <class 'str'>\n",
      "4640 <class 'str'>\n",
      "2436 <class 'str'>\n",
      "981 <class 'str'>\n",
      "2805 <class 'str'>\n",
      "3877 <class 'str'>\n",
      "441 <class 'str'>\n",
      "6736 <class 'str'>\n",
      "1490 <class 'str'>\n",
      "54 <class 'str'>\n",
      "209 <class 'str'>\n",
      "2702 <class 'str'>\n",
      "4088 <class 'str'>\n",
      "2740 <class 'str'>\n",
      "6351 <class 'str'>\n",
      "2167 <class 'str'>\n",
      "266 <class 'str'>\n",
      "899 <class 'str'>\n",
      "4142 <class 'str'>\n",
      "90 <class 'str'>\n",
      "422 <class 'str'>\n",
      "12 <class 'str'>\n",
      "2507 <class 'str'>\n",
      "670 <class 'str'>\n",
      "6942 <class 'str'>\n",
      "1941 <class 'str'>\n",
      "4793 <class 'str'>\n",
      "684 <class 'str'>\n",
      "2957 <class 'str'>\n",
      "4371 <class 'str'>\n",
      "124 <class 'str'>\n",
      "1328 <class 'str'>\n",
      "521 <class 'str'>\n",
      "2450 <class 'str'>\n",
      "2687 <class 'str'>\n",
      "1386 <class 'str'>\n",
      "2846 <class 'str'>\n",
      "2149 <class 'str'>\n",
      "343 <class 'str'>\n",
      "2119 <class 'str'>\n",
      "4216 <class 'str'>\n",
      "4153 <class 'str'>\n",
      "1818 <class 'str'>\n",
      "5226 <class 'str'>\n",
      "4094 <class 'str'>\n",
      "5385 <class 'str'>\n",
      "5666 <class 'str'>\n",
      "408 <class 'str'>\n",
      "3345 <class 'str'>\n",
      "3943 <class 'str'>\n",
      "2690 <class 'str'>\n",
      "3826 <class 'str'>\n",
      "767 <class 'str'>\n",
      "1514 <class 'str'>\n",
      "3412 <class 'str'>\n",
      "1493 <class 'str'>\n",
      "2996 <class 'str'>\n",
      "4629 <class 'str'>\n",
      "591 <class 'str'>\n",
      "1348 <class 'str'>\n",
      "2915 <class 'str'>\n",
      "5451 <class 'str'>\n",
      "287 <class 'str'>\n",
      "620 <class 'str'>\n",
      "3267 <class 'str'>\n",
      "3895 <class 'str'>\n",
      "2316 <class 'str'>\n",
      "156 <class 'str'>\n",
      "1876 <class 'str'>\n",
      "3218 <class 'str'>\n",
      "4103 <class 'str'>\n",
      "5173 <class 'str'>\n",
      "2281 <class 'str'>\n",
      "3474 <class 'str'>\n",
      "2874 <class 'str'>\n",
      "1362 <class 'str'>\n",
      "1972 <class 'str'>\n",
      "5487 <class 'str'>\n",
      "424 <class 'str'>\n",
      "164 <class 'str'>\n",
      "1650 <class 'str'>\n",
      "6759 <class 'str'>\n",
      "2788 <class 'str'>\n",
      "1536 <class 'str'>\n",
      "3518 <class 'str'>\n",
      "3113 <class 'str'>\n",
      "3695 <class 'str'>\n",
      "5596 <class 'str'>\n",
      "4826 <class 'str'>\n",
      "223 <class 'str'>\n",
      "4882 <class 'str'>\n",
      "5398 <class 'str'>\n",
      "4067 <class 'str'>\n",
      "940 <class 'str'>\n",
      "7201 <class 'str'>\n",
      "708 <class 'str'>\n",
      "2723 <class 'str'>\n",
      "3842 <class 'str'>\n",
      "3422 <class 'str'>\n",
      "3665 <class 'str'>\n",
      "7942 <class 'str'>\n",
      "2471 <class 'str'>\n",
      "1443 <class 'str'>\n",
      "5425 <class 'str'>\n",
      "5234 <class 'str'>\n",
      "878 <class 'str'>\n",
      "6277 <class 'str'>\n",
      "1983 <class 'str'>\n",
      "3210 <class 'str'>\n",
      "3076 <class 'str'>\n",
      "4805 <class 'str'>\n",
      "3931 <class 'str'>\n",
      "5436 <class 'str'>\n",
      "3242 <class 'str'>\n",
      "1129 <class 'str'>\n",
      "4966 <class 'str'>\n",
      "1516 <class 'str'>\n",
      "7537 <class 'str'>\n",
      "3016 <class 'str'>\n",
      "1586 <class 'str'>\n",
      "1627 <class 'str'>\n",
      "1069 <class 'str'>\n",
      "6491 <class 'str'>\n",
      "3409 <class 'str'>\n",
      "270 <class 'str'>\n",
      "7561 <class 'str'>\n",
      "1247 <class 'str'>\n",
      "3327 <class 'str'>\n",
      "984 <class 'str'>\n",
      "4635 <class 'str'>\n",
      "5053 <class 'str'>\n",
      "897 <class 'str'>\n",
      "3129 <class 'str'>\n",
      "2421 <class 'str'>\n",
      "3675 <class 'str'>\n",
      "4600 <class 'str'>\n",
      "1905 <class 'str'>\n",
      "946 <class 'str'>\n",
      "2907 <class 'str'>\n",
      "1091 <class 'str'>\n",
      "2641 <class 'str'>\n",
      "1364 <class 'str'>\n",
      "1922 <class 'str'>\n",
      "954 <class 'str'>\n",
      "5009 <class 'str'>\n",
      "2916 <class 'str'>\n",
      "3548 <class 'str'>\n",
      "1068 <class 'str'>\n",
      "2414 <class 'str'>\n",
      "6594 <class 'str'>\n",
      "5245 <class 'str'>\n",
      "956 <class 'str'>\n",
      "307 <class 'str'>\n",
      "2820 <class 'str'>\n",
      "3473 <class 'str'>\n",
      "254 <class 'str'>\n",
      "991 <class 'str'>\n",
      "1416 <class 'str'>\n",
      "5127 <class 'str'>\n",
      "1260 <class 'str'>\n",
      "137 <class 'str'>\n",
      "2965 <class 'str'>\n",
      "1421 <class 'str'>\n",
      "112 <class 'str'>\n",
      "599 <class 'str'>\n",
      "1867 <class 'str'>\n",
      "1429 <class 'str'>\n",
      "3980 <class 'str'>\n",
      "3029 <class 'str'>\n",
      "6845 <class 'str'>\n",
      "1303 <class 'str'>\n",
      "4402 <class 'str'>\n",
      "1438 <class 'str'>\n",
      "576 <class 'str'>\n",
      "4684 <class 'str'>\n",
      "2628 <class 'str'>\n",
      "1230 <class 'str'>\n",
      "867 <class 'str'>\n",
      "425 <class 'str'>\n",
      "3277 <class 'str'>\n",
      "1731 <class 'str'>\n",
      "190 <class 'str'>\n",
      "3307 <class 'str'>\n",
      "2331 <class 'str'>\n",
      "7380 <class 'str'>\n",
      "333 <class 'str'>\n",
      "1307 <class 'str'>\n",
      "6899 <class 'str'>\n",
      "3225 <class 'str'>\n",
      "1788 <class 'str'>\n",
      "6783 <class 'str'>\n",
      "327 <class 'str'>\n",
      "1511 <class 'str'>\n",
      "4839 <class 'str'>\n",
      "633 <class 'str'>\n",
      "5851 <class 'str'>\n",
      "4200 <class 'str'>\n",
      "3522 <class 'str'>\n",
      "872 <class 'str'>\n",
      "1600 <class 'str'>\n",
      "3573 <class 'str'>\n",
      "1394 <class 'str'>\n",
      "204 <class 'str'>\n",
      "4823 <class 'str'>\n",
      "8014 <class 'str'>\n",
      "2527 <class 'str'>\n",
      "1205 <class 'str'>\n",
      "274 <class 'str'>\n",
      "935 <class 'str'>\n",
      "396 <class 'str'>\n",
      "4273 <class 'str'>\n",
      "5021 <class 'str'>\n",
      "2852 <class 'str'>\n",
      "2775 <class 'str'>\n",
      "2879 <class 'str'>\n",
      "1288 <class 'str'>\n",
      "4714 <class 'str'>\n",
      "5037 <class 'str'>\n",
      "28 <class 'str'>\n",
      "4237 <class 'str'>\n",
      "1499 <class 'str'>\n",
      "5926 <class 'str'>\n",
      "945 <class 'str'>\n",
      "1403 <class 'str'>\n",
      "3222 <class 'str'>\n",
      "3440 <class 'str'>\n",
      "5185 <class 'str'>\n",
      "727 <class 'str'>\n",
      "2656 <class 'str'>\n",
      "51 <class 'str'>\n",
      "496 <class 'str'>\n",
      "459 <class 'str'>\n",
      "6867 <class 'str'>\n",
      "5195 <class 'str'>\n",
      "2495 <class 'str'>\n",
      "629 <class 'str'>\n",
      "5353 <class 'str'>\n",
      "1525 <class 'str'>\n",
      "937 <class 'str'>\n",
      "5393 <class 'str'>\n",
      "6059 <class 'str'>\n",
      "2262 <class 'str'>\n",
      "3296 <class 'str'>\n",
      "3640 <class 'str'>\n",
      "2512 <class 'str'>\n",
      "2095 <class 'str'>\n",
      "673 <class 'str'>\n",
      "129 <class 'str'>\n",
      "4124 <class 'str'>\n",
      "345 <class 'str'>\n",
      "1639 <class 'str'>\n",
      "2569 <class 'str'>\n",
      "6710 <class 'str'>\n",
      "2817 <class 'str'>\n",
      "2753 <class 'str'>\n",
      "5157 <class 'str'>\n",
      "2075 <class 'str'>\n",
      "1522 <class 'str'>\n",
      "5350 <class 'str'>\n",
      "4164 <class 'str'>\n",
      "1427 <class 'str'>\n",
      "1092 <class 'str'>\n",
      "127 <class 'str'>\n",
      "1615 <class 'str'>\n",
      "1146 <class 'str'>\n",
      "5267 <class 'str'>\n",
      "1706 <class 'str'>\n",
      "3293 <class 'str'>\n",
      "409 <class 'str'>\n",
      "1158 <class 'str'>\n",
      "880 <class 'str'>\n",
      "1229 <class 'str'>\n",
      "2410 <class 'str'>\n",
      "453 <class 'str'>\n",
      "3145 <class 'str'>\n",
      "2898 <class 'str'>\n",
      "865 <class 'str'>\n",
      "2240 <class 'str'>\n",
      "1877 <class 'str'>\n",
      "6839 <class 'str'>\n",
      "1606 <class 'str'>\n",
      "3971 <class 'str'>\n",
      "1444 <class 'str'>\n",
      "1554 <class 'str'>\n",
      "1705 <class 'str'>\n",
      "5614 <class 'str'>\n",
      "2523 <class 'str'>\n",
      "761 <class 'str'>\n",
      "110 <class 'str'>\n",
      "3671 <class 'str'>\n",
      "4083 <class 'str'>\n",
      "4423 <class 'str'>\n",
      "1131 <class 'str'>\n",
      "2330 <class 'str'>\n",
      "315 <class 'str'>\n",
      "893 <class 'str'>\n",
      "840 <class 'str'>\n",
      "2773 <class 'str'>\n",
      "1764 <class 'str'>\n",
      "3632 <class 'str'>\n",
      "5690 <class 'str'>\n",
      "2858 <class 'str'>\n",
      "5005 <class 'str'>\n",
      "5140 <class 'str'>\n",
      "5674 <class 'str'>\n",
      "2518 <class 'str'>\n",
      "1426 <class 'str'>\n",
      "6316 <class 'str'>\n",
      "2382 <class 'str'>\n",
      "6299 <class 'str'>\n",
      "4982 <class 'str'>\n",
      "3623 <class 'str'>\n",
      "2265 <class 'str'>\n",
      "4283 <class 'str'>\n",
      "2607 <class 'str'>\n",
      "5759 <class 'str'>\n",
      "2322 <class 'str'>\n",
      "2472 <class 'str'>\n",
      "502 <class 'str'>\n",
      "480 <class 'str'>\n",
      "2911 <class 'str'>\n",
      "4038 <class 'str'>\n",
      "1916 <class 'str'>\n",
      "4185 <class 'str'>\n",
      "2459 <class 'str'>\n",
      "2020 <class 'str'>\n",
      "1734 <class 'str'>\n",
      "877 <class 'str'>\n",
      "2834 <class 'str'>\n",
      "5686 <class 'str'>\n",
      "3097 <class 'str'>\n",
      "2738 <class 'str'>\n",
      "3572 <class 'str'>\n",
      "2340 <class 'str'>\n",
      "2616 <class 'str'>\n",
      "4991 <class 'str'>\n",
      "1840 <class 'str'>\n",
      "6061 <class 'str'>\n",
      "1657 <class 'str'>\n",
      "1862 <class 'str'>\n",
      "3427 <class 'str'>\n",
      "6073 <class 'str'>\n",
      "4967 <class 'str'>\n",
      "6344 <class 'str'>\n",
      "122 <class 'str'>\n",
      "1324 <class 'str'>\n",
      "6010 <class 'str'>\n",
      "493 <class 'str'>\n",
      "6150 <class 'str'>\n",
      "1994 <class 'str'>\n",
      "2169 <class 'str'>\n",
      "696 <class 'str'>\n",
      "3466 <class 'str'>\n",
      "75 <class 'str'>\n",
      "4719 <class 'str'>\n",
      "281 <class 'str'>\n",
      "1560 <class 'str'>\n",
      "3680 <class 'str'>\n",
      "2157 <class 'str'>\n",
      "1742 <class 'str'>\n",
      "2648 <class 'str'>\n",
      "6015 <class 'str'>\n",
      "2385 <class 'str'>\n",
      "1361 <class 'str'>\n",
      "2793 <class 'str'>\n",
      "1773 <class 'str'>\n",
      "861 <class 'str'>\n",
      "5570 <class 'str'>\n",
      "4361 <class 'str'>\n",
      "4159 <class 'str'>\n",
      "284 <class 'str'>\n",
      "2803 <class 'str'>\n",
      "483 <class 'str'>\n",
      "35 <class 'str'>\n",
      "1696 <class 'str'>\n",
      "1534 <class 'str'>\n",
      "2161 <class 'str'>\n",
      "1566 <class 'str'>\n",
      "381 <class 'str'>\n",
      "4899 <class 'str'>\n",
      "1684 <class 'str'>\n",
      "2904 <class 'str'>\n",
      "2795 <class 'str'>\n",
      "6044 <class 'str'>\n",
      "7445 <class 'str'>\n",
      "5612 <class 'str'>\n",
      "186 <class 'str'>\n",
      "6406 <class 'str'>\n",
      "1761 <class 'str'>\n",
      "900 <class 'str'>\n",
      "1460 <class 'str'>\n",
      "347 <class 'str'>\n",
      "722 <class 'str'>\n",
      "1320 <class 'str'>\n",
      "5517 <class 'str'>\n",
      "2749 <class 'str'>\n",
      "5466 <class 'str'>\n",
      "2818 <class 'str'>\n",
      "271 <class 'str'>\n",
      "6463 <class 'str'>\n",
      "1125 <class 'str'>\n",
      "1174 <class 'str'>\n",
      "5565 <class 'str'>\n",
      "918 <class 'str'>\n",
      "5865 <class 'str'>\n",
      "2981 <class 'str'>\n",
      "7065 <class 'str'>\n",
      "1400 <class 'str'>\n",
      "3816 <class 'str'>\n",
      "5442 <class 'str'>\n",
      "1437 <class 'str'>\n",
      "4011 <class 'str'>\n",
      "1783 <class 'str'>\n",
      "462 <class 'str'>\n",
      "5201 <class 'str'>\n",
      "6296 <class 'str'>\n",
      "2474 <class 'str'>\n",
      "610 <class 'str'>\n",
      "1891 <class 'str'>\n",
      "4579 <class 'str'>\n",
      "1822 <class 'str'>\n",
      "4027 <class 'str'>\n",
      "780 <class 'str'>\n",
      "6893 <class 'str'>\n",
      "7523 <class 'str'>\n",
      "979 <class 'str'>\n",
      "4922 <class 'str'>\n",
      "1039 <class 'str'>\n",
      "932 <class 'str'>\n",
      "4428 <class 'str'>\n",
      "5664 <class 'str'>\n",
      "5411 <class 'str'>\n",
      "1164 <class 'str'>\n",
      "3833 <class 'str'>\n",
      "430 <class 'str'>\n",
      "1381 <class 'str'>\n",
      "6965 <class 'str'>\n",
      "965 <class 'str'>\n",
      "4032 <class 'str'>\n",
      "4465 <class 'str'>\n",
      "5485 <class 'str'>\n",
      "2409 <class 'str'>\n",
      "675 <class 'str'>\n",
      "5189 <class 'str'>\n",
      "1873 <class 'str'>\n",
      "2477 <class 'str'>\n",
      "4832 <class 'str'>\n",
      "1079 <class 'str'>\n",
      "2211 <class 'str'>\n",
      "5013 <class 'str'>\n",
      "5368 <class 'str'>\n",
      "4389 <class 'str'>\n",
      "1753 <class 'str'>\n",
      "132 <class 'str'>\n",
      "4503 <class 'str'>\n",
      "2292 <class 'str'>\n",
      "4981 <class 'str'>\n",
      "2847 <class 'str'>\n",
      "3779 <class 'str'>\n",
      "2510 <class 'str'>\n",
      "2279 <class 'str'>\n",
      "3202 <class 'str'>\n",
      "4087 <class 'str'>\n",
      "5638 <class 'str'>\n",
      "6913 <class 'str'>\n",
      "89 <class 'str'>\n",
      "1139 <class 'str'>\n",
      "2135 <class 'str'>\n",
      "2709 <class 'str'>\n",
      "1116 <class 'str'>\n",
      "2118 <class 'str'>\n",
      "201 <class 'str'>\n",
      "1166 <class 'str'>\n",
      "3265 <class 'str'>\n",
      "2105 <class 'str'>\n",
      "5514 <class 'str'>\n",
      "4923 <class 'str'>\n",
      "6934 <class 'str'>\n",
      "6117 <class 'str'>\n",
      "5266 <class 'str'>\n",
      "3659 <class 'str'>\n",
      "1612 <class 'str'>\n",
      "74 <class 'str'>\n",
      "62 <class 'str'>\n",
      "581 <class 'str'>\n",
      "4426 <class 'str'>\n",
      "6256 <class 'str'>\n",
      "2768 <class 'str'>\n",
      "2976 <class 'str'>\n",
      "4062 <class 'str'>\n",
      "1942 <class 'str'>\n",
      "5164 <class 'str'>\n",
      "4190 <class 'str'>\n",
      "4327 <class 'str'>\n",
      "3259 <class 'str'>\n",
      "5846 <class 'str'>\n",
      "2033 <class 'str'>\n",
      "5222 <class 'str'>\n",
      "6615 <class 'str'>\n",
      "1993 <class 'str'>\n",
      "3514 <class 'str'>\n",
      "99 <class 'str'>\n",
      "5687 <class 'str'>\n",
      "6957 <class 'str'>\n",
      "495 <class 'str'>\n",
      "2980 <class 'str'>\n",
      "3641 <class 'str'>\n",
      "1944 <class 'str'>\n",
      "1561 <class 'str'>\n",
      "4424 <class 'str'>\n",
      "1708 <class 'str'>\n",
      "4340 <class 'str'>\n",
      "1805 <class 'str'>\n",
      "4985 <class 'str'>\n",
      "6683 <class 'str'>\n",
      "4193 <class 'str'>\n",
      "705 <class 'str'>\n",
      "2757 <class 'str'>\n",
      "3399 <class 'str'>\n",
      "4427 <class 'str'>\n",
      "1363 <class 'str'>\n",
      "1956 <class 'str'>\n",
      "4219 <class 'str'>\n",
      "3090 <class 'str'>\n",
      "1228 <class 'str'>\n",
      "515 <class 'str'>\n",
      "603 <class 'str'>\n",
      "4226 <class 'str'>\n",
      "6250 <class 'str'>\n",
      "4626 <class 'str'>\n",
      "1518 <class 'str'>\n",
      "2530 <class 'str'>\n",
      "4924 <class 'str'>\n",
      "6802 <class 'str'>\n",
      "1352 <class 'str'>\n",
      "3167 <class 'str'>\n",
      "5291 <class 'str'>\n",
      "5785 <class 'str'>\n",
      "2025 <class 'str'>\n",
      "3459 <class 'str'>\n",
      "7750 <class 'str'>\n",
      "4738 <class 'str'>\n",
      "1789 <class 'str'>\n",
      "819 <class 'str'>\n",
      "1422 <class 'str'>\n",
      "293 <class 'str'>\n",
      "1472 <class 'str'>\n",
      "1380 <class 'str'>\n",
      "1579 <class 'str'>\n",
      "3171 <class 'str'>\n",
      "1290 <class 'str'>\n",
      "1977 <class 'str'>\n",
      "7972 <class 'str'>\n",
      "3229 <class 'str'>\n",
      "634 <class 'str'>\n",
      "4680 <class 'str'>\n",
      "6517 <class 'str'>\n",
      "4446 <class 'str'>\n",
      "4180 <class 'str'>\n",
      "2091 <class 'str'>\n",
      "5816 <class 'str'>\n",
      "5963 <class 'str'>\n",
      "4453 <class 'str'>\n",
      "803 <class 'str'>\n",
      "2355 <class 'str'>\n",
      "1047 <class 'str'>\n",
      "2304 <class 'str'>\n",
      "455 <class 'str'>\n",
      "1643 <class 'str'>\n",
      "3237 <class 'str'>\n",
      "3988 <class 'str'>\n",
      "1233 <class 'str'>\n",
      "2731 <class 'str'>\n",
      "219 <class 'str'>\n",
      "5082 <class 'str'>\n",
      "842 <class 'str'>\n",
      "6329 <class 'str'>\n",
      "1712 <class 'str'>\n",
      "1685 <class 'str'>\n",
      "3976 <class 'str'>\n",
      "4478 <class 'str'>\n",
      "3977 <class 'str'>\n",
      "822 <class 'str'>\n",
      "4542 <class 'str'>\n",
      "3594 <class 'str'>\n",
      "1902 <class 'str'>\n",
      "557 <class 'str'>\n",
      "1143 <class 'str'>\n",
      "4244 <class 'str'>\n",
      "1391 <class 'str'>\n",
      "676 <class 'str'>\n",
      "5149 <class 'str'>\n",
      "6021 <class 'str'>\n",
      "4514 <class 'str'>\n",
      "6067 <class 'str'>\n",
      "1483 <class 'str'>\n",
      "5306 <class 'str'>\n",
      "1780 <class 'str'>\n",
      "2387 <class 'str'>\n",
      "3552 <class 'str'>\n",
      "6130 <class 'str'>\n",
      "860 <class 'str'>\n",
      "3378 <class 'str'>\n",
      "5280 <class 'str'>\n",
      "2044 <class 'str'>\n",
      "4281 <class 'str'>\n",
      "5396 <class 'str'>\n",
      "2748 <class 'str'>\n",
      "2112 <class 'str'>\n",
      "1108 <class 'str'>\n",
      "2383 <class 'str'>\n",
      "2123 <class 'str'>\n",
      "3072 <class 'str'>\n",
      "3953 <class 'str'>\n",
      "1056 <class 'str'>\n",
      "1904 <class 'str'>\n",
      "1464 <class 'str'>\n",
      "1861 <class 'str'>\n",
      "2116 <class 'str'>\n",
      "3226 <class 'str'>\n",
      "5012 <class 'str'>\n",
      "5519 <class 'str'>\n",
      "699 <class 'str'>\n",
      "2774 <class 'str'>\n",
      "1432 <class 'str'>\n",
      "5284 <class 'str'>\n",
      "4247 <class 'str'>\n",
      "5456 <class 'str'>\n",
      "5236 <class 'str'>\n",
      "1842 <class 'str'>\n",
      "234 <class 'str'>\n",
      "554 <class 'str'>\n",
      "2614 <class 'str'>\n",
      "3302 <class 'str'>\n",
      "2372 <class 'str'>\n",
      "6118 <class 'str'>\n",
      "1412 <class 'str'>\n",
      "4255 <class 'str'>\n",
      "6147 <class 'str'>\n",
      "1117 <class 'str'>\n",
      "1147 <class 'str'>\n",
      "5646 <class 'str'>\n",
      "3982 <class 'str'>\n",
      "6910 <class 'str'>\n",
      "1105 <class 'str'>\n",
      "5989 <class 'str'>\n",
      "114 <class 'str'>\n",
      "3268 <class 'str'>\n",
      "6779 <class 'str'>\n",
      "162 <class 'str'>\n",
      "4059 <class 'str'>\n",
      "1390 <class 'str'>\n",
      "6793 <class 'str'>\n",
      "3855 <class 'str'>\n",
      "3762 <class 'str'>\n",
      "2406 <class 'str'>\n",
      "1494 <class 'str'>\n",
      "6570 <class 'str'>\n",
      "3418 <class 'str'>\n",
      "1838 <class 'str'>\n",
      "5454 <class 'str'>\n",
      "6459 <class 'str'>\n",
      "2139 <class 'str'>\n",
      "3348 <class 'str'>\n",
      "2009 <class 'str'>\n",
      "4977 <class 'str'>\n",
      "1626 <class 'str'>\n",
      "6224 <class 'str'>\n",
      "776 <class 'str'>\n",
      "3685 <class 'str'>\n",
      "5661 <class 'str'>\n",
      "1285 <class 'str'>\n",
      "2362 <class 'str'>\n",
      "1170 <class 'str'>\n",
      "3789 <class 'str'>\n",
      "257 <class 'str'>\n",
      "5107 <class 'str'>\n",
      "4999 <class 'str'>\n",
      "3230 <class 'str'>\n",
      "1991 <class 'str'>\n",
      "2973 <class 'str'>\n",
      "7555 <class 'str'>\n",
      "6032 <class 'str'>\n",
      "563 <class 'str'>\n",
      "40 <class 'str'>\n",
      "2188 <class 'str'>\n",
      "2633 <class 'str'>\n",
      "1710 <class 'str'>\n",
      "627 <class 'str'>\n",
      "3428 <class 'str'>\n",
      "4404 <class 'str'>\n",
      "7450 <class 'str'>\n",
      "2457 <class 'str'>\n",
      "3629 <class 'str'>\n",
      "4692 <class 'str'>\n",
      "4762 <class 'str'>\n",
      "363 <class 'str'>\n",
      "4266 <class 'str'>\n",
      "569 <class 'str'>\n",
      "5533 <class 'str'>\n",
      "3144 <class 'str'>\n",
      "514 <class 'str'>\n",
      "4671 <class 'str'>\n",
      "1452 <class 'str'>\n",
      "4025 <class 'str'>\n",
      "4046 <class 'str'>\n",
      "3534 <class 'str'>\n",
      "3201 <class 'str'>\n",
      "3334 <class 'str'>\n",
      "348 <class 'str'>\n",
      "183 <class 'str'>\n",
      "1811 <class 'str'>\n",
      "3255 <class 'str'>\n",
      "1360 <class 'str'>\n",
      "2680 <class 'str'>\n",
      "5295 <class 'str'>\n",
      "4844 <class 'str'>\n",
      "3482 <class 'str'>\n",
      "3243 <class 'str'>\n",
      "4608 <class 'str'>\n",
      "3605 <class 'str'>\n",
      "4615 <class 'str'>\n",
      "120 <class 'str'>\n",
      "2259 <class 'str'>\n",
      "2841 <class 'str'>\n",
      "1067 <class 'str'>\n",
      "805 <class 'str'>\n",
      "3019 <class 'str'>\n",
      "494 <class 'str'>\n",
      "1656 <class 'str'>\n",
      "3396 <class 'str'>\n",
      "141 <class 'str'>\n",
      "283 <class 'str'>\n",
      "1242 <class 'str'>\n",
      "1003 <class 'str'>\n",
      "5276 <class 'str'>\n",
      "1624 <class 'str'>\n",
      "2716 <class 'str'>\n",
      "6755 <class 'str'>\n",
      "5986 <class 'str'>\n",
      "5452 <class 'str'>\n",
      "6642 <class 'str'>\n",
      "439 <class 'str'>\n",
      "7257 <class 'str'>\n",
      "5167 <class 'str'>\n",
      "3435 <class 'str'>\n",
      "2816 <class 'str'>\n",
      "882 <class 'str'>\n",
      "4070 <class 'str'>\n",
      "680 <class 'str'>\n",
      "3940 <class 'str'>\n",
      "626 <class 'str'>\n",
      "925 <class 'str'>\n",
      "1322 <class 'str'>\n",
      "5915 <class 'str'>\n",
      "1134 <class 'str'>\n",
      "2743 <class 'str'>\n",
      "864 <class 'str'>\n",
      "4194 <class 'str'>\n",
      "912 <class 'str'>\n",
      "3398 <class 'str'>\n",
      "5105 <class 'str'>\n",
      "2675 <class 'str'>\n",
      "975 <class 'str'>\n",
      "6822 <class 'str'>\n",
      "2887 <class 'str'>\n",
      "741 <class 'str'>\n",
      "930 <class 'str'>\n",
      "1376 <class 'str'>\n",
      "2004 <class 'str'>\n",
      "1370 <class 'str'>\n",
      "2312 <class 'str'>\n",
      "7164 <class 'str'>\n",
      "2721 <class 'str'>\n",
      "799 <class 'str'>\n",
      "3015 <class 'str'>\n",
      "3347 <class 'str'>\n",
      "1843 <class 'str'>\n",
      "3714 <class 'str'>\n",
      "105 <class 'str'>\n",
      "229 <class 'str'>\n",
      "1315 <class 'str'>\n",
      "5356 <class 'str'>\n",
      "5694 <class 'str'>\n",
      "3030 <class 'str'>\n",
      "1378 <class 'str'>\n",
      "6640 <class 'str'>\n",
      "3491 <class 'str'>\n",
      "3848 <class 'str'>\n",
      "31 <class 'str'>\n",
      "3859 <class 'str'>\n",
      "2637 <class 'str'>\n",
      "3800 <class 'str'>\n",
      "6062 <class 'str'>\n",
      "7688 <class 'str'>\n",
      "38 <class 'str'>\n",
      "1024 <class 'str'>\n",
      "6835 <class 'str'>\n",
      "917 <class 'str'>\n",
      "291 <class 'str'>\n",
      "3662 <class 'str'>\n",
      "3922 <class 'str'>\n",
      "7258 <class 'str'>\n",
      "2128 <class 'str'>\n",
      "6055 <class 'str'>\n",
      "6596 <class 'str'>\n",
      "5605 <class 'str'>\n",
      "6335 <class 'str'>\n",
      "2097 <class 'str'>\n",
      "888 <class 'str'>\n",
      "855 <class 'str'>\n",
      "6882 <class 'str'>\n",
      "240 <class 'str'>\n",
      "1266 <class 'str'>\n",
      "839 <class 'str'>\n",
      "6709 <class 'str'>\n",
      "562 <class 'str'>\n",
      "30 <class 'str'>\n",
      "1531 <class 'str'>\n",
      "4712 <class 'str'>\n",
      "3937 <class 'str'>\n",
      "3220 <class 'str'>\n",
      "4407 <class 'str'>\n",
      "1385 <class 'str'>\n",
      "2536 <class 'str'>\n",
      "1265 <class 'str'>\n",
      "1414 <class 'str'>\n",
      "2761 <class 'str'>\n",
      "1806 <class 'str'>\n",
      "7324 <class 'str'>\n",
      "3884 <class 'str'>\n",
      "797 <class 'str'>\n",
      "3066 <class 'str'>\n",
      "1925 <class 'str'>\n",
      "4413 <class 'str'>\n",
      "5073 <class 'str'>\n",
      "6572 <class 'str'>\n",
      "2250 <class 'str'>\n",
      "6789 <class 'str'>\n",
      "640 <class 'str'>\n",
      "4176 <class 'str'>\n",
      "3908 <class 'str'>\n",
      "471 <class 'str'>\n",
      "2373 <class 'str'>\n",
      "6908 <class 'str'>\n",
      "5404 <class 'str'>\n",
      "5475 <class 'str'>\n",
      "1207 <class 'str'>\n",
      "844 <class 'str'>\n",
      "5945 <class 'str'>\n",
      "3206 <class 'str'>\n",
      "242 <class 'str'>\n",
      "1011 <class 'str'>\n",
      "5640 <class 'str'>\n",
      "1005 <class 'str'>\n",
      "5228 <class 'str'>\n",
      "2489 <class 'str'>\n",
      "639 <class 'str'>\n",
      "1674 <class 'str'>\n",
      "3708 <class 'str'>\n",
      "5789 <class 'str'>\n",
      "6450 <class 'str'>\n",
      "2694 <class 'str'>\n",
      "3269 <class 'str'>\n",
      "3541 <class 'str'>\n",
      "5125 <class 'str'>\n",
      "4728 <class 'str'>\n",
      "2517 <class 'str'>\n",
      "1601 <class 'str'>\n",
      "5735 <class 'str'>\n",
      "5160 <class 'str'>\n",
      "3203 <class 'str'>\n",
      "783 <class 'str'>\n",
      "27 <class 'str'>\n",
      "1217 <class 'str'>\n",
      "5263 <class 'str'>\n",
      "2573 <class 'str'>\n",
      "3923 <class 'str'>\n",
      "3528 <class 'str'>\n",
      "964 <class 'str'>\n",
      "2469 <class 'str'>\n",
      "2622 <class 'str'>\n",
      "1074 <class 'str'>\n",
      "1630 <class 'str'>\n",
      "4007 <class 'str'>\n",
      "3763 <class 'str'>\n",
      "6811 <class 'str'>\n",
      "4278 <class 'str'>\n",
      "4583 <class 'str'>\n",
      "3408 <class 'str'>\n",
      "3308 <class 'str'>\n",
      "1130 <class 'str'>\n",
      "4234 <class 'str'>\n",
      "244 <class 'str'>\n",
      "5168 <class 'str'>\n",
      "3677 <class 'str'>\n",
      "37 <class 'str'>\n",
      "3654 <class 'str'>\n",
      "845 <class 'str'>\n",
      "7365 <class 'str'>\n",
      "4848 <class 'str'>\n",
      "3281 <class 'str'>\n",
      "2984 <class 'str'>\n",
      "4366 <class 'str'>\n",
      "4368 <class 'str'>\n",
      "3049 <class 'str'>\n",
      "6678 <class 'str'>\n",
      "5441 <class 'str'>\n",
      "1645 <class 'str'>\n",
      "1330 <class 'str'>\n",
      "1848 <class 'str'>\n",
      "2940 <class 'str'>\n",
      "5439 <class 'str'>\n",
      "510 <class 'str'>\n",
      "4529 <class 'str'>\n",
      "2183 <class 'str'>\n",
      "3647 <class 'str'>\n",
      "1940 <class 'str'>\n",
      "1462 <class 'str'>\n",
      "1574 <class 'str'>\n",
      "1841 <class 'str'>\n",
      "56 <class 'str'>\n",
      "3346 <class 'str'>\n",
      "1683 <class 'str'>\n",
      "1581 <class 'str'>\n",
      "955 <class 'str'>\n",
      "6846 <class 'str'>\n",
      "2443 <class 'str'>\n",
      "2900 <class 'str'>\n",
      "2219 <class 'str'>\n",
      "1210 <class 'str'>\n",
      "2144 <class 'str'>\n",
      "3279 <class 'str'>\n",
      "1548 <class 'str'>\n",
      "3887 <class 'str'>\n",
      "386 <class 'str'>\n",
      "4121 <class 'str'>\n",
      "3227 <class 'str'>\n",
      "4105 <class 'str'>\n",
      "3531 <class 'str'>\n",
      "5702 <class 'str'>\n",
      "3612 <class 'str'>\n",
      "1707 <class 'str'>\n",
      "1726 <class 'str'>\n",
      "370 <class 'str'>\n",
      "1396 <class 'str'>\n",
      "4222 <class 'str'>\n",
      "1278 <class 'str'>\n",
      "5039 <class 'str'>\n",
      "1552 <class 'str'>\n",
      "4906 <class 'str'>\n",
      "658 <class 'str'>\n",
      "841 <class 'str'>\n",
      "2396 <class 'str'>\n",
      "3116 <class 'str'>\n",
      "4419 <class 'str'>\n",
      "1754 <class 'str'>\n",
      "4016 <class 'str'>\n",
      "971 <class 'str'>\n",
      "4388 <class 'str'>\n",
      "3529 <class 'str'>\n",
      "3756 <class 'str'>\n",
      "1274 <class 'str'>\n",
      "4746 <class 'str'>\n",
      "2393 <class 'str'>\n",
      "5124 <class 'str'>\n",
      "1236 <class 'str'>\n",
      "5577 <class 'str'>\n",
      "5364 <class 'str'>\n",
      "5372 <class 'str'>\n",
      "303 <class 'str'>\n",
      "4665 <class 'str'>\n",
      "6142 <class 'str'>\n",
      "4319 <class 'str'>\n",
      "5790 <class 'str'>\n",
      "2989 <class 'str'>\n",
      "1463 <class 'str'>\n",
      "2953 <class 'str'>\n",
      "100 <class 'str'>\n",
      "4580 <class 'str'>\n",
      "838 <class 'str'>\n",
      "253 <class 'str'>\n",
      "6199 <class 'str'>\n",
      "814 <class 'str'>\n",
      "1654 <class 'str'>\n",
      "6695 <class 'str'>\n",
      "277 <class 'str'>\n",
      "6583 <class 'str'>\n",
      "3247 <class 'str'>\n",
      "1795 <class 'str'>\n",
      "3809 <class 'str'>\n",
      "2368 <class 'str'>\n",
      "651 <class 'str'>\n",
      "4173 <class 'str'>\n",
      "1073 <class 'str'>\n",
      "6662 <class 'str'>\n",
      "6739 <class 'str'>\n",
      "1750 <class 'str'>\n",
      "5900 <class 'str'>\n",
      "6443 <class 'str'>\n",
      "6352 <class 'str'>\n",
      "1346 <class 'str'>\n",
      "3830 <class 'str'>\n",
      "1786 <class 'str'>\n",
      "1359 <class 'str'>\n",
      "2930 <class 'str'>\n",
      "487 <class 'str'>\n",
      "3653 <class 'str'>\n",
      "1057 <class 'str'>\n",
      "133 <class 'str'>\n",
      "3151 <class 'str'>\n",
      "5798 <class 'str'>\n",
      "4783 <class 'str'>\n",
      "1597 <class 'str'>\n",
      "1733 <class 'str'>\n",
      "2585 <class 'str'>\n",
      "2595 <class 'str'>\n",
      "1193 <class 'str'>\n",
      "4972 <class 'str'>\n",
      "4042 <class 'str'>\n",
      "3818 <class 'str'>\n",
      "3863 <class 'str'>\n",
      "5091 <class 'str'>\n",
      "197 <class 'str'>\n",
      "216 <class 'str'>\n",
      "2586 <class 'str'>\n",
      "6464 <class 'str'>\n",
      "2155 <class 'str'>\n",
      "2220 <class 'str'>\n",
      "4945 <class 'str'>\n",
      "314 <class 'str'>\n",
      "7733 <class 'str'>\n",
      "5911 <class 'str'>\n",
      "6036 <class 'str'>\n",
      "3373 <class 'str'>\n",
      "928 <class 'str'>\n",
      "4663 <class 'str'>\n",
      "5944 <class 'str'>\n",
      "273 <class 'str'>\n",
      "4482 <class 'str'>\n",
      "3295 <class 'str'>\n",
      "1541 <class 'str'>\n",
      "383 <class 'str'>\n",
      "1365 <class 'str'>\n",
      "5366 <class 'str'>\n",
      "5414 <class 'str'>\n",
      "3901 <class 'str'>\n",
      "4818 <class 'str'>\n",
      "1777 <class 'str'>\n",
      "745 <class 'str'>\n",
      "3065 <class 'str'>\n",
      "3716 <class 'str'>\n",
      "1455 <class 'str'>\n",
      "321 <class 'str'>\n",
      "3945 <class 'str'>\n",
      "2213 <class 'str'>\n",
      "144 <class 'str'>\n",
      "2358 <class 'str'>\n",
      "5309 <class 'str'>\n",
      "4610 <class 'str'>\n",
      "5615 <class 'str'>\n",
      "2588 <class 'str'>\n",
      "2195 <class 'str'>\n",
      "7694 <class 'str'>\n",
      "6984 <class 'str'>\n",
      "507 <class 'str'>\n",
      "2652 <class 'str'>\n",
      "4217 <class 'str'>\n",
      "2653 <class 'str'>\n",
      "2115 <class 'str'>\n",
      "4679 <class 'str'>\n",
      "2855 <class 'str'>\n",
      "6363 <class 'str'>\n",
      "3664 <class 'str'>\n",
      "6140 <class 'str'>\n",
      "3272 <class 'str'>\n",
      "5559 <class 'str'>\n",
      "2593 <class 'str'>\n",
      "3214 <class 'str'>\n",
      "4363 <class 'str'>\n",
      "6143 <class 'str'>\n",
      "6107 <class 'str'>\n",
      "2859 <class 'str'>\n",
      "615 <class 'str'>\n",
      "4280 <class 'str'>\n",
      "1156 <class 'str'>\n",
      "1202 <class 'str'>\n",
      "2658 <class 'str'>\n",
      "4888 <class 'str'>\n",
      "6372 <class 'str'>\n",
      "931 <class 'str'>\n",
      "3759 <class 'str'>\n",
      "6498 <class 'str'>\n",
      "7620 <class 'str'>\n",
      "1567 <class 'str'>\n",
      "4880 <class 'str'>\n",
      "3002 <class 'str'>\n",
      "3556 <class 'str'>\n",
      "1405 <class 'str'>\n",
      "1172 <class 'str'>\n",
      "852 <class 'str'>\n",
      "5427 <class 'str'>\n",
      "3767 <class 'str'>\n",
      "1020 <class 'str'>\n",
      "1760 <class 'str'>\n",
      "3933 <class 'str'>\n",
      "1714 <class 'str'>\n",
      "3155 <class 'str'>\n",
      "648 <class 'str'>\n",
      "550 <class 'str'>\n",
      "1487 <class 'str'>\n",
      "2781 <class 'str'>\n",
      "2587 <class 'str'>\n",
      "2086 <class 'str'>\n",
      "44 <class 'str'>\n",
      "1017 <class 'str'>\n",
      "1043 <class 'str'>\n",
      "807 <class 'str'>\n",
      "779 <class 'str'>\n",
      "2990 <class 'str'>\n",
      "570 <class 'str'>\n",
      "6612 <class 'str'>\n",
      "753 <class 'str'>\n",
      "3280 <class 'str'>\n",
      "5139 <class 'str'>\n",
      "3883 <class 'str'>\n",
      "2635 <class 'str'>\n",
      "4485 <class 'str'>\n",
      "5960 <class 'str'>\n",
      "1474 <class 'str'>\n",
      "4956 <class 'str'>\n",
      "3710 <class 'str'>\n",
      "3017 <class 'str'>\n",
      "1030 <class 'str'>\n",
      "2207 <class 'str'>\n",
      "4437 <class 'str'>\n",
      "49 <class 'str'>\n",
      "3924 <class 'str'>\n",
      "3172 <class 'str'>\n",
      "8045 <class 'str'>\n",
      "1333 <class 'str'>\n",
      "1794 <class 'str'>\n",
      "3921 <class 'str'>\n",
      "4713 <class 'str'>\n",
      "4830 <class 'str'>\n",
      "5131 <class 'str'>\n",
      "3323 <class 'str'>\n",
      "374 <class 'str'>\n",
      "1102 <class 'str'>\n",
      "1124 <class 'str'>\n",
      "6318 <class 'str'>\n",
      "2643 <class 'str'>\n",
      "967 <class 'str'>\n",
      "4794 <class 'str'>\n",
      "4157 <class 'str'>\n",
      "613 <class 'str'>\n",
      "936 <class 'str'>\n",
      "4572 <class 'str'>\n",
      "1921 <class 'str'>\n",
      "2238 <class 'str'>\n",
      "7338 <class 'str'>\n",
      "475 <class 'str'>\n",
      "1107 <class 'str'>\n",
      "4646 <class 'str'>\n",
      "2488 <class 'str'>\n",
      "4387 <class 'str'>\n",
      "344 <class 'str'>\n",
      "3890 <class 'str'>\n",
      "5089 <class 'str'>\n",
      "6164 <class 'str'>\n",
      "1695 <class 'str'>\n",
      "4545 <class 'str'>\n",
      "2222 <class 'str'>\n",
      "2895 <class 'str'>\n",
      "3367 <class 'str'>\n",
      "2545 <class 'str'>\n",
      "6647 <class 'str'>\n",
      "5618 <class 'str'>\n",
      "2815 <class 'str'>\n",
      "2363 <class 'str'>\n",
      "4811 <class 'str'>\n",
      "3154 <class 'str'>\n",
      "6289 <class 'str'>\n",
      "5876 <class 'str'>\n",
      "395 <class 'str'>\n",
      "2893 <class 'str'>\n",
      "1782 <class 'str'>\n",
      "8065 <class 'str'>\n",
      "2218 <class 'str'>\n",
      "3276 <class 'str'>\n",
      "3660 <class 'str'>\n",
      "2133 <class 'str'>\n",
      "5578 <class 'str'>\n",
      "2074 <class 'str'>\n",
      "2792 <class 'str'>\n",
      "2750 <class 'str'>\n",
      "4084 <class 'str'>\n",
      "2934 <class 'str'>\n",
      "3620 <class 'str'>\n",
      "4604 <class 'str'>\n",
      "1313 <class 'str'>\n",
      "4755 <class 'str'>\n",
      "6981 <class 'str'>\n",
      "3492 <class 'str'>\n",
      "4385 <class 'str'>\n",
      "6477 <class 'str'>\n",
      "2657 <class 'str'>\n",
      "1176 <class 'str'>\n",
      "6863 <class 'str'>\n",
      "106 <class 'str'>\n",
      "2592 <class 'str'>\n",
      "3939 <class 'str'>\n",
      "2999 <class 'str'>\n",
      "6128 <class 'str'>\n",
      "4420 <class 'str'>\n",
      "3749 <class 'str'>\n",
      "1759 <class 'str'>\n",
      "820 <class 'str'>\n",
      "3402 <class 'str'>\n",
      "4857 <class 'str'>\n",
      "4651 <class 'str'>\n",
      "3152 <class 'str'>\n",
      "5046 <class 'str'>\n",
      "6367 <class 'str'>\n",
      "2666 <class 'str'>\n",
      "3993 <class 'str'>\n",
      "1407 <class 'str'>\n",
      "2639 <class 'str'>\n",
      "5446 <class 'str'>\n",
      "6557 <class 'str'>\n",
      "539 <class 'str'>\n",
      "1037 <class 'str'>\n",
      "4694 <class 'str'>\n",
      "1071 <class 'str'>\n",
      "4879 <class 'str'>\n",
      "6079 <class 'str'>\n",
      "5830 <class 'str'>\n",
      "355 <class 'str'>\n",
      "3772 <class 'str'>\n",
      "2756 <class 'str'>\n",
      "6267 <class 'str'>\n",
      "4757 <class 'str'>\n",
      "4781 <class 'str'>\n",
      "7405 <class 'str'>\n",
      "138 <class 'str'>\n",
      "3546 <class 'str'>\n",
      "3079 <class 'str'>\n",
      "1542 <class 'str'>\n",
      "265 <class 'str'>\n",
      "2623 <class 'str'>\n",
      "5726 <class 'str'>\n",
      "5317 <class 'str'>\n",
      "1095 <class 'str'>\n",
      "2435 <class 'str'>\n",
      "3058 <class 'str'>\n",
      "2766 <class 'str'>\n",
      "3768 <class 'str'>\n",
      "4188 <class 'str'>\n",
      "340 <class 'str'>\n",
      "6514 <class 'str'>\n",
      "1173 <class 'str'>\n",
      "3320 <class 'str'>\n",
      "4761 <class 'str'>\n",
      "6261 <class 'str'>\n",
      "2391 <class 'str'>\n",
      "7279 <class 'str'>\n",
      "5004 <class 'str'>\n",
      "1820 <class 'str'>\n",
      "5834 <class 'str'>\n",
      "1957 <class 'str'>\n",
      "713 <class 'str'>\n",
      "5641 <class 'str'>\n",
      "5568 <class 'str'>\n",
      "1595 <class 'str'>\n",
      "559 <class 'str'>\n",
      "2185 <class 'str'>\n",
      "5302 <class 'str'>\n",
      "2404 <class 'str'>\n",
      "4230 <class 'str'>\n",
      "898 <class 'str'>\n",
      "4732 <class 'str'>\n",
      "3315 <class 'str'>\n",
      "2454 <class 'str'>\n",
      "6685 <class 'str'>\n",
      "972 <class 'str'>\n",
      "3062 <class 'str'>\n",
      "750 <class 'str'>\n",
      "2977 <class 'str'>\n",
      "4766 <class 'str'>\n",
      "1270 <class 'str'>\n",
      "4341 <class 'str'>\n",
      "5345 <class 'str'>\n",
      "3669 <class 'str'>\n",
      "4876 <class 'str'>\n",
      "3721 <class 'str'>\n",
      "2902 <class 'str'>\n",
      "1901 <class 'str'>\n",
      "4345 <class 'str'>\n",
      "3729 <class 'str'>\n",
      "5621 <class 'str'>\n",
      "1135 <class 'str'>\n",
      "6857 <class 'str'>\n",
      "4399 <class 'str'>\n",
      "1577 <class 'str'>\n",
      "3846 <class 'str'>\n",
      "2718 <class 'str'>\n",
      "1587 <class 'str'>\n",
      "7100 <class 'str'>\n",
      "6054 <class 'str'>\n",
      "5477 <class 'str'>\n",
      "5626 <class 'str'>\n",
      "4317 <class 'str'>\n",
      "2134 <class 'str'>\n",
      "1874 <class 'str'>\n",
      "4249 <class 'str'>\n",
      "2744 <class 'str'>\n",
      "5251 <class 'str'>\n",
      "1072 <class 'str'>\n",
      "3089 <class 'str'>\n",
      "859 <class 'str'>\n",
      "5691 <class 'str'>\n",
      "5528 <class 'str'>\n",
      "1576 <class 'str'>\n",
      "1263 <class 'str'>\n",
      "2678 <class 'str'>\n",
      "4854 <class 'str'>\n",
      "4168 <class 'str'>\n",
      "4725 <class 'str'>\n",
      "5102 <class 'str'>\n",
      "6618 <class 'str'>\n",
      "2535 <class 'str'>\n",
      "6263 <class 'str'>\n",
      "2892 <class 'str'>\n",
      "1500 <class 'str'>\n",
      "5440 <class 'str'>\n",
      "2461 <class 'str'>\n",
      "821 <class 'str'>\n",
      "1837 <class 'str'>\n",
      "1823 <class 'str'>\n",
      "6161 <class 'str'>\n",
      "4774 <class 'str'>\n",
      "4462 <class 'str'>\n",
      "3512 <class 'str'>\n",
      "624 <class 'str'>\n",
      "2291 <class 'str'>\n",
      "743 <class 'str'>\n",
      "4589 <class 'str'>\n",
      "2428 <class 'str'>\n",
      "3589 <class 'str'>\n",
      "829 <class 'str'>\n",
      "357 <class 'str'>\n",
      "976 <class 'str'>\n",
      "6599 <class 'str'>\n",
      "2431 <class 'str'>\n",
      "3732 <class 'str'>\n",
      "169 <class 'str'>\n",
      "587 <class 'str'>\n",
      "3200 <class 'str'>\n",
      "7699 <class 'str'>\n",
      "4653 <class 'str'>\n",
      "3361 <class 'str'>\n",
      "6013 <class 'str'>\n",
      "6223 <class 'str'>\n",
      "1667 <class 'str'>\n",
      "2693 <class 'str'>\n",
      "702 <class 'str'>\n",
      "5812 <class 'str'>\n",
      "4127 <class 'str'>\n",
      "3535 <class 'str'>\n",
      "215 <class 'str'>\n",
      "5580 <class 'str'>\n",
      "3920 <class 'str'>\n",
      "7373 <class 'str'>\n",
      "4189 <class 'str'>\n",
      "4495 <class 'str'>\n",
      "7278 <class 'str'>\n",
      "5803 <class 'str'>\n",
      "1410 <class 'str'>\n",
      "6088 <class 'str'>\n",
      "5020 <class 'str'>\n",
      "997 <class 'str'>\n",
      "1090 <class 'str'>\n",
      "2826 <class 'str'>\n",
      "2456 <class 'str'>\n",
      "4745 <class 'str'>\n",
      "7125 <class 'str'>\n",
      "2877 <class 'str'>\n",
      "2691 <class 'str'>\n",
      "3724 <class 'str'>\n",
      "1549 <class 'str'>\n",
      "2364 <class 'str'>\n",
      "3047 <class 'str'>\n",
      "92 <class 'str'>\n",
      "5095 <class 'str'>\n",
      "4597 <class 'str'>\n",
      "1461 <class 'str'>\n",
      "6989 <class 'str'>\n",
      "2039 <class 'str'>\n",
      "3185 <class 'str'>\n",
      "6452 <class 'str'>\n",
      "1126 <class 'str'>\n",
      "2496 <class 'str'>\n",
      "4901 <class 'str'>\n",
      "4398 <class 'str'>\n",
      "3679 <class 'str'>\n",
      "5734 <class 'str'>\n",
      "4322 <class 'str'>\n",
      "5 <class 'str'>\n",
      "1448 <class 'str'>\n",
      "561 <class 'str'>\n",
      "3168 <class 'str'>\n",
      "2365 <class 'str'>\n",
      "2867 <class 'str'>\n",
      "1749 <class 'str'>\n",
      "2402 <class 'str'>\n",
      "3158 <class 'str'>\n",
      "4271 <class 'str'>\n",
      "1771 <class 'str'>\n",
      "1100 <class 'str'>\n",
      "5842 <class 'str'>\n",
      "251 <class 'str'>\n",
      "488 <class 'str'>\n",
      "1686 <class 'str'>\n",
      "3449 <class 'str'>\n",
      "4306 <class 'str'>\n",
      "6178 <class 'str'>\n",
      "2175 <class 'str'>\n",
      "3731 <class 'str'>\n",
      "10 <class 'str'>\n",
      "3678 <class 'str'>\n",
      "870 <class 'str'>\n",
      "6750 <class 'str'>\n",
      "691 <class 'str'>\n",
      "4862 <class 'str'>\n",
      "3932 <class 'str'>\n",
      "1868 <class 'str'>\n",
      "477 <class 'str'>\n",
      "3452 <class 'str'>\n",
      "3349 <class 'str'>\n",
      "1402 <class 'str'>\n",
      "4466 <class 'str'>\n",
      "1188 <class 'str'>\n",
      "3793 <class 'str'>\n",
      "5550 <class 'str'>\n",
      "5564 <class 'str'>\n",
      "4397 <class 'str'>\n",
      "3282 <class 'str'>\n",
      "6468 <class 'str'>\n",
      "2862 <class 'str'>\n",
      "5026 <class 'str'>\n",
      "2285 <class 'str'>\n",
      "7095 <class 'str'>\n",
      "2676 <class 'str'>\n",
      "6907 <class 'str'>\n",
      "5191 <class 'str'>\n",
      "7321 <class 'str'>\n",
      "2713 <class 'str'>\n",
      "3478 <class 'str'>\n",
      "82 <class 'str'>\n",
      "535 <class 'str'>\n",
      "342 <class 'str'>\n",
      "3764 <class 'str'>\n",
      "1273 <class 'str'>\n",
      "3693 <class 'str'>\n",
      "774 <class 'str'>\n",
      "4299 <class 'str'>\n",
      "3183 <class 'str'>\n",
      "7368 <class 'str'>\n",
      "6512 <class 'str'>\n",
      "960 <class 'str'>\n",
      "6121 <class 'str'>\n",
      "5298 <class 'str'>\n",
      "1619 <class 'str'>\n",
      "142 <class 'str'>\n",
      "5397 <class 'str'>\n",
      "4165 <class 'str'>\n",
      "316 <class 'str'>\n",
      "1029 <class 'str'>\n",
      "3610 <class 'str'>\n",
      "2770 <class 'str'>\n",
      "1138 <class 'str'>\n",
      "2145 <class 'str'>\n",
      "7943 <class 'str'>\n",
      "5507 <class 'str'>\n",
      "4270 <class 'str'>\n",
      "7639 <class 'str'>\n",
      "2193 <class 'str'>\n",
      "3166 <class 'str'>\n",
      "6133 <class 'str'>\n",
      "4779 <class 'str'>\n",
      "6632 <class 'str'>\n",
      "5043 <class 'str'>\n",
      "6080 <class 'str'>\n",
      "4047 <class 'str'>\n",
      "609 <class 'str'>\n",
      "5402 <class 'str'>\n",
      "5400 <class 'str'>\n",
      "6213 <class 'str'>\n",
      "5582 <class 'str'>\n",
      "3476 <class 'str'>\n",
      "2332 <class 'str'>\n",
      "3060 <class 'str'>\n",
      "4767 <class 'str'>\n",
      "2901 <class 'str'>\n",
      "4034 <class 'str'>\n",
      "2714 <class 'str'>\n",
      "2138 <class 'str'>\n",
      "319 <class 'str'>\n",
      "6895 <class 'str'>\n",
      "437 <class 'str'>\n",
      "788 <class 'str'>\n",
      "7992 <class 'str'>\n",
      "524 <class 'str'>\n",
      "958 <class 'str'>\n",
      "751 <class 'str'>\n",
      "5348 <class 'str'>\n",
      "7443 <class 'str'>\n",
      "2256 <class 'str'>\n",
      "3045 <class 'str'>\n",
      "1103 <class 'str'>\n",
      "3896 <class 'str'>\n",
      "2544 <class 'str'>\n",
      "4638 <class 'str'>\n",
      "1633 <class 'str'>\n",
      "346 <class 'str'>\n",
      "5562 <class 'str'>\n",
      "6022 <class 'str'>\n",
      "3285 <class 'str'>\n",
      "83 <class 'str'>\n",
      "2551 <class 'str'>\n",
      "2640 <class 'str'>\n",
      "3983 <class 'str'>\n",
      "671 <class 'str'>\n",
      "4722 <class 'str'>\n",
      "3656 <class 'str'>\n",
      "1485 <class 'str'>\n",
      "1631 <class 'str'>\n",
      "3745 <class 'str'>\n",
      "6936 <class 'str'>\n",
      "781 <class 'str'>\n",
      "4158 <class 'str'>\n",
      "6270 <class 'str'>\n",
      "677 <class 'str'>\n",
      "3417 <class 'str'>\n",
      "2246 <class 'str'>\n",
      "1181 <class 'str'>\n",
      "5377 <class 'str'>\n",
      "5547 <class 'str'>\n",
      "2398 <class 'str'>\n",
      "5810 <class 'str'>\n",
      "4886 <class 'str'>\n",
      "1808 <class 'str'>\n",
      "5649 <class 'str'>\n",
      "3118 <class 'str'>\n",
      "2636 <class 'str'>\n",
      "3536 <class 'str'>\n",
      "7107 <class 'str'>\n",
      "2982 <class 'str'>\n",
      "950 <class 'str'>\n",
      "6801 <class 'str'>\n",
      "2873 <class 'str'>\n",
      "1185 <class 'str'>\n",
      "6993 <class 'str'>\n",
      "104 <class 'str'>\n",
      "4693 <class 'str'>\n",
      "804 <class 'str'>\n",
      "1923 <class 'str'>\n",
      "3525 <class 'str'>\n",
      "924 <class 'str'>\n",
      "5412 <class 'str'>\n",
      "5081 <class 'str'>\n",
      "2619 <class 'str'>\n",
      "2498 <class 'str'>\n",
      "5495 <class 'str'>\n",
      "1776 <class 'str'>\n",
      "288 <class 'str'>\n",
      "6069 <class 'str'>\n",
      "3288 <class 'str'>\n",
      "5137 <class 'str'>\n",
      "3490 <class 'str'>\n",
      "1997 <class 'str'>\n",
      "4259 <class 'str'>\n",
      "5622 <class 'str'>\n",
      "3178 <class 'str'>\n",
      "7583 <class 'str'>\n",
      "1934 <class 'str'>\n",
      "4380 <class 'str'>\n",
      "2548 <class 'str'>\n",
      "586 <class 'str'>\n",
      "2968 <class 'str'>\n",
      "992 <class 'str'>\n",
      "69 <class 'str'>\n",
      "7089 <class 'str'>\n",
      "7315 <class 'str'>\n",
      "7686 <class 'str'>\n",
      "1345 <class 'str'>\n",
      "4549 <class 'str'>\n",
      "7440 <class 'str'>\n",
      "3811 <class 'str'>\n",
      "2604 <class 'str'>\n",
      "1870 <class 'str'>\n",
      "2249 <class 'str'>\n",
      "7774 <class 'str'>\n",
      "707 <class 'str'>\n",
      "636 <class 'str'>\n",
      "6342 <class 'str'>\n",
      "595 <class 'str'>\n",
      "3261 <class 'str'>\n",
      "3223 <class 'str'>\n",
      "7269 <class 'str'>\n",
      "1372 <class 'str'>\n",
      "4749 <class 'str'>\n",
      "3020 <class 'str'>\n",
      "7309 <class 'str'>\n",
      "4666 <class 'str'>\n",
      "1572 <class 'str'>\n",
      "4061 <class 'str'>\n",
      "1162 <class 'str'>\n",
      "6885 <class 'str'>\n",
      "1077 <class 'str'>\n",
      "5359 <class 'str'>\n",
      "3338 <class 'str'>\n",
      "2985 <class 'str'>\n",
      "5460 <class 'str'>\n",
      "3744 <class 'str'>\n",
      "3970 <class 'str'>\n",
      "848 <class 'str'>\n",
      "130 <class 'str'>\n",
      "1264 <class 'str'>\n",
      "2465 <class 'str'>\n",
      "2559 <class 'str'>\n",
      "3110 <class 'str'>\n",
      "3358 <class 'str'>\n",
      "227 <class 'str'>\n",
      "5422 <class 'str'>\n",
      "5635 <class 'str'>\n",
      "4567 <class 'str'>\n",
      "2695 <class 'str'>\n",
      "2665 <class 'str'>\n",
      "1150 <class 'str'>\n",
      "1774 <class 'str'>\n",
      "4960 <class 'str'>\n",
      "1655 <class 'str'>\n",
      "1575 <class 'str'>\n",
      "2173 <class 'str'>\n",
      "5724 <class 'str'>\n",
      "687 <class 'str'>\n",
      "5998 <class 'str'>\n",
      "312 <class 'str'>\n",
      "2444 <class 'str'>\n",
      "5935 <class 'str'>\n",
      "8105 <class 'str'>\n",
      "2278 <class 'str'>\n",
      "3530 <class 'str'>\n",
      "526 <class 'str'>\n",
      "185 <class 'str'>\n",
      "2959 <class 'str'>\n",
      "6732 <class 'str'>\n",
      "410 <class 'str'>\n",
      "3565 <class 'str'>\n",
      "3233 <class 'str'>\n",
      "5206 <class 'str'>\n",
      "2918 <class 'str'>\n",
      "602 <class 'str'>\n",
      "503 <class 'str'>\n",
      "3784 <class 'str'>\n",
      "5906 <class 'str'>\n",
      "3091 <class 'str'>\n",
      "64 <class 'str'>\n",
      "6072 <class 'str'>\n",
      "4538 <class 'str'>\n",
      "6317 <class 'str'>\n",
      "4396 <class 'str'>\n",
      "1206 <class 'str'>\n",
      "2759 <class 'str'>\n",
      "1906 <class 'str'>\n",
      "349 <class 'str'>\n",
      "5995 <class 'str'>\n",
      "4469 <class 'str'>\n",
      "2661 <class 'str'>\n",
      "739 <class 'str'>\n",
      "1111 <class 'str'>\n",
      "168 <class 'str'>\n",
      "1479 <class 'str'>\n",
      "2079 <class 'str'>\n",
      "6039 <class 'str'>\n",
      "1271 <class 'str'>\n",
      "6086 <class 'str'>\n",
      "5764 <class 'str'>\n",
      "3702 <class 'str'>\n",
      "4796 <class 'str'>\n",
      "2380 <class 'str'>\n",
      "1744 <class 'str'>\n",
      "868 <class 'str'>\n",
      "5253 <class 'str'>\n",
      "2140 <class 'str'>\n",
      "5373 <class 'str'>\n",
      "96 <class 'str'>\n",
      "1829 <class 'str'>\n",
      "4554 <class 'str'>\n",
      "4959 <class 'str'>\n",
      "7234 <class 'str'>\n",
      "151 <class 'str'>\n",
      "6403 <class 'str'>\n",
      "4904 <class 'str'>\n",
      "2360 <class 'str'>\n",
      "6551 <class 'str'>\n",
      "208 <class 'str'>\n",
      "1664 <class 'str'>\n",
      "6883 <class 'str'>\n",
      "543 <class 'str'>\n",
      "4867 <class 'str'>\n",
      "3115 <class 'str'>\n",
      "5543 <class 'str'>\n",
      "3837 <class 'str'>\n",
      "5354 <class 'str'>\n",
      "2324 <class 'str'>\n",
      "3808 <class 'str'>\n",
      "5918 <class 'str'>\n",
      "531 <class 'str'>\n",
      "7431 <class 'str'>\n",
      "3368 <class 'str'>\n",
      "1711 <class 'str'>\n",
      "3861 <class 'str'>\n",
      "4444 <class 'str'>\n",
      "1291 <class 'str'>\n",
      "2746 <class 'str'>\n",
      "6154 <class 'str'>\n",
      "4498 <class 'str'>\n",
      "302 <class 'str'>\n",
      "1258 <class 'str'>\n",
      "4933 <class 'str'>\n",
      "793 <class 'str'>\n",
      "1442 <class 'str'>\n",
      "260 <class 'str'>\n",
      "2053 <class 'str'>\n",
      "1297 <class 'str'>\n",
      "2070 <class 'str'>\n",
      "3604 <class 'str'>\n",
      "7526 <class 'str'>\n",
      "1735 <class 'str'>\n",
      "2610 <class 'str'>\n",
      "4594 <class 'str'>\n",
      "5884 <class 'str'>\n",
      "5878 <class 'str'>\n",
      "3657 <class 'str'>\n",
      "4664 <class 'str'>\n",
      "7036 <class 'str'>\n",
      "7576 <class 'str'>\n",
      "4891 <class 'str'>\n",
      "7250 <class 'str'>\n",
      "7013 <class 'str'>\n",
      "760 <class 'str'>\n",
      "2014 <class 'str'>\n",
      "3838 <class 'str'>\n",
      "5930 <class 'str'>\n",
      "2617 <class 'str'>\n",
      "4156 <class 'str'>\n",
      "3991 <class 'str'>\n",
      "4323 <class 'str'>\n",
      "2308 <class 'str'>\n",
      "393 <class 'str'>\n",
      "5230 <class 'str'>\n",
      "672 <class 'str'>\n",
      "6975 <class 'str'>\n",
      "3737 <class 'str'>\n",
      "1064 <class 'str'>\n",
      "289 <class 'str'>\n",
      "4410 <class 'str'>\n",
      "836 <class 'str'>\n",
      "5819 <class 'str'>\n",
      "3711 <class 'str'>\n",
      "6160 <class 'str'>\n",
      "5224 <class 'str'>\n",
      "1523 <class 'str'>\n",
      "6441 <class 'str'>\n",
      "5352 <class 'str'>\n",
      "4187 <class 'str'>\n",
      "5657 <class 'str'>\n",
      "6442 <class 'str'>\n",
      "5579 <class 'str'>\n",
      "1679 <class 'str'>\n",
      "618 <class 'str'>\n",
      "2790 <class 'str'>\n",
      "442 <class 'str'>\n",
      "5636 <class 'str'>\n",
      "959 <class 'str'>\n",
      "2511 <class 'str'>\n",
      "801 <class 'str'>\n",
      "4120 <class 'str'>\n",
      "5895 <class 'str'>\n",
      "785 <class 'str'>\n",
      "7417 <class 'str'>\n",
      "2969 <class 'str'>\n",
      "3926 <class 'str'>\n",
      "402 <class 'str'>\n",
      "3238 <class 'str'>\n",
      "3157 <class 'str'>\n",
      "6690 <class 'str'>\n",
      "4558 <class 'str'>\n",
      "228 <class 'str'>\n",
      "1791 <class 'str'>\n",
      "26 <class 'str'>\n",
      "2293 <class 'str'>\n",
      "6272 <class 'str'>\n",
      "863 <class 'str'>\n",
      "3774 <class 'str'>\n",
      "1912 <class 'str'>\n",
      "4581 <class 'str'>\n",
      "7679 <class 'str'>\n",
      "2336 <class 'str'>\n",
      "6806 <class 'str'>\n",
      "6577 <class 'str'>\n",
      "5880 <class 'str'>\n",
      "3052 <class 'str'>\n",
      "492 <class 'str'>\n",
      "1725 <class 'str'>\n",
      "3101 <class 'str'>\n",
      "5755 <class 'str'>\n",
      "1149 <class 'str'>\n",
      "235 <class 'str'>\n",
      "4422 <class 'str'>\n",
      "3228 <class 'str'>\n",
      "795 <class 'str'>\n",
      "2068 <class 'str'>\n",
      "2376 <class 'str'>\n",
      "2669 <class 'str'>\n",
      "5730 <class 'str'>\n",
      "464 <class 'str'>\n",
      "7582 <class 'str'>\n",
      "3061 <class 'str'>\n",
      "2408 <class 'str'>\n",
      "2125 <class 'str'>\n",
      "6696 <class 'str'>\n",
      "7531 <class 'str'>\n",
      "6462 <class 'str'>\n",
      "3889 <class 'str'>\n",
      "2924 <class 'str'>\n",
      "4934 <class 'str'>\n",
      "789 <class 'str'>\n",
      "2066 <class 'str'>\n",
      "1652 <class 'str'>\n",
      "2356 <class 'str'>\n",
      "5644 <class 'str'>\n",
      "484 <class 'str'>\n",
      "5971 <class 'str'>\n",
      "4248 <class 'str'>\n",
      "5054 <class 'str'>\n",
      "5610 <class 'str'>\n",
      "134 <class 'str'>\n",
      "553 <class 'str'>\n",
      "5061 <class 'str'>\n",
      "4657 <class 'str'>\n",
      "7002 <class 'str'>\n",
      "6645 <class 'str'>\n",
      "6017 <class 'str'>\n",
      "1371 <class 'str'>\n",
      "835 <class 'str'>\n",
      "6817 <class 'str'>\n",
      "3173 <class 'str'>\n",
      "4648 <class 'str'>\n",
      "1588 <class 'str'>\n",
      "5554 <class 'str'>\n",
      "372 <class 'str'>\n",
      "2 <class 'str'>\n",
      "4974 <class 'str'>\n",
      "3707 <class 'str'>\n",
      "6180 <class 'str'>\n",
      "7651 <class 'str'>\n",
      "6383 <class 'str'>\n",
      "1160 <class 'str'>\n",
      "63 <class 'str'>\n",
      "1507 <class 'str'>\n",
      "5490 <class 'str'>\n",
      "6903 <class 'str'>\n",
      "1489 <class 'str'>\n",
      "4990 <class 'str'>\n",
      "6046 <class 'str'>\n",
      "1756 <class 'str'>\n",
      "6747 <class 'str'>\n",
      "643 <class 'str'>\n",
      "4670 <class 'str'>\n",
      "4432 <class 'str'>\n",
      "3725 <class 'str'>\n",
      "6713 <class 'str'>\n",
      "3018 <class 'str'>\n",
      "353 <class 'str'>\n",
      "2881 <class 'str'>\n",
      "6829 <class 'str'>\n",
      "6234 <class 'str'>\n",
      "1976 <class 'str'>\n",
      "1798 <class 'str'>\n",
      "2018 <class 'str'>\n",
      "1220 <class 'str'>\n",
      "2335 <class 'str'>\n",
      "692 <class 'str'>\n",
      "463 <class 'str'>\n",
      "5294 <class 'str'>\n",
      "6437 <class 'str'>\n",
      "3046 <class 'str'>\n",
      "2490 <class 'str'>\n",
      "5859 <class 'str'>\n",
      "1184 <class 'str'>\n",
      "6259 <class 'str'>\n",
      "3886 <class 'str'>\n",
      "1167 <class 'str'>\n",
      "1810 <class 'str'>\n",
      "623 <class 'str'>\n",
      "150 <class 'str'>\n",
      "6184 <class 'str'>\n",
      "1800 <class 'str'>\n",
      "1510 <class 'str'>\n",
      "1793 <class 'str'>\n",
      "533 <class 'str'>\n",
      "884 <class 'str'>\n",
      "5924 <class 'str'>\n",
      "4242 <class 'str'>\n",
      "5408 <class 'str'>\n",
      "3968 <class 'str'>\n",
      "5630 <class 'str'>\n",
      "1659 <class 'str'>\n",
      "246 <class 'str'>\n",
      "2359 <class 'str'>\n",
      "320 <class 'str'>\n",
      "5967 <class 'str'>\n",
      "7346 <class 'str'>\n",
      "2022 <class 'str'>\n",
      "4820 <class 'str'>\n",
      "2783 <class 'str'>\n",
      "2464 <class 'str'>\n",
      "4125 <class 'str'>\n",
      "5889 <class 'str'>\n",
      "2006 <class 'str'>\n",
      "7683 <class 'str'>\n",
      "6547 <class 'str'>\n",
      "2089 <class 'str'>\n",
      "212 <class 'str'>\n",
      "585 <class 'str'>\n",
      "2941 <class 'str'>\n",
      "4339 <class 'str'>\n",
      "7798 <class 'str'>\n",
      "3995 <class 'str'>\n",
      "6912 <class 'str'>\n",
      "4037 <class 'str'>\n",
      "1200 <class 'str'>\n",
      "5503 <class 'str'>\n",
      "6229 <class 'str'>\n",
      "3125 <class 'str'>\n",
      "3096 <class 'str'>\n",
      "7119 <class 'str'>\n",
      "1984 <class 'str'>\n",
      "3132 <class 'str'>\n",
      "2997 <class 'str'>\n",
      "3769 <class 'str'>\n",
      "2612 <class 'str'>\n",
      "4971 <class 'str'>\n",
      "6650 <class 'str'>\n",
      "5469 <class 'str'>\n",
      "1936 <class 'str'>\n",
      "2063 <class 'str'>\n",
      "6515 <class 'str'>\n",
      "5727 <class 'str'>\n",
      "1802 <class 'str'>\n",
      "3138 <class 'str'>\n",
      "1250 <class 'str'>\n",
      "3164 <class 'str'>\n",
      "3681 <class 'str'>\n",
      "1397 <class 'str'>\n",
      "3432 <class 'str'>\n",
      "1583 <class 'str'>\n",
      "1557 <class 'str'>\n",
      "3743 <class 'str'>\n",
      "1163 <class 'str'>\n",
      "3012 <class 'str'>\n",
      "4057 <class 'str'>\n",
      "3897 <class 'str'>\n",
      "3683 <class 'str'>\n",
      "2903 <class 'str'>\n",
      "1240 <class 'str'>\n",
      "2078 <class 'str'>\n",
      "1110 <class 'str'>\n",
      "506 <class 'str'>\n",
      "5162 <class 'str'>\n",
      "2422 <class 'str'>\n",
      "2667 <class 'str'>\n",
      "2913 <class 'str'>\n",
      "1080 <class 'str'>\n",
      "3934 <class 'str'>\n",
      "2096 <class 'str'>\n",
      "7186 <class 'str'>\n",
      "4085 <class 'str'>\n",
      "3658 <class 'str'>\n",
      "3567 <class 'str'>\n",
      "5855 <class 'str'>\n",
      "999 <class 'str'>\n",
      "7239 <class 'str'>\n",
      "6446 <class 'str'>\n",
      "5824 <class 'str'>\n",
      "3187 <class 'str'>\n",
      "6834 <class 'str'>\n",
      "1772 <class 'str'>\n",
      "2284 <class 'str'>\n",
      "5668 <class 'str'>\n",
      "1477 <class 'str'>\n",
      "2906 <class 'str'>\n",
      "2697 <class 'str'>\n",
      "1374 <class 'str'>\n",
      "2153 <class 'str'>\n",
      "6576 <class 'str'>\n",
      "4254 <class 'str'>\n",
      "135 <class 'str'>\n",
      "3299 <class 'str'>\n",
      "6951 <class 'str'>\n",
      "5602 <class 'str'>\n",
      "5542 <class 'str'>\n",
      "7656 <class 'str'>\n",
      "3240 <class 'str'>\n",
      "6575 <class 'str'>\n",
      "2508 <class 'str'>\n",
      "117 <class 'str'>\n",
      "3486 <class 'str'>\n",
      "3788 <class 'str'>\n",
      "2807 <class 'str'>\n",
      "6944 <class 'str'>\n",
      "4434 <class 'str'>\n",
      "2399 <class 'str'>\n",
      "6074 <class 'str'>\n",
      "3123 <class 'str'>\n",
      "3264 <class 'str'>\n",
      "6967 <class 'str'>\n",
      "3009 <class 'str'>\n",
      "4507 <class 'str'>\n",
      "1537 <class 'str'>\n",
      "5632 <class 'str'>\n",
      "4650 <class 'str'>\n",
      "1341 <class 'str'>\n",
      "4202 <class 'str'>\n",
      "7255 <class 'str'>\n",
      "5077 <class 'str'>\n",
      "1689 <class 'str'>\n",
      "5016 <class 'str'>\n",
      "2785 <class 'str'>\n",
      "2905 <class 'str'>\n",
      "1470 <class 'str'>\n",
      "7050 <class 'str'>\n",
      "6257 <class 'str'>\n",
      "6077 <class 'str'>\n",
      "1486 <class 'str'>\n",
      "3177 <class 'str'>\n",
      "4483 <class 'str'>\n",
      "1649 <class 'str'>\n",
      "4304 <class 'str'>\n",
      "4006 <class 'str'>\n",
      "6040 <class 'str'>\n",
      "4367 <class 'str'>\n",
      "1406 <class 'str'>\n",
      "6826 <class 'str'>\n",
      "2798 <class 'str'>\n",
      "1384 <class 'str'>\n",
      "1177 <class 'str'>\n",
      "2023 <class 'str'>\n",
      "6248 <class 'str'>\n",
      "1204 <class 'str'>\n",
      "7003 <class 'str'>\n",
      "4708 <class 'str'>\n",
      "1618 <class 'str'>\n",
      "1227 <class 'str'>\n",
      "4332 <class 'str'>\n",
      "6313 <class 'str'>\n",
      "5529 <class 'str'>\n",
      "4374 <class 'str'>\n",
      "5249 <class 'str'>\n",
      "1555 <class 'str'>\n",
      "6715 <class 'str'>\n",
      "3364 <class 'str'>\n",
      "4392 <class 'str'>\n",
      "6124 <class 'str'>\n",
      "3207 <class 'str'>\n",
      "2729 <class 'str'>\n",
      "1721 <class 'str'>\n",
      "4289 <class 'str'>\n",
      "3093 <class 'str'>\n",
      "879 <class 'str'>\n",
      "4166 <class 'str'>\n",
      "1199 <class 'str'>\n",
      "4005 <class 'str'>\n",
      "1413 <class 'str'>\n",
      "2829 <class 'str'>\n",
      "2329 <class 'str'>\n",
      "2747 <class 'str'>\n",
      "5040 <class 'str'>\n",
      "1613 <class 'str'>\n",
      "1550 <class 'str'>\n",
      "6152 <class 'str'>\n",
      "1310 <class 'str'>\n",
      "5118 <class 'str'>\n",
      "3291 <class 'str'>\n",
      "7428 <class 'str'>\n",
      "939 <class 'str'>\n",
      "7648 <class 'str'>\n",
      "2524 <class 'str'>\n",
      "4013 <class 'str'>\n",
      "7287 <class 'str'>\n",
      "3234 <class 'str'>\n",
      "2598 <class 'str'>\n",
      "4292 <class 'str'>\n",
      "777 <class 'str'>\n",
      "4264 <class 'str'>\n",
      "4706 <class 'str'>\n",
      "2381 <class 'str'>\n",
      "1122 <class 'str'>\n",
      "4919 <class 'str'>\n",
      "2681 <class 'str'>\n",
      "230 <class 'str'>\n",
      "2306 <class 'str'>\n",
      "5847 <class 'str'>\n",
      "6265 <class 'str'>\n",
      "5175 <class 'str'>\n",
      "4777 <class 'str'>\n",
      "5818 <class 'str'>\n",
      "1087 <class 'str'>\n",
      "3618 <class 'str'>\n",
      "2225 <class 'str'>\n",
      "4775 <class 'str'>\n",
      "180 <class 'str'>\n",
      "3596 <class 'str'>\n",
      "2233 <class 'str'>\n",
      "5248 <class 'str'>\n",
      "7536 <class 'str'>\n",
      "1571 <class 'str'>\n",
      "4086 <class 'str'>\n",
      "2191 <class 'str'>\n",
      "5232 <class 'str'>\n",
      "4370 <class 'str'>\n",
      "4643 <class 'str'>\n",
      "2058 <class 'str'>\n",
      "1682 <class 'str'>\n",
      "5972 <class 'str'>\n",
      "2561 <class 'str'>\n",
      "6821 <class 'str'>\n",
      "3479 <class 'str'>\n",
      "6593 <class 'str'>\n",
      "4394 <class 'str'>\n",
      "421 <class 'str'>\n",
      "1881 <class 'str'>\n",
      "3909 <class 'str'>\n",
      "5470 <class 'str'>\n",
      "1088 <class 'str'>\n",
      "6294 <class 'str'>\n",
      "5272 <class 'str'>\n",
      "6831 <class 'str'>\n",
      "6070 <class 'str'>\n",
      "5088 <class 'str'>\n",
      "2433 <class 'str'>\n",
      "1715 <class 'str'>\n",
      "1254 <class 'str'>\n",
      "4911 <class 'str'>\n",
      "1528 <class 'str'>\n",
      "3840 <class 'str'>\n",
      "6465 <class 'str'>\n",
      "3163 <class 'str'>\n",
      "1515 <class 'str'>\n",
      "6661 <class 'str'>\n",
      "2003 <class 'str'>\n",
      "7388 <class 'str'>\n",
      "3489 <class 'str'>\n",
      "466 <class 'str'>\n",
      "4784 <class 'str'>\n",
      "7465 <class 'str'>\n",
      "2460 <class 'str'>\n",
      "5959 <class 'str'>\n",
      "1853 <class 'str'>\n",
      "7293 <class 'str'>\n",
      "7307 <class 'str'>\n",
      "4739 <class 'str'>\n",
      "3340 <class 'str'>\n",
      "6684 <class 'str'>\n",
      "2974 <class 'str'>\n",
      "1844 <class 'str'>\n",
      "405 <class 'str'>\n",
      "1101 <class 'str'>\n",
      "4701 <class 'str'>\n",
      "4513 <class 'str'>\n",
      "4177 <class 'str'>\n",
      "5134 <class 'str'>\n",
      "6192 <class 'str'>\n",
      "2164 <class 'str'>\n",
      "2109 <class 'str'>\n",
      "862 <class 'str'>\n",
      "3421 <class 'str'>\n",
      "697 <class 'str'>\n",
      "7481 <class 'str'>\n",
      "3960 <class 'str'>\n",
      "6959 <class 'str'>\n",
      "6382 <class 'str'>\n",
      "84 <class 'str'>\n",
      "2000 <class 'str'>\n",
      "2890 <class 'str'>\n",
      "5531 <class 'str'>\n",
      "6617 <class 'str'>\n",
      "2015 <class 'str'>\n",
      "5209 <class 'str'>\n",
      "1475 <class 'str'>\n",
      "3959 <class 'str'>\n",
      "1239 <class 'str'>\n",
      "6669 <class 'str'>\n",
      "4183 <class 'str'>\n",
      "1898 <class 'str'>\n",
      "6332 <class 'str'>\n",
      "3433 <class 'str'>\n",
      "6131 <class 'str'>\n",
      "3036 <class 'str'>\n",
      "2309 <class 'str'>\n",
      "3561 <class 'str'>\n",
      "1985 <class 'str'>\n",
      "1019 <class 'str'>\n",
      "5981 <class 'str'>\n",
      "6212 <class 'str'>\n",
      "175 <class 'str'>\n",
      "7702 <class 'str'>\n",
      "7076 <class 'str'>\n",
      "1114 <class 'str'>\n",
      "1255 <class 'str'>\n",
      "325 <class 'str'>\n",
      "7140 <class 'str'>\n",
      "947 <class 'str'>\n",
      "6784 <class 'str'>\n",
      "4940 <class 'str'>\n",
      "4390 <class 'str'>\n",
      "4118 <class 'str'>\n",
      "29 <class 'str'>\n",
      "6243 <class 'str'>\n",
      "3112 <class 'str'>\n",
      "966 <class 'str'>\n",
      "1739 <class 'str'>\n",
      "7177 <class 'str'>\n",
      "6096 <class 'str'>\n",
      "2198 <class 'str'>\n",
      "4530 <class 'str'>\n",
      "470 <class 'str'>\n",
      "6262 <class 'str'>\n",
      "3872 <class 'str'>\n",
      "6720 <class 'str'>\n",
      "2339 <class 'str'>\n",
      "894 <class 'str'>\n",
      "995 <class 'str'>\n",
      "824 <class 'str'>\n",
      "5575 <class 'str'>\n",
      "3182 <class 'str'>\n",
      "6904 <class 'str'>\n",
      "4384 <class 'str'>\n",
      "4850 <class 'str'>\n",
      "4395 <class 'str'>\n",
      "2863 <class 'str'>\n",
      "6183 <class 'str'>\n",
      "3407 <class 'str'>\n",
      "6404 <class 'str'>\n",
      "778 <class 'str'>\n",
      "6871 <class 'str'>\n",
      "5138 <class 'str'>\n",
      "5320 <class 'str'>\n",
      "6486 <class 'str'>\n",
      "412 <class 'str'>\n",
      "5902 <class 'str'>\n",
      "7769 <class 'str'>\n",
      "3947 <class 'str'>\n",
      "832 <class 'str'>\n",
      "335 <class 'str'>\n",
      "5035 <class 'str'>\n",
      "3260 <class 'str'>\n",
      "7459 <class 'str'>\n",
      "2031 <class 'str'>\n",
      "5314 <class 'str'>\n",
      "4301 <class 'str'>\n",
      "2645 <class 'str'>\n",
      "513 <class 'str'>\n",
      "1529 <class 'str'>\n",
      "1393 <class 'str'>\n",
      "4976 <class 'str'>\n",
      "452 <class 'str'>\n",
      "3413 <class 'str'>\n",
      "523 <class 'str'>\n",
      "4358 <class 'str'>\n",
      "3351 <class 'str'>\n",
      "2921 <class 'str'>\n",
      "4233 <class 'str'>\n",
      "1967 <class 'str'>\n",
      "3031 <class 'str'>\n",
      "7412 <class 'str'>\n",
      "2506 <class 'str'>\n",
      "723 <class 'str'>\n",
      "2131 <class 'str'>\n",
      "3078 <class 'str'>\n",
      "679 <class 'str'>\n",
      "1054 <class 'str'>\n",
      "688 <class 'str'>\n",
      "1213 <class 'str'>\n",
      "3257 <class 'str'>\n",
      "6219 <class 'str'>\n",
      "165 <class 'str'>\n",
      "1035 <class 'str'>\n",
      "5688 <class 'str'>\n",
      "886 <class 'str'>\n",
      "6359 <class 'str'>\n",
      "3856 <class 'str'>\n",
      "6397 <class 'str'>\n",
      "5964 <class 'str'>\n",
      "2235 <class 'str'>\n",
      "6390 <class 'str'>\n",
      "7739 <class 'str'>\n",
      "4546 <class 'str'>\n",
      "7390 <class 'str'>\n",
      "1981 <class 'str'>\n",
      "4752 <class 'str'>\n",
      "747 <class 'str'>\n",
      "5929 <class 'str'>\n",
      "6842 <class 'str'>\n",
      "1224 <class 'str'>\n",
      "2685 <class 'str'>\n",
      "938 <class 'str'>\n",
      "834 <class 'str'>\n",
      "4197 <class 'str'>\n",
      "22 <class 'str'>\n",
      "2760 <class 'str'>\n",
      "3964 <class 'str'>\n",
      "1179 <class 'str'>\n",
      "7577 <class 'str'>\n",
      "5355 <class 'str'>\n",
      "659 <class 'str'>\n",
      "5718 <class 'str'>\n",
      "5290 <class 'str'>\n",
      "2780 <class 'str'>\n",
      "3169 <class 'str'>\n",
      "2226 <class 'str'>\n",
      "3850 <class 'str'>\n",
      "7161 <class 'str'>\n",
      "5740 <class 'str'>\n",
      "798 <class 'str'>\n",
      "7505 <class 'str'>\n",
      "3835 <class 'str'>\n",
      "612 <class 'str'>\n",
      "5177 <class 'str'>\n",
      "121 <class 'str'>\n",
      "572 <class 'str'>\n",
      "1762 <class 'str'>\n",
      "4112 <class 'str'>\n",
      "1358 <class 'str'>\n",
      "1591 <class 'str'>\n",
      "7040 <class 'str'>\n",
      "3357 <class 'str'>\n",
      "1013 <class 'str'>\n",
      "6700 <class 'str'>\n",
      "6523 <class 'str'>\n",
      "5165 <class 'str'>\n",
      "5008 <class 'str'>\n",
      "5762 <class 'str'>\n",
      "2899 <class 'str'>\n",
      "5063 <class 'str'>\n",
      "7218 <class 'str'>\n",
      "4201 <class 'str'>\n",
      "7043 <class 'str'>\n",
      "4563 <class 'str'>\n",
      "3197 <class 'str'>\n",
      "7330 <class 'str'>\n",
      "1787 <class 'str'>\n",
      "2442 <class 'str'>\n",
      "6639 <class 'str'>\n",
      "6841 <class 'str'>\n",
      "3092 <class 'str'>\n",
      "1093 <class 'str'>\n",
      "6553 <class 'str'>\n",
      "7462 <class 'str'>\n",
      "4408 <class 'str'>\n",
      "6413 <class 'str'>\n",
      "1634 <class 'str'>\n",
      "3726 <class 'str'>\n",
      "1334 <class 'str'>\n",
      "94 <class 'str'>\n",
      "3713 <class 'str'>\n",
      "6227 <class 'str'>\n",
      "2470 <class 'str'>\n",
      "5142 <class 'str'>\n",
      "187 <class 'str'>\n",
      "4246 <class 'str'>\n",
      "6326 <class 'str'>\n",
      "5747 <class 'str'>\n",
      "2964 <class 'str'>\n",
      "7165 <class 'str'>\n",
      "660 <class 'str'>\n",
      "3044 <class 'str'>\n",
      "4517 <class 'str'>\n",
      "5384 <class 'str'>\n",
      "3570 <class 'str'>\n",
      "6667 <class 'str'>\n",
      "1608 <class 'str'>\n",
      "2165 <class 'str'>\n",
      "5545 <class 'str'>\n",
      "4298 <class 'str'>\n",
      "2672 <class 'str'>\n",
      "1675 <class 'str'>\n",
      "1914 <class 'str'>\n",
      "3266 <class 'str'>\n",
      "2597 <class 'str'>\n",
      "953 <class 'str'>\n",
      "6727 <class 'str'>\n",
      "6780 <class 'str'>\n",
      "5999 <class 'str'>\n",
      "6226 <class 'str'>\n",
      "6688 <class 'str'>\n",
      "698 <class 'str'>\n",
      "5448 <class 'str'>\n",
      "5957 <class 'str'>\n",
      "5560 <class 'str'>\n",
      "5229 <class 'str'>\n",
      "6535 <class 'str'>\n",
      "2106 <class 'str'>\n",
      "2782 <class 'str'>\n",
      "2814 <class 'str'>\n",
      "7419 <class 'str'>\n",
      "3637 <class 'str'>\n",
      "3688 <class 'str'>\n",
      "7244 <class 'str'>\n",
      "2963 <class 'str'>\n",
      "3783 <class 'str'>\n",
      "3444 <class 'str'>\n",
      "5786 <class 'str'>\n",
      "6877 <class 'str'>\n",
      "4310 <class 'str'>\n",
      "1327 <class 'str'>\n",
      "3804 <class 'str'>\n",
      "4009 <class 'str'>\n",
      "2822 <class 'str'>\n",
      "2567 <class 'str'>\n",
      "6311 <class 'str'>\n",
      "5663 <class 'str'>\n",
      "746 <class 'str'>\n",
      "3271 <class 'str'>\n",
      "4852 <class 'str'>\n",
      "7007 <class 'str'>\n",
      "3591 <class 'str'>\n",
      "4146 <class 'str'>\n",
      "5100 <class 'str'>\n",
      "5756 <class 'str'>\n",
      "6304 <class 'str'>\n",
      "7044 <class 'str'>\n",
      "2866 <class 'str'>\n",
      "1866 <class 'str'>\n",
      "6740 <class 'str'>\n",
      "686 <class 'str'>\n",
      "2317 <class 'str'>\n",
      "1948 <class 'str'>\n",
      "2649 <class 'str'>\n",
      "5180 <class 'str'>\n",
      "7797 <class 'str'>\n",
      "4769 <class 'str'>\n",
      "7281 <class 'str'>\n",
      "1995 <class 'str'>\n",
      "5885 <class 'str'>\n",
      "4668 <class 'str'>\n",
      "152 <class 'str'>\n",
      "2734 <class 'str'>\n",
      "2021 <class 'str'>\n",
      "6027 <class 'str'>\n",
      "4314 <class 'str'>\n",
      "4995 <class 'str'>\n",
      "3366 <class 'str'>\n",
      "7829 <class 'str'>\n",
      "1280 <class 'str'>\n",
      "4044 <class 'str'>\n",
      "220 <class 'str'>\n",
      "5419 <class 'str'>\n",
      "6531 <class 'str'>\n",
      "7041 <class 'str'>\n",
      "2114 <class 'str'>\n",
      "5619 <class 'str'>\n",
      "1459 <class 'str'>\n",
      "3471 <class 'str'>\n",
      "5220 <class 'str'>\n",
      "2229 <class 'str'>\n",
      "2028 <class 'str'>\n",
      "6619 <class 'str'>\n",
      "3851 <class 'str'>\n",
      "2611 <class 'str'>\n",
      "5405 <class 'str'>\n",
      "530 <class 'str'>\n",
      "2221 <class 'str'>\n",
      "7486 <class 'str'>\n",
      "2416 <class 'str'>\n",
      "6144 <class 'str'>\n",
      "2439 <class 'str'>\n",
      "3538 <class 'str'>\n",
      "4807 <class 'str'>\n",
      "1482 <class 'str'>\n",
      "3216 <class 'str'>\n",
      "3501 <class 'str'>\n",
      "3353 <class 'str'>\n",
      "1732 <class 'str'>\n",
      "5822 <class 'str'>\n",
      "661 <class 'str'>\n",
      "5064 <class 'str'>\n",
      "5279 <class 'str'>\n",
      "6485 <class 'str'>\n",
      "511 <class 'str'>\n",
      "4439 <class 'str'>\n",
      "6623 <class 'str'>\n",
      "2141 <class 'str'>\n",
      "541 <class 'str'>\n",
      "6590 <class 'str'>\n",
      "2556 <class 'str'>\n",
      "2467 <class 'str'>\n",
      "4645 <class 'str'>\n",
      "5416 <class 'str'>\n",
      "3773 <class 'str'>\n",
      "3606 <class 'str'>\n",
      "2794 <class 'str'>\n",
      "3969 <class 'str'>\n",
      "5104 <class 'str'>\n",
      "3199 <class 'str'>\n",
      "3278 <class 'str'>\n",
      "5032 <class 'str'>\n",
      "469 <class 'str'>\n",
      "4540 <class 'str'>\n",
      "2958 <class 'str'>\n",
      "361 <class 'str'>\n",
      "2674 <class 'str'>\n",
      "1628 <class 'str'>\n",
      "1990 <class 'str'>\n",
      "826 <class 'str'>\n",
      "5067 <class 'str'>\n",
      "3313 <class 'str'>\n",
      "4316 <class 'str'>\n",
      "247 <class 'str'>\n",
      "2158 <class 'str'>\n",
      "968 <class 'str'>\n",
      "2242 <class 'str'>\n",
      "4543 <class 'str'>\n",
      "7628 <class 'str'>\n",
      "3143 <class 'str'>\n",
      "7042 <class 'str'>\n",
      "6008 <class 'str'>\n",
      "4375 <class 'str'>\n",
      "1424 <class 'str'>\n",
      "2888 <class 'str'>\n",
      "876 <class 'str'>\n",
      "6518 <class 'str'>\n",
      "3930 <class 'str'>\n",
      "5273 <class 'str'>\n",
      "2227 <class 'str'>\n",
      "5304 <class 'str'>\n",
      "6220 <class 'str'>\n",
      "7318 <class 'str'>\n",
      "5516 <class 'str'>\n",
      "5736 <class 'str'>\n",
      "7517 <class 'str'>\n",
      "1061 <class 'str'>\n",
      "4720 <class 'str'>\n",
      "6327 <class 'str'>\n",
      "4605 <class 'str'>\n",
      "6963 <class 'str'>\n",
      "588 <class 'str'>\n",
      "3996 <class 'str'>\n",
      "4494 <class 'str'>\n",
      "6176 <class 'str'>\n",
      "5374 <class 'str'>\n",
      "178 <class 'str'>\n",
      "989 <class 'str'>\n",
      "2876 <class 'str'>\n",
      "3342 <class 'str'>\n",
      "4501 <class 'str'>\n",
      "2030 <class 'str'>\n",
      "3782 <class 'str'>\n",
      "5186 <class 'str'>\n",
      "1086 <class 'str'>\n",
      "5480 <class 'str'>\n",
      "1864 <class 'str'>\n",
      "1859 <class 'str'>\n",
      "7062 <class 'str'>\n",
      "1640 <class 'str'>\n",
      "2126 <class 'str'>\n",
      "6717 <class 'str'>\n",
      "7030 <class 'str'>\n",
      "3876 <class 'str'>\n",
      "5567 <class 'str'>\n",
      "479 <class 'str'>\n",
      "5045 <class 'str'>\n",
      "7634 <class 'str'>\n",
      "3752 <class 'str'>\n",
      "5903 <class 'str'>\n",
      "6487 <class 'str'>\n",
      "1932 <class 'str'>\n",
      "2388 <class 'str'>\n",
      "4082 <class 'str'>\n",
      "2189 <class 'str'>\n",
      "4379 <class 'str'>\n",
      "4021 <class 'str'>\n",
      "4238 <class 'str'>\n",
      "4171 <class 'str'>\n",
      "5788 <class 'str'>\n",
      "1226 <class 'str'>\n",
      "4002 <class 'str'>\n",
      "1218 <class 'str'>\n",
      "6622 <class 'str'>\n",
      "2076 <class 'str'>\n",
      "3387 <class 'str'>\n",
      "4100 <class 'str'>\n",
      "902 <class 'str'>\n",
      "5265 <class 'str'>\n",
      "3627 <class 'str'>\n",
      "1332 <class 'str'>\n",
      "594 <class 'str'>\n",
      "6065 <class 'str'>\n",
      "6132 <class 'str'>\n",
      "4556 <class 'str'>\n",
      "6671 <class 'str'>\n",
      "4272 <class 'str'>\n",
      "731 <class 'str'>\n",
      "719 <class 'str'>\n",
      "5428 <class 'str'>\n",
      "2819 <class 'str'>\n",
      "2836 <class 'str'>\n",
      "6550 <class 'str'>\n",
      "5203 <class 'str'>\n",
      "3105 <class 'str'>\n",
      "7439 <class 'str'>\n",
      "6598 <class 'str'>\n",
      "3005 <class 'str'>\n",
      "2684 <class 'str'>\n",
      "4204 <class 'str'>\n",
      "2955 <class 'str'>\n",
      "2736 <class 'str'>\n",
      "909 <class 'str'>\n",
      "2481 <class 'str'>\n",
      "5732 <class 'str'>\n",
      "7336 <class 'str'>\n",
      "4167 <class 'str'>\n",
      "4898 <class 'str'>\n",
      "3043 <class 'str'>\n",
      "875 <class 'str'>\n",
      "7784 <class 'str'>\n",
      "7090 <class 'str'>\n",
      "4236 <class 'str'>\n",
      "1016 <class 'str'>\n",
      "744 <class 'str'>\n",
      "1724 <class 'str'>\n",
      "268 <class 'str'>\n",
      "6014 <class 'str'>\n",
      "4935 <class 'str'>\n",
      "4731 <class 'str'>\n",
      "1716 <class 'str'>\n",
      "4916 <class 'str'>\n",
      "5928 <class 'str'>\n",
      "3619 <class 'str'>\n",
      "5548 <class 'str'>\n",
      "616 <class 'str'>\n",
      "4504 <class 'str'>\n",
      "3631 <class 'str'>\n",
      "923 <class 'str'>\n",
      "2584 <class 'str'>\n",
      "1398 <class 'str'>\n",
      "4022 <class 'str'>\n",
      "5587 <class 'str'>\n",
      "3186 <class 'str'>\n",
      "3354 <class 'str'>\n",
      "4557 <class 'str'>\n",
      "982 <class 'str'>\n",
      "3791 <class 'str'>\n",
      "5776 <class 'str'>\n",
      "2939 <class 'str'>\n",
      "2967 <class 'str'>\n",
      "4632 <class 'str'>\n",
      "625 <class 'str'>\n",
      "6260 <class 'str'>\n",
      "3867 <class 'str'>\n",
      "3703 <class 'str'>\n",
      "5494 <class 'str'>\n",
      "2737 <class 'str'>\n",
      "736 <class 'str'>\n",
      "4154 <class 'str'>\n",
      "1747 <class 'str'>\n",
      "4885 <class 'str'>\n",
      "2186 <class 'str'>\n",
      "123 <class 'str'>\n",
      "6781 <class 'str'>\n",
      "5407 <class 'str'>\n",
      "2425 <class 'str'>\n",
      "4300 <class 'str'>\n",
      "4490 <class 'str'>\n",
      "1283 <class 'str'>\n",
      "1644 <class 'str'>\n",
      "4869 <class 'str'>\n",
      "4320 <class 'str'>\n",
      "298 <class 'str'>\n",
      "2374 <class 'str'>\n",
      "1165 <class 'str'>\n",
      "2223 <class 'str'>\n",
      "7389 <class 'str'>\n",
      "5337 <class 'str'>\n",
      "2228 <class 'str'>\n",
      "2562 <class 'str'>\n",
      "1882 <class 'str'>\n",
      "7753 <class 'str'>\n",
      "2159 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['notRepairedDamage'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OF2uK3mK0V0y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1750469706424,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "OF2uK3mK0V0y",
    "outputId": "01455bd4-c0e7-4751-fc69-88a51c3b604e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>104864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>31105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "gearbox\n",
       "0.0      104864\n",
       "1.0       31105\n",
       "0          3373\n",
       "15.0       1517\n",
       "-          1387\n",
       "          ...  \n",
       "1988          1\n",
       "2598          1\n",
       "436           1\n",
       "19312         1\n",
       "191           1\n",
       "Name: count, Length: 302, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['gearbox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w-YfzBWs0tbv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1750469723434,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "w-YfzBWs0tbv",
    "outputId": "edafeec1-208a-4136-db3c-33ad0d49b790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 <class 'str'>\n",
      "1.0 <class 'str'>\n",
      "15.0 <class 'str'>\n",
      "90 <class 'str'>\n",
      "60 <class 'str'>\n",
      "0 <class 'str'>\n",
      "115 <class 'str'>\n",
      "50 <class 'str'>\n",
      "- <class 'str'>\n",
      "142 <class 'str'>\n",
      "8.0 <class 'str'>\n",
      "265 <class 'str'>\n",
      "101 <class 'str'>\n",
      "170 <class 'str'>\n",
      "190 <class 'str'>\n",
      "349 <class 'str'>\n",
      "61 <class 'str'>\n",
      "12.5 <class 'str'>\n",
      "150 <class 'str'>\n",
      "45 <class 'str'>\n",
      "65 <class 'str'>\n",
      "75 <class 'str'>\n",
      "54 <class 'str'>\n",
      "187 <class 'str'>\n",
      "136 <class 'str'>\n",
      "125 <class 'str'>\n",
      "143 <class 'str'>\n",
      "58 <class 'str'>\n",
      "70 <class 'str'>\n",
      "29 <class 'str'>\n",
      "74 <class 'str'>\n",
      "95 <class 'str'>\n",
      "55 <class 'str'>\n",
      "167 <class 'str'>\n",
      "116 <class 'str'>\n",
      "120 <class 'str'>\n",
      "140 <class 'str'>\n",
      "163 <class 'str'>\n",
      "33 <class 'str'>\n",
      "2.0 <class 'str'>\n",
      "56 <class 'str'>\n",
      "110 <class 'str'>\n",
      "131 <class 'str'>\n",
      "250 <class 'str'>\n",
      "100 <class 'str'>\n",
      "211 <class 'str'>\n",
      "71 <class 'str'>\n",
      "10.0 <class 'str'>\n",
      "102 <class 'str'>\n",
      "88 <class 'str'>\n",
      "5.0 <class 'str'>\n",
      "165 <class 'str'>\n",
      "64 <class 'str'>\n",
      "179 <class 'str'>\n",
      "73 <class 'str'>\n",
      "400 <class 'str'>\n",
      "87 <class 'str'>\n",
      "238 <class 'str'>\n",
      "86 <class 'str'>\n",
      "105 <class 'str'>\n",
      "107 <class 'str'>\n",
      "144 <class 'str'>\n",
      "6.0 <class 'str'>\n",
      "94 <class 'str'>\n",
      "177 <class 'str'>\n",
      "135 <class 'str'>\n",
      "80 <class 'str'>\n",
      "301 <class 'str'>\n",
      "72 <class 'str'>\n",
      "147 <class 'str'>\n",
      "122 <class 'str'>\n",
      "77 <class 'str'>\n",
      "0.5 <class 'str'>\n",
      "160 <class 'str'>\n",
      "44 <class 'str'>\n",
      "207 <class 'str'>\n",
      "68 <class 'str'>\n",
      "155 <class 'str'>\n",
      "82 <class 'str'>\n",
      "158 <class 'str'>\n",
      "109 <class 'str'>\n",
      "133 <class 'str'>\n",
      "200 <class 'str'>\n",
      "103 <class 'str'>\n",
      "130 <class 'str'>\n",
      "41 <class 'str'>\n",
      "20 <class 'str'>\n",
      "193 <class 'str'>\n",
      "89 <class 'str'>\n",
      "84 <class 'str'>\n",
      "9.0 <class 'str'>\n",
      "278 <class 'str'>\n",
      "292 <class 'str'>\n",
      "121 <class 'str'>\n",
      "258 <class 'str'>\n",
      "286 <class 'str'>\n",
      "240 <class 'str'>\n",
      "113 <class 'str'>\n",
      "7.0 <class 'str'>\n",
      "66 <class 'str'>\n",
      "218 <class 'str'>\n",
      "195 <class 'str'>\n",
      "192 <class 'str'>\n",
      "507 <class 'str'>\n",
      "299 <class 'str'>\n",
      "108 <class 'str'>\n",
      "174 <class 'str'>\n",
      "67 <class 'str'>\n",
      "232 <class 'str'>\n",
      "224 <class 'str'>\n",
      "184 <class 'str'>\n",
      "40 <class 'str'>\n",
      "52 <class 'str'>\n",
      "114 <class 'str'>\n",
      "275 <class 'str'>\n",
      "78 <class 'str'>\n",
      "272 <class 'str'>\n",
      "137 <class 'str'>\n",
      "69 <class 'str'>\n",
      "145 <class 'str'>\n",
      "4.0 <class 'str'>\n",
      "220 <class 'str'>\n",
      "1 <class 'str'>\n",
      "96 <class 'str'>\n",
      "6920 <class 'str'>\n",
      "12 <class 'str'>\n",
      "235 <class 'str'>\n",
      "129 <class 'str'>\n",
      "280 <class 'str'>\n",
      "104 <class 'str'>\n",
      "366 <class 'str'>\n",
      "492 <class 'str'>\n",
      "97 <class 'str'>\n",
      "149 <class 'str'>\n",
      "185 <class 'str'>\n",
      "230 <class 'str'>\n",
      "1500 <class 'str'>\n",
      "39 <class 'str'>\n",
      "204 <class 'str'>\n",
      "252 <class 'str'>\n",
      "98 <class 'str'>\n",
      "206 <class 'str'>\n",
      "175 <class 'str'>\n",
      "306 <class 'str'>\n",
      "300 <class 'str'>\n",
      "106 <class 'str'>\n",
      "166 <class 'str'>\n",
      "63 <class 'str'>\n",
      "57 <class 'str'>\n",
      "227 <class 'str'>\n",
      "85 <class 'str'>\n",
      "132 <class 'str'>\n",
      "1082 <class 'str'>\n",
      "156 <class 'str'>\n",
      "118 <class 'str'>\n",
      "148 <class 'str'>\n",
      "333 <class 'str'>\n",
      "196 <class 'str'>\n",
      "180 <class 'str'>\n",
      "3.0 <class 'str'>\n",
      "182 <class 'str'>\n",
      "141 <class 'str'>\n",
      "126 <class 'str'>\n",
      "92 <class 'str'>\n",
      "198 <class 'str'>\n",
      "285 <class 'str'>\n",
      "146 <class 'str'>\n",
      "4 <class 'str'>\n",
      "335 <class 'str'>\n",
      "134 <class 'str'>\n",
      "154 <class 'str'>\n",
      "197 <class 'str'>\n",
      "313 <class 'str'>\n",
      "151 <class 'str'>\n",
      "231 <class 'str'>\n",
      "128 <class 'str'>\n",
      "53 <class 'str'>\n",
      "210 <class 'str'>\n",
      "186 <class 'str'>\n",
      "83 <class 'str'>\n",
      "460 <class 'str'>\n",
      "51 <class 'str'>\n",
      "1011 <class 'str'>\n",
      "81 <class 'str'>\n",
      "47 <class 'str'>\n",
      "320 <class 'str'>\n",
      "245 <class 'str'>\n",
      "59 <class 'str'>\n",
      "305 <class 'str'>\n",
      "279 <class 'str'>\n",
      "5 <class 'str'>\n",
      "241 <class 'str'>\n",
      "631 <class 'str'>\n",
      "408 <class 'str'>\n",
      "124 <class 'str'>\n",
      "181 <class 'str'>\n",
      "297 <class 'str'>\n",
      "112 <class 'str'>\n",
      "194 <class 'str'>\n",
      "303 <class 'str'>\n",
      "338 <class 'str'>\n",
      "79 <class 'str'>\n",
      "225 <class 'str'>\n",
      "173 <class 'str'>\n",
      "260 <class 'str'>\n",
      "380 <class 'str'>\n",
      "76 <class 'str'>\n",
      "215 <class 'str'>\n",
      "367 <class 'str'>\n",
      "159 <class 'str'>\n",
      "123 <class 'str'>\n",
      "168 <class 'str'>\n",
      "385 <class 'str'>\n",
      "213 <class 'str'>\n",
      "176 <class 'str'>\n",
      "237 <class 'str'>\n",
      "222 <class 'str'>\n",
      "343 <class 'str'>\n",
      "46 <class 'str'>\n",
      "212 <class 'str'>\n",
      "236 <class 'str'>\n",
      "350 <class 'str'>\n",
      "111 <class 'str'>\n",
      "500 <class 'str'>\n",
      "390 <class 'str'>\n",
      "513 <class 'str'>\n",
      "164 <class 'str'>\n",
      "256 <class 'str'>\n",
      "48 <class 'str'>\n",
      "1090 <class 'str'>\n",
      "25 <class 'str'>\n",
      "117 <class 'str'>\n",
      "139 <class 'str'>\n",
      "420 <class 'str'>\n",
      "169 <class 'str'>\n",
      "340 <class 'str'>\n",
      "360 <class 'str'>\n",
      "239 <class 'str'>\n",
      "99 <class 'str'>\n",
      "226 <class 'str'>\n",
      "162 <class 'str'>\n",
      "178 <class 'str'>\n",
      "62 <class 'str'>\n",
      "43 <class 'str'>\n",
      "439 <class 'str'>\n",
      "15 <class 'str'>\n",
      "354 <class 'str'>\n",
      "201 <class 'str'>\n",
      "318 <class 'str'>\n",
      "430 <class 'str'>\n",
      "37 <class 'str'>\n",
      "171 <class 'str'>\n",
      "450 <class 'str'>\n",
      "2172 <class 'str'>\n",
      "388 <class 'str'>\n",
      "188 <class 'str'>\n",
      "234 <class 'str'>\n",
      "358 <class 'str'>\n",
      "1503 <class 'str'>\n",
      "289 <class 'str'>\n",
      "1922 <class 'str'>\n",
      "16 <class 'str'>\n",
      "127 <class 'str'>\n",
      "243 <class 'str'>\n",
      "1988 <class 'str'>\n",
      "209 <class 'str'>\n",
      "602 <class 'str'>\n",
      "521 <class 'str'>\n",
      "203 <class 'str'>\n",
      "270 <class 'str'>\n",
      "732 <class 'str'>\n",
      "172 <class 'str'>\n",
      "3500 <class 'str'>\n",
      "1995 <class 'str'>\n",
      "233 <class 'str'>\n",
      "119 <class 'str'>\n",
      "435 <class 'str'>\n",
      "7512 <class 'str'>\n",
      "30 <class 'str'>\n",
      "138 <class 'str'>\n",
      "42 <class 'str'>\n",
      "515 <class 'str'>\n",
      "2017 <class 'str'>\n",
      "205 <class 'str'>\n",
      "276 <class 'str'>\n",
      "489 <class 'str'>\n",
      "17 <class 'str'>\n",
      "91 <class 'str'>\n",
      "345 <class 'str'>\n",
      "214 <class 'str'>\n",
      "612 <class 'str'>\n",
      "1256 <class 'str'>\n",
      "1005 <class 'str'>\n",
      "208 <class 'str'>\n",
      "161 <class 'str'>\n",
      "1003 <class 'str'>\n",
      "310 <class 'str'>\n",
      "487 <class 'str'>\n",
      "2598 <class 'str'>\n",
      "436 <class 'str'>\n",
      "19312 <class 'str'>\n",
      "191 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['gearbox'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZwNlfJ8m01Ix",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1750469727233,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "ZwNlfJ8m01Ix",
    "outputId": "3d881c43-4aea-4ceb-fcd4-26d864e2ea76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>7793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>6091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6677</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17700</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "power\n",
       "75       8798\n",
       "15.0     7793\n",
       "0        7186\n",
       "150      6091\n",
       "60       5781\n",
       "         ... \n",
       "6677        1\n",
       "5886        1\n",
       "5240        1\n",
       "3757        1\n",
       "17700       1\n",
       "Name: count, Length: 1573, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['power'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YgTNO8UY1fOS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1750469729843,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "YgTNO8UY1fOS",
    "outputId": "9cf7d835-d1dc-4e5e-c98d-e79d8f64bdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 <class 'str'>\n",
      "0 <class 'str'>\n",
      "163 <class 'str'>\n",
      "193 <class 'str'>\n",
      "68 <class 'str'>\n",
      "109 <class 'str'>\n",
      "150 <class 'str'>\n",
      "101 <class 'str'>\n",
      "179 <class 'str'>\n",
      "88 <class 'str'>\n",
      "75 <class 'str'>\n",
      "58 <class 'str'>\n",
      "- <class 'str'>\n",
      "128 <class 'str'>\n",
      "239 <class 'str'>\n",
      "145 <class 'str'>\n",
      "45 <class 'str'>\n",
      "105 <class 'str'>\n",
      "54 <class 'str'>\n",
      "143 <class 'str'>\n",
      "218 <class 'str'>\n",
      "170 <class 'str'>\n",
      "90 <class 'str'>\n",
      "306 <class 'str'>\n",
      "133 <class 'str'>\n",
      "116 <class 'str'>\n",
      "15.0 <class 'str'>\n",
      "102 <class 'str'>\n",
      "177 <class 'str'>\n",
      "140 <class 'str'>\n",
      "115 <class 'str'>\n",
      "180 <class 'str'>\n",
      "131 <class 'str'>\n",
      "110 <class 'str'>\n",
      "160 <class 'str'>\n",
      "65 <class 'str'>\n",
      "120 <class 'str'>\n",
      "73 <class 'str'>\n",
      "77 <class 'str'>\n",
      "500 <class 'str'>\n",
      "136 <class 'str'>\n",
      "233 <class 'str'>\n",
      "125 <class 'str'>\n",
      "300 <class 'str'>\n",
      "190 <class 'str'>\n",
      "192 <class 'str'>\n",
      "126 <class 'str'>\n",
      "203 <class 'str'>\n",
      "55 <class 'str'>\n",
      "100 <class 'str'>\n",
      "122 <class 'str'>\n",
      "174 <class 'str'>\n",
      "69 <class 'str'>\n",
      "165 <class 'str'>\n",
      "320 <class 'str'>\n",
      "64 <class 'str'>\n",
      "78 <class 'str'>\n",
      "224 <class 'str'>\n",
      "80 <class 'str'>\n",
      "71 <class 'str'>\n",
      "340 <class 'str'>\n",
      "144 <class 'str'>\n",
      "387 <class 'str'>\n",
      "230 <class 'str'>\n",
      "86 <class 'str'>\n",
      "0.5 <class 'str'>\n",
      "111 <class 'str'>\n",
      "12.5 <class 'str'>\n",
      "107 <class 'str'>\n",
      "61 <class 'str'>\n",
      "103 <class 'str'>\n",
      "63 <class 'str'>\n",
      "95 <class 'str'>\n",
      "204 <class 'str'>\n",
      "40 <class 'str'>\n",
      "284 <class 'str'>\n",
      "3.0 <class 'str'>\n",
      "740 <class 'str'>\n",
      "97 <class 'str'>\n",
      "8.0 <class 'str'>\n",
      "1.0 <class 'str'>\n",
      "272 <class 'str'>\n",
      "50 <class 'str'>\n",
      "87 <class 'str'>\n",
      "260 <class 'str'>\n",
      "135 <class 'str'>\n",
      "0.0 <class 'str'>\n",
      "9.0 <class 'str'>\n",
      "211 <class 'str'>\n",
      "106 <class 'str'>\n",
      "200 <class 'str'>\n",
      "333 <class 'str'>\n",
      "220 <class 'str'>\n",
      "10.0 <class 'str'>\n",
      "299 <class 'str'>\n",
      "114 <class 'str'>\n",
      "67 <class 'str'>\n",
      "245 <class 'str'>\n",
      "82 <class 'str'>\n",
      "196 <class 'str'>\n",
      "258 <class 'str'>\n",
      "4.0 <class 'str'>\n",
      "70 <class 'str'>\n",
      "155 <class 'str'>\n",
      "313 <class 'str'>\n",
      "113 <class 'str'>\n",
      "1135 <class 'str'>\n",
      "184 <class 'str'>\n",
      "345 <class 'str'>\n",
      "108 <class 'str'>\n",
      "98 <class 'str'>\n",
      "129 <class 'str'>\n",
      "84 <class 'str'>\n",
      "59 <class 'str'>\n",
      "250 <class 'str'>\n",
      "321 <class 'str'>\n",
      "235 <class 'str'>\n",
      "256 <class 'str'>\n",
      "231 <class 'str'>\n",
      "252 <class 'str'>\n",
      "7515 <class 'str'>\n",
      "197 <class 'str'>\n",
      "280 <class 'str'>\n",
      "1224 <class 'str'>\n",
      "41 <class 'str'>\n",
      "185 <class 'str'>\n",
      "232 <class 'str'>\n",
      "396 <class 'str'>\n",
      "43 <class 'str'>\n",
      "205 <class 'str'>\n",
      "1945 <class 'str'>\n",
      "99 <class 'str'>\n",
      "104 <class 'str'>\n",
      "85 <class 'str'>\n",
      "431 <class 'str'>\n",
      "225 <class 'str'>\n",
      "156 <class 'str'>\n",
      "46 <class 'str'>\n",
      "226 <class 'str'>\n",
      "175 <class 'str'>\n",
      "424 <class 'str'>\n",
      "92 <class 'str'>\n",
      "1398 <class 'str'>\n",
      "121 <class 'str'>\n",
      "130 <class 'str'>\n",
      "172 <class 'str'>\n",
      "91 <class 'str'>\n",
      "315 <class 'str'>\n",
      "141 <class 'str'>\n",
      "334 <class 'str'>\n",
      "119 <class 'str'>\n",
      "132 <class 'str'>\n",
      "420 <class 'str'>\n",
      "147 <class 'str'>\n",
      "305 <class 'str'>\n",
      "4 <class 'str'>\n",
      "118 <class 'str'>\n",
      "44 <class 'str'>\n",
      "582 <class 'str'>\n",
      "1233 <class 'str'>\n",
      "117 <class 'str'>\n",
      "240 <class 'str'>\n",
      "112 <class 'str'>\n",
      "241 <class 'str'>\n",
      "385 <class 'str'>\n",
      "564 <class 'str'>\n",
      "124 <class 'str'>\n",
      "1652 <class 'str'>\n",
      "7.0 <class 'str'>\n",
      "194 <class 'str'>\n",
      "2.0 <class 'str'>\n",
      "450 <class 'str'>\n",
      "83 <class 'str'>\n",
      "1143 <class 'str'>\n",
      "182 <class 'str'>\n",
      "6.0 <class 'str'>\n",
      "286 <class 'str'>\n",
      "408 <class 'str'>\n",
      "1386 <class 'str'>\n",
      "3377 <class 'str'>\n",
      "3521 <class 'str'>\n",
      "39 <class 'str'>\n",
      "265 <class 'str'>\n",
      "5499 <class 'str'>\n",
      "2128 <class 'str'>\n",
      "1830 <class 'str'>\n",
      "56 <class 'str'>\n",
      "207 <class 'str'>\n",
      "1836 <class 'str'>\n",
      "581 <class 'str'>\n",
      "76 <class 'str'>\n",
      "367 <class 'str'>\n",
      "400 <class 'str'>\n",
      "137 <class 'str'>\n",
      "166 <class 'str'>\n",
      "355 <class 'str'>\n",
      "295 <class 'str'>\n",
      "151 <class 'str'>\n",
      "480 <class 'str'>\n",
      "74 <class 'str'>\n",
      "51 <class 'str'>\n",
      "555 <class 'str'>\n",
      "52 <class 'str'>\n",
      "4020 <class 'str'>\n",
      "57 <class 'str'>\n",
      "158 <class 'str'>\n",
      "167 <class 'str'>\n",
      "72 <class 'str'>\n",
      "94 <class 'str'>\n",
      "139 <class 'str'>\n",
      "349 <class 'str'>\n",
      "138 <class 'str'>\n",
      "2182 <class 'str'>\n",
      "5.0 <class 'str'>\n",
      "171 <class 'str'>\n",
      "275 <class 'str'>\n",
      "186 <class 'str'>\n",
      "354 <class 'str'>\n",
      "2623 <class 'str'>\n",
      "134 <class 'str'>\n",
      "322 <class 'str'>\n",
      "5 <class 'str'>\n",
      "148 <class 'str'>\n",
      "360 <class 'str'>\n",
      "271 <class 'str'>\n",
      "3436 <class 'str'>\n",
      "560 <class 'str'>\n",
      "290 <class 'str'>\n",
      "79 <class 'str'>\n",
      "1452 <class 'str'>\n",
      "1000 <class 'str'>\n",
      "3856 <class 'str'>\n",
      "343 <class 'str'>\n",
      "237 <class 'str'>\n",
      "7186 <class 'str'>\n",
      "254 <class 'str'>\n",
      "1518 <class 'str'>\n",
      "457 <class 'str'>\n",
      "53 <class 'str'>\n",
      "152 <class 'str'>\n",
      "4008 <class 'str'>\n",
      "89 <class 'str'>\n",
      "869 <class 'str'>\n",
      "209 <class 'str'>\n",
      "6332 <class 'str'>\n",
      "2452 <class 'str'>\n",
      "373 <class 'str'>\n",
      "344 <class 'str'>\n",
      "181 <class 'str'>\n",
      "3463 <class 'str'>\n",
      "746 <class 'str'>\n",
      "162 <class 'str'>\n",
      "173 <class 'str'>\n",
      "883 <class 'str'>\n",
      "259 <class 'str'>\n",
      "350 <class 'str'>\n",
      "2684 <class 'str'>\n",
      "3166 <class 'str'>\n",
      "66 <class 'str'>\n",
      "601 <class 'str'>\n",
      "195 <class 'str'>\n",
      "292 <class 'str'>\n",
      "123 <class 'str'>\n",
      "187 <class 'str'>\n",
      "249 <class 'str'>\n",
      "2285 <class 'str'>\n",
      "243 <class 'str'>\n",
      "404 <class 'str'>\n",
      "169 <class 'str'>\n",
      "900 <class 'str'>\n",
      "1771 <class 'str'>\n",
      "1085 <class 'str'>\n",
      "62 <class 'str'>\n",
      "3874 <class 'str'>\n",
      "309 <class 'str'>\n",
      "1598 <class 'str'>\n",
      "310 <class 'str'>\n",
      "7033 <class 'str'>\n",
      "48 <class 'str'>\n",
      "326 <class 'str'>\n",
      "3060 <class 'str'>\n",
      "587 <class 'str'>\n",
      "6551 <class 'str'>\n",
      "1653 <class 'str'>\n",
      "3576 <class 'str'>\n",
      "146 <class 'str'>\n",
      "3518 <class 'str'>\n",
      "1713 <class 'str'>\n",
      "476 <class 'str'>\n",
      "210 <class 'str'>\n",
      "242 <class 'str'>\n",
      "176 <class 'str'>\n",
      "557 <class 'str'>\n",
      "4484 <class 'str'>\n",
      "407 <class 'str'>\n",
      "159 <class 'str'>\n",
      "24 <class 'str'>\n",
      "981 <class 'str'>\n",
      "11 <class 'str'>\n",
      "188 <class 'str'>\n",
      "10218 <class 'str'>\n",
      "164 <class 'str'>\n",
      "416 <class 'str'>\n",
      "4128 <class 'str'>\n",
      "2509 <class 'str'>\n",
      "3168 <class 'str'>\n",
      "4732 <class 'str'>\n",
      "2482 <class 'str'>\n",
      "329 <class 'str'>\n",
      "9 <class 'str'>\n",
      "238 <class 'str'>\n",
      "386 <class 'str'>\n",
      "4445 <class 'str'>\n",
      "365 <class 'str'>\n",
      "525 <class 'str'>\n",
      "615 <class 'str'>\n",
      "47 <class 'str'>\n",
      "4669 <class 'str'>\n",
      "3113 <class 'str'>\n",
      "497 <class 'str'>\n",
      "1103 <class 'str'>\n",
      "5264 <class 'str'>\n",
      "127 <class 'str'>\n",
      "2197 <class 'str'>\n",
      "1004 <class 'str'>\n",
      "435 <class 'str'>\n",
      "178 <class 'str'>\n",
      "951 <class 'str'>\n",
      "328 <class 'str'>\n",
      "2893 <class 'str'>\n",
      "253 <class 'str'>\n",
      "330 <class 'str'>\n",
      "8500 <class 'str'>\n",
      "436 <class 'str'>\n",
      "4478 <class 'str'>\n",
      "510 <class 'str'>\n",
      "3973 <class 'str'>\n",
      "1369 <class 'str'>\n",
      "2024 <class 'str'>\n",
      "325 <class 'str'>\n",
      "3365 <class 'str'>\n",
      "201 <class 'str'>\n",
      "273 <class 'str'>\n",
      "314 <class 'str'>\n",
      "6530 <class 'str'>\n",
      "405 <class 'str'>\n",
      "449 <class 'str'>\n",
      "1800 <class 'str'>\n",
      "12 <class 'str'>\n",
      "5962 <class 'str'>\n",
      "3345 <class 'str'>\n",
      "142 <class 'str'>\n",
      "6081 <class 'str'>\n",
      "1692 <class 'str'>\n",
      "2096 <class 'str'>\n",
      "3361 <class 'str'>\n",
      "149 <class 'str'>\n",
      "552 <class 'str'>\n",
      "198 <class 'str'>\n",
      "4727 <class 'str'>\n",
      "1129 <class 'str'>\n",
      "1347 <class 'str'>\n",
      "6067 <class 'str'>\n",
      "514 <class 'str'>\n",
      "352 <class 'str'>\n",
      "1917 <class 'str'>\n",
      "208 <class 'str'>\n",
      "168 <class 'str'>\n",
      "2362 <class 'str'>\n",
      "1051 <class 'str'>\n",
      "6039 <class 'str'>\n",
      "1049 <class 'str'>\n",
      "6227 <class 'str'>\n",
      "234 <class 'str'>\n",
      "2247 <class 'str'>\n",
      "6929 <class 'str'>\n",
      "4402 <class 'str'>\n",
      "5420 <class 'str'>\n",
      "247 <class 'str'>\n",
      "216 <class 'str'>\n",
      "1156 <class 'str'>\n",
      "540 <class 'str'>\n",
      "2385 <class 'str'>\n",
      "31 <class 'str'>\n",
      "189 <class 'str'>\n",
      "1874 <class 'str'>\n",
      "279 <class 'str'>\n",
      "611 <class 'str'>\n",
      "228 <class 'str'>\n",
      "1101 <class 'str'>\n",
      "5468 <class 'str'>\n",
      "212 <class 'str'>\n",
      "5159 <class 'str'>\n",
      "3790 <class 'str'>\n",
      "432 <class 'str'>\n",
      "5434 <class 'str'>\n",
      "1 <class 'str'>\n",
      "516 <class 'str'>\n",
      "1422 <class 'str'>\n",
      "2562 <class 'str'>\n",
      "5550 <class 'str'>\n",
      "4378 <class 'str'>\n",
      "335 <class 'str'>\n",
      "3877 <class 'str'>\n",
      "1027 <class 'str'>\n",
      "1624 <class 'str'>\n",
      "2978 <class 'str'>\n",
      "261 <class 'str'>\n",
      "1196 <class 'str'>\n",
      "376 <class 'str'>\n",
      "3742 <class 'str'>\n",
      "37 <class 'str'>\n",
      "421 <class 'str'>\n",
      "3388 <class 'str'>\n",
      "296 <class 'str'>\n",
      "5554 <class 'str'>\n",
      "2296 <class 'str'>\n",
      "33 <class 'str'>\n",
      "154 <class 'str'>\n",
      "2062 <class 'str'>\n",
      "81 <class 'str'>\n",
      "3154 <class 'str'>\n",
      "1581 <class 'str'>\n",
      "3611 <class 'str'>\n",
      "3501 <class 'str'>\n",
      "6329 <class 'str'>\n",
      "18 <class 'str'>\n",
      "262 <class 'str'>\n",
      "5951 <class 'str'>\n",
      "6933 <class 'str'>\n",
      "96 <class 'str'>\n",
      "277 <class 'str'>\n",
      "4459 <class 'str'>\n",
      "764 <class 'str'>\n",
      "5788 <class 'str'>\n",
      "6489 <class 'str'>\n",
      "6455 <class 'str'>\n",
      "4491 <class 'str'>\n",
      "1760 <class 'str'>\n",
      "1404 <class 'str'>\n",
      "2773 <class 'str'>\n",
      "3000 <class 'str'>\n",
      "214 <class 'str'>\n",
      "5507 <class 'str'>\n",
      "4817 <class 'str'>\n",
      "1627 <class 'str'>\n",
      "2798 <class 'str'>\n",
      "353 <class 'str'>\n",
      "409 <class 'str'>\n",
      "3340 <class 'str'>\n",
      "380 <class 'str'>\n",
      "3304 <class 'str'>\n",
      "2205 <class 'str'>\n",
      "1891 <class 'str'>\n",
      "370 <class 'str'>\n",
      "5529 <class 'str'>\n",
      "7779 <class 'str'>\n",
      "401 <class 'str'>\n",
      "4627 <class 'str'>\n",
      "507 <class 'str'>\n",
      "4891 <class 'str'>\n",
      "585 <class 'str'>\n",
      "904 <class 'str'>\n",
      "6325 <class 'str'>\n",
      "1609 <class 'str'>\n",
      "3863 <class 'str'>\n",
      "257 <class 'str'>\n",
      "213 <class 'str'>\n",
      "2986 <class 'str'>\n",
      "5056 <class 'str'>\n",
      "5088 <class 'str'>\n",
      "2133 <class 'str'>\n",
      "274 <class 'str'>\n",
      "2145 <class 'str'>\n",
      "1350 <class 'str'>\n",
      "215 <class 'str'>\n",
      "2932 <class 'str'>\n",
      "153 <class 'str'>\n",
      "5356 <class 'str'>\n",
      "1271 <class 'str'>\n",
      "2470 <class 'str'>\n",
      "2477 <class 'str'>\n",
      "799 <class 'str'>\n",
      "723 <class 'str'>\n",
      "5185 <class 'str'>\n",
      "285 <class 'str'>\n",
      "246 <class 'str'>\n",
      "3536 <class 'str'>\n",
      "362 <class 'str'>\n",
      "2111 <class 'str'>\n",
      "1599 <class 'str'>\n",
      "270 <class 'str'>\n",
      "5324 <class 'str'>\n",
      "1324 <class 'str'>\n",
      "4031 <class 'str'>\n",
      "2083 <class 'str'>\n",
      "1685 <class 'str'>\n",
      "6150 <class 'str'>\n",
      "3 <class 'str'>\n",
      "4164 <class 'str'>\n",
      "3850 <class 'str'>\n",
      "442 <class 'str'>\n",
      "26 <class 'str'>\n",
      "5940 <class 'str'>\n",
      "551 <class 'str'>\n",
      "6178 <class 'str'>\n",
      "1694 <class 'str'>\n",
      "6846 <class 'str'>\n",
      "2496 <class 'str'>\n",
      "2725 <class 'str'>\n",
      "579 <class 'str'>\n",
      "1086 <class 'str'>\n",
      "6 <class 'str'>\n",
      "689 <class 'str'>\n",
      "1333 <class 'str'>\n",
      "3015 <class 'str'>\n",
      "1801 <class 'str'>\n",
      "950 <class 'str'>\n",
      "6644 <class 'str'>\n",
      "6111 <class 'str'>\n",
      "1900 <class 'str'>\n",
      "287 <class 'str'>\n",
      "4292 <class 'str'>\n",
      "4755 <class 'str'>\n",
      "42 <class 'str'>\n",
      "666 <class 'str'>\n",
      "1021 <class 'str'>\n",
      "4694 <class 'str'>\n",
      "1447 <class 'str'>\n",
      "5838 <class 'str'>\n",
      "10520 <class 'str'>\n",
      "278 <class 'str'>\n",
      "955 <class 'str'>\n",
      "2135 <class 'str'>\n",
      "5936 <class 'str'>\n",
      "1433 <class 'str'>\n",
      "2090 <class 'str'>\n",
      "4063 <class 'str'>\n",
      "3573 <class 'str'>\n",
      "4839 <class 'str'>\n",
      "506 <class 'str'>\n",
      "347 <class 'str'>\n",
      "3504 <class 'str'>\n",
      "6786 <class 'str'>\n",
      "4215 <class 'str'>\n",
      "1843 <class 'str'>\n",
      "2999 <class 'str'>\n",
      "1861 <class 'str'>\n",
      "161 <class 'str'>\n",
      "6142 <class 'str'>\n",
      "4820 <class 'str'>\n",
      "1881 <class 'str'>\n",
      "5367 <class 'str'>\n",
      "426 <class 'str'>\n",
      "2535 <class 'str'>\n",
      "1299 <class 'str'>\n",
      "394 <class 'str'>\n",
      "2383 <class 'str'>\n",
      "602 <class 'str'>\n",
      "289 <class 'str'>\n",
      "303 <class 'str'>\n",
      "217 <class 'str'>\n",
      "282 <class 'str'>\n",
      "440 <class 'str'>\n",
      "381 <class 'str'>\n",
      "2850 <class 'str'>\n",
      "244 <class 'str'>\n",
      "3307 <class 'str'>\n",
      "324 <class 'str'>\n",
      "1132 <class 'str'>\n",
      "5915 <class 'str'>\n",
      "5989 <class 'str'>\n",
      "302 <class 'str'>\n",
      "2115 <class 'str'>\n",
      "236 <class 'str'>\n",
      "183 <class 'str'>\n",
      "4700 <class 'str'>\n",
      "266 <class 'str'>\n",
      "2422 <class 'str'>\n",
      "2369 <class 'str'>\n",
      "933 <class 'str'>\n",
      "229 <class 'str'>\n",
      "399 <class 'str'>\n",
      "2158 <class 'str'>\n",
      "1099 <class 'str'>\n",
      "3221 <class 'str'>\n",
      "348 <class 'str'>\n",
      "223 <class 'str'>\n",
      "6095 <class 'str'>\n",
      "2127 <class 'str'>\n",
      "2792 <class 'str'>\n",
      "519 <class 'str'>\n",
      "2859 <class 'str'>\n",
      "1444 <class 'str'>\n",
      "1450 <class 'str'>\n",
      "20 <class 'str'>\n",
      "801 <class 'str'>\n",
      "4469 <class 'str'>\n",
      "1768 <class 'str'>\n",
      "2063 <class 'str'>\n",
      "202 <class 'str'>\n",
      "4309 <class 'str'>\n",
      "1070 <class 'str'>\n",
      "2690 <class 'str'>\n",
      "5358 <class 'str'>\n",
      "379 <class 'str'>\n",
      "3784 <class 'str'>\n",
      "7209 <class 'str'>\n",
      "3652 <class 'str'>\n",
      "1368 <class 'str'>\n",
      "517 <class 'str'>\n",
      "5166 <class 'str'>\n",
      "219 <class 'str'>\n",
      "363 <class 'str'>\n",
      "1796 <class 'str'>\n",
      "2669 <class 'str'>\n",
      "35 <class 'str'>\n",
      "7257 <class 'str'>\n",
      "2017 <class 'str'>\n",
      "1972 <class 'str'>\n",
      "430 <class 'str'>\n",
      "2 <class 'str'>\n",
      "3238 <class 'str'>\n",
      "36 <class 'str'>\n",
      "610 <class 'str'>\n",
      "4077 <class 'str'>\n",
      "25 <class 'str'>\n",
      "6241 <class 'str'>\n",
      "382 <class 'str'>\n",
      "2675 <class 'str'>\n",
      "1091 <class 'str'>\n",
      "445 <class 'str'>\n",
      "2768 <class 'str'>\n",
      "4201 <class 'str'>\n",
      "364 <class 'str'>\n",
      "3707 <class 'str'>\n",
      "2334 <class 'str'>\n",
      "1946 <class 'str'>\n",
      "7976 <class 'str'>\n",
      "4875 <class 'str'>\n",
      "1403 <class 'str'>\n",
      "2991 <class 'str'>\n",
      "2097 <class 'str'>\n",
      "959 <class 'str'>\n",
      "3392 <class 'str'>\n",
      "460 <class 'str'>\n",
      "14 <class 'str'>\n",
      "2633 <class 'str'>\n",
      "4498 <class 'str'>\n",
      "2920 <class 'str'>\n",
      "264 <class 'str'>\n",
      "4212 <class 'str'>\n",
      "281 <class 'str'>\n",
      "4357 <class 'str'>\n",
      "93 <class 'str'>\n",
      "603 <class 'str'>\n",
      "423 <class 'str'>\n",
      "206 <class 'str'>\n",
      "1372 <class 'str'>\n",
      "4887 <class 'str'>\n",
      "4161 <class 'str'>\n",
      "1934 <class 'str'>\n",
      "222 <class 'str'>\n",
      "2304 <class 'str'>\n",
      "157 <class 'str'>\n",
      "2340 <class 'str'>\n",
      "1571 <class 'str'>\n",
      "1761 <class 'str'>\n",
      "351 <class 'str'>\n",
      "327 <class 'str'>\n",
      "4244 <class 'str'>\n",
      "753 <class 'str'>\n",
      "32 <class 'str'>\n",
      "307 <class 'str'>\n",
      "5004 <class 'str'>\n",
      "8038 <class 'str'>\n",
      "577 <class 'str'>\n",
      "897 <class 'str'>\n",
      "7282 <class 'str'>\n",
      "1953 <class 'str'>\n",
      "6502 <class 'str'>\n",
      "2726 <class 'str'>\n",
      "4107 <class 'str'>\n",
      "1500 <class 'str'>\n",
      "1147 <class 'str'>\n",
      "4701 <class 'str'>\n",
      "1319 <class 'str'>\n",
      "2973 <class 'str'>\n",
      "1124 <class 'str'>\n",
      "505 <class 'str'>\n",
      "1153 <class 'str'>\n",
      "2602 <class 'str'>\n",
      "574 <class 'str'>\n",
      "1478 <class 'str'>\n",
      "13636 <class 'str'>\n",
      "5609 <class 'str'>\n",
      "1582 <class 'str'>\n",
      "911 <class 'str'>\n",
      "191 <class 'str'>\n",
      "1014 <class 'str'>\n",
      "1282 <class 'str'>\n",
      "1291 <class 'str'>\n",
      "1734 <class 'str'>\n",
      "2345 <class 'str'>\n",
      "487 <class 'str'>\n",
      "882 <class 'str'>\n",
      "375 <class 'str'>\n",
      "3558 <class 'str'>\n",
      "2287 <class 'str'>\n",
      "1572 <class 'str'>\n",
      "1007 <class 'str'>\n",
      "2154 <class 'str'>\n",
      "411 <class 'str'>\n",
      "298 <class 'str'>\n",
      "2869 <class 'str'>\n",
      "3148 <class 'str'>\n",
      "268 <class 'str'>\n",
      "17322 <class 'str'>\n",
      "798 <class 'str'>\n",
      "1182 <class 'str'>\n",
      "699 <class 'str'>\n",
      "2120 <class 'str'>\n",
      "14009 <class 'str'>\n",
      "4742 <class 'str'>\n",
      "12684 <class 'str'>\n",
      "6750 <class 'str'>\n",
      "308 <class 'str'>\n",
      "17 <class 'str'>\n",
      "949 <class 'str'>\n",
      "784 <class 'str'>\n",
      "822 <class 'str'>\n",
      "5503 <class 'str'>\n",
      "5115 <class 'str'>\n",
      "1012 <class 'str'>\n",
      "338 <class 'str'>\n",
      "5197 <class 'str'>\n",
      "28 <class 'str'>\n",
      "1451 <class 'str'>\n",
      "4482 <class 'str'>\n",
      "501 <class 'str'>\n",
      "1712 <class 'str'>\n",
      "16 <class 'str'>\n",
      "1958 <class 'str'>\n",
      "4753 <class 'str'>\n",
      "1065 <class 'str'>\n",
      "4540 <class 'str'>\n",
      "4959 <class 'str'>\n",
      "6409 <class 'str'>\n",
      "1468 <class 'str'>\n",
      "263 <class 'str'>\n",
      "620 <class 'str'>\n",
      "4896 <class 'str'>\n",
      "709 <class 'str'>\n",
      "2801 <class 'str'>\n",
      "1793 <class 'str'>\n",
      "2997 <class 'str'>\n",
      "1159 <class 'str'>\n",
      "4100 <class 'str'>\n",
      "199 <class 'str'>\n",
      "4153 <class 'str'>\n",
      "1001 <class 'str'>\n",
      "761 <class 'str'>\n",
      "1294 <class 'str'>\n",
      "3157 <class 'str'>\n",
      "3270 <class 'str'>\n",
      "1731 <class 'str'>\n",
      "3219 <class 'str'>\n",
      "6042 <class 'str'>\n",
      "2514 <class 'str'>\n",
      "1770 <class 'str'>\n",
      "2833 <class 'str'>\n",
      "6800 <class 'str'>\n",
      "6531 <class 'str'>\n",
      "5014 <class 'str'>\n",
      "586 <class 'str'>\n",
      "3259 <class 'str'>\n",
      "2433 <class 'str'>\n",
      "1120 <class 'str'>\n",
      "4651 <class 'str'>\n",
      "255 <class 'str'>\n",
      "1998 <class 'str'>\n",
      "7129 <class 'str'>\n",
      "2554 <class 'str'>\n",
      "1563 <class 'str'>\n",
      "288 <class 'str'>\n",
      "1536 <class 'str'>\n",
      "2814 <class 'str'>\n",
      "463 <class 'str'>\n",
      "4707 <class 'str'>\n",
      "4617 <class 'str'>\n",
      "1597 <class 'str'>\n",
      "701 <class 'str'>\n",
      "1490 <class 'str'>\n",
      "1970 <class 'str'>\n",
      "3761 <class 'str'>\n",
      "3650 <class 'str'>\n",
      "3067 <class 'str'>\n",
      "1077 <class 'str'>\n",
      "1102 <class 'str'>\n",
      "4729 <class 'str'>\n",
      "4874 <class 'str'>\n",
      "11530 <class 'str'>\n",
      "6253 <class 'str'>\n",
      "5232 <class 'str'>\n",
      "4916 <class 'str'>\n",
      "991 <class 'str'>\n",
      "3658 <class 'str'>\n",
      "2038 <class 'str'>\n",
      "4314 <class 'str'>\n",
      "4277 <class 'str'>\n",
      "1940 <class 'str'>\n",
      "1275 <class 'str'>\n",
      "1304 <class 'str'>\n",
      "4624 <class 'str'>\n",
      "34 <class 'str'>\n",
      "417 <class 'str'>\n",
      "468 <class 'str'>\n",
      "388 <class 'str'>\n",
      "5613 <class 'str'>\n",
      "283 <class 'str'>\n",
      "1075 <class 'str'>\n",
      "810 <class 'str'>\n",
      "6852 <class 'str'>\n",
      "1501 <class 'str'>\n",
      "3683 <class 'str'>\n",
      "2964 <class 'str'>\n",
      "4670 <class 'str'>\n",
      "504 <class 'str'>\n",
      "3517 <class 'str'>\n",
      "604 <class 'str'>\n",
      "4202 <class 'str'>\n",
      "719 <class 'str'>\n",
      "1243 <class 'str'>\n",
      "4254 <class 'str'>\n",
      "2584 <class 'str'>\n",
      "4273 <class 'str'>\n",
      "1241 <class 'str'>\n",
      "3747 <class 'str'>\n",
      "7529 <class 'str'>\n",
      "1040 <class 'str'>\n",
      "5364 <class 'str'>\n",
      "5030 <class 'str'>\n",
      "5528 <class 'str'>\n",
      "1270 <class 'str'>\n",
      "2330 <class 'str'>\n",
      "896 <class 'str'>\n",
      "7150 <class 'str'>\n",
      "2883 <class 'str'>\n",
      "1482 <class 'str'>\n",
      "3418 <class 'str'>\n",
      "276 <class 'str'>\n",
      "1841 <class 'str'>\n",
      "2049 <class 'str'>\n",
      "3708 <class 'str'>\n",
      "1996 <class 'str'>\n",
      "1409 <class 'str'>\n",
      "576 <class 'str'>\n",
      "659 <class 'str'>\n",
      "372 <class 'str'>\n",
      "1895 <class 'str'>\n",
      "4924 <class 'str'>\n",
      "49 <class 'str'>\n",
      "443 <class 'str'>\n",
      "301 <class 'str'>\n",
      "8259 <class 'str'>\n",
      "1548 <class 'str'>\n",
      "941 <class 'str'>\n",
      "1987 <class 'str'>\n",
      "5249 <class 'str'>\n",
      "1993 <class 'str'>\n",
      "3514 <class 'str'>\n",
      "3871 <class 'str'>\n",
      "3780 <class 'str'>\n",
      "3199 <class 'str'>\n",
      "7 <class 'str'>\n",
      "1878 <class 'str'>\n",
      "19 <class 'str'>\n",
      "1008 <class 'str'>\n",
      "1808 <class 'str'>\n",
      "10 <class 'str'>\n",
      "2981 <class 'str'>\n",
      "2013 <class 'str'>\n",
      "227 <class 'str'>\n",
      "4610 <class 'str'>\n",
      "390 <class 'str'>\n",
      "751 <class 'str'>\n",
      "6532 <class 'str'>\n",
      "7259 <class 'str'>\n",
      "2417 <class 'str'>\n",
      "1587 <class 'str'>\n",
      "2977 <class 'str'>\n",
      "30 <class 'str'>\n",
      "526 <class 'str'>\n",
      "8 <class 'str'>\n",
      "4795 <class 'str'>\n",
      "4634 <class 'str'>\n",
      "495 <class 'str'>\n",
      "2246 <class 'str'>\n",
      "5234 <class 'str'>\n",
      "439 <class 'str'>\n",
      "462 <class 'str'>\n",
      "371 <class 'str'>\n",
      "1253 <class 'str'>\n",
      "3547 <class 'str'>\n",
      "1880 <class 'str'>\n",
      "4252 <class 'str'>\n",
      "935 <class 'str'>\n",
      "600 <class 'str'>\n",
      "1360 <class 'str'>\n",
      "23 <class 'str'>\n",
      "6291 <class 'str'>\n",
      "4818 <class 'str'>\n",
      "502 <class 'str'>\n",
      "743 <class 'str'>\n",
      "2440 <class 'str'>\n",
      "6629 <class 'str'>\n",
      "269 <class 'str'>\n",
      "1380 <class 'str'>\n",
      "1394 <class 'str'>\n",
      "4016 <class 'str'>\n",
      "3384 <class 'str'>\n",
      "5954 <class 'str'>\n",
      "2185 <class 'str'>\n",
      "13 <class 'str'>\n",
      "515 <class 'str'>\n",
      "1408 <class 'str'>\n",
      "2466 <class 'str'>\n",
      "770 <class 'str'>\n",
      "5991 <class 'str'>\n",
      "903 <class 'str'>\n",
      "6226 <class 'str'>\n",
      "829 <class 'str'>\n",
      "3085 <class 'str'>\n",
      "4149 <class 'str'>\n",
      "1915 <class 'str'>\n",
      "7856 <class 'str'>\n",
      "559 <class 'str'>\n",
      "750 <class 'str'>\n",
      "1523 <class 'str'>\n",
      "2594 <class 'str'>\n",
      "2934 <class 'str'>\n",
      "5398 <class 'str'>\n",
      "318 <class 'str'>\n",
      "441 <class 'str'>\n",
      "3325 <class 'str'>\n",
      "668 <class 'str'>\n",
      "3974 <class 'str'>\n",
      "650 <class 'str'>\n",
      "714 <class 'str'>\n",
      "556 <class 'str'>\n",
      "573 <class 'str'>\n",
      "1411 <class 'str'>\n",
      "3923 <class 'str'>\n",
      "850 <class 'str'>\n",
      "2374 <class 'str'>\n",
      "2228 <class 'str'>\n",
      "803 <class 'str'>\n",
      "2853 <class 'str'>\n",
      "15 <class 'str'>\n",
      "2968 <class 'str'>\n",
      "5385 <class 'str'>\n",
      "1485 <class 'str'>\n",
      "2232 <class 'str'>\n",
      "4279 <class 'str'>\n",
      "1687 <class 'str'>\n",
      "6985 <class 'str'>\n",
      "1592 <class 'str'>\n",
      "3090 <class 'str'>\n",
      "2744 <class 'str'>\n",
      "3454 <class 'str'>\n",
      "703 <class 'str'>\n",
      "5143 <class 'str'>\n",
      "6422 <class 'str'>\n",
      "3271 <class 'str'>\n",
      "3288 <class 'str'>\n",
      "4973 <class 'str'>\n",
      "1530 <class 'str'>\n",
      "720 <class 'str'>\n",
      "676 <class 'str'>\n",
      "6396 <class 'str'>\n",
      "4508 <class 'str'>\n",
      "1656 <class 'str'>\n",
      "2679 <class 'str'>\n",
      "455 <class 'str'>\n",
      "2150 <class 'str'>\n",
      "6088 <class 'str'>\n",
      "5712 <class 'str'>\n",
      "4439 <class 'str'>\n",
      "4199 <class 'str'>\n",
      "5134 <class 'str'>\n",
      "4786 <class 'str'>\n",
      "3751 <class 'str'>\n",
      "994 <class 'str'>\n",
      "3873 <class 'str'>\n",
      "1168 <class 'str'>\n",
      "644 <class 'str'>\n",
      "1234 <class 'str'>\n",
      "1332 <class 'str'>\n",
      "584 <class 'str'>\n",
      "1757 <class 'str'>\n",
      "1273 <class 'str'>\n",
      "4384 <class 'str'>\n",
      "7596 <class 'str'>\n",
      "3628 <class 'str'>\n",
      "3417 <class 'str'>\n",
      "6571 <class 'str'>\n",
      "717 <class 'str'>\n",
      "765 <class 'str'>\n",
      "1376 <class 'str'>\n",
      "466 <class 'str'>\n",
      "1123 <class 'str'>\n",
      "377 <class 'str'>\n",
      "5767 <class 'str'>\n",
      "2658 <class 'str'>\n",
      "1552 <class 'str'>\n",
      "1016 <class 'str'>\n",
      "858 <class 'str'>\n",
      "1858 <class 'str'>\n",
      "2222 <class 'str'>\n",
      "739 <class 'str'>\n",
      "2025 <class 'str'>\n",
      "1327 <class 'str'>\n",
      "1550 <class 'str'>\n",
      "638 <class 'str'>\n",
      "1630 <class 'str'>\n",
      "398 <class 'str'>\n",
      "2829 <class 'str'>\n",
      "2957 <class 'str'>\n",
      "3982 <class 'str'>\n",
      "3604 <class 'str'>\n",
      "2242 <class 'str'>\n",
      "2209 <class 'str'>\n",
      "3772 <class 'str'>\n",
      "4025 <class 'str'>\n",
      "2054 <class 'str'>\n",
      "29 <class 'str'>\n",
      "1363 <class 'str'>\n",
      "3062 <class 'str'>\n",
      "969 <class 'str'>\n",
      "1455 <class 'str'>\n",
      "2709 <class 'str'>\n",
      "2333 <class 'str'>\n",
      "3308 <class 'str'>\n",
      "679 <class 'str'>\n",
      "473 <class 'str'>\n",
      "4336 <class 'str'>\n",
      "4558 <class 'str'>\n",
      "1401 <class 'str'>\n",
      "5277 <class 'str'>\n",
      "909 <class 'str'>\n",
      "3756 <class 'str'>\n",
      "1361 <class 'str'>\n",
      "1790 <class 'str'>\n",
      "1947 <class 'str'>\n",
      "434 <class 'str'>\n",
      "2392 <class 'str'>\n",
      "800 <class 'str'>\n",
      "3702 <class 'str'>\n",
      "5320 <class 'str'>\n",
      "7511 <class 'str'>\n",
      "1437 <class 'str'>\n",
      "317 <class 'str'>\n",
      "3103 <class 'str'>\n",
      "953 <class 'str'>\n",
      "4914 <class 'str'>\n",
      "1973 <class 'str'>\n",
      "474 <class 'str'>\n",
      "4720 <class 'str'>\n",
      "3555 <class 'str'>\n",
      "3172 <class 'str'>\n",
      "4463 <class 'str'>\n",
      "6828 <class 'str'>\n",
      "3588 <class 'str'>\n",
      "4331 <class 'str'>\n",
      "5870 <class 'str'>\n",
      "2178 <class 'str'>\n",
      "1374 <class 'str'>\n",
      "1116 <class 'str'>\n",
      "6820 <class 'str'>\n",
      "1635 <class 'str'>\n",
      "3645 <class 'str'>\n",
      "2136 <class 'str'>\n",
      "1786 <class 'str'>\n",
      "851 <class 'str'>\n",
      "6815 <class 'str'>\n",
      "346 <class 'str'>\n",
      "2760 <class 'str'>\n",
      "1160 <class 'str'>\n",
      "1149 <class 'str'>\n",
      "267 <class 'str'>\n",
      "2665 <class 'str'>\n",
      "535 <class 'str'>\n",
      "4316 <class 'str'>\n",
      "38 <class 'str'>\n",
      "6909 <class 'str'>\n",
      "3548 <class 'str'>\n",
      "2617 <class 'str'>\n",
      "3826 <class 'str'>\n",
      "1745 <class 'str'>\n",
      "710 <class 'str'>\n",
      "712 <class 'str'>\n",
      "2942 <class 'str'>\n",
      "4969 <class 'str'>\n",
      "972 <class 'str'>\n",
      "3413 <class 'str'>\n",
      "1968 <class 'str'>\n",
      "2132 <class 'str'>\n",
      "1763 <class 'str'>\n",
      "4770 <class 'str'>\n",
      "521 <class 'str'>\n",
      "3272 <class 'str'>\n",
      "1876 <class 'str'>\n",
      "410 <class 'str'>\n",
      "1622 <class 'str'>\n",
      "7319 <class 'str'>\n",
      "828 <class 'str'>\n",
      "1995 <class 'str'>\n",
      "1285 <class 'str'>\n",
      "3429 <class 'str'>\n",
      "974 <class 'str'>\n",
      "1060 <class 'str'>\n",
      "5133 <class 'str'>\n",
      "319 <class 'str'>\n",
      "2107 <class 'str'>\n",
      "1079 <class 'str'>\n",
      "1480 <class 'str'>\n",
      "1456 <class 'str'>\n",
      "3134 <class 'str'>\n",
      "4333 <class 'str'>\n",
      "6044 <class 'str'>\n",
      "3773 <class 'str'>\n",
      "1896 <class 'str'>\n",
      "7548 <class 'str'>\n",
      "2747 <class 'str'>\n",
      "4058 <class 'str'>\n",
      "776 <class 'str'>\n",
      "612 <class 'str'>\n",
      "1427 <class 'str'>\n",
      "2531 <class 'str'>\n",
      "1385 <class 'str'>\n",
      "3631 <class 'str'>\n",
      "6755 <class 'str'>\n",
      "1174 <class 'str'>\n",
      "590 <class 'str'>\n",
      "2877 <class 'str'>\n",
      "4638 <class 'str'>\n",
      "2993 <class 'str'>\n",
      "1590 <class 'str'>\n",
      "4838 <class 'str'>\n",
      "3498 <class 'str'>\n",
      "2803 <class 'str'>\n",
      "6696 <class 'str'>\n",
      "392 <class 'str'>\n",
      "3427 <class 'str'>\n",
      "580 <class 'str'>\n",
      "1164 <class 'str'>\n",
      "979 <class 'str'>\n",
      "5379 <class 'str'>\n",
      "2854 <class 'str'>\n",
      "3203 <class 'str'>\n",
      "4739 <class 'str'>\n",
      "3482 <class 'str'>\n",
      "6322 <class 'str'>\n",
      "2168 <class 'str'>\n",
      "891 <class 'str'>\n",
      "5242 <class 'str'>\n",
      "3091 <class 'str'>\n",
      "2778 <class 'str'>\n",
      "5016 <class 'str'>\n",
      "1596 <class 'str'>\n",
      "3530 <class 'str'>\n",
      "4294 <class 'str'>\n",
      "1943 <class 'str'>\n",
      "17932 <class 'str'>\n",
      "1162 <class 'str'>\n",
      "3592 <class 'str'>\n",
      "470 <class 'str'>\n",
      "878 <class 'str'>\n",
      "1784 <class 'str'>\n",
      "1264 <class 'str'>\n",
      "1899 <class 'str'>\n",
      "1308 <class 'str'>\n",
      "625 <class 'str'>\n",
      "1445 <class 'str'>\n",
      "4041 <class 'str'>\n",
      "4032 <class 'str'>\n",
      "624 <class 'str'>\n",
      "3811 <class 'str'>\n",
      "1312 <class 'str'>\n",
      "383 <class 'str'>\n",
      "1122 <class 'str'>\n",
      "1912 <class 'str'>\n",
      "3832 <class 'str'>\n",
      "2002 <class 'str'>\n",
      "6598 <class 'str'>\n",
      "2102 <class 'str'>\n",
      "2057 <class 'str'>\n",
      "7400 <class 'str'>\n",
      "1288 <class 'str'>\n",
      "341 <class 'str'>\n",
      "3250 <class 'str'>\n",
      "2800 <class 'str'>\n",
      "3789 <class 'str'>\n",
      "1647 <class 'str'>\n",
      "6006 <class 'str'>\n",
      "3607 <class 'str'>\n",
      "3675 <class 'str'>\n",
      "494 <class 'str'>\n",
      "813 <class 'str'>\n",
      "3451 <class 'str'>\n",
      "3666 <class 'str'>\n",
      "536 <class 'str'>\n",
      "2342 <class 'str'>\n",
      "2931 <class 'str'>\n",
      "1701 <class 'str'>\n",
      "3822 <class 'str'>\n",
      "248 <class 'str'>\n",
      "1399 <class 'str'>\n",
      "766 <class 'str'>\n",
      "3278 <class 'str'>\n",
      "3486 <class 'str'>\n",
      "757 <class 'str'>\n",
      "937 <class 'str'>\n",
      "3434 <class 'str'>\n",
      "2069 <class 'str'>\n",
      "999 <class 'str'>\n",
      "5033 <class 'str'>\n",
      "827 <class 'str'>\n",
      "2927 <class 'str'>\n",
      "5130 <class 'str'>\n",
      "5018 <class 'str'>\n",
      "477 <class 'str'>\n",
      "2887 <class 'str'>\n",
      "680 <class 'str'>\n",
      "3523 <class 'str'>\n",
      "1032 <class 'str'>\n",
      "4076 <class 'str'>\n",
      "3136 <class 'str'>\n",
      "3988 <class 'str'>\n",
      "5019 <class 'str'>\n",
      "2806 <class 'str'>\n",
      "3334 <class 'str'>\n",
      "1054 <class 'str'>\n",
      "2550 <class 'str'>\n",
      "3677 <class 'str'>\n",
      "3002 <class 'str'>\n",
      "17011 <class 'str'>\n",
      "762 <class 'str'>\n",
      "1967 <class 'str'>\n",
      "1193 <class 'str'>\n",
      "311 <class 'str'>\n",
      "5348 <class 'str'>\n",
      "3970 <class 'str'>\n",
      "5519 <class 'str'>\n",
      "6289 <class 'str'>\n",
      "4854 <class 'str'>\n",
      "1551 <class 'str'>\n",
      "1778 <class 'str'>\n",
      "415 <class 'str'>\n",
      "530 <class 'str'>\n",
      "1920 <class 'str'>\n",
      "1902 <class 'str'>\n",
      "336 <class 'str'>\n",
      "674 <class 'str'>\n",
      "5703 <class 'str'>\n",
      "1367 <class 'str'>\n",
      "2034 <class 'str'>\n",
      "2519 <class 'str'>\n",
      "3516 <class 'str'>\n",
      "5112 <class 'str'>\n",
      "2834 <class 'str'>\n",
      "3938 <class 'str'>\n",
      "4475 <class 'str'>\n",
      "1362 <class 'str'>\n",
      "1708 <class 'str'>\n",
      "5975 <class 'str'>\n",
      "2274 <class 'str'>\n",
      "1158 <class 'str'>\n",
      "5372 <class 'str'>\n",
      "1043 <class 'str'>\n",
      "6840 <class 'str'>\n",
      "2960 <class 'str'>\n",
      "2697 <class 'str'>\n",
      "4797 <class 'str'>\n",
      "2000 <class 'str'>\n",
      "965 <class 'str'>\n",
      "2430 <class 'str'>\n",
      "481 <class 'str'>\n",
      "4793 <class 'str'>\n",
      "5786 <class 'str'>\n",
      "4555 <class 'str'>\n",
      "1984 <class 'str'>\n",
      "741 <class 'str'>\n",
      "4166 <class 'str'>\n",
      "3991 <class 'str'>\n",
      "5423 <class 'str'>\n",
      "4819 <class 'str'>\n",
      "6251 <class 'str'>\n",
      "1470 <class 'str'>\n",
      "5494 <class 'str'>\n",
      "2439 <class 'str'>\n",
      "3939 <class 'str'>\n",
      "4026 <class 'str'>\n",
      "1127 <class 'str'>\n",
      "4465 <class 'str'>\n",
      "1115 <class 'str'>\n",
      "695 <class 'str'>\n",
      "558 <class 'str'>\n",
      "1642 <class 'str'>\n",
      "583 <class 'str'>\n",
      "1138 <class 'str'>\n",
      "7544 <class 'str'>\n",
      "759 <class 'str'>\n",
      "4434 <class 'str'>\n",
      "221 <class 'str'>\n",
      "291 <class 'str'>\n",
      "3948 <class 'str'>\n",
      "3357 <class 'str'>\n",
      "1172 <class 'str'>\n",
      "2947 <class 'str'>\n",
      "1278 <class 'str'>\n",
      "3360 <class 'str'>\n",
      "4052 <class 'str'>\n",
      "4210 <class 'str'>\n",
      "3059 <class 'str'>\n",
      "4029 <class 'str'>\n",
      "4966 <class 'str'>\n",
      "2713 <class 'str'>\n",
      "575 <class 'str'>\n",
      "958 <class 'str'>\n",
      "4447 <class 'str'>\n",
      "1322 <class 'str'>\n",
      "968 <class 'str'>\n",
      "2512 <class 'str'>\n",
      "3704 <class 'str'>\n",
      "2966 <class 'str'>\n",
      "1157 <class 'str'>\n",
      "2645 <class 'str'>\n",
      "3151 <class 'str'>\n",
      "2561 <class 'str'>\n",
      "1175 <class 'str'>\n",
      "2033 <class 'str'>\n",
      "5610 <class 'str'>\n",
      "2411 <class 'str'>\n",
      "617 <class 'str'>\n",
      "1776 <class 'str'>\n",
      "744 <class 'str'>\n",
      "2251 <class 'str'>\n",
      "3102 <class 'str'>\n",
      "304 <class 'str'>\n",
      "1341 <class 'str'>\n",
      "1908 <class 'str'>\n",
      "2113 <class 'str'>\n",
      "12012 <class 'str'>\n",
      "642 <class 'str'>\n",
      "597 <class 'str'>\n",
      "1942 <class 'str'>\n",
      "928 <class 'str'>\n",
      "4906 <class 'str'>\n",
      "1658 <class 'str'>\n",
      "788 <class 'str'>\n",
      "469 <class 'str'>\n",
      "6036 <class 'str'>\n",
      "6280 <class 'str'>\n",
      "5815 <class 'str'>\n",
      "570 <class 'str'>\n",
      "3825 <class 'str'>\n",
      "7264 <class 'str'>\n",
      "3551 <class 'str'>\n",
      "572 <class 'str'>\n",
      "1287 <class 'str'>\n",
      "1189 <class 'str'>\n",
      "2750 <class 'str'>\n",
      "3823 <class 'str'>\n",
      "4904 <class 'str'>\n",
      "1705 <class 'str'>\n",
      "2402 <class 'str'>\n",
      "1073 <class 'str'>\n",
      "3866 <class 'str'>\n",
      "3094 <class 'str'>\n",
      "4799 <class 'str'>\n",
      "1400 <class 'str'>\n",
      "4668 <class 'str'>\n",
      "3096 <class 'str'>\n",
      "5427 <class 'str'>\n",
      "5345 <class 'str'>\n",
      "2702 <class 'str'>\n",
      "2775 <class 'str'>\n",
      "4551 <class 'str'>\n",
      "1108 <class 'str'>\n",
      "2739 <class 'str'>\n",
      "3313 <class 'str'>\n",
      "4405 <class 'str'>\n",
      "2219 <class 'str'>\n",
      "956 <class 'str'>\n",
      "5313 <class 'str'>\n",
      "2086 <class 'str'>\n",
      "332 <class 'str'>\n",
      "1966 <class 'str'>\n",
      "7850 <class 'str'>\n",
      "6827 <class 'str'>\n",
      "6430 <class 'str'>\n",
      "2471 <class 'str'>\n",
      "2553 <class 'str'>\n",
      "2539 <class 'str'>\n",
      "952 <class 'str'>\n",
      "2536 <class 'str'>\n",
      "2729 <class 'str'>\n",
      "2279 <class 'str'>\n",
      "3316 <class 'str'>\n",
      "1302 <class 'str'>\n",
      "7365 <class 'str'>\n",
      "3674 <class 'str'>\n",
      "3004 <class 'str'>\n",
      "1726 <class 'str'>\n",
      "6744 <class 'str'>\n",
      "3127 <class 'str'>\n",
      "1506 <class 'str'>\n",
      "6515 <class 'str'>\n",
      "4768 <class 'str'>\n",
      "880 <class 'str'>\n",
      "3167 <class 'str'>\n",
      "2644 <class 'str'>\n",
      "1765 <class 'str'>\n",
      "5666 <class 'str'>\n",
      "4652 <class 'str'>\n",
      "1139 <class 'str'>\n",
      "1416 <class 'str'>\n",
      "1474 <class 'str'>\n",
      "785 <class 'str'>\n",
      "629 <class 'str'>\n",
      "1289 <class 'str'>\n",
      "1818 <class 'str'>\n",
      "17410 <class 'str'>\n",
      "4220 <class 'str'>\n",
      "2325 <class 'str'>\n",
      "1492 <class 'str'>\n",
      "2810 <class 'str'>\n",
      "4120 <class 'str'>\n",
      "2786 <class 'str'>\n",
      "7005 <class 'str'>\n",
      "1553 <class 'str'>\n",
      "932 <class 'str'>\n",
      "6452 <class 'str'>\n",
      "678 <class 'str'>\n",
      "2555 <class 'str'>\n",
      "726 <class 'str'>\n",
      "1011 <class 'str'>\n",
      "7399 <class 'str'>\n",
      "2231 <class 'str'>\n",
      "3665 <class 'str'>\n",
      "665 <class 'str'>\n",
      "7281 <class 'str'>\n",
      "2337 <class 'str'>\n",
      "1659 <class 'str'>\n",
      "3053 <class 'str'>\n",
      "1410 <class 'str'>\n",
      "293 <class 'str'>\n",
      "1905 <class 'str'>\n",
      "5137 <class 'str'>\n",
      "4944 <class 'str'>\n",
      "1654 <class 'str'>\n",
      "4247 <class 'str'>\n",
      "3263 <class 'str'>\n",
      "3847 <class 'str'>\n",
      "1425 <class 'str'>\n",
      "2284 <class 'str'>\n",
      "5299 <class 'str'>\n",
      "2796 <class 'str'>\n",
      "6957 <class 'str'>\n",
      "3795 <class 'str'>\n",
      "3348 <class 'str'>\n",
      "331 <class 'str'>\n",
      "2156 <class 'str'>\n",
      "2286 <class 'str'>\n",
      "3533 <class 'str'>\n",
      "6185 <class 'str'>\n",
      "3068 <class 'str'>\n",
      "3487 <class 'str'>\n",
      "2167 <class 'str'>\n",
      "5948 <class 'str'>\n",
      "4422 <class 'str'>\n",
      "5390 <class 'str'>\n",
      "1558 <class 'str'>\n",
      "3568 <class 'str'>\n",
      "1884 <class 'str'>\n",
      "821 <class 'str'>\n",
      "1197 <class 'str'>\n",
      "3399 <class 'str'>\n",
      "5306 <class 'str'>\n",
      "4559 <class 'str'>\n",
      "1003 <class 'str'>\n",
      "3425 <class 'str'>\n",
      "5303 <class 'str'>\n",
      "778 <class 'str'>\n",
      "914 <class 'str'>\n",
      "2736 <class 'str'>\n",
      "681 <class 'str'>\n",
      "3100 <class 'str'>\n",
      "3836 <class 'str'>\n",
      "5670 <class 'str'>\n",
      "4297 <class 'str'>\n",
      "562 <class 'str'>\n",
      "5945 <class 'str'>\n",
      "2663 <class 'str'>\n",
      "2821 <class 'str'>\n",
      "6418 <class 'str'>\n",
      "3657 <class 'str'>\n",
      "5911 <class 'str'>\n",
      "872 <class 'str'>\n",
      "7298 <class 'str'>\n",
      "1916 <class 'str'>\n",
      "3140 <class 'str'>\n",
      "4689 <class 'str'>\n",
      "4203 <class 'str'>\n",
      "3731 <class 'str'>\n",
      "3120 <class 'str'>\n",
      "2600 <class 'str'>\n",
      "2188 <class 'str'>\n",
      "3610 <class 'str'>\n",
      "7266 <class 'str'>\n",
      "1357 <class 'str'>\n",
      "3493 <class 'str'>\n",
      "5262 <class 'str'>\n",
      "2980 <class 'str'>\n",
      "2777 <class 'str'>\n",
      "16312 <class 'str'>\n",
      "1460 <class 'str'>\n",
      "6720 <class 'str'>\n",
      "1971 <class 'str'>\n",
      "2317 <class 'str'>\n",
      "6295 <class 'str'>\n",
      "6779 <class 'str'>\n",
      "1365 <class 'str'>\n",
      "4855 <class 'str'>\n",
      "736 <class 'str'>\n",
      "6653 <class 'str'>\n",
      "3206 <class 'str'>\n",
      "4007 <class 'str'>\n",
      "2134 <class 'str'>\n",
      "1948 <class 'str'>\n",
      "1250 <class 'str'>\n",
      "1690 <class 'str'>\n",
      "5295 <class 'str'>\n",
      "4369 <class 'str'>\n",
      "735 <class 'str'>\n",
      "4889 <class 'str'>\n",
      "1567 <class 'str'>\n",
      "1151 <class 'str'>\n",
      "754 <class 'str'>\n",
      "368 <class 'str'>\n",
      "7422 <class 'str'>\n",
      "5955 <class 'str'>\n",
      "3552 <class 'str'>\n",
      "3627 <class 'str'>\n",
      "745 <class 'str'>\n",
      "957 <class 'str'>\n",
      "2784 <class 'str'>\n",
      "4418 <class 'str'>\n",
      "316 <class 'str'>\n",
      "6351 <class 'str'>\n",
      "17700 <class 'str'>\n",
      "3757 <class 'str'>\n",
      "5240 <class 'str'>\n",
      "5886 <class 'str'>\n",
      "6677 <class 'str'>\n",
      "2693 <class 'str'>\n",
      "4660 <class 'str'>\n",
      "549 <class 'str'>\n",
      "2283 <class 'str'>\n",
      "2359 <class 'str'>\n",
      "2816 <class 'str'>\n",
      "7078 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['power'].unique():\n",
    "    print(val, type(val))\n",
    "    # 数据类型不对且有异常值, [0,600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZXjz6iWx1v4C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750469733896,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "ZXjz6iWx1v4C",
    "outputId": "de1acc5d-7de9-4d83-b4a9-f4770609e434"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilometer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>86699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.5</th>\n",
       "      <td>14534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1582 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "kilometer\n",
       "15.0    86699\n",
       "12.5    14534\n",
       "10.0     5975\n",
       "0.0      4980\n",
       "9.0      4927\n",
       "        ...  \n",
       "5809        1\n",
       "6486        1\n",
       "344         1\n",
       "4290        1\n",
       "4655        1\n",
       "Name: count, Length: 1582, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['kilometer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xe6w7Kxc2A7l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1750469736054,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "Xe6w7Kxc2A7l",
    "outputId": "4bd9f31f-2be6-4f67-9c95-9008feba3226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5 <class 'str'>\n",
      "15.0 <class 'str'>\n",
      "5.0 <class 'str'>\n",
      "10.0 <class 'str'>\n",
      "2.0 <class 'str'>\n",
      "6.0 <class 'str'>\n",
      "3972 <class 'str'>\n",
      "1278 <class 'str'>\n",
      "3.0 <class 'str'>\n",
      "0.0 <class 'str'>\n",
      "7.0 <class 'str'>\n",
      "8.0 <class 'str'>\n",
      "9.0 <class 'str'>\n",
      "26 <class 'str'>\n",
      "4.0 <class 'str'>\n",
      "2976 <class 'str'>\n",
      "1.0 <class 'str'>\n",
      "- <class 'str'>\n",
      "0 <class 'str'>\n",
      "0.5 <class 'str'>\n",
      "2615 <class 'str'>\n",
      "896 <class 'str'>\n",
      "6597 <class 'str'>\n",
      "3741 <class 'str'>\n",
      "4566 <class 'str'>\n",
      "6696 <class 'str'>\n",
      "179 <class 'str'>\n",
      "944 <class 'str'>\n",
      "5649 <class 'str'>\n",
      "368 <class 'str'>\n",
      "5963 <class 'str'>\n",
      "2294 <class 'str'>\n",
      "1294 <class 'str'>\n",
      "3519 <class 'str'>\n",
      "491 <class 'str'>\n",
      "2482 <class 'str'>\n",
      "1123 <class 'str'>\n",
      "2247 <class 'str'>\n",
      "208 <class 'str'>\n",
      "2607 <class 'str'>\n",
      "4062 <class 'str'>\n",
      "2593 <class 'str'>\n",
      "1168 <class 'str'>\n",
      "2705 <class 'str'>\n",
      "290 <class 'str'>\n",
      "3216 <class 'str'>\n",
      "4494 <class 'str'>\n",
      "4682 <class 'str'>\n",
      "2603 <class 'str'>\n",
      "6839 <class 'str'>\n",
      "3780 <class 'str'>\n",
      "2472 <class 'str'>\n",
      "213 <class 'str'>\n",
      "78 <class 'str'>\n",
      "449 <class 'str'>\n",
      "6539 <class 'str'>\n",
      "125 <class 'str'>\n",
      "5295 <class 'str'>\n",
      "3413 <class 'str'>\n",
      "2144 <class 'str'>\n",
      "521 <class 'str'>\n",
      "5743 <class 'str'>\n",
      "828 <class 'str'>\n",
      "3297 <class 'str'>\n",
      "3516 <class 'str'>\n",
      "233 <class 'str'>\n",
      "4688 <class 'str'>\n",
      "3142 <class 'str'>\n",
      "2902 <class 'str'>\n",
      "2797 <class 'str'>\n",
      "5951 <class 'str'>\n",
      "1049 <class 'str'>\n",
      "644 <class 'str'>\n",
      "2853 <class 'str'>\n",
      "4812 <class 'str'>\n",
      "2340 <class 'str'>\n",
      "2134 <class 'str'>\n",
      "2241 <class 'str'>\n",
      "316 <class 'str'>\n",
      "2518 <class 'str'>\n",
      "1518 <class 'str'>\n",
      "495 <class 'str'>\n",
      "858 <class 'str'>\n",
      "963 <class 'str'>\n",
      "2222 <class 'str'>\n",
      "1846 <class 'str'>\n",
      "3431 <class 'str'>\n",
      "6074 <class 'str'>\n",
      "3808 <class 'str'>\n",
      "1403 <class 'str'>\n",
      "2443 <class 'str'>\n",
      "787 <class 'str'>\n",
      "656 <class 'str'>\n",
      "1793 <class 'str'>\n",
      "1147 <class 'str'>\n",
      "3444 <class 'str'>\n",
      "2320 <class 'str'>\n",
      "4336 <class 'str'>\n",
      "5352 <class 'str'>\n",
      "3521 <class 'str'>\n",
      "2174 <class 'str'>\n",
      "3810 <class 'str'>\n",
      "3850 <class 'str'>\n",
      "770 <class 'str'>\n",
      "1431 <class 'str'>\n",
      "2714 <class 'str'>\n",
      "4094 <class 'str'>\n",
      "5489 <class 'str'>\n",
      "2834 <class 'str'>\n",
      "1070 <class 'str'>\n",
      "4986 <class 'str'>\n",
      "2676 <class 'str'>\n",
      "6556 <class 'str'>\n",
      "6025 <class 'str'>\n",
      "1483 <class 'str'>\n",
      "3227 <class 'str'>\n",
      "484 <class 'str'>\n",
      "3545 <class 'str'>\n",
      "789 <class 'str'>\n",
      "4463 <class 'str'>\n",
      "2229 <class 'str'>\n",
      "85 <class 'str'>\n",
      "5993 <class 'str'>\n",
      "1600 <class 'str'>\n",
      "2123 <class 'str'>\n",
      "3425 <class 'str'>\n",
      "3218 <class 'str'>\n",
      "2409 <class 'str'>\n",
      "698 <class 'str'>\n",
      "1958 <class 'str'>\n",
      "1516 <class 'str'>\n",
      "3009 <class 'str'>\n",
      "2849 <class 'str'>\n",
      "4312 <class 'str'>\n",
      "1086 <class 'str'>\n",
      "5452 <class 'str'>\n",
      "4319 <class 'str'>\n",
      "75 <class 'str'>\n",
      "2800 <class 'str'>\n",
      "5324 <class 'str'>\n",
      "3984 <class 'str'>\n",
      "147 <class 'str'>\n",
      "3487 <class 'str'>\n",
      "1208 <class 'str'>\n",
      "3959 <class 'str'>\n",
      "2038 <class 'str'>\n",
      "2032 <class 'str'>\n",
      "5571 <class 'str'>\n",
      "3774 <class 'str'>\n",
      "10 <class 'str'>\n",
      "1637 <class 'str'>\n",
      "3076 <class 'str'>\n",
      "2062 <class 'str'>\n",
      "3239 <class 'str'>\n",
      "741 <class 'str'>\n",
      "1894 <class 'str'>\n",
      "2618 <class 'str'>\n",
      "965 <class 'str'>\n",
      "762 <class 'str'>\n",
      "1007 <class 'str'>\n",
      "6070 <class 'str'>\n",
      "869 <class 'str'>\n",
      "3985 <class 'str'>\n",
      "1327 <class 'str'>\n",
      "7197 <class 'str'>\n",
      "2469 <class 'str'>\n",
      "3042 <class 'str'>\n",
      "1146 <class 'str'>\n",
      "338 <class 'str'>\n",
      "317 <class 'str'>\n",
      "1205 <class 'str'>\n",
      "620 <class 'str'>\n",
      "225 <class 'str'>\n",
      "3682 <class 'str'>\n",
      "1259 <class 'str'>\n",
      "4921 <class 'str'>\n",
      "7122 <class 'str'>\n",
      "3786 <class 'str'>\n",
      "4281 <class 'str'>\n",
      "2424 <class 'str'>\n",
      "3861 <class 'str'>\n",
      "6262 <class 'str'>\n",
      "1788 <class 'str'>\n",
      "1151 <class 'str'>\n",
      "163 <class 'str'>\n",
      "4466 <class 'str'>\n",
      "1312 <class 'str'>\n",
      "1454 <class 'str'>\n",
      "4135 <class 'str'>\n",
      "3863 <class 'str'>\n",
      "2162 <class 'str'>\n",
      "4212 <class 'str'>\n",
      "1089 <class 'str'>\n",
      "3514 <class 'str'>\n",
      "281 <class 'str'>\n",
      "73 <class 'str'>\n",
      "3468 <class 'str'>\n",
      "182 <class 'str'>\n",
      "6462 <class 'str'>\n",
      "5432 <class 'str'>\n",
      "7707 <class 'str'>\n",
      "6250 <class 'str'>\n",
      "6120 <class 'str'>\n",
      "4542 <class 'str'>\n",
      "7743 <class 'str'>\n",
      "3607 <class 'str'>\n",
      "4307 <class 'str'>\n",
      "1828 <class 'str'>\n",
      "7950 <class 'str'>\n",
      "6761 <class 'str'>\n",
      "616 <class 'str'>\n",
      "3750 <class 'str'>\n",
      "4268 <class 'str'>\n",
      "1389 <class 'str'>\n",
      "3637 <class 'str'>\n",
      "447 <class 'str'>\n",
      "269 <class 'str'>\n",
      "3345 <class 'str'>\n",
      "2061 <class 'str'>\n",
      "2625 <class 'str'>\n",
      "1297 <class 'str'>\n",
      "1590 <class 'str'>\n",
      "1731 <class 'str'>\n",
      "2025 <class 'str'>\n",
      "2986 <class 'str'>\n",
      "1873 <class 'str'>\n",
      "5753 <class 'str'>\n",
      "1851 <class 'str'>\n",
      "1475 <class 'str'>\n",
      "527 <class 'str'>\n",
      "3980 <class 'str'>\n",
      "2304 <class 'str'>\n",
      "7470 <class 'str'>\n",
      "7326 <class 'str'>\n",
      "5585 <class 'str'>\n",
      "6829 <class 'str'>\n",
      "1458 <class 'str'>\n",
      "1832 <class 'str'>\n",
      "1106 <class 'str'>\n",
      "1764 <class 'str'>\n",
      "1018 <class 'str'>\n",
      "2116 <class 'str'>\n",
      "381 <class 'str'>\n",
      "4309 <class 'str'>\n",
      "1953 <class 'str'>\n",
      "5557 <class 'str'>\n",
      "4690 <class 'str'>\n",
      "5780 <class 'str'>\n",
      "103 <class 'str'>\n",
      "837 <class 'str'>\n",
      "1591 <class 'str'>\n",
      "868 <class 'str'>\n",
      "1048 <class 'str'>\n",
      "3072 <class 'str'>\n",
      "1823 <class 'str'>\n",
      "345 <class 'str'>\n",
      "5061 <class 'str'>\n",
      "4273 <class 'str'>\n",
      "7257 <class 'str'>\n",
      "2477 <class 'str'>\n",
      "5177 <class 'str'>\n",
      "1102 <class 'str'>\n",
      "2036 <class 'str'>\n",
      "238 <class 'str'>\n",
      "6593 <class 'str'>\n",
      "1624 <class 'str'>\n",
      "2011 <class 'str'>\n",
      "302 <class 'str'>\n",
      "4291 <class 'str'>\n",
      "5507 <class 'str'>\n",
      "4186 <class 'str'>\n",
      "4627 <class 'str'>\n",
      "1002 <class 'str'>\n",
      "3724 <class 'str'>\n",
      "753 <class 'str'>\n",
      "1382 <class 'str'>\n",
      "4646 <class 'str'>\n",
      "3725 <class 'str'>\n",
      "2803 <class 'str'>\n",
      "3027 <class 'str'>\n",
      "707 <class 'str'>\n",
      "5845 <class 'str'>\n",
      "32 <class 'str'>\n",
      "2078 <class 'str'>\n",
      "703 <class 'str'>\n",
      "5444 <class 'str'>\n",
      "241 <class 'str'>\n",
      "1924 <class 'str'>\n",
      "2657 <class 'str'>\n",
      "1438 <class 'str'>\n",
      "1654 <class 'str'>\n",
      "1120 <class 'str'>\n",
      "370 <class 'str'>\n",
      "611 <class 'str'>\n",
      "2786 <class 'str'>\n",
      "1943 <class 'str'>\n",
      "3093 <class 'str'>\n",
      "3565 <class 'str'>\n",
      "1125 <class 'str'>\n",
      "2658 <class 'str'>\n",
      "6138 <class 'str'>\n",
      "2971 <class 'str'>\n",
      "455 <class 'str'>\n",
      "3418 <class 'str'>\n",
      "1142 <class 'str'>\n",
      "239 <class 'str'>\n",
      "633 <class 'str'>\n",
      "4244 <class 'str'>\n",
      "1630 <class 'str'>\n",
      "46 <class 'str'>\n",
      "1429 <class 'str'>\n",
      "4808 <class 'str'>\n",
      "1520 <class 'str'>\n",
      "3400 <class 'str'>\n",
      "3470 <class 'str'>\n",
      "3689 <class 'str'>\n",
      "5218 <class 'str'>\n",
      "4560 <class 'str'>\n",
      "3178 <class 'str'>\n",
      "3195 <class 'str'>\n",
      "2338 <class 'str'>\n",
      "1451 <class 'str'>\n",
      "2740 <class 'str'>\n",
      "1135 <class 'str'>\n",
      "1270 <class 'str'>\n",
      "1060 <class 'str'>\n",
      "5054 <class 'str'>\n",
      "117 <class 'str'>\n",
      "1482 <class 'str'>\n",
      "3694 <class 'str'>\n",
      "933 <class 'str'>\n",
      "3528 <class 'str'>\n",
      "788 <class 'str'>\n",
      "3948 <class 'str'>\n",
      "2836 <class 'str'>\n",
      "8071 <class 'str'>\n",
      "4097 <class 'str'>\n",
      "49 <class 'str'>\n",
      "2568 <class 'str'>\n",
      "577 <class 'str'>\n",
      "4692 <class 'str'>\n",
      "6791 <class 'str'>\n",
      "2209 <class 'str'>\n",
      "6345 <class 'str'>\n",
      "172 <class 'str'>\n",
      "4822 <class 'str'>\n",
      "2855 <class 'str'>\n",
      "3074 <class 'str'>\n",
      "2219 <class 'str'>\n",
      "6177 <class 'str'>\n",
      "3721 <class 'str'>\n",
      "1720 <class 'str'>\n",
      "1880 <class 'str'>\n",
      "1264 <class 'str'>\n",
      "7756 <class 'str'>\n",
      "1524 <class 'str'>\n",
      "2860 <class 'str'>\n",
      "6023 <class 'str'>\n",
      "222 <class 'str'>\n",
      "6077 <class 'str'>\n",
      "5001 <class 'str'>\n",
      "2073 <class 'str'>\n",
      "563 <class 'str'>\n",
      "5158 <class 'str'>\n",
      "4139 <class 'str'>\n",
      "4493 <class 'str'>\n",
      "1810 <class 'str'>\n",
      "706 <class 'str'>\n",
      "1319 <class 'str'>\n",
      "3982 <class 'str'>\n",
      "4388 <class 'str'>\n",
      "1209 <class 'str'>\n",
      "3226 <class 'str'>\n",
      "953 <class 'str'>\n",
      "3492 <class 'str'>\n",
      "993 <class 'str'>\n",
      "2399 <class 'str'>\n",
      "1380 <class 'str'>\n",
      "396 <class 'str'>\n",
      "437 <class 'str'>\n",
      "937 <class 'str'>\n",
      "451 <class 'str'>\n",
      "905 <class 'str'>\n",
      "2509 <class 'str'>\n",
      "4047 <class 'str'>\n",
      "2722 <class 'str'>\n",
      "5487 <class 'str'>\n",
      "2833 <class 'str'>\n",
      "4538 <class 'str'>\n",
      "2192 <class 'str'>\n",
      "129 <class 'str'>\n",
      "288 <class 'str'>\n",
      "1760 <class 'str'>\n",
      "253 <class 'str'>\n",
      "3021 <class 'str'>\n",
      "5035 <class 'str'>\n",
      "2102 <class 'str'>\n",
      "171 <class 'str'>\n",
      "1801 <class 'str'>\n",
      "472 <class 'str'>\n",
      "5495 <class 'str'>\n",
      "4830 <class 'str'>\n",
      "430 <class 'str'>\n",
      "203 <class 'str'>\n",
      "376 <class 'str'>\n",
      "4059 <class 'str'>\n",
      "2096 <class 'str'>\n",
      "854 <class 'str'>\n",
      "1340 <class 'str'>\n",
      "5730 <class 'str'>\n",
      "372 <class 'str'>\n",
      "454 <class 'str'>\n",
      "70 <class 'str'>\n",
      "800 <class 'str'>\n",
      "6447 <class 'str'>\n",
      "2850 <class 'str'>\n",
      "39 <class 'str'>\n",
      "757 <class 'str'>\n",
      "417 <class 'str'>\n",
      "2103 <class 'str'>\n",
      "3281 <class 'str'>\n",
      "4255 <class 'str'>\n",
      "2927 <class 'str'>\n",
      "1884 <class 'str'>\n",
      "641 <class 'str'>\n",
      "796 <class 'str'>\n",
      "805 <class 'str'>\n",
      "851 <class 'str'>\n",
      "1008 <class 'str'>\n",
      "4668 <class 'str'>\n",
      "3544 <class 'str'>\n",
      "2067 <class 'str'>\n",
      "570 <class 'str'>\n",
      "2397 <class 'str'>\n",
      "5666 <class 'str'>\n",
      "1837 <class 'str'>\n",
      "1843 <class 'str'>\n",
      "2870 <class 'str'>\n",
      "2196 <class 'str'>\n",
      "4369 <class 'str'>\n",
      "1563 <class 'str'>\n",
      "1157 <class 'str'>\n",
      "3070 <class 'str'>\n",
      "2172 <class 'str'>\n",
      "1466 <class 'str'>\n",
      "3169 <class 'str'>\n",
      "630 <class 'str'>\n",
      "1841 <class 'str'>\n",
      "149 <class 'str'>\n",
      "2468 <class 'str'>\n",
      "2445 <class 'str'>\n",
      "2783 <class 'str'>\n",
      "2113 <class 'str'>\n",
      "6017 <class 'str'>\n",
      "7941 <class 'str'>\n",
      "4276 <class 'str'>\n",
      "3674 <class 'str'>\n",
      "1009 <class 'str'>\n",
      "1947 <class 'str'>\n",
      "4247 <class 'str'>\n",
      "7789 <class 'str'>\n",
      "3735 <class 'str'>\n",
      "5284 <class 'str'>\n",
      "1973 <class 'str'>\n",
      "355 <class 'str'>\n",
      "175 <class 'str'>\n",
      "587 <class 'str'>\n",
      "4866 <class 'str'>\n",
      "1627 <class 'str'>\n",
      "5299 <class 'str'>\n",
      "5940 <class 'str'>\n",
      "2754 <class 'str'>\n",
      "7364 <class 'str'>\n",
      "2962 <class 'str'>\n",
      "4758 <class 'str'>\n",
      "4640 <class 'str'>\n",
      "2387 <class 'str'>\n",
      "1888 <class 'str'>\n",
      "5045 <class 'str'>\n",
      "3155 <class 'str'>\n",
      "2531 <class 'str'>\n",
      "2533 <class 'str'>\n",
      "3909 <class 'str'>\n",
      "1004 <class 'str'>\n",
      "378 <class 'str'>\n",
      "1704 <class 'str'>\n",
      "1554 <class 'str'>\n",
      "1369 <class 'str'>\n",
      "1169 <class 'str'>\n",
      "2716 <class 'str'>\n",
      "3422 <class 'str'>\n",
      "7224 <class 'str'>\n",
      "4237 <class 'str'>\n",
      "799 <class 'str'>\n",
      "786 <class 'str'>\n",
      "4264 <class 'str'>\n",
      "256 <class 'str'>\n",
      "3414 <class 'str'>\n",
      "3149 <class 'str'>\n",
      "1595 <class 'str'>\n",
      "2977 <class 'str'>\n",
      "3266 <class 'str'>\n",
      "3823 <class 'str'>\n",
      "1942 <class 'str'>\n",
      "3533 <class 'str'>\n",
      "1425 <class 'str'>\n",
      "468 <class 'str'>\n",
      "2816 <class 'str'>\n",
      "1191 <class 'str'>\n",
      "1040 <class 'str'>\n",
      "1961 <class 'str'>\n",
      "3230 <class 'str'>\n",
      "3571 <class 'str'>\n",
      "2083 <class 'str'>\n",
      "264 <class 'str'>\n",
      "2807 <class 'str'>\n",
      "859 <class 'str'>\n",
      "4946 <class 'str'>\n",
      "2248 <class 'str'>\n",
      "1997 <class 'str'>\n",
      "5933 <class 'str'>\n",
      "1051 <class 'str'>\n",
      "710 <class 'str'>\n",
      "2574 <class 'str'>\n",
      "746 <class 'str'>\n",
      "87 <class 'str'>\n",
      "4528 <class 'str'>\n",
      "2595 <class 'str'>\n",
      "1495 <class 'str'>\n",
      "2596 <class 'str'>\n",
      "2333 <class 'str'>\n",
      "72 <class 'str'>\n",
      "1101 <class 'str'>\n",
      "923 <class 'str'>\n",
      "7150 <class 'str'>\n",
      "2188 <class 'str'>\n",
      "5504 <class 'str'>\n",
      "1777 <class 'str'>\n",
      "467 <class 'str'>\n",
      "143 <class 'str'>\n",
      "599 <class 'str'>\n",
      "7627 <class 'str'>\n",
      "5540 <class 'str'>\n",
      "102 <class 'str'>\n",
      "6567 <class 'str'>\n",
      "7115 <class 'str'>\n",
      "857 <class 'str'>\n",
      "462 <class 'str'>\n",
      "1580 <class 'str'>\n",
      "6733 <class 'str'>\n",
      "2969 <class 'str'>\n",
      "3872 <class 'str'>\n",
      "5011 <class 'str'>\n",
      "1184 <class 'str'>\n",
      "1750 <class 'str'>\n",
      "2149 <class 'str'>\n",
      "647 <class 'str'>\n",
      "157 <class 'str'>\n",
      "1833 <class 'str'>\n",
      "1027 <class 'str'>\n",
      "1234 <class 'str'>\n",
      "2120 <class 'str'>\n",
      "3392 <class 'str'>\n",
      "4763 <class 'str'>\n",
      "590 <class 'str'>\n",
      "1158 <class 'str'>\n",
      "3669 <class 'str'>\n",
      "7290 <class 'str'>\n",
      "1073 <class 'str'>\n",
      "4446 <class 'str'>\n",
      "7475 <class 'str'>\n",
      "2770 <class 'str'>\n",
      "2630 <class 'str'>\n",
      "1280 <class 'str'>\n",
      "2785 <class 'str'>\n",
      "177 <class 'str'>\n",
      "1324 <class 'str'>\n",
      "1211 <class 'str'>\n",
      "4816 <class 'str'>\n",
      "1408 <class 'str'>\n",
      "2557 <class 'str'>\n",
      "995 <class 'str'>\n",
      "2394 <class 'str'>\n",
      "2504 <class 'str'>\n",
      "1233 <class 'str'>\n",
      "771 <class 'str'>\n",
      "3094 <class 'str'>\n",
      "1628 <class 'str'>\n",
      "124 <class 'str'>\n",
      "904 <class 'str'>\n",
      "3486 <class 'str'>\n",
      "1501 <class 'str'>\n",
      "58 <class 'str'>\n",
      "1684 <class 'str'>\n",
      "2065 <class 'str'>\n",
      "1220 <class 'str'>\n",
      "2799 <class 'str'>\n",
      "2872 <class 'str'>\n",
      "6228 <class 'str'>\n",
      "4775 <class 'str'>\n",
      "3931 <class 'str'>\n",
      "2571 <class 'str'>\n",
      "929 <class 'str'>\n",
      "3736 <class 'str'>\n",
      "248 <class 'str'>\n",
      "2879 <class 'str'>\n",
      "6272 <class 'str'>\n",
      "3026 <class 'str'>\n",
      "331 <class 'str'>\n",
      "1302 <class 'str'>\n",
      "5383 <class 'str'>\n",
      "1980 <class 'str'>\n",
      "3409 <class 'str'>\n",
      "5858 <class 'str'>\n",
      "2826 <class 'str'>\n",
      "637 <class 'str'>\n",
      "1614 <class 'str'>\n",
      "5525 <class 'str'>\n",
      "1805 <class 'str'>\n",
      "3536 <class 'str'>\n",
      "867 <class 'str'>\n",
      "5421 <class 'str'>\n",
      "1260 <class 'str'>\n",
      "1221 <class 'str'>\n",
      "968 <class 'str'>\n",
      "2796 <class 'str'>\n",
      "314 <class 'str'>\n",
      "3874 <class 'str'>\n",
      "813 <class 'str'>\n",
      "4918 <class 'str'>\n",
      "691 <class 'str'>\n",
      "3293 <class 'str'>\n",
      "4932 <class 'str'>\n",
      "1620 <class 'str'>\n",
      "1479 <class 'str'>\n",
      "1012 <class 'str'>\n",
      "2690 <class 'str'>\n",
      "3221 <class 'str'>\n",
      "2694 <class 'str'>\n",
      "2893 <class 'str'>\n",
      "3661 <class 'str'>\n",
      "4732 <class 'str'>\n",
      "1937 <class 'str'>\n",
      "1766 <class 'str'>\n",
      "6465 <class 'str'>\n",
      "2154 <class 'str'>\n",
      "597 <class 'str'>\n",
      "1994 <class 'str'>\n",
      "6075 <class 'str'>\n",
      "1632 <class 'str'>\n",
      "3002 <class 'str'>\n",
      "1699 <class 'str'>\n",
      "5060 <class 'str'>\n",
      "412 <class 'str'>\n",
      "4610 <class 'str'>\n",
      "3855 <class 'str'>\n",
      "485 <class 'str'>\n",
      "1609 <class 'str'>\n",
      "1021 <class 'str'>\n",
      "1159 <class 'str'>\n",
      "2405 <class 'str'>\n",
      "1763 <class 'str'>\n",
      "1819 <class 'str'>\n",
      "6415 <class 'str'>\n",
      "2706 <class 'str'>\n",
      "4904 <class 'str'>\n",
      "457 <class 'str'>\n",
      "936 <class 'str'>\n",
      "3962 <class 'str'>\n",
      "2628 <class 'str'>\n",
      "3630 <class 'str'>\n",
      "128 <class 'str'>\n",
      "5276 <class 'str'>\n",
      "148 <class 'str'>\n",
      "2014 <class 'str'>\n",
      "7536 <class 'str'>\n",
      "6148 <class 'str'>\n",
      "4916 <class 'str'>\n",
      "283 <class 'str'>\n",
      "3046 <class 'str'>\n",
      "559 <class 'str'>\n",
      "829 <class 'str'>\n",
      "1617 <class 'str'>\n",
      "4201 <class 'str'>\n",
      "475 <class 'str'>\n",
      "1639 <class 'str'>\n",
      "1926 <class 'str'>\n",
      "292 <class 'str'>\n",
      "6129 <class 'str'>\n",
      "30 <class 'str'>\n",
      "6916 <class 'str'>\n",
      "5074 <class 'str'>\n",
      "3541 <class 'str'>\n",
      "1504 <class 'str'>\n",
      "5364 <class 'str'>\n",
      "4779 <class 'str'>\n",
      "4870 <class 'str'>\n",
      "2049 <class 'str'>\n",
      "2476 <class 'str'>\n",
      "4982 <class 'str'>\n",
      "1463 <class 'str'>\n",
      "852 <class 'str'>\n",
      "5397 <class 'str'>\n",
      "614 <class 'str'>\n",
      "6178 <class 'str'>\n",
      "329 <class 'str'>\n",
      "2466 <class 'str'>\n",
      "4457 <class 'str'>\n",
      "696 <class 'str'>\n",
      "2546 <class 'str'>\n",
      "1409 <class 'str'>\n",
      "57 <class 'str'>\n",
      "1866 <class 'str'>\n",
      "341 <class 'str'>\n",
      "6974 <class 'str'>\n",
      "517 <class 'str'>\n",
      "4922 <class 'str'>\n",
      "4420 <class 'str'>\n",
      "3057 <class 'str'>\n",
      "1589 <class 'str'>\n",
      "6919 <class 'str'>\n",
      "568 <class 'str'>\n",
      "4468 <class 'str'>\n",
      "2353 <class 'str'>\n",
      "207 <class 'str'>\n",
      "1348 <class 'str'>\n",
      "1416 <class 'str'>\n",
      "2159 <class 'str'>\n",
      "4535 <class 'str'>\n",
      "745 <class 'str'>\n",
      "4761 <class 'str'>\n",
      "6006 <class 'str'>\n",
      "448 <class 'str'>\n",
      "3254 <class 'str'>\n",
      "2281 <class 'str'>\n",
      "1522 <class 'str'>\n",
      "1331 <class 'str'>\n",
      "4425 <class 'str'>\n",
      "4935 <class 'str'>\n",
      "1328 <class 'str'>\n",
      "4984 <class 'str'>\n",
      "5040 <class 'str'>\n",
      "6566 <class 'str'>\n",
      "4553 <class 'str'>\n",
      "1556 <class 'str'>\n",
      "4 <class 'str'>\n",
      "1676 <class 'str'>\n",
      "700 <class 'str'>\n",
      "255 <class 'str'>\n",
      "1534 <class 'str'>\n",
      "5878 <class 'str'>\n",
      "860 <class 'str'>\n",
      "3115 <class 'str'>\n",
      "1346 <class 'str'>\n",
      "5240 <class 'str'>\n",
      "3157 <class 'str'>\n",
      "2417 <class 'str'>\n",
      "6301 <class 'str'>\n",
      "4484 <class 'str'>\n",
      "5579 <class 'str'>\n",
      "2147 <class 'str'>\n",
      "1800 <class 'str'>\n",
      "5846 <class 'str'>\n",
      "7393 <class 'str'>\n",
      "3283 <class 'str'>\n",
      "777 <class 'str'>\n",
      "195 <class 'str'>\n",
      "3274 <class 'str'>\n",
      "2645 <class 'str'>\n",
      "841 <class 'str'>\n",
      "2317 <class 'str'>\n",
      "5098 <class 'str'>\n",
      "538 <class 'str'>\n",
      "251 <class 'str'>\n",
      "4261 <class 'str'>\n",
      "4022 <class 'str'>\n",
      "24 <class 'str'>\n",
      "2457 <class 'str'>\n",
      "2075 <class 'str'>\n",
      "1703 <class 'str'>\n",
      "2832 <class 'str'>\n",
      "2055 <class 'str'>\n",
      "5134 <class 'str'>\n",
      "4259 <class 'str'>\n",
      "2009 <class 'str'>\n",
      "1148 <class 'str'>\n",
      "176 <class 'str'>\n",
      "3204 <class 'str'>\n",
      "2384 <class 'str'>\n",
      "18 <class 'str'>\n",
      "1572 <class 'str'>\n",
      "254 <class 'str'>\n",
      "6295 <class 'str'>\n",
      "4550 <class 'str'>\n",
      "4707 <class 'str'>\n",
      "1634 <class 'str'>\n",
      "1963 <class 'str'>\n",
      "420 <class 'str'>\n",
      "752 <class 'str'>\n",
      "1224 <class 'str'>\n",
      "4471 <class 'str'>\n",
      "4503 <class 'str'>\n",
      "4222 <class 'str'>\n",
      "7018 <class 'str'>\n",
      "2711 <class 'str'>\n",
      "646 <class 'str'>\n",
      "5735 <class 'str'>\n",
      "3280 <class 'str'>\n",
      "1886 <class 'str'>\n",
      "2480 <class 'str'>\n",
      "4835 <class 'str'>\n",
      "874 <class 'str'>\n",
      "1749 <class 'str'>\n",
      "1433 <class 'str'>\n",
      "2345 <class 'str'>\n",
      "1733 <class 'str'>\n",
      "610 <class 'str'>\n",
      "4579 <class 'str'>\n",
      "907 <class 'str'>\n",
      "4397 <class 'str'>\n",
      "3090 <class 'str'>\n",
      "4174 <class 'str'>\n",
      "2240 <class 'str'>\n",
      "416 <class 'str'>\n",
      "5404 <class 'str'>\n",
      "3548 <class 'str'>\n",
      "5198 <class 'str'>\n",
      "4664 <class 'str'>\n",
      "1956 <class 'str'>\n",
      "3693 <class 'str'>\n",
      "4357 <class 'str'>\n",
      "3546 <class 'str'>\n",
      "2244 <class 'str'>\n",
      "5402 <class 'str'>\n",
      "1444 <class 'str'>\n",
      "2369 <class 'str'>\n",
      "1127 <class 'str'>\n",
      "428 <class 'str'>\n",
      "1795 <class 'str'>\n",
      "1615 <class 'str'>\n",
      "473 <class 'str'>\n",
      "2265 <class 'str'>\n",
      "5166 <class 'str'>\n",
      "369 <class 'str'>\n",
      "1803 <class 'str'>\n",
      "358 <class 'str'>\n",
      "1621 <class 'str'>\n",
      "2204 <class 'str'>\n",
      "3945 <class 'str'>\n",
      "1257 <class 'str'>\n",
      "1180 <class 'str'>\n",
      "2057 <class 'str'>\n",
      "595 <class 'str'>\n",
      "265 <class 'str'>\n",
      "2989 <class 'str'>\n",
      "2280 <class 'str'>\n",
      "3000 <class 'str'>\n",
      "7288 <class 'str'>\n",
      "4198 <class 'str'>\n",
      "1134 <class 'str'>\n",
      "3160 <class 'str'>\n",
      "6669 <class 'str'>\n",
      "2659 <class 'str'>\n",
      "4120 <class 'str'>\n",
      "61 <class 'str'>\n",
      "6455 <class 'str'>\n",
      "282 <class 'str'>\n",
      "1983 <class 'str'>\n",
      "1577 <class 'str'>\n",
      "2167 <class 'str'>\n",
      "321 <class 'str'>\n",
      "6613 <class 'str'>\n",
      "1974 <class 'str'>\n",
      "6937 <class 'str'>\n",
      "4116 <class 'str'>\n",
      "4861 <class 'str'>\n",
      "480 <class 'str'>\n",
      "4445 <class 'str'>\n",
      "1818 <class 'str'>\n",
      "4007 <class 'str'>\n",
      "1396 <class 'str'>\n",
      "1807 <class 'str'>\n",
      "1440 <class 'str'>\n",
      "3120 <class 'str'>\n",
      "1193 <class 'str'>\n",
      "1985 <class 'str'>\n",
      "631 <class 'str'>\n",
      "4464 <class 'str'>\n",
      "1045 <class 'str'>\n",
      "6110 <class 'str'>\n",
      "5223 <class 'str'>\n",
      "258 <class 'str'>\n",
      "4214 <class 'str'>\n",
      "2324 <class 'str'>\n",
      "3880 <class 'str'>\n",
      "1365 <class 'str'>\n",
      "998 <class 'str'>\n",
      "118 <class 'str'>\n",
      "1083 <class 'str'>\n",
      "2112 <class 'str'>\n",
      "1028 <class 'str'>\n",
      "967 <class 'str'>\n",
      "5804 <class 'str'>\n",
      "7330 <class 'str'>\n",
      "1288 <class 'str'>\n",
      "3854 <class 'str'>\n",
      "1612 <class 'str'>\n",
      "4230 <class 'str'>\n",
      "3573 <class 'str'>\n",
      "308 <class 'str'>\n",
      "3970 <class 'str'>\n",
      "3396 <class 'str'>\n",
      "3348 <class 'str'>\n",
      "4128 <class 'str'>\n",
      "3271 <class 'str'>\n",
      "3172 <class 'str'>\n",
      "5067 <class 'str'>\n",
      "1850 <class 'str'>\n",
      "2024 <class 'str'>\n",
      "7883 <class 'str'>\n",
      "1128 <class 'str'>\n",
      "1443 <class 'str'>\n",
      "1706 <class 'str'>\n",
      "4713 <class 'str'>\n",
      "4045 <class 'str'>\n",
      "1304 <class 'str'>\n",
      "1500 <class 'str'>\n",
      "3876 <class 'str'>\n",
      "1143 <class 'str'>\n",
      "1541 <class 'str'>\n",
      "7085 <class 'str'>\n",
      "1371 <class 'str'>\n",
      "2039 <class 'str'>\n",
      "3743 <class 'str'>\n",
      "2 <class 'str'>\n",
      "3963 <class 'str'>\n",
      "2973 <class 'str'>\n",
      "1829 <class 'str'>\n",
      "5385 <class 'str'>\n",
      "3338 <class 'str'>\n",
      "6838 <class 'str'>\n",
      "959 <class 'str'>\n",
      "1658 <class 'str'>\n",
      "2854 <class 'str'>\n",
      "82 <class 'str'>\n",
      "586 <class 'str'>\n",
      "4829 <class 'str'>\n",
      "1890 <class 'str'>\n",
      "4202 <class 'str'>\n",
      "464 <class 'str'>\n",
      "4338 <class 'str'>\n",
      "2060 <class 'str'>\n",
      "2502 <class 'str'>\n",
      "5782 <class 'str'>\n",
      "1456 <class 'str'>\n",
      "1625 <class 'str'>\n",
      "3691 <class 'str'>\n",
      "5020 <class 'str'>\n",
      "204 <class 'str'>\n",
      "3635 <class 'str'>\n",
      "2620 <class 'str'>\n",
      "4906 <class 'str'>\n",
      "1179 <class 'str'>\n",
      "6384 <class 'str'>\n",
      "814 <class 'str'>\n",
      "4482 <class 'str'>\n",
      "244 <class 'str'>\n",
      "3798 <class 'str'>\n",
      "2313 <class 'str'>\n",
      "7509 <class 'str'>\n",
      "7611 <class 'str'>\n",
      "4531 <class 'str'>\n",
      "2095 <class 'str'>\n",
      "1708 <class 'str'>\n",
      "3259 <class 'str'>\n",
      "954 <class 'str'>\n",
      "1490 <class 'str'>\n",
      "6094 <class 'str'>\n",
      "5564 <class 'str'>\n",
      "5210 <class 'str'>\n",
      "2812 <class 'str'>\n",
      "2554 <class 'str'>\n",
      "5280 <class 'str'>\n",
      "360 <class 'str'>\n",
      "6802 <class 'str'>\n",
      "1291 <class 'str'>\n",
      "7599 <class 'str'>\n",
      "5776 <class 'str'>\n",
      "2035 <class 'str'>\n",
      "5371 <class 'str'>\n",
      "1611 <class 'str'>\n",
      "1188 <class 'str'>\n",
      "6229 <class 'str'>\n",
      "4639 <class 'str'>\n",
      "5960 <class 'str'>\n",
      "4953 <class 'str'>\n",
      "2235 <class 'str'>\n",
      "992 <class 'str'>\n",
      "3631 <class 'str'>\n",
      "534 <class 'str'>\n",
      "5208 <class 'str'>\n",
      "1757 <class 'str'>\n",
      "3417 <class 'str'>\n",
      "723 <class 'str'>\n",
      "3673 <class 'str'>\n",
      "2105 <class 'str'>\n",
      "1599 <class 'str'>\n",
      "7532 <class 'str'>\n",
      "6853 <class 'str'>\n",
      "2484 <class 'str'>\n",
      "6632 <class 'str'>\n",
      "6526 <class 'str'>\n",
      "5206 <class 'str'>\n",
      "699 <class 'str'>\n",
      "3416 <class 'str'>\n",
      "3276 <class 'str'>\n",
      "2765 <class 'str'>\n",
      "764 <class 'str'>\n",
      "291 <class 'str'>\n",
      "3842 <class 'str'>\n",
      "2631 <class 'str'>\n",
      "734 <class 'str'>\n",
      "2965 <class 'str'>\n",
      "4680 <class 'str'>\n",
      "7664 <class 'str'>\n",
      "5807 <class 'str'>\n",
      "320 <class 'str'>\n",
      "1303 <class 'str'>\n",
      "3192 <class 'str'>\n",
      "5186 <class 'str'>\n",
      "795 <class 'str'>\n",
      "192 <class 'str'>\n",
      "1448 <class 'str'>\n",
      "190 <class 'str'>\n",
      "509 <class 'str'>\n",
      "543 <class 'str'>\n",
      "1437 <class 'str'>\n",
      "6714 <class 'str'>\n",
      "3301 <class 'str'>\n",
      "6439 <class 'str'>\n",
      "551 <class 'str'>\n",
      "638 <class 'str'>\n",
      "648 <class 'str'>\n",
      "1909 <class 'str'>\n",
      "1450 <class 'str'>\n",
      "4099 <class 'str'>\n",
      "3866 <class 'str'>\n",
      "3879 <class 'str'>\n",
      "1198 <class 'str'>\n",
      "2007 <class 'str'>\n",
      "486 <class 'str'>\n",
      "2966 <class 'str'>\n",
      "939 <class 'str'>\n",
      "3759 <class 'str'>\n",
      "3711 <class 'str'>\n",
      "5090 <class 'str'>\n",
      "1390 <class 'str'>\n",
      "4218 <class 'str'>\n",
      "3703 <class 'str'>\n",
      "7080 <class 'str'>\n",
      "210 <class 'str'>\n",
      "2403 <class 'str'>\n",
      "6320 <class 'str'>\n",
      "4416 <class 'str'>\n",
      "3979 <class 'str'>\n",
      "1226 <class 'str'>\n",
      "1936 <class 'str'>\n",
      "1539 <class 'str'>\n",
      "6328 <class 'str'>\n",
      "3065 <class 'str'>\n",
      "2418 <class 'str'>\n",
      "2270 <class 'str'>\n",
      "824 <class 'str'>\n",
      "471 <class 'str'>\n",
      "7336 <class 'str'>\n",
      "617 <class 'str'>\n",
      "605 <class 'str'>\n",
      "3918 <class 'str'>\n",
      "2027 <class 'str'>\n",
      "602 <class 'str'>\n",
      "5023 <class 'str'>\n",
      "1899 <class 'str'>\n",
      "424 <class 'str'>\n",
      "216 <class 'str'>\n",
      "6368 <class 'str'>\n",
      "761 <class 'str'>\n",
      "1555 <class 'str'>\n",
      "3719 <class 'str'>\n",
      "4623 <class 'str'>\n",
      "2019 <class 'str'>\n",
      "2348 <class 'str'>\n",
      "3320 <class 'str'>\n",
      "7753 <class 'str'>\n",
      "5266 <class 'str'>\n",
      "193 <class 'str'>\n",
      "1565 <class 'str'>\n",
      "3304 <class 'str'>\n",
      "122 <class 'str'>\n",
      "5291 <class 'str'>\n",
      "1275 <class 'str'>\n",
      "4000 <class 'str'>\n",
      "5429 <class 'str'>\n",
      "2092 <class 'str'>\n",
      "4279 <class 'str'>\n",
      "766 <class 'str'>\n",
      "6132 <class 'str'>\n",
      "3354 <class 'str'>\n",
      "1744 <class 'str'>\n",
      "702 <class 'str'>\n",
      "1368 <class 'str'>\n",
      "6057 <class 'str'>\n",
      "6532 <class 'str'>\n",
      "1199 <class 'str'>\n",
      "2831 <class 'str'>\n",
      "2010 <class 'str'>\n",
      "3582 <class 'str'>\n",
      "4718 <class 'str'>\n",
      "425 <class 'str'>\n",
      "405 <class 'str'>\n",
      "1972 <class 'str'>\n",
      "5874 <class 'str'>\n",
      "5046 <class 'str'>\n",
      "2180 <class 'str'>\n",
      "4903 <class 'str'>\n",
      "1096 <class 'str'>\n",
      "5920 <class 'str'>\n",
      "5261 <class 'str'>\n",
      "2238 <class 'str'>\n",
      "4156 <class 'str'>\n",
      "970 <class 'str'>\n",
      "5 <class 'str'>\n",
      "488 <class 'str'>\n",
      "749 <class 'str'>\n",
      "4455 <class 'str'>\n",
      "583 <class 'str'>\n",
      "1845 <class 'str'>\n",
      "3197 <class 'str'>\n",
      "4849 <class 'str'>\n",
      "2530 <class 'str'>\n",
      "5675 <class 'str'>\n",
      "2555 <class 'str'>\n",
      "562 <class 'str'>\n",
      "4370 <class 'str'>\n",
      "3655 <class 'str'>\n",
      "261 <class 'str'>\n",
      "64 <class 'str'>\n",
      "780 <class 'str'>\n",
      "5523 <class 'str'>\n",
      "297 <class 'str'>\n",
      "2512 <class 'str'>\n",
      "2066 <class 'str'>\n",
      "236 <class 'str'>\n",
      "5612 <class 'str'>\n",
      "3575 <class 'str'>\n",
      "2013 <class 'str'>\n",
      "2097 <class 'str'>\n",
      "133 <class 'str'>\n",
      "3568 <class 'str'>\n",
      "4804 <class 'str'>\n",
      "307 <class 'str'>\n",
      "720 <class 'str'>\n",
      "2715 <class 'str'>\n",
      "3316 <class 'str'>\n",
      "3799 <class 'str'>\n",
      "3098 <class 'str'>\n",
      "7442 <class 'str'>\n",
      "1481 <class 'str'>\n",
      "3156 <class 'str'>\n",
      "6051 <class 'str'>\n",
      "130 <class 'str'>\n",
      "671 <class 'str'>\n",
      "5459 <class 'str'>\n",
      "2724 <class 'str'>\n",
      "266 <class 'str'>\n",
      "1875 <class 'str'>\n",
      "2093 <class 'str'>\n",
      "1755 <class 'str'>\n",
      "2649 <class 'str'>\n",
      "3459 <class 'str'>\n",
      "628 <class 'str'>\n",
      "1356 <class 'str'>\n",
      "3781 <class 'str'>\n",
      "4519 <class 'str'>\n",
      "5151 <class 'str'>\n",
      "1248 <class 'str'>\n",
      "3128 <class 'str'>\n",
      "3024 <class 'str'>\n",
      "661 <class 'str'>\n",
      "2777 <class 'str'>\n",
      "482 <class 'str'>\n",
      "1338 <class 'str'>\n",
      "1506 <class 'str'>\n",
      "2486 <class 'str'>\n",
      "6076 <class 'str'>\n",
      "5362 <class 'str'>\n",
      "5851 <class 'str'>\n",
      "2017 <class 'str'>\n",
      "861 <class 'str'>\n",
      "1415 <class 'str'>\n",
      "259 <class 'str'>\n",
      "4662 <class 'str'>\n",
      "669 <class 'str'>\n",
      "2059 <class 'str'>\n",
      "946 <class 'str'>\n",
      "1950 <class 'str'>\n",
      "7221 <class 'str'>\n",
      "4924 <class 'str'>\n",
      "1351 <class 'str'>\n",
      "2359 <class 'str'>\n",
      "4046 <class 'str'>\n",
      "3014 <class 'str'>\n",
      "4956 <class 'str'>\n",
      "2481 <class 'str'>\n",
      "3657 <class 'str'>\n",
      "4193 <class 'str'>\n",
      "1526 <class 'str'>\n",
      "1337 <class 'str'>\n",
      "31 <class 'str'>\n",
      "3977 <class 'str'>\n",
      "2586 <class 'str'>\n",
      "1318 <class 'str'>\n",
      "831 <class 'str'>\n",
      "2549 <class 'str'>\n",
      "2759 <class 'str'>\n",
      "4880 <class 'str'>\n",
      "1734 <class 'str'>\n",
      "3267 <class 'str'>\n",
      "1962 <class 'str'>\n",
      "164 <class 'str'>\n",
      "262 <class 'str'>\n",
      "3538 <class 'str'>\n",
      "7033 <class 'str'>\n",
      "3933 <class 'str'>\n",
      "3586 <class 'str'>\n",
      "5073 <class 'str'>\n",
      "1748 <class 'str'>\n",
      "5948 <class 'str'>\n",
      "2528 <class 'str'>\n",
      "3378 <class 'str'>\n",
      "4524 <class 'str'>\n",
      "126 <class 'str'>\n",
      "6925 <class 'str'>\n",
      "1299 <class 'str'>\n",
      "2005 <class 'str'>\n",
      "463 <class 'str'>\n",
      "6571 <class 'str'>\n",
      "3088 <class 'str'>\n",
      "260 <class 'str'>\n",
      "474 <class 'str'>\n",
      "3390 <class 'str'>\n",
      "4882 <class 'str'>\n",
      "754 <class 'str'>\n",
      "2702 <class 'str'>\n",
      "4657 <class 'str'>\n",
      "367 <class 'str'>\n",
      "5702 <class 'str'>\n",
      "1741 <class 'str'>\n",
      "44 <class 'str'>\n",
      "4320 <class 'str'>\n",
      "1948 <class 'str'>\n",
      "1212 <class 'str'>\n",
      "220 <class 'str'>\n",
      "4840 <class 'str'>\n",
      "763 <class 'str'>\n",
      "1402 <class 'str'>\n",
      "883 <class 'str'>\n",
      "2585 <class 'str'>\n",
      "900 <class 'str'>\n",
      "3939 <class 'str'>\n",
      "145 <class 'str'>\n",
      "2523 <class 'str'>\n",
      "4029 <class 'str'>\n",
      "3672 <class 'str'>\n",
      "6667 <class 'str'>\n",
      "5241 <class 'str'>\n",
      "3208 <class 'str'>\n",
      "489 <class 'str'>\n",
      "2478 <class 'str'>\n",
      "1006 <class 'str'>\n",
      "7084 <class 'str'>\n",
      "2337 <class 'str'>\n",
      "6137 <class 'str'>\n",
      "2820 <class 'str'>\n",
      "3926 <class 'str'>\n",
      "342 <class 'str'>\n",
      "2830 <class 'str'>\n",
      "1525 <class 'str'>\n",
      "65 <class 'str'>\n",
      "4697 <class 'str'>\n",
      "3246 <class 'str'>\n",
      "5013 <class 'str'>\n",
      "2291 <class 'str'>\n",
      "6512 <class 'str'>\n",
      "3461 <class 'str'>\n",
      "86 <class 'str'>\n",
      "1222 <class 'str'>\n",
      "5277 <class 'str'>\n",
      "6096 <class 'str'>\n",
      "7240 <class 'str'>\n",
      "3191 <class 'str'>\n",
      "6339 <class 'str'>\n",
      "654 <class 'str'>\n",
      "3290 <class 'str'>\n",
      "1244 <class 'str'>\n",
      "4364 <class 'str'>\n",
      "3518 <class 'str'>\n",
      "629 <class 'str'>\n",
      "2045 <class 'str'>\n",
      "3015 <class 'str'>\n",
      "5109 <class 'str'>\n",
      "612 <class 'str'>\n",
      "2470 <class 'str'>\n",
      "6235 <class 'str'>\n",
      "833 <class 'str'>\n",
      "2821 <class 'str'>\n",
      "1404 <class 'str'>\n",
      "1680 <class 'str'>\n",
      "3357 <class 'str'>\n",
      "6271 <class 'str'>\n",
      "3285 <class 'str'>\n",
      "1412 <class 'str'>\n",
      "1434 <class 'str'>\n",
      "878 <class 'str'>\n",
      "6375 <class 'str'>\n",
      "97 <class 'str'>\n",
      "2396 <class 'str'>\n",
      "4242 <class 'str'>\n",
      "2146 <class 'str'>\n",
      "5684 <class 'str'>\n",
      "2886 <class 'str'>\n",
      "441 <class 'str'>\n",
      "3030 <class 'str'>\n",
      "5419 <class 'str'>\n",
      "882 <class 'str'>\n",
      "835 <class 'str'>\n",
      "5115 <class 'str'>\n",
      "572 <class 'str'>\n",
      "6282 <class 'str'>\n",
      "1387 <class 'str'>\n",
      "2527 <class 'str'>\n",
      "2600 <class 'str'>\n",
      "1066 <class 'str'>\n",
      "560 <class 'str'>\n",
      "3122 <class 'str'>\n",
      "3592 <class 'str'>\n",
      "2293 <class 'str'>\n",
      "1114 <class 'str'>\n",
      "1558 <class 'str'>\n",
      "3060 <class 'str'>\n",
      "784 <class 'str'>\n",
      "1694 <class 'str'>\n",
      "4841 <class 'str'>\n",
      "2404 <class 'str'>\n",
      "3702 <class 'str'>\n",
      "4967 <class 'str'>\n",
      "7987 <class 'str'>\n",
      "3203 <class 'str'>\n",
      "3581 <class 'str'>\n",
      "1768 <class 'str'>\n",
      "743 <class 'str'>\n",
      "218 <class 'str'>\n",
      "1834 <class 'str'>\n",
      "4638 <class 'str'>\n",
      "423 <class 'str'>\n",
      "384 <class 'str'>\n",
      "3031 <class 'str'>\n",
      "1996 <class 'str'>\n",
      "7740 <class 'str'>\n",
      "3398 <class 'str'>\n",
      "5274 <class 'str'>\n",
      "6039 <class 'str'>\n",
      "769 <class 'str'>\n",
      "7404 <class 'str'>\n",
      "1979 <class 'str'>\n",
      "2636 <class 'str'>\n",
      "153 <class 'str'>\n",
      "2485 <class 'str'>\n",
      "4474 <class 'str'>\n",
      "1033 <class 'str'>\n",
      "2983 <class 'str'>\n",
      "4596 <class 'str'>\n",
      "17 <class 'str'>\n",
      "1272 <class 'str'>\n",
      "1069 <class 'str'>\n",
      "3069 <class 'str'>\n",
      "6426 <class 'str'>\n",
      "2748 <class 'str'>\n",
      "4329 <class 'str'>\n",
      "6185 <class 'str'>\n",
      "4703 <class 'str'>\n",
      "5945 <class 'str'>\n",
      "2957 <class 'str'>\n",
      "2859 <class 'str'>\n",
      "626 <class 'str'>\n",
      "4065 <class 'str'>\n",
      "79 <class 'str'>\n",
      "1310 <class 'str'>\n",
      "6626 <class 'str'>\n",
      "1740 <class 'str'>\n",
      "107 <class 'str'>\n",
      "941 <class 'str'>\n",
      "4133 <class 'str'>\n",
      "1905 <class 'str'>\n",
      "2224 <class 'str'>\n",
      "1887 <class 'str'>\n",
      "2937 <class 'str'>\n",
      "1776 <class 'str'>\n",
      "2118 <class 'str'>\n",
      "2110 <class 'str'>\n",
      "4248 <class 'str'>\n",
      "2004 <class 'str'>\n",
      "7302 <class 'str'>\n",
      "1914 <class 'str'>\n",
      "2757 <class 'str'>\n",
      "7087 <class 'str'>\n",
      "6983 <class 'str'>\n",
      "1296 <class 'str'>\n",
      "1549 <class 'str'>\n",
      "1185 <class 'str'>\n",
      "2475 <class 'str'>\n",
      "6547 <class 'str'>\n",
      "1153 <class 'str'>\n",
      "7669 <class 'str'>\n",
      "2046 <class 'str'>\n",
      "3213 <class 'str'>\n",
      "1085 <class 'str'>\n",
      "2193 <class 'str'>\n",
      "4044 <class 'str'>\n",
      "2258 <class 'str'>\n",
      "3022 <class 'str'>\n",
      "1827 <class 'str'>\n",
      "465 <class 'str'>\n",
      "997 <class 'str'>\n",
      "5732 <class 'str'>\n",
      "5133 <class 'str'>\n",
      "4359 <class 'str'>\n",
      "3096 <class 'str'>\n",
      "767 <class 'str'>\n",
      "3404 <class 'str'>\n",
      "621 <class 'str'>\n",
      "5181 <class 'str'>\n",
      "398 <class 'str'>\n",
      "104 <class 'str'>\n",
      "806 <class 'str'>\n",
      "1653 <class 'str'>\n",
      "1399 <class 'str'>\n",
      "3704 <class 'str'>\n",
      "187 <class 'str'>\n",
      "4681 <class 'str'>\n",
      "2561 <class 'str'>\n",
      "4165 <class 'str'>\n",
      "2883 <class 'str'>\n",
      "1359 <class 'str'>\n",
      "2847 <class 'str'>\n",
      "5703 <class 'str'>\n",
      "3182 <class 'str'>\n",
      "1806 <class 'str'>\n",
      "3873 <class 'str'>\n",
      "7202 <class 'str'>\n",
      "855 <class 'str'>\n",
      "888 <class 'str'>\n",
      "6287 <class 'str'>\n",
      "5674 <class 'str'>\n",
      "5745 <class 'str'>\n",
      "899 <class 'str'>\n",
      "981 <class 'str'>\n",
      "493 <class 'str'>\n",
      "4945 <class 'str'>\n",
      "6378 <class 'str'>\n",
      "3911 <class 'str'>\n",
      "4418 <class 'str'>\n",
      "4152 <class 'str'>\n",
      "624 <class 'str'>\n",
      "45 <class 'str'>\n",
      "4686 <class 'str'>\n",
      "4200 <class 'str'>\n",
      "6553 <class 'str'>\n",
      "2423 <class 'str'>\n",
      "585 <class 'str'>\n",
      "6582 <class 'str'>\n",
      "681 <class 'str'>\n",
      "7813 <class 'str'>\n",
      "2251 <class 'str'>\n",
      "5815 <class 'str'>\n",
      "242 <class 'str'>\n",
      "1074 <class 'str'>\n",
      "2599 <class 'str'>\n",
      "6482 <class 'str'>\n",
      "7096 <class 'str'>\n",
      "7383 <class 'str'>\n",
      "8086 <class 'str'>\n",
      "3574 <class 'str'>\n",
      "6806 <class 'str'>\n",
      "4150 <class 'str'>\n",
      "3265 <class 'str'>\n",
      "4140 <class 'str'>\n",
      "955 <class 'str'>\n",
      "4478 <class 'str'>\n",
      "1635 <class 'str'>\n",
      "3988 <class 'str'>\n",
      "2422 <class 'str'>\n",
      "1077 <class 'str'>\n",
      "1570 <class 'str'>\n",
      "395 <class 'str'>\n",
      "6936 <class 'str'>\n",
      "1309 <class 'str'>\n",
      "4475 <class 'str'>\n",
      "6719 <class 'str'>\n",
      "2559 <class 'str'>\n",
      "6515 <class 'str'>\n",
      "2563 <class 'str'>\n",
      "298 <class 'str'>\n",
      "2736 <class 'str'>\n",
      "7135 <class 'str'>\n",
      "5165 <class 'str'>\n",
      "5415 <class 'str'>\n",
      "4573 <class 'str'>\n",
      "178 <class 'str'>\n",
      "1366 <class 'str'>\n",
      "645 <class 'str'>\n",
      "3563 <class 'str'>\n",
      "2772 <class 'str'>\n",
      "827 <class 'str'>\n",
      "1261 <class 'str'>\n",
      "6291 <class 'str'>\n",
      "3127 <class 'str'>\n",
      "2667 <class 'str'>\n",
      "6165 <class 'str'>\n",
      "718 <class 'str'>\n",
      "1465 <class 'str'>\n",
      "1696 <class 'str'>\n",
      "7804 <class 'str'>\n",
      "1626 <class 'str'>\n",
      "4653 <class 'str'>\n",
      "2999 <class 'str'>\n",
      "2385 <class 'str'>\n",
      "2431 <class 'str'>\n",
      "3856 <class 'str'>\n",
      "2912 <class 'str'>\n",
      "1659 <class 'str'>\n",
      "870 <class 'str'>\n",
      "1548 <class 'str'>\n",
      "2435 <class 'str'>\n",
      "4793 <class 'str'>\n",
      "4025 <class 'str'>\n",
      "2198 <class 'str'>\n",
      "1273 <class 'str'>\n",
      "2012 <class 'str'>\n",
      "5769 <class 'str'>\n",
      "5537 <class 'str'>\n",
      "3511 <class 'str'>\n",
      "2367 <class 'str'>\n",
      "6909 <class 'str'>\n",
      "1724 <class 'str'>\n",
      "4655 <class 'str'>\n",
      "4290 <class 'str'>\n",
      "344 <class 'str'>\n",
      "6486 <class 'str'>\n",
      "5809 <class 'str'>\n",
      "6011 <class 'str'>\n",
      "694 <class 'str'>\n",
      "2128 <class 'str'>\n",
      "6580 <class 'str'>\n",
      "3555 <class 'str'>\n",
      "4813 <class 'str'>\n",
      "1492 <class 'str'>\n",
      "4178 <class 'str'>\n",
      "4863 <class 'str'>\n",
      "2111 <class 'str'>\n",
      "1984 <class 'str'>\n",
      "7936 <class 'str'>\n",
      "5509 <class 'str'>\n",
      "7833 <class 'str'>\n",
      "100 <class 'str'>\n",
      "5116 <class 'str'>\n",
      "174 <class 'str'>\n",
      "3145 <class 'str'>\n",
      "1401 <class 'str'>\n",
      "2388 <class 'str'>\n",
      "1970 <class 'str'>\n",
      "785 <class 'str'>\n",
      "4439 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['kilometer'].unique():\n",
    "    print(val, type(val))\n",
    "    # 数据类型不对且有异常值, [0,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MHXWlHFf21sM",
   "metadata": {
    "id": "MHXWlHFf21sM"
   },
   "source": [
    "### 1.2.2 test data - 数据类别检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-SRL4mmR28f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1750469748966,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "-SRL4mmR28f5",
    "outputId": "42898802-04ef-4bfc-b56f-118e6044cdce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>35382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>5847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2310 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "notRepairedDamage\n",
       "0.0     35382\n",
       "-        5847\n",
       "1.0      4127\n",
       "0        1120\n",
       "1530       19\n",
       "        ...  \n",
       "1241        1\n",
       "1525        1\n",
       "2619        1\n",
       "864         1\n",
       "1550        1\n",
       "Name: count, Length: 2310, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NT59Ln3D3KuU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1750469756053,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "NT59Ln3D3KuU",
    "outputId": "a4912132-7e6d-4645-87ff-ec13dd6d3569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 <class 'str'>\n",
      "1.0 <class 'str'>\n",
      "- <class 'str'>\n",
      "2085 <class 'str'>\n",
      "0 <class 'str'>\n",
      "5953 <class 'str'>\n",
      "3169 <class 'str'>\n",
      "964 <class 'str'>\n",
      "2025 <class 'str'>\n",
      "5623 <class 'str'>\n",
      "3351 <class 'str'>\n",
      "1233 <class 'str'>\n",
      "4007 <class 'str'>\n",
      "1552 <class 'str'>\n",
      "2962 <class 'str'>\n",
      "3517 <class 'str'>\n",
      "309 <class 'str'>\n",
      "4454 <class 'str'>\n",
      "803 <class 'str'>\n",
      "2859 <class 'str'>\n",
      "4175 <class 'str'>\n",
      "831 <class 'str'>\n",
      "1222 <class 'str'>\n",
      "4107 <class 'str'>\n",
      "2251 <class 'str'>\n",
      "4652 <class 'str'>\n",
      "4573 <class 'str'>\n",
      "718 <class 'str'>\n",
      "238 <class 'str'>\n",
      "2718 <class 'str'>\n",
      "1535 <class 'str'>\n",
      "5191 <class 'str'>\n",
      "2957 <class 'str'>\n",
      "3677 <class 'str'>\n",
      "3047 <class 'str'>\n",
      "1597 <class 'str'>\n",
      "84 <class 'str'>\n",
      "2986 <class 'str'>\n",
      "1973 <class 'str'>\n",
      "3953 <class 'str'>\n",
      "725 <class 'str'>\n",
      "2219 <class 'str'>\n",
      "2396 <class 'str'>\n",
      "2829 <class 'str'>\n",
      "502 <class 'str'>\n",
      "1185 <class 'str'>\n",
      "167 <class 'str'>\n",
      "5748 <class 'str'>\n",
      "3428 <class 'str'>\n",
      "874 <class 'str'>\n",
      "99 <class 'str'>\n",
      "3143 <class 'str'>\n",
      "998 <class 'str'>\n",
      "5548 <class 'str'>\n",
      "2711 <class 'str'>\n",
      "4236 <class 'str'>\n",
      "4749 <class 'str'>\n",
      "6039 <class 'str'>\n",
      "453 <class 'str'>\n",
      "1627 <class 'str'>\n",
      "1125 <class 'str'>\n",
      "2353 <class 'str'>\n",
      "2143 <class 'str'>\n",
      "4248 <class 'str'>\n",
      "3892 <class 'str'>\n",
      "2403 <class 'str'>\n",
      "7028 <class 'str'>\n",
      "85 <class 'str'>\n",
      "7668 <class 'str'>\n",
      "514 <class 'str'>\n",
      "3594 <class 'str'>\n",
      "5089 <class 'str'>\n",
      "4326 <class 'str'>\n",
      "4566 <class 'str'>\n",
      "2350 <class 'str'>\n",
      "1727 <class 'str'>\n",
      "6047 <class 'str'>\n",
      "1369 <class 'str'>\n",
      "5618 <class 'str'>\n",
      "1577 <class 'str'>\n",
      "585 <class 'str'>\n",
      "6794 <class 'str'>\n",
      "1985 <class 'str'>\n",
      "1231 <class 'str'>\n",
      "4398 <class 'str'>\n",
      "7612 <class 'str'>\n",
      "925 <class 'str'>\n",
      "2680 <class 'str'>\n",
      "2940 <class 'str'>\n",
      "2187 <class 'str'>\n",
      "5959 <class 'str'>\n",
      "2383 <class 'str'>\n",
      "512 <class 'str'>\n",
      "556 <class 'str'>\n",
      "3018 <class 'str'>\n",
      "524 <class 'str'>\n",
      "939 <class 'str'>\n",
      "1819 <class 'str'>\n",
      "343 <class 'str'>\n",
      "6713 <class 'str'>\n",
      "2781 <class 'str'>\n",
      "5222 <class 'str'>\n",
      "800 <class 'str'>\n",
      "4807 <class 'str'>\n",
      "4264 <class 'str'>\n",
      "4852 <class 'str'>\n",
      "3571 <class 'str'>\n",
      "1340 <class 'str'>\n",
      "2548 <class 'str'>\n",
      "1504 <class 'str'>\n",
      "3747 <class 'str'>\n",
      "328 <class 'str'>\n",
      "1253 <class 'str'>\n",
      "526 <class 'str'>\n",
      "155 <class 'str'>\n",
      "2193 <class 'str'>\n",
      "1756 <class 'str'>\n",
      "2638 <class 'str'>\n",
      "776 <class 'str'>\n",
      "3979 <class 'str'>\n",
      "4034 <class 'str'>\n",
      "3989 <class 'str'>\n",
      "3134 <class 'str'>\n",
      "369 <class 'str'>\n",
      "2837 <class 'str'>\n",
      "2596 <class 'str'>\n",
      "36 <class 'str'>\n",
      "5484 <class 'str'>\n",
      "381 <class 'str'>\n",
      "5537 <class 'str'>\n",
      "6861 <class 'str'>\n",
      "2536 <class 'str'>\n",
      "268 <class 'str'>\n",
      "159 <class 'str'>\n",
      "6491 <class 'str'>\n",
      "2836 <class 'str'>\n",
      "1981 <class 'str'>\n",
      "6813 <class 'str'>\n",
      "2053 <class 'str'>\n",
      "782 <class 'str'>\n",
      "970 <class 'str'>\n",
      "3130 <class 'str'>\n",
      "1857 <class 'str'>\n",
      "6086 <class 'str'>\n",
      "3490 <class 'str'>\n",
      "3844 <class 'str'>\n",
      "1404 <class 'str'>\n",
      "1567 <class 'str'>\n",
      "2550 <class 'str'>\n",
      "1530 <class 'str'>\n",
      "3945 <class 'str'>\n",
      "4170 <class 'str'>\n",
      "6492 <class 'str'>\n",
      "2578 <class 'str'>\n",
      "2438 <class 'str'>\n",
      "2510 <class 'str'>\n",
      "1429 <class 'str'>\n",
      "3278 <class 'str'>\n",
      "1069 <class 'str'>\n",
      "2038 <class 'str'>\n",
      "1148 <class 'str'>\n",
      "1696 <class 'str'>\n",
      "7055 <class 'str'>\n",
      "2002 <class 'str'>\n",
      "2959 <class 'str'>\n",
      "2099 <class 'str'>\n",
      "5728 <class 'str'>\n",
      "4361 <class 'str'>\n",
      "1777 <class 'str'>\n",
      "1326 <class 'str'>\n",
      "1581 <class 'str'>\n",
      "1955 <class 'str'>\n",
      "3512 <class 'str'>\n",
      "555 <class 'str'>\n",
      "5804 <class 'str'>\n",
      "577 <class 'str'>\n",
      "340 <class 'str'>\n",
      "1012 <class 'str'>\n",
      "7558 <class 'str'>\n",
      "1128 <class 'str'>\n",
      "1637 <class 'str'>\n",
      "923 <class 'str'>\n",
      "5107 <class 'str'>\n",
      "3660 <class 'str'>\n",
      "886 <class 'str'>\n",
      "3547 <class 'str'>\n",
      "5385 <class 'str'>\n",
      "147 <class 'str'>\n",
      "1179 <class 'str'>\n",
      "1362 <class 'str'>\n",
      "3661 <class 'str'>\n",
      "2064 <class 'str'>\n",
      "463 <class 'str'>\n",
      "3918 <class 'str'>\n",
      "2557 <class 'str'>\n",
      "70 <class 'str'>\n",
      "5507 <class 'str'>\n",
      "486 <class 'str'>\n",
      "5404 <class 'str'>\n",
      "4474 <class 'str'>\n",
      "695 <class 'str'>\n",
      "1294 <class 'str'>\n",
      "2498 <class 'str'>\n",
      "2154 <class 'str'>\n",
      "1551 <class 'str'>\n",
      "1580 <class 'str'>\n",
      "72 <class 'str'>\n",
      "2102 <class 'str'>\n",
      "2626 <class 'str'>\n",
      "2523 <class 'str'>\n",
      "4062 <class 'str'>\n",
      "2775 <class 'str'>\n",
      "5351 <class 'str'>\n",
      "1630 <class 'str'>\n",
      "3750 <class 'str'>\n",
      "1311 <class 'str'>\n",
      "4845 <class 'str'>\n",
      "3705 <class 'str'>\n",
      "1416 <class 'str'>\n",
      "7387 <class 'str'>\n",
      "1129 <class 'str'>\n",
      "305 <class 'str'>\n",
      "2042 <class 'str'>\n",
      "3027 <class 'str'>\n",
      "13 <class 'str'>\n",
      "1283 <class 'str'>\n",
      "702 <class 'str'>\n",
      "362 <class 'str'>\n",
      "378 <class 'str'>\n",
      "1159 <class 'str'>\n",
      "5575 <class 'str'>\n",
      "4054 <class 'str'>\n",
      "3565 <class 'str'>\n",
      "4094 <class 'str'>\n",
      "3832 <class 'str'>\n",
      "1470 <class 'str'>\n",
      "1709 <class 'str'>\n",
      "2437 <class 'str'>\n",
      "1845 <class 'str'>\n",
      "3690 <class 'str'>\n",
      "3785 <class 'str'>\n",
      "3142 <class 'str'>\n",
      "4336 <class 'str'>\n",
      "5456 <class 'str'>\n",
      "3646 <class 'str'>\n",
      "2545 <class 'str'>\n",
      "1151 <class 'str'>\n",
      "4266 <class 'str'>\n",
      "430 <class 'str'>\n",
      "1987 <class 'str'>\n",
      "5356 <class 'str'>\n",
      "719 <class 'str'>\n",
      "2805 <class 'str'>\n",
      "1200 <class 'str'>\n",
      "507 <class 'str'>\n",
      "4138 <class 'str'>\n",
      "3840 <class 'str'>\n",
      "641 <class 'str'>\n",
      "6473 <class 'str'>\n",
      "1030 <class 'str'>\n",
      "185 <class 'str'>\n",
      "112 <class 'str'>\n",
      "1479 <class 'str'>\n",
      "658 <class 'str'>\n",
      "2020 <class 'str'>\n",
      "7306 <class 'str'>\n",
      "1363 <class 'str'>\n",
      "663 <class 'str'>\n",
      "2180 <class 'str'>\n",
      "5116 <class 'str'>\n",
      "1043 <class 'str'>\n",
      "3563 <class 'str'>\n",
      "3187 <class 'str'>\n",
      "1959 <class 'str'>\n",
      "1908 <class 'str'>\n",
      "1203 <class 'str'>\n",
      "1508 <class 'str'>\n",
      "425 <class 'str'>\n",
      "144 <class 'str'>\n",
      "483 <class 'str'>\n",
      "4280 <class 'str'>\n",
      "2563 <class 'str'>\n",
      "145 <class 'str'>\n",
      "5541 <class 'str'>\n",
      "2224 <class 'str'>\n",
      "2628 <class 'str'>\n",
      "191 <class 'str'>\n",
      "331 <class 'str'>\n",
      "3957 <class 'str'>\n",
      "457 <class 'str'>\n",
      "4972 <class 'str'>\n",
      "1924 <class 'str'>\n",
      "4919 <class 'str'>\n",
      "4217 <class 'str'>\n",
      "4419 <class 'str'>\n",
      "2359 <class 'str'>\n",
      "2525 <class 'str'>\n",
      "1914 <class 'str'>\n",
      "3822 <class 'str'>\n",
      "4927 <class 'str'>\n",
      "4947 <class 'str'>\n",
      "1515 <class 'str'>\n",
      "1371 <class 'str'>\n",
      "2831 <class 'str'>\n",
      "3866 <class 'str'>\n",
      "441 <class 'str'>\n",
      "3631 <class 'str'>\n",
      "1602 <class 'str'>\n",
      "1521 <class 'str'>\n",
      "1624 <class 'str'>\n",
      "3235 <class 'str'>\n",
      "3911 <class 'str'>\n",
      "6998 <class 'str'>\n",
      "1092 <class 'str'>\n",
      "480 <class 'str'>\n",
      "938 <class 'str'>\n",
      "958 <class 'str'>\n",
      "4322 <class 'str'>\n",
      "428 <class 'str'>\n",
      "2801 <class 'str'>\n",
      "2165 <class 'str'>\n",
      "2587 <class 'str'>\n",
      "1943 <class 'str'>\n",
      "4114 <class 'str'>\n",
      "2301 <class 'str'>\n",
      "948 <class 'str'>\n",
      "281 <class 'str'>\n",
      "6939 <class 'str'>\n",
      "1867 <class 'str'>\n",
      "244 <class 'str'>\n",
      "1793 <class 'str'>\n",
      "713 <class 'str'>\n",
      "3939 <class 'str'>\n",
      "471 <class 'str'>\n",
      "3023 <class 'str'>\n",
      "3650 <class 'str'>\n",
      "3243 <class 'str'>\n",
      "3645 <class 'str'>\n",
      "1977 <class 'str'>\n",
      "4664 <class 'str'>\n",
      "614 <class 'str'>\n",
      "6430 <class 'str'>\n",
      "5354 <class 'str'>\n",
      "98 <class 'str'>\n",
      "3227 <class 'str'>\n",
      "2222 <class 'str'>\n",
      "2764 <class 'str'>\n",
      "4388 <class 'str'>\n",
      "1492 <class 'str'>\n",
      "4055 <class 'str'>\n",
      "4977 <class 'str'>\n",
      "3072 <class 'str'>\n",
      "232 <class 'str'>\n",
      "1298 <class 'str'>\n",
      "2759 <class 'str'>\n",
      "1264 <class 'str'>\n",
      "6006 <class 'str'>\n",
      "771 <class 'str'>\n",
      "1287 <class 'str'>\n",
      "3145 <class 'str'>\n",
      "2561 <class 'str'>\n",
      "2413 <class 'str'>\n",
      "4096 <class 'str'>\n",
      "4469 <class 'str'>\n",
      "2230 <class 'str'>\n",
      "2688 <class 'str'>\n",
      "1520 <class 'str'>\n",
      "3118 <class 'str'>\n",
      "7744 <class 'str'>\n",
      "2951 <class 'str'>\n",
      "5480 <class 'str'>\n",
      "5619 <class 'str'>\n",
      "482 <class 'str'>\n",
      "1961 <class 'str'>\n",
      "1786 <class 'str'>\n",
      "7170 <class 'str'>\n",
      "2238 <class 'str'>\n",
      "1299 <class 'str'>\n",
      "716 <class 'str'>\n",
      "2594 <class 'str'>\n",
      "4455 <class 'str'>\n",
      "6688 <class 'str'>\n",
      "5445 <class 'str'>\n",
      "633 <class 'str'>\n",
      "4543 <class 'str'>\n",
      "5729 <class 'str'>\n",
      "436 <class 'str'>\n",
      "255 <class 'str'>\n",
      "2215 <class 'str'>\n",
      "1175 <class 'str'>\n",
      "5719 <class 'str'>\n",
      "4079 <class 'str'>\n",
      "6212 <class 'str'>\n",
      "3199 <class 'str'>\n",
      "2471 <class 'str'>\n",
      "4005 <class 'str'>\n",
      "2062 <class 'str'>\n",
      "542 <class 'str'>\n",
      "631 <class 'str'>\n",
      "3307 <class 'str'>\n",
      "6604 <class 'str'>\n",
      "143 <class 'str'>\n",
      "7092 <class 'str'>\n",
      "1193 <class 'str'>\n",
      "5859 <class 'str'>\n",
      "88 <class 'str'>\n",
      "5519 <class 'str'>\n",
      "872 <class 'str'>\n",
      "1134 <class 'str'>\n",
      "113 <class 'str'>\n",
      "759 <class 'str'>\n",
      "3780 <class 'str'>\n",
      "1463 <class 'str'>\n",
      "4234 <class 'str'>\n",
      "2374 <class 'str'>\n",
      "16 <class 'str'>\n",
      "1950 <class 'str'>\n",
      "5731 <class 'str'>\n",
      "2584 <class 'str'>\n",
      "827 <class 'str'>\n",
      "967 <class 'str'>\n",
      "765 <class 'str'>\n",
      "944 <class 'str'>\n",
      "1866 <class 'str'>\n",
      "1731 <class 'str'>\n",
      "2148 <class 'str'>\n",
      "1009 <class 'str'>\n",
      "1077 <class 'str'>\n",
      "754 <class 'str'>\n",
      "1304 <class 'str'>\n",
      "4470 <class 'str'>\n",
      "3053 <class 'str'>\n",
      "1837 <class 'str'>\n",
      "1088 <class 'str'>\n",
      "156 <class 'str'>\n",
      "1734 <class 'str'>\n",
      "4580 <class 'str'>\n",
      "3896 <class 'str'>\n",
      "2953 <class 'str'>\n",
      "4201 <class 'str'>\n",
      "3002 <class 'str'>\n",
      "125 <class 'str'>\n",
      "3580 <class 'str'>\n",
      "3501 <class 'str'>\n",
      "2916 <class 'str'>\n",
      "2947 <class 'str'>\n",
      "3057 <class 'str'>\n",
      "852 <class 'str'>\n",
      "2151 <class 'str'>\n",
      "329 <class 'str'>\n",
      "2037 <class 'str'>\n",
      "2447 <class 'str'>\n",
      "4156 <class 'str'>\n",
      "4747 <class 'str'>\n",
      "5299 <class 'str'>\n",
      "4859 <class 'str'>\n",
      "485 <class 'str'>\n",
      "1164 <class 'str'>\n",
      "2721 <class 'str'>\n",
      "5195 <class 'str'>\n",
      "674 <class 'str'>\n",
      "4779 <class 'str'>\n",
      "1747 <class 'str'>\n",
      "2417 <class 'str'>\n",
      "714 <class 'str'>\n",
      "4761 <class 'str'>\n",
      "2905 <class 'str'>\n",
      "869 <class 'str'>\n",
      "3208 <class 'str'>\n",
      "358 <class 'str'>\n",
      "550 <class 'str'>\n",
      "2565 <class 'str'>\n",
      "2190 <class 'str'>\n",
      "3771 <class 'str'>\n",
      "755 <class 'str'>\n",
      "778 <class 'str'>\n",
      "4775 <class 'str'>\n",
      "6174 <class 'str'>\n",
      "3113 <class 'str'>\n",
      "5889 <class 'str'>\n",
      "647 <class 'str'>\n",
      "2534 <class 'str'>\n",
      "3080 <class 'str'>\n",
      "3495 <class 'str'>\n",
      "1511 <class 'str'>\n",
      "135 <class 'str'>\n",
      "247 <class 'str'>\n",
      "2542 <class 'str'>\n",
      "4757 <class 'str'>\n",
      "2866 <class 'str'>\n",
      "1452 <class 'str'>\n",
      "7758 <class 'str'>\n",
      "978 <class 'str'>\n",
      "1610 <class 'str'>\n",
      "2342 <class 'str'>\n",
      "1659 <class 'str'>\n",
      "18 <class 'str'>\n",
      "2993 <class 'str'>\n",
      "153 <class 'str'>\n",
      "730 <class 'str'>\n",
      "4222 <class 'str'>\n",
      "1652 <class 'str'>\n",
      "4954 <class 'str'>\n",
      "3233 <class 'str'>\n",
      "3394 <class 'str'>\n",
      "717 <class 'str'>\n",
      "2235 <class 'str'>\n",
      "259 <class 'str'>\n",
      "3026 <class 'str'>\n",
      "3379 <class 'str'>\n",
      "2106 <class 'str'>\n",
      "969 <class 'str'>\n",
      "5044 <class 'str'>\n",
      "5838 <class 'str'>\n",
      "2588 <class 'str'>\n",
      "7270 <class 'str'>\n",
      "805 <class 'str'>\n",
      "1792 <class 'str'>\n",
      "703 <class 'str'>\n",
      "2162 <class 'str'>\n",
      "680 <class 'str'>\n",
      "821 <class 'str'>\n",
      "4704 <class 'str'>\n",
      "1626 <class 'str'>\n",
      "4026 <class 'str'>\n",
      "7626 <class 'str'>\n",
      "1895 <class 'str'>\n",
      "955 <class 'str'>\n",
      "6866 <class 'str'>\n",
      "11 <class 'str'>\n",
      "1519 <class 'str'>\n",
      "234 <class 'str'>\n",
      "2076 <class 'str'>\n",
      "5816 <class 'str'>\n",
      "5181 <class 'str'>\n",
      "1464 <class 'str'>\n",
      "2281 <class 'str'>\n",
      "1405 <class 'str'>\n",
      "1836 <class 'str'>\n",
      "1278 <class 'str'>\n",
      "4442 <class 'str'>\n",
      "2747 <class 'str'>\n",
      "4777 <class 'str'>\n",
      "3721 <class 'str'>\n",
      "6841 <class 'str'>\n",
      "1188 <class 'str'>\n",
      "4268 <class 'str'>\n",
      "1958 <class 'str'>\n",
      "2110 <class 'str'>\n",
      "7576 <class 'str'>\n",
      "296 <class 'str'>\n",
      "1805 <class 'str'>\n",
      "2505 <class 'str'>\n",
      "2707 <class 'str'>\n",
      "757 <class 'str'>\n",
      "1603 <class 'str'>\n",
      "4200 <class 'str'>\n",
      "617 <class 'str'>\n",
      "1797 <class 'str'>\n",
      "5027 <class 'str'>\n",
      "3724 <class 'str'>\n",
      "2086 <class 'str'>\n",
      "980 <class 'str'>\n",
      "887 <class 'str'>\n",
      "5045 <class 'str'>\n",
      "5183 <class 'str'>\n",
      "2217 <class 'str'>\n",
      "753 <class 'str'>\n",
      "6333 <class 'str'>\n",
      "3149 <class 'str'>\n",
      "1969 <class 'str'>\n",
      "2304 <class 'str'>\n",
      "69 <class 'str'>\n",
      "1115 <class 'str'>\n",
      "1576 <class 'str'>\n",
      "1680 <class 'str'>\n",
      "111 <class 'str'>\n",
      "3222 <class 'str'>\n",
      "79 <class 'str'>\n",
      "434 <class 'str'>\n",
      "1575 <class 'str'>\n",
      "4582 <class 'str'>\n",
      "2431 <class 'str'>\n",
      "2879 <class 'str'>\n",
      "1641 <class 'str'>\n",
      "5897 <class 'str'>\n",
      "2722 <class 'str'>\n",
      "44 <class 'str'>\n",
      "1142 <class 'str'>\n",
      "409 <class 'str'>\n",
      "6624 <class 'str'>\n",
      "2287 <class 'str'>\n",
      "3032 <class 'str'>\n",
      "1842 <class 'str'>\n",
      "5311 <class 'str'>\n",
      "263 <class 'str'>\n",
      "954 <class 'str'>\n",
      "3203 <class 'str'>\n",
      "107 <class 'str'>\n",
      "2284 <class 'str'>\n",
      "764 <class 'str'>\n",
      "2612 <class 'str'>\n",
      "924 <class 'str'>\n",
      "2001 <class 'str'>\n",
      "2275 <class 'str'>\n",
      "14 <class 'str'>\n",
      "5154 <class 'str'>\n",
      "2571 <class 'str'>\n",
      "4924 <class 'str'>\n",
      "5060 <class 'str'>\n",
      "3066 <class 'str'>\n",
      "481 <class 'str'>\n",
      "738 <class 'str'>\n",
      "3459 <class 'str'>\n",
      "3218 <class 'str'>\n",
      "183 <class 'str'>\n",
      "1621 <class 'str'>\n",
      "6800 <class 'str'>\n",
      "1741 <class 'str'>\n",
      "3030 <class 'str'>\n",
      "1213 <class 'str'>\n",
      "644 <class 'str'>\n",
      "2719 <class 'str'>\n",
      "3095 <class 'str'>\n",
      "2862 <class 'str'>\n",
      "4458 <class 'str'>\n",
      "4579 <class 'str'>\n",
      "3280 <class 'str'>\n",
      "7303 <class 'str'>\n",
      "2870 <class 'str'>\n",
      "1302 <class 'str'>\n",
      "2146 <class 'str'>\n",
      "3931 <class 'str'>\n",
      "3972 <class 'str'>\n",
      "1850 <class 'str'>\n",
      "3009 <class 'str'>\n",
      "1401 <class 'str'>\n",
      "586 <class 'str'>\n",
      "1498 <class 'str'>\n",
      "515 <class 'str'>\n",
      "2491 <class 'str'>\n",
      "3064 <class 'str'>\n",
      "2060 <class 'str'>\n",
      "1458 <class 'str'>\n",
      "4273 <class 'str'>\n",
      "2271 <class 'str'>\n",
      "1154 <class 'str'>\n",
      "536 <class 'str'>\n",
      "2981 <class 'str'>\n",
      "554 <class 'str'>\n",
      "4608 <class 'str'>\n",
      "454 <class 'str'>\n",
      "5632 <class 'str'>\n",
      "5180 <class 'str'>\n",
      "799 <class 'str'>\n",
      "4630 <class 'str'>\n",
      "4209 <class 'str'>\n",
      "1029 <class 'str'>\n",
      "5495 <class 'str'>\n",
      "3784 <class 'str'>\n",
      "5142 <class 'str'>\n",
      "3269 <class 'str'>\n",
      "1379 <class 'str'>\n",
      "6014 <class 'str'>\n",
      "2272 <class 'str'>\n",
      "1172 <class 'str'>\n",
      "1944 <class 'str'>\n",
      "7366 <class 'str'>\n",
      "1501 <class 'str'>\n",
      "1802 <class 'str'>\n",
      "3413 <class 'str'>\n",
      "3895 <class 'str'>\n",
      "6711 <class 'str'>\n",
      "5826 <class 'str'>\n",
      "734 <class 'str'>\n",
      "122 <class 'str'>\n",
      "5350 <class 'str'>\n",
      "5347 <class 'str'>\n",
      "5533 <class 'str'>\n",
      "2650 <class 'str'>\n",
      "1740 <class 'str'>\n",
      "815 <class 'str'>\n",
      "487 <class 'str'>\n",
      "439 <class 'str'>\n",
      "5307 <class 'str'>\n",
      "3096 <class 'str'>\n",
      "4429 <class 'str'>\n",
      "3470 <class 'str'>\n",
      "233 <class 'str'>\n",
      "5735 <class 'str'>\n",
      "1438 <class 'str'>\n",
      "3301 <class 'str'>\n",
      "1425 <class 'str'>\n",
      "4271 <class 'str'>\n",
      "1804 <class 'str'>\n",
      "2850 <class 'str'>\n",
      "1827 <class 'str'>\n",
      "5915 <class 'str'>\n",
      "2208 <class 'str'>\n",
      "2057 <class 'str'>\n",
      "2237 <class 'str'>\n",
      "3628 <class 'str'>\n",
      "6404 <class 'str'>\n",
      "1589 <class 'str'>\n",
      "1244 <class 'str'>\n",
      "1157 <class 'str'>\n",
      "2023 <class 'str'>\n",
      "2092 <class 'str'>\n",
      "7563 <class 'str'>\n",
      "2109 <class 'str'>\n",
      "307 <class 'str'>\n",
      "1166 <class 'str'>\n",
      "2585 <class 'str'>\n",
      "2428 <class 'str'>\n",
      "2477 <class 'str'>\n",
      "2683 <class 'str'>\n",
      "813 <class 'str'>\n",
      "2740 <class 'str'>\n",
      "5246 <class 'str'>\n",
      "942 <class 'str'>\n",
      "1947 <class 'str'>\n",
      "628 <class 'str'>\n",
      "2444 <class 'str'>\n",
      "4553 <class 'str'>\n",
      "6518 <class 'str'>\n",
      "2111 <class 'str'>\n",
      "1153 <class 'str'>\n",
      "2470 <class 'str'>\n",
      "1091 <class 'str'>\n",
      "5628 <class 'str'>\n",
      "2824 <class 'str'>\n",
      "1763 <class 'str'>\n",
      "2091 <class 'str'>\n",
      "7654 <class 'str'>\n",
      "7421 <class 'str'>\n",
      "3282 <class 'str'>\n",
      "3789 <class 'str'>\n",
      "2149 <class 'str'>\n",
      "2821 <class 'str'>\n",
      "4673 <class 'str'>\n",
      "694 <class 'str'>\n",
      "2348 <class 'str'>\n",
      "1776 <class 'str'>\n",
      "2644 <class 'str'>\n",
      "2107 <class 'str'>\n",
      "4509 <class 'str'>\n",
      "2178 <class 'str'>\n",
      "1398 <class 'str'>\n",
      "562 <class 'str'>\n",
      "597 <class 'str'>\n",
      "1480 <class 'str'>\n",
      "2717 <class 'str'>\n",
      "4000 <class 'str'>\n",
      "1098 <class 'str'>\n",
      "825 <class 'str'>\n",
      "3363 <class 'str'>\n",
      "4740 <class 'str'>\n",
      "2377 <class 'str'>\n",
      "5950 <class 'str'>\n",
      "1252 <class 'str'>\n",
      "4078 <class 'str'>\n",
      "1357 <class 'str'>\n",
      "2679 <class 'str'>\n",
      "462 <class 'str'>\n",
      "3112 <class 'str'>\n",
      "3929 <class 'str'>\n",
      "3617 <class 'str'>\n",
      "1047 <class 'str'>\n",
      "795 <class 'str'>\n",
      "6087 <class 'str'>\n",
      "1875 <class 'str'>\n",
      "6357 <class 'str'>\n",
      "1150 <class 'str'>\n",
      "7512 <class 'str'>\n",
      "1339 <class 'str'>\n",
      "5133 <class 'str'>\n",
      "2088 <class 'str'>\n",
      "1799 <class 'str'>\n",
      "601 <class 'str'>\n",
      "2663 <class 'str'>\n",
      "3055 <class 'str'>\n",
      "6069 <class 'str'>\n",
      "4813 <class 'str'>\n",
      "1526 <class 'str'>\n",
      "3399 <class 'str'>\n",
      "4672 <class 'str'>\n",
      "302 <class 'str'>\n",
      "1329 <class 'str'>\n",
      "2883 <class 'str'>\n",
      "4468 <class 'str'>\n",
      "4844 <class 'str'>\n",
      "5267 <class 'str'>\n",
      "3710 <class 'str'>\n",
      "5449 <class 'str'>\n",
      "6659 <class 'str'>\n",
      "2991 <class 'str'>\n",
      "5168 <class 'str'>\n",
      "573 <class 'str'>\n",
      "6205 <class 'str'>\n",
      "1896 <class 'str'>\n",
      "2914 <class 'str'>\n",
      "4225 <class 'str'>\n",
      "3860 <class 'str'>\n",
      "2046 <class 'str'>\n",
      "3811 <class 'str'>\n",
      "6120 <class 'str'>\n",
      "5 <class 'str'>\n",
      "720 <class 'str'>\n",
      "686 <class 'str'>\n",
      "7098 <class 'str'>\n",
      "588 <class 'str'>\n",
      "5747 <class 'str'>\n",
      "5071 <class 'str'>\n",
      "1945 <class 'str'>\n",
      "3613 <class 'str'>\n",
      "4748 <class 'str'>\n",
      "42 <class 'str'>\n",
      "5442 <class 'str'>\n",
      "60 <class 'str'>\n",
      "3268 <class 'str'>\n",
      "220 <class 'str'>\n",
      "182 <class 'str'>\n",
      "6065 <class 'str'>\n",
      "7555 <class 'str'>\n",
      "4142 <class 'str'>\n",
      "1165 <class 'str'>\n",
      "5342 <class 'str'>\n",
      "2326 <class 'str'>\n",
      "6446 <class 'str'>\n",
      "4770 <class 'str'>\n",
      "3046 <class 'str'>\n",
      "5005 <class 'str'>\n",
      "5238 <class 'str'>\n",
      "5206 <class 'str'>\n",
      "705 <class 'str'>\n",
      "2072 <class 'str'>\n",
      "4311 <class 'str'>\n",
      "2369 <class 'str'>\n",
      "1090 <class 'str'>\n",
      "1518 <class 'str'>\n",
      "5564 <class 'str'>\n",
      "110 <class 'str'>\n",
      "1349 <class 'str'>\n",
      "444 <class 'str'>\n",
      "1192 <class 'str'>\n",
      "4955 <class 'str'>\n",
      "3679 <class 'str'>\n",
      "1445 <class 'str'>\n",
      "3167 <class 'str'>\n",
      "6582 <class 'str'>\n",
      "1051 <class 'str'>\n",
      "30 <class 'str'>\n",
      "315 <class 'str'>\n",
      "3116 <class 'str'>\n",
      "509 <class 'str'>\n",
      "1135 <class 'str'>\n",
      "1587 <class 'str'>\n",
      "3816 <class 'str'>\n",
      "2789 <class 'str'>\n",
      "1599 <class 'str'>\n",
      "332 <class 'str'>\n",
      "5431 <class 'str'>\n",
      "667 <class 'str'>\n",
      "300 <class 'str'>\n",
      "419 <class 'str'>\n",
      "2163 <class 'str'>\n",
      "1126 <class 'str'>\n",
      "137 <class 'str'>\n",
      "4396 <class 'str'>\n",
      "1892 <class 'str'>\n",
      "2924 <class 'str'>\n",
      "3017 <class 'str'>\n",
      "837 <class 'str'>\n",
      "200 <class 'str'>\n",
      "3647 <class 'str'>\n",
      "141 <class 'str'>\n",
      "911 <class 'str'>\n",
      "1003 <class 'str'>\n",
      "38 <class 'str'>\n",
      "1469 <class 'str'>\n",
      "522 <class 'str'>\n",
      "2336 <class 'str'>\n",
      "6532 <class 'str'>\n",
      "204 <class 'str'>\n",
      "6801 <class 'str'>\n",
      "5610 <class 'str'>\n",
      "3948 <class 'str'>\n",
      "394 <class 'str'>\n",
      "4783 <class 'str'>\n",
      "2160 <class 'str'>\n",
      "488 <class 'str'>\n",
      "71 <class 'str'>\n",
      "6915 <class 'str'>\n",
      "5479 <class 'str'>\n",
      "431 <class 'str'>\n",
      "2077 <class 'str'>\n",
      "6051 <class 'str'>\n",
      "1399 <class 'str'>\n",
      "6899 <class 'str'>\n",
      "363 <class 'str'>\n",
      "57 <class 'str'>\n",
      "4825 <class 'str'>\n",
      "1005 <class 'str'>\n",
      "6555 <class 'str'>\n",
      "5752 <class 'str'>\n",
      "748 <class 'str'>\n",
      "1588 <class 'str'>\n",
      "739 <class 'str'>\n",
      "4303 <class 'str'>\n",
      "5034 <class 'str'>\n",
      "1628 <class 'str'>\n",
      "3436 <class 'str'>\n",
      "4848 <class 'str'>\n",
      "6289 <class 'str'>\n",
      "2404 <class 'str'>\n",
      "2692 <class 'str'>\n",
      "77 <class 'str'>\n",
      "1811 <class 'str'>\n",
      "494 <class 'str'>\n",
      "2531 <class 'str'>\n",
      "2258 <class 'str'>\n",
      "3191 <class 'str'>\n",
      "6060 <class 'str'>\n",
      "3040 <class 'str'>\n",
      "832 <class 'str'>\n",
      "1505 <class 'str'>\n",
      "3138 <class 'str'>\n",
      "2586 <class 'str'>\n",
      "1474 <class 'str'>\n",
      "94 <class 'str'>\n",
      "58 <class 'str'>\n",
      "1936 <class 'str'>\n",
      "3809 <class 'str'>\n",
      "3520 <class 'str'>\n",
      "4505 <class 'str'>\n",
      "297 <class 'str'>\n",
      "5237 <class 'str'>\n",
      "3015 <class 'str'>\n",
      "5725 <class 'str'>\n",
      "3890 <class 'str'>\n",
      "5550 <class 'str'>\n",
      "106 <class 'str'>\n",
      "1800 <class 'str'>\n",
      "6199 <class 'str'>\n",
      "1146 <class 'str'>\n",
      "6371 <class 'str'>\n",
      "4584 <class 'str'>\n",
      "3031 <class 'str'>\n",
      "6783 <class 'str'>\n",
      "2574 <class 'str'>\n",
      "4085 <class 'str'>\n",
      "2848 <class 'str'>\n",
      "6255 <class 'str'>\n",
      "1301 <class 'str'>\n",
      "5247 <class 'str'>\n",
      "3938 <class 'str'>\n",
      "2346 <class 'str'>\n",
      "1890 <class 'str'>\n",
      "3538 <class 'str'>\n",
      "3665 <class 'str'>\n",
      "3207 <class 'str'>\n",
      "3836 <class 'str'>\n",
      "198 <class 'str'>\n",
      "4527 <class 'str'>\n",
      "3341 <class 'str'>\n",
      "4890 <class 'str'>\n",
      "3356 <class 'str'>\n",
      "965 <class 'str'>\n",
      "3746 <class 'str'>\n",
      "3103 <class 'str'>\n",
      "2124 <class 'str'>\n",
      "310 <class 'str'>\n",
      "4472 <class 'str'>\n",
      "5715 <class 'str'>\n",
      "261 <class 'str'>\n",
      "3877 <class 'str'>\n",
      "2476 <class 'str'>\n",
      "2372 <class 'str'>\n",
      "1965 <class 'str'>\n",
      "3225 <class 'str'>\n",
      "3861 <class 'str'>\n",
      "1053 <class 'str'>\n",
      "3254 <class 'str'>\n",
      "484 <class 'str'>\n",
      "1688 <class 'str'>\n",
      "3883 <class 'str'>\n",
      "7727 <class 'str'>\n",
      "5813 <class 'str'>\n",
      "6224 <class 'str'>\n",
      "5317 <class 'str'>\n",
      "5487 <class 'str'>\n",
      "851 <class 'str'>\n",
      "1557 <class 'str'>\n",
      "2664 <class 'str'>\n",
      "5080 <class 'str'>\n",
      "1657 <class 'str'>\n",
      "2103 <class 'str'>\n",
      "2743 <class 'str'>\n",
      "3067 <class 'str'>\n",
      "1426 <class 'str'>\n",
      "2854 <class 'str'>\n",
      "442 <class 'str'>\n",
      "1750 <class 'str'>\n",
      "215 <class 'str'>\n",
      "2931 <class 'str'>\n",
      "4510 <class 'str'>\n",
      "3035 <class 'str'>\n",
      "900 <class 'str'>\n",
      "7630 <class 'str'>\n",
      "1848 <class 'str'>\n",
      "314 <class 'str'>\n",
      "1353 <class 'str'>\n",
      "3290 <class 'str'>\n",
      "5322 <class 'str'>\n",
      "3607 <class 'str'>\n",
      "2117 <class 'str'>\n",
      "2418 <class 'str'>\n",
      "3823 <class 'str'>\n",
      "2345 <class 'str'>\n",
      "2675 <class 'str'>\n",
      "3489 <class 'str'>\n",
      "2167 <class 'str'>\n",
      "6335 <class 'str'>\n",
      "3521 <class 'str'>\n",
      "2291 <class 'str'>\n",
      "1205 <class 'str'>\n",
      "2067 <class 'str'>\n",
      "1312 <class 'str'>\n",
      "196 <class 'str'>\n",
      "55 <class 'str'>\n",
      "2478 <class 'str'>\n",
      "5872 <class 'str'>\n",
      "1427 <class 'str'>\n",
      "3574 <class 'str'>\n",
      "2423 <class 'str'>\n",
      "2196 <class 'str'>\n",
      "4091 <class 'str'>\n",
      "913 <class 'str'>\n",
      "4600 <class 'str'>\n",
      "947 <class 'str'>\n",
      "1541 <class 'str'>\n",
      "678 <class 'str'>\n",
      "2172 <class 'str'>\n",
      "4379 <class 'str'>\n",
      "172 <class 'str'>\n",
      "786 <class 'str'>\n",
      "2352 <class 'str'>\n",
      "5035 <class 'str'>\n",
      "2210 <class 'str'>\n",
      "704 <class 'str'>\n",
      "5061 <class 'str'>\n",
      "2593 <class 'str'>\n",
      "1377 <class 'str'>\n",
      "7368 <class 'str'>\n",
      "4625 <class 'str'>\n",
      "4512 <class 'str'>\n",
      "4935 <class 'str'>\n",
      "6044 <class 'str'>\n",
      "4529 <class 'str'>\n",
      "1483 <class 'str'>\n",
      "833 <class 'str'>\n",
      "1296 <class 'str'>\n",
      "4654 <class 'str'>\n",
      "3862 <class 'str'>\n",
      "1342 <class 'str'>\n",
      "1109 <class 'str'>\n",
      "2285 <class 'str'>\n",
      "1687 <class 'str'>\n",
      "458 <class 'str'>\n",
      "893 <class 'str'>\n",
      "3772 <class 'str'>\n",
      "3460 <class 'str'>\n",
      "737 <class 'str'>\n",
      "3826 <class 'str'>\n",
      "91 <class 'str'>\n",
      "2834 <class 'str'>\n",
      "1180 <class 'str'>\n",
      "5978 <class 'str'>\n",
      "982 <class 'str'>\n",
      "3085 <class 'str'>\n",
      "3848 <class 'str'>\n",
      "1647 <class 'str'>\n",
      "4684 <class 'str'>\n",
      "1436 <class 'str'>\n",
      "4466 <class 'str'>\n",
      "3653 <class 'str'>\n",
      "7671 <class 'str'>\n",
      "303 <class 'str'>\n",
      "993 <class 'str'>\n",
      "4448 <class 'str'>\n",
      "373 <class 'str'>\n",
      "6257 <class 'str'>\n",
      "225 <class 'str'>\n",
      "2205 <class 'str'>\n",
      "6479 <class 'str'>\n",
      "1136 <class 'str'>\n",
      "3429 <class 'str'>\n",
      "1920 <class 'str'>\n",
      "4166 <class 'str'>\n",
      "2590 <class 'str'>\n",
      "3168 <class 'str'>\n",
      "1983 <class 'str'>\n",
      "2738 <class 'str'>\n",
      "2702 <class 'str'>\n",
      "3534 <class 'str'>\n",
      "568 <class 'str'>\n",
      "1039 <class 'str'>\n",
      "1382 <class 'str'>\n",
      "2483 <class 'str'>\n",
      "5282 <class 'str'>\n",
      "6477 <class 'str'>\n",
      "2915 <class 'str'>\n",
      "3148 <class 'str'>\n",
      "908 <class 'str'>\n",
      "4384 <class 'str'>\n",
      "2613 <class 'str'>\n",
      "4031 <class 'str'>\n",
      "2128 <class 'str'>\n",
      "3543 <class 'str'>\n",
      "1719 <class 'str'>\n",
      "2147 <class 'str'>\n",
      "2623 <class 'str'>\n",
      "2955 <class 'str'>\n",
      "3471 <class 'str'>\n",
      "1507 <class 'str'>\n",
      "2169 <class 'str'>\n",
      "5208 <class 'str'>\n",
      "2358 <class 'str'>\n",
      "6235 <class 'str'>\n",
      "2410 <class 'str'>\n",
      "5986 <class 'str'>\n",
      "2226 <class 'str'>\n",
      "4843 <class 'str'>\n",
      "1331 <class 'str'>\n",
      "1328 <class 'str'>\n",
      "1851 <class 'str'>\n",
      "4707 <class 'str'>\n",
      "7889 <class 'str'>\n",
      "4046 <class 'str'>\n",
      "6827 <class 'str'>\n",
      "3933 <class 'str'>\n",
      "4261 <class 'str'>\n",
      "1266 <class 'str'>\n",
      "888 <class 'str'>\n",
      "616 <class 'str'>\n",
      "4331 <class 'str'>\n",
      "5236 <class 'str'>\n",
      "3272 <class 'str'>\n",
      "1013 <class 'str'>\n",
      "3602 <class 'str'>\n",
      "1376 <class 'str'>\n",
      "2356 <class 'str'>\n",
      "6409 <class 'str'>\n",
      "6988 <class 'str'>\n",
      "690 <class 'str'>\n",
      "5849 <class 'str'>\n",
      "595 <class 'str'>\n",
      "4485 <class 'str'>\n",
      "370 <class 'str'>\n",
      "5767 <class 'str'>\n",
      "2553 <class 'str'>\n",
      "5291 <class 'str'>\n",
      "2132 <class 'str'>\n",
      "2615 <class 'str'>\n",
      "2814 <class 'str'>\n",
      "2170 <class 'str'>\n",
      "396 <class 'str'>\n",
      "188 <class 'str'>\n",
      "5651 <class 'str'>\n",
      "2504 <class 'str'>\n",
      "877 <class 'str'>\n",
      "3213 <class 'str'>\n",
      "1773 <class 'str'>\n",
      "5221 <class 'str'>\n",
      "2607 <class 'str'>\n",
      "2202 <class 'str'>\n",
      "2894 <class 'str'>\n",
      "1017 <class 'str'>\n",
      "3491 <class 'str'>\n",
      "61 <class 'str'>\n",
      "1706 <class 'str'>\n",
      "4805 <class 'str'>\n",
      "742 <class 'str'>\n",
      "4627 <class 'str'>\n",
      "4262 <class 'str'>\n",
      "1306 <class 'str'>\n",
      "4250 <class 'str'>\n",
      "1506 <class 'str'>\n",
      "896 <class 'str'>\n",
      "6619 <class 'str'>\n",
      "5058 <class 'str'>\n",
      "1998 <class 'str'>\n",
      "4365 <class 'str'>\n",
      "2078 <class 'str'>\n",
      "2666 <class 'str'>\n",
      "321 <class 'str'>\n",
      "352 <class 'str'>\n",
      "529 <class 'str'>\n",
      "3163 <class 'str'>\n",
      "2391 <class 'str'>\n",
      "2514 <class 'str'>\n",
      "2061 <class 'str'>\n",
      "4112 <class 'str'>\n",
      "417 <class 'str'>\n",
      "2720 <class 'str'>\n",
      "740 <class 'str'>\n",
      "3062 <class 'str'>\n",
      "23 <class 'str'>\n",
      "3329 <class 'str'>\n",
      "1728 <class 'str'>\n",
      "2699 <class 'str'>\n",
      "1334 <class 'str'>\n",
      "2997 <class 'str'>\n",
      "4811 <class 'str'>\n",
      "3068 <class 'str'>\n",
      "4640 <class 'str'>\n",
      "4475 <class 'str'>\n",
      "4371 <class 'str'>\n",
      "249 <class 'str'>\n",
      "1516 <class 'str'>\n",
      "3444 <class 'str'>\n",
      "2966 <class 'str'>\n",
      "5112 <class 'str'>\n",
      "3461 <class 'str'>\n",
      "164 <class 'str'>\n",
      "883 <class 'str'>\n",
      "4767 <class 'str'>\n",
      "4218 <class 'str'>\n",
      "4876 <class 'str'>\n",
      "1513 <class 'str'>\n",
      "4116 <class 'str'>\n",
      "4999 <class 'str'>\n",
      "3745 <class 'str'>\n",
      "590 <class 'str'>\n",
      "3922 <class 'str'>\n",
      "327 <class 'str'>\n",
      "216 <class 'str'>\n",
      "350 <class 'str'>\n",
      "2583 <class 'str'>\n",
      "736 <class 'str'>\n",
      "1632 <class 'str'>\n",
      "5037 <class 'str'>\n",
      "4802 <class 'str'>\n",
      "2635 <class 'str'>\n",
      "909 <class 'str'>\n",
      "4299 <class 'str'>\n",
      "610 <class 'str'>\n",
      "241 <class 'str'>\n",
      "2216 <class 'str'>\n",
      "2728 <class 'str'>\n",
      "2983 <class 'str'>\n",
      "2573 <class 'str'>\n",
      "2461 <class 'str'>\n",
      "1270 <class 'str'>\n",
      "1261 <class 'str'>\n",
      "2568 <class 'str'>\n",
      "615 <class 'str'>\n",
      "6247 <class 'str'>\n",
      "2895 <class 'str'>\n",
      "347 <class 'str'>\n",
      "4282 <class 'str'>\n",
      "1156 <class 'str'>\n",
      "4287 <class 'str'>\n",
      "4995 <class 'str'>\n",
      "5780 <class 'str'>\n",
      "3700 <class 'str'>\n",
      "78 <class 'str'>\n",
      "3871 <class 'str'>\n",
      "1466 <class 'str'>\n",
      "1380 <class 'str'>\n",
      "6002 <class 'str'>\n",
      "6881 <class 'str'>\n",
      "3581 <class 'str'>\n",
      "3389 <class 'str'>\n",
      "3597 <class 'str'>\n",
      "1019 <class 'str'>\n",
      "5665 <class 'str'>\n",
      "423 <class 'str'>\n",
      "5090 <class 'str'>\n",
      "4932 <class 'str'>\n",
      "4916 <class 'str'>\n",
      "478 <class 'str'>\n",
      "2975 <class 'str'>\n",
      "1570 <class 'str'>\n",
      "4597 <class 'str'>\n",
      "3995 <class 'str'>\n",
      "323 <class 'str'>\n",
      "6779 <class 'str'>\n",
      "5073 <class 'str'>\n",
      "6179 <class 'str'>\n",
      "5066 <class 'str'>\n",
      "3155 <class 'str'>\n",
      "789 <class 'str'>\n",
      "604 <class 'str'>\n",
      "517 <class 'str'>\n",
      "1411 <class 'str'>\n",
      "3573 <class 'str'>\n",
      "3081 <class 'str'>\n",
      "1041 <class 'str'>\n",
      "1646 <class 'str'>\n",
      "2029 <class 'str'>\n",
      "4547 <class 'str'>\n",
      "679 <class 'str'>\n",
      "620 <class 'str'>\n",
      "1066 <class 'str'>\n",
      "1190 <class 'str'>\n",
      "6113 <class 'str'>\n",
      "7935 <class 'str'>\n",
      "2706 <class 'str'>\n",
      "1538 <class 'str'>\n",
      "3274 <class 'str'>\n",
      "5370 <class 'str'>\n",
      "4727 <class 'str'>\n",
      "2949 <class 'str'>\n",
      "4829 <class 'str'>\n",
      "3683 <class 'str'>\n",
      "2376 <class 'str'>\n",
      "5109 <class 'str'>\n",
      "5434 <class 'str'>\n",
      "3478 <class 'str'>\n",
      "687 <class 'str'>\n",
      "2954 <class 'str'>\n",
      "1975 <class 'str'>\n",
      "3526 <class 'str'>\n",
      "6438 <class 'str'>\n",
      "1240 <class 'str'>\n",
      "4434 <class 'str'>\n",
      "3000 <class 'str'>\n",
      "2012 <class 'str'>\n",
      "6423 <class 'str'>\n",
      "1917 <class 'str'>\n",
      "6978 <class 'str'>\n",
      "2122 <class 'str'>\n",
      "2349 <class 'str'>\n",
      "294 <class 'str'>\n",
      "1565 <class 'str'>\n",
      "3304 <class 'str'>\n",
      "4056 <class 'str'>\n",
      "1736 <class 'str'>\n",
      "1189 <class 'str'>\n",
      "3652 <class 'str'>\n",
      "448 <class 'str'>\n",
      "2546 <class 'str'>\n",
      "2179 <class 'str'>\n",
      "1131 <class 'str'>\n",
      "346 <class 'str'>\n",
      "2988 <class 'str'>\n",
      "708 <class 'str'>\n",
      "1676 <class 'str'>\n",
      "5612 <class 'str'>\n",
      "2065 <class 'str'>\n",
      "2472 <class 'str'>\n",
      "451 <class 'str'>\n",
      "4391 <class 'str'>\n",
      "258 <class 'str'>\n",
      "5762 <class 'str'>\n",
      "1460 <class 'str'>\n",
      "7201 <class 'str'>\n",
      "2603 <class 'str'>\n",
      "3166 <class 'str'>\n",
      "3952 <class 'str'>\n",
      "76 <class 'str'>\n",
      "603 <class 'str'>\n",
      "5980 <class 'str'>\n",
      "700 <class 'str'>\n",
      "875 <class 'str'>\n",
      "6091 <class 'str'>\n",
      "4791 <class 'str'>\n",
      "4446 <class 'str'>\n",
      "1370 <class 'str'>\n",
      "163 <class 'str'>\n",
      "2360 <class 'str'>\n",
      "867 <class 'str'>\n",
      "7484 <class 'str'>\n",
      "505 <class 'str'>\n",
      "2164 <class 'str'>\n",
      "1787 <class 'str'>\n",
      "3415 <class 'str'>\n",
      "2625 <class 'str'>\n",
      "5743 <class 'str'>\n",
      "3508 <class 'str'>\n",
      "7571 <class 'str'>\n",
      "715 <class 'str'>\n",
      "2668 <class 'str'>\n",
      "1880 <class 'str'>\n",
      "2316 <class 'str'>\n",
      "6019 <class 'str'>\n",
      "1749 <class 'str'>\n",
      "491 <class 'str'>\n",
      "1539 <class 'str'>\n",
      "5009 <class 'str'>\n",
      "7239 <class 'str'>\n",
      "558 <class 'str'>\n",
      "1361 <class 'str'>\n",
      "2512 <class 'str'>\n",
      "2820 <class 'str'>\n",
      "2750 <class 'str'>\n",
      "1634 <class 'str'>\n",
      "3445 <class 'str'>\n",
      "1902 <class 'str'>\n",
      "1859 <class 'str'>\n",
      "4065 <class 'str'>\n",
      "6940 <class 'str'>\n",
      "2467 <class 'str'>\n",
      "4070 <class 'str'>\n",
      "1566 <class 'str'>\n",
      "3045 <class 'str'>\n",
      "3605 <class 'str'>\n",
      "449 <class 'str'>\n",
      "3422 <class 'str'>\n",
      "1984 <class 'str'>\n",
      "6355 <class 'str'>\n",
      "4423 <class 'str'>\n",
      "2415 <class 'str'>\n",
      "92 <class 'str'>\n",
      "2645 <class 'str'>\n",
      "4966 <class 'str'>\n",
      "2617 <class 'str'>\n",
      "262 <class 'str'>\n",
      "1059 <class 'str'>\n",
      "3281 <class 'str'>\n",
      "3611 <class 'str'>\n",
      "1625 <class 'str'>\n",
      "1104 <class 'str'>\n",
      "891 <class 'str'>\n",
      "5493 <class 'str'>\n",
      "2754 <class 'str'>\n",
      "2705 <class 'str'>\n",
      "996 <class 'str'>\n",
      "1454 <class 'str'>\n",
      "1224 <class 'str'>\n",
      "1940 <class 'str'>\n",
      "4854 <class 'str'>\n",
      "3782 <class 'str'>\n",
      "3545 <class 'str'>\n",
      "989 <class 'str'>\n",
      "6806 <class 'str'>\n",
      "1307 <class 'str'>\n",
      "1578 <class 'str'>\n",
      "3293 <class 'str'>\n",
      "760 <class 'str'>\n",
      "5514 <class 'str'>\n",
      "5672 <class 'str'>\n",
      "3778 <class 'str'>\n",
      "5919 <class 'str'>\n",
      "3959 <class 'str'>\n",
      "2227 <class 'str'>\n",
      "218 <class 'str'>\n",
      "2223 <class 'str'>\n",
      "4980 <class 'str'>\n",
      "1276 <class 'str'>\n",
      "3582 <class 'str'>\n",
      "1871 <class 'str'>\n",
      "126 <class 'str'>\n",
      "706 <class 'str'>\n",
      "1124 <class 'str'>\n",
      "1145 <class 'str'>\n",
      "1937 <class 'str'>\n",
      "6196 <class 'str'>\n",
      "1700 <class 'str'>\n",
      "2816 <class 'str'>\n",
      "2489 <class 'str'>\n",
      "5662 <class 'str'>\n",
      "7405 <class 'str'>\n",
      "1639 <class 'str'>\n",
      "2123 <class 'str'>\n",
      "3623 <class 'str'>\n",
      "2656 <class 'str'>\n",
      "2660 <class 'str'>\n",
      "5625 <class 'str'>\n",
      "936 <class 'str'>\n",
      "2689 <class 'str'>\n",
      "4045 <class 'str'>\n",
      "1707 <class 'str'>\n",
      "979 <class 'str'>\n",
      "93 <class 'str'>\n",
      "1555 <class 'str'>\n",
      "5920 <class 'str'>\n",
      "2457 <class 'str'>\n",
      "290 <class 'str'>\n",
      "368 <class 'str'>\n",
      "5273 <class 'str'>\n",
      "906 <class 'str'>\n",
      "4808 <class 'str'>\n",
      "24 <class 'str'>\n",
      "1823 <class 'str'>\n",
      "752 <class 'str'>\n",
      "3859 <class 'str'>\n",
      "902 <class 'str'>\n",
      "3857 <class 'str'>\n",
      "4643 <class 'str'>\n",
      "937 <class 'str'>\n",
      "1751 <class 'str'>\n",
      "2095 <class 'str'>\n",
      "5461 <class 'str'>\n",
      "7022 <class 'str'>\n",
      "207 <class 'str'>\n",
      "7550 <class 'str'>\n",
      "1447 <class 'str'>\n",
      "984 <class 'str'>\n",
      "4732 <class 'str'>\n",
      "5407 <class 'str'>\n",
      "6432 <class 'str'>\n",
      "878 <class 'str'>\n",
      "3283 <class 'str'>\n",
      "1876 <class 'str'>\n",
      "1350 <class 'str'>\n",
      "2589 <class 'str'>\n",
      "3154 <class 'str'>\n",
      "1143 <class 'str'>\n",
      "791 <class 'str'>\n",
      "4052 <class 'str'>\n",
      "1938 <class 'str'>\n",
      "374 <class 'str'>\n",
      "698 <class 'str'>\n",
      "5901 <class 'str'>\n",
      "5406 <class 'str'>\n",
      "3212 <class 'str'>\n",
      "4781 <class 'str'>\n",
      "2577 <class 'str'>\n",
      "4982 <class 'str'>\n",
      "1318 <class 'str'>\n",
      "1275 <class 'str'>\n",
      "5554 <class 'str'>\n",
      "5824 <class 'str'>\n",
      "635 <class 'str'>\n",
      "1065 <class 'str'>\n",
      "2138 <class 'str'>\n",
      "5534 <class 'str'>\n",
      "3006 <class 'str'>\n",
      "2341 <class 'str'>\n",
      "1257 <class 'str'>\n",
      "666 <class 'str'>\n",
      "5535 <class 'str'>\n",
      "1211 <class 'str'>\n",
      "1093 <class 'str'>\n",
      "4617 <class 'str'>\n",
      "1963 <class 'str'>\n",
      "1537 <class 'str'>\n",
      "4191 <class 'str'>\n",
      "2026 <class 'str'>\n",
      "4086 <class 'str'>\n",
      "2188 <class 'str'>\n",
      "1368 <class 'str'>\n",
      "4320 <class 'str'>\n",
      "1523 <class 'str'>\n",
      "862 <class 'str'>\n",
      "3999 <class 'str'>\n",
      "2351 <class 'str'>\n",
      "1650 <class 'str'>\n",
      "1271 <class 'str'>\n",
      "102 <class 'str'>\n",
      "2293 <class 'str'>\n",
      "1770 <class 'str'>\n",
      "762 <class 'str'>\n",
      "3863 <class 'str'>\n",
      "1929 <class 'str'>\n",
      "3434 <class 'str'>\n",
      "5803 <class 'str'>\n",
      "6 <class 'str'>\n",
      "1130 <class 'str'>\n",
      "3020 <class 'str'>\n",
      "4426 <class 'str'>\n",
      "1004 <class 'str'>\n",
      "3261 <class 'str'>\n",
      "1791 <class 'str'>\n",
      "5966 <class 'str'>\n",
      "1798 <class 'str'>\n",
      "3120 <class 'str'>\n",
      "1903 <class 'str'>\n",
      "4892 <class 'str'>\n",
      "527 <class 'str'>\n",
      "828 <class 'str'>\n",
      "3111 <class 'str'>\n",
      "4888 <class 'str'>\n",
      "3487 <class 'str'>\n",
      "7679 <class 'str'>\n",
      "5303 <class 'str'>\n",
      "2582 <class 'str'>\n",
      "4520 <class 'str'>\n",
      "746 <class 'str'>\n",
      "4439 <class 'str'>\n",
      "3348 <class 'str'>\n",
      "2260 <class 'str'>\n",
      "2786 <class 'str'>\n",
      "308 <class 'str'>\n",
      "476 <class 'str'>\n",
      "3358 <class 'str'>\n",
      "2214 <class 'str'>\n",
      "4316 <class 'str'>\n",
      "1225 <class 'str'>\n",
      "3285 <class 'str'>\n",
      "1297 <class 'str'>\n",
      "256 <class 'str'>\n",
      "5343 <class 'str'>\n",
      "3019 <class 'str'>\n",
      "4922 <class 'str'>\n",
      "271 <class 'str'>\n",
      "1254 <class 'str'>\n",
      "3409 <class 'str'>\n",
      "3388 <class 'str'>\n",
      "2803 <class 'str'>\n",
      "10 <class 'str'>\n",
      "933 <class 'str'>\n",
      "692 <class 'str'>\n",
      "4648 <class 'str'>\n",
      "4677 <class 'str'>\n",
      "3673 <class 'str'>\n",
      "535 <class 'str'>\n",
      "245 <class 'str'>\n",
      "2033 <class 'str'>\n",
      "2822 <class 'str'>\n",
      "4606 <class 'str'>\n",
      "3256 <class 'str'>\n",
      "567 <class 'str'>\n",
      "4406 <class 'str'>\n",
      "7072 <class 'str'>\n",
      "1045 <class 'str'>\n",
      "1990 <class 'str'>\n",
      "3872 <class 'str'>\n",
      "49 <class 'str'>\n",
      "2941 <class 'str'>\n",
      "411 <class 'str'>\n",
      "2817 <class 'str'>\n",
      "4029 <class 'str'>\n",
      "45 <class 'str'>\n",
      "3716 <class 'str'>\n",
      "2812 <class 'str'>\n",
      "4465 <class 'str'>\n",
      "5605 <class 'str'>\n",
      "591 <class 'str'>\n",
      "1313 <class 'str'>\n",
      "1285 <class 'str'>\n",
      "1655 <class 'str'>\n",
      "2115 <class 'str'>\n",
      "4386 <class 'str'>\n",
      "4445 <class 'str'>\n",
      "6662 <class 'str'>\n",
      "1953 <class 'str'>\n",
      "2630 <class 'str'>\n",
      "1402 <class 'str'>\n",
      "929 <class 'str'>\n",
      "4211 <class 'str'>\n",
      "643 <class 'str'>\n",
      "1919 <class 'str'>\n",
      "1170 <class 'str'>\n",
      "1790 <class 'str'>\n",
      "1720 <class 'str'>\n",
      "569 <class 'str'>\n",
      "656 <class 'str'>\n",
      "1753 <class 'str'>\n",
      "1071 <class 'str'>\n",
      "3971 <class 'str'>\n",
      "2737 <class 'str'>\n",
      "1472 <class 'str'>\n",
      "779 <class 'str'>\n",
      "3131 <class 'str'>\n",
      "977 <class 'str'>\n",
      "1522 <class 'str'>\n",
      "2211 <class 'str'>\n",
      "3190 <class 'str'>\n",
      "3083 <class 'str'>\n",
      "6471 <class 'str'>\n",
      "7333 <class 'str'>\n",
      "4037 <class 'str'>\n",
      "4548 <class 'str'>\n",
      "4568 <class 'str'>\n",
      "4274 <class 'str'>\n",
      "1177 <class 'str'>\n",
      "3541 <class 'str'>\n",
      "211 <class 'str'>\n",
      "213 <class 'str'>\n",
      "3077 <class 'str'>\n",
      "2526 <class 'str'>\n",
      "6678 <class 'str'>\n",
      "5910 <class 'str'>\n",
      "1906 <class 'str'>\n",
      "5741 <class 'str'>\n",
      "2797 <class 'str'>\n",
      "4700 <class 'str'>\n",
      "5427 <class 'str'>\n",
      "361 <class 'str'>\n",
      "1007 <class 'str'>\n",
      "2312 <class 'str'>\n",
      "6946 <class 'str'>\n",
      "1803 <class 'str'>\n",
      "1081 <class 'str'>\n",
      "627 <class 'str'>\n",
      "1497 <class 'str'>\n",
      "2923 <class 'str'>\n",
      "1212 <class 'str'>\n",
      "4886 <class 'str'>\n",
      "3418 <class 'str'>\n",
      "2361 <class 'str'>\n",
      "433 <class 'str'>\n",
      "1744 <class 'str'>\n",
      "636 <class 'str'>\n",
      "3837 <class 'str'>\n",
      "1789 <class 'str'>\n",
      "3964 <class 'str'>\n",
      "2022 <class 'str'>\n",
      "337 <class 'str'>\n",
      "4212 <class 'str'>\n",
      "3102 <class 'str'>\n",
      "6510 <class 'str'>\n",
      "2830 <class 'str'>\n",
      "2642 <class 'str'>\n",
      "5528 <class 'str'>\n",
      "934 <class 'str'>\n",
      "5330 <class 'str'>\n",
      "1900 <class 'str'>\n",
      "1738 <class 'str'>\n",
      "1769 <class 'str'>\n",
      "7025 <class 'str'>\n",
      "1343 <class 'str'>\n",
      "4693 <class 'str'>\n",
      "1226 <class 'str'>\n",
      "1883 <class 'str'>\n",
      "1601 <class 'str'>\n",
      "1187 <class 'str'>\n",
      "1595 <class 'str'>\n",
      "721 <class 'str'>\n",
      "2087 <class 'str'>\n",
      "1106 <class 'str'>\n",
      "3276 <class 'str'>\n",
      "4990 <class 'str'>\n",
      "5586 <class 'str'>\n",
      "861 <class 'str'>\n",
      "4594 <class 'str'>\n",
      "3511 <class 'str'>\n",
      "1886 <class 'str'>\n",
      "1082 <class 'str'>\n",
      "2300 <class 'str'>\n",
      "3627 <class 'str'>\n",
      "2529 <class 'str'>\n",
      "3600 <class 'str'>\n",
      "2524 <class 'str'>\n",
      "130 <class 'str'>\n",
      "1531 <class 'str'>\n",
      "5829 <class 'str'>\n",
      "4639 <class 'str'>\n",
      "2810 <class 'str'>\n",
      "1708 <class 'str'>\n",
      "1694 <class 'str'>\n",
      "4185 <class 'str'>\n",
      "5057 <class 'str'>\n",
      "2466 <class 'str'>\n",
      "855 <class 'str'>\n",
      "5884 <class 'str'>\n",
      "1036 <class 'str'>\n",
      "7815 <class 'str'>\n",
      "2240 <class 'str'>\n",
      "272 <class 'str'>\n",
      "264 <class 'str'>\n",
      "251 <class 'str'>\n",
      "5114 <class 'str'>\n",
      "889 <class 'str'>\n",
      "7445 <class 'str'>\n",
      "1759 <class 'str'>\n",
      "2516 <class 'str'>\n",
      "5761 <class 'str'>\n",
      "192 <class 'str'>\n",
      "2653 <class 'str'>\n",
      "672 <class 'str'>\n",
      "2414 <class 'str'>\n",
      "520 <class 'str'>\n",
      "3804 <class 'str'>\n",
      "1168 <class 'str'>\n",
      "927 <class 'str'>\n",
      "1434 <class 'str'>\n",
      "1968 <class 'str'>\n",
      "5781 <class 'str'>\n",
      "4624 <class 'str'>\n",
      "5170 <class 'str'>\n",
      "4583 <class 'str'>\n",
      "607 <class 'str'>\n",
      "4147 <class 'str'>\n",
      "4549 <class 'str'>\n",
      "1076 <class 'str'>\n",
      "443 <class 'str'>\n",
      "1980 <class 'str'>\n",
      "941 <class 'str'>\n",
      "2591 <class 'str'>\n",
      "3050 <class 'str'>\n",
      "1208 <class 'str'>\n",
      "151 <class 'str'>\n",
      "2283 <class 'str'>\n",
      "5054 <class 'str'>\n",
      "6390 <class 'str'>\n",
      "4793 <class 'str'>\n",
      "3267 <class 'str'>\n",
      "1877 <class 'str'>\n",
      "2079 <class 'str'>\n",
      "2365 <class 'str'>\n",
      "3615 <class 'str'>\n",
      "162 <class 'str'>\n",
      "2047 <class 'str'>\n",
      "2439 <class 'str'>\n",
      "6634 <class 'str'>\n",
      "4117 <class 'str'>\n",
      "1714 <class 'str'>\n",
      "1288 <class 'str'>\n",
      "6358 <class 'str'>\n",
      "2334 <class 'str'>\n",
      "5712 <class 'str'>\n",
      "4478 <class 'str'>\n",
      "3575 <class 'str'>\n",
      "5435 <class 'str'>\n",
      "124 <class 'str'>\n",
      "201 <class 'str'>\n",
      "2244 <class 'str'>\n",
      "6153 <class 'str'>\n",
      "829 <class 'str'>\n",
      "1898 <class 'str'>\n",
      "2051 <class 'str'>\n",
      "3094 <class 'str'>\n",
      "5173 <class 'str'>\n",
      "4182 <class 'str'>\n",
      "3210 <class 'str'>\n",
      "1308 <class 'str'>\n",
      "342 <class 'str'>\n",
      "741 <class 'str'>\n",
      "5703 <class 'str'>\n",
      "1111 <class 'str'>\n",
      "1615 <class 'str'>\n",
      "1120 <class 'str'>\n",
      "1888 <class 'str'>\n",
      "4971 <class 'str'>\n",
      "968 <class 'str'>\n",
      "5483 <class 'str'>\n",
      "1049 <class 'str'>\n",
      "1705 <class 'str'>\n",
      "5771 <class 'str'>\n",
      "4581 <class 'str'>\n",
      "6443 <class 'str'>\n",
      "3367 <class 'str'>\n",
      "278 <class 'str'>\n",
      "5878 <class 'str'>\n",
      "1572 <class 'str'>\n",
      "1839 <class 'str'>\n",
      "918 <class 'str'>\n",
      "3897 <class 'str'>\n",
      "407 <class 'str'>\n",
      "2861 <class 'str'>\n",
      "820 <class 'str'>\n",
      "3955 <class 'str'>\n",
      "1544 <class 'str'>\n",
      "2177 <class 'str'>\n",
      "2264 <class 'str'>\n",
      "4960 <class 'str'>\n",
      "2961 <class 'str'>\n",
      "52 <class 'str'>\n",
      "4390 <class 'str'>\n",
      "669 <class 'str'>\n",
      "6572 <class 'str'>\n",
      "7481 <class 'str'>\n",
      "6096 <class 'str'>\n",
      "4330 <class 'str'>\n",
      "3873 <class 'str'>\n",
      "6304 <class 'str'>\n",
      "469 <class 'str'>\n",
      "318 <class 'str'>\n",
      "2934 <class 'str'>\n",
      "5441 <class 'str'>\n",
      "6122 <class 'str'>\n",
      "853 <class 'str'>\n",
      "6434 <class 'str'>\n",
      "116 <class 'str'>\n",
      "1303 <class 'str'>\n",
      "6228 <class 'str'>\n",
      "2794 <class 'str'>\n",
      "2265 <class 'str'>\n",
      "1444 <class 'str'>\n",
      "199 <class 'str'>\n",
      "4901 <class 'str'>\n",
      "2825 <class 'str'>\n",
      "3431 <class 'str'>\n",
      "3956 <class 'str'>\n",
      "4723 <class 'str'>\n",
      "1123 <class 'str'>\n",
      "1801 <class 'str'>\n",
      "35 <class 'str'>\n",
      "6762 <class 'str'>\n",
      "5472 <class 'str'>\n",
      "3909 <class 'str'>\n",
      "3592 <class 'str'>\n",
      "3923 <class 'str'>\n",
      "4080 <class 'str'>\n",
      "3330 <class 'str'>\n",
      "1138 <class 'str'>\n",
      "4523 <class 'str'>\n",
      "3610 <class 'str'>\n",
      "770 <class 'str'>\n",
      "3216 <class 'str'>\n",
      "587 <class 'str'>\n",
      "3992 <class 'str'>\n",
      "2857 <class 'str'>\n",
      "1897 <class 'str'>\n",
      "593 <class 'str'>\n",
      "4846 <class 'str'>\n",
      "904 <class 'str'>\n",
      "34 <class 'str'>\n",
      "4703 <class 'str'>\n",
      "4205 <class 'str'>\n",
      "5393 <class 'str'>\n",
      "2554 <class 'str'>\n",
      "1127 <class 'str'>\n",
      "5819 <class 'str'>\n",
      "2013 <class 'str'>\n",
      "5240 <class 'str'>\n",
      "660 <class 'str'>\n",
      "1074 <class 'str'>\n",
      "1413 <class 'str'>\n",
      "710 <class 'str'>\n",
      "2445 <class 'str'>\n",
      "7202 <class 'str'>\n",
      "1704 <class 'str'>\n",
      "1528 <class 'str'>\n",
      "282 <class 'str'>\n",
      "2701 <class 'str'>\n",
      "2800 <class 'str'>\n",
      "7430 <class 'str'>\n",
      "5532 <class 'str'>\n",
      "3926 <class 'str'>\n",
      "6814 <class 'str'>\n",
      "2907 <class 'str'>\n",
      "3712 <class 'str'>\n",
      "3089 <class 'str'>\n",
      "17 <class 'str'>\n",
      "3273 <class 'str'>\n",
      "7954 <class 'str'>\n",
      "4457 <class 'str'>\n",
      "459 <class 'str'>\n",
      "138 <class 'str'>\n",
      "2900 <class 'str'>\n",
      "3467 <class 'str'>\n",
      "956 <class 'str'>\n",
      "5947 <class 'str'>\n",
      "1356 <class 'str'>\n",
      "2843 <class 'str'>\n",
      "7322 <class 'str'>\n",
      "1268 <class 'str'>\n",
      "1058 <class 'str'>\n",
      "3583 <class 'str'>\n",
      "4967 <class 'str'>\n",
      "3692 <class 'str'>\n",
      "3088 <class 'str'>\n",
      "1046 <class 'str'>\n",
      "4592 <class 'str'>\n",
      "1899 <class 'str'>\n",
      "7273 <class 'str'>\n",
      "907 <class 'str'>\n",
      "5259 <class 'str'>\n",
      "7804 <class 'str'>\n",
      "4103 <class 'str'>\n",
      "1942 <class 'str'>\n",
      "7069 <class 'str'>\n",
      "1558 <class 'str'>\n",
      "1450 <class 'str'>\n",
      "6896 <class 'str'>\n",
      "4290 <class 'str'>\n",
      "89 <class 'str'>\n",
      "6808 <class 'str'>\n",
      "2399 <class 'str'>\n",
      "1893 <class 'str'>\n",
      "1861 <class 'str'>\n",
      "1860 <class 'str'>\n",
      "3993 <class 'str'>\n",
      "2340 <class 'str'>\n",
      "4836 <class 'str'>\n",
      "1197 <class 'str'>\n",
      "6632 <class 'str'>\n",
      "1250 <class 'str'>\n",
      "1054 <class 'str'>\n",
      "212 <class 'str'>\n",
      "4839 <class 'str'>\n",
      "3182 <class 'str'>\n",
      "2044 <class 'str'>\n",
      "1910 <class 'str'>\n",
      "3427 <class 'str'>\n",
      "4453 <class 'str'>\n",
      "4194 <class 'str'>\n",
      "1248 <class 'str'>\n",
      "945 <class 'str'>\n",
      "5209 <class 'str'>\n",
      "3246 <class 'str'>\n",
      "2682 <class 'str'>\n",
      "5644 <class 'str'>\n",
      "1818 <class 'str'>\n",
      "1585 <class 'str'>\n",
      "1038 <class 'str'>\n",
      "1954 <class 'str'>\n",
      "123 <class 'str'>\n",
      "621 <class 'str'>\n",
      "5051 <class 'str'>\n",
      "1274 <class 'str'>\n",
      "2315 <class 'str'>\n",
      "1841 <class 'str'>\n",
      "4120 <class 'str'>\n",
      "341 <class 'str'>\n",
      "688 <class 'str'>\n",
      "5553 <class 'str'>\n",
      "5219 <class 'str'>\n",
      "2490 <class 'str'>\n",
      "4035 <class 'str'>\n",
      "2725 <class 'str'>\n",
      "7498 <class 'str'>\n",
      "1543 <class 'str'>\n",
      "2887 <class 'str'>\n",
      "1102 <class 'str'>\n",
      "809 <class 'str'>\n",
      "3400 <class 'str'>\n",
      "6271 <class 'str'>\n",
      "292 <class 'str'>\n",
      "5416 <class 'str'>\n",
      "6425 <class 'str'>\n",
      "5419 <class 'str'>\n",
      "1056 <class 'str'>\n",
      "109 <class 'str'>\n",
      "132 <class 'str'>\n",
      "2145 <class 'str'>\n",
      "3186 <class 'str'>\n",
      "2116 <class 'str'>\n",
      "3299 <class 'str'>\n",
      "372 <class 'str'>\n",
      "6799 <class 'str'>\n",
      "4276 <class 'str'>\n",
      "3087 <class 'str'>\n",
      "4665 <class 'str'>\n",
      "533 <class 'str'>\n",
      "1451 <class 'str'>\n",
      "429 <class 'str'>\n",
      "723 <class 'str'>\n",
      "4874 <class 'str'>\n",
      "7651 <class 'str'>\n",
      "3902 <class 'str'>\n",
      "1527 <class 'str'>\n",
      "1279 <class 'str'>\n",
      "4564 <class 'str'>\n",
      "2970 <class 'str'>\n",
      "3255 <class 'str'>\n",
      "880 <class 'str'>\n",
      "2871 <class 'str'>\n",
      "7365 <class 'str'>\n",
      "2007 <class 'str'>\n",
      "179 <class 'str'>\n",
      "1432 <class 'str'>\n",
      "2908 <class 'str'>\n",
      "4355 <class 'str'>\n",
      "4503 <class 'str'>\n",
      "3518 <class 'str'>\n",
      "3688 <class 'str'>\n",
      "5763 <class 'str'>\n",
      "769 <class 'str'>\n",
      "3533 <class 'str'>\n",
      "2126 <class 'str'>\n",
      "3368 <class 'str'>\n",
      "1807 <class 'str'>\n",
      "1542 <class 'str'>\n",
      "5313 <class 'str'>\n",
      "1330 <class 'str'>\n",
      "4764 <class 'str'>\n",
      "128 <class 'str'>\n",
      "6734 <class 'str'>\n",
      "2849 <class 'str'>\n",
      "7408 <class 'str'>\n",
      "3829 <class 'str'>\n",
      "5661 <class 'str'>\n",
      "2530 <class 'str'>\n",
      "6815 <class 'str'>\n",
      "4128 <class 'str'>\n",
      "3059 <class 'str'>\n",
      "5627 <class 'str'>\n",
      "4068 <class 'str'>\n",
      "2881 <class 'str'>\n",
      "3649 <class 'str'>\n",
      "4909 <class 'str'>\n",
      "114 <class 'str'>\n",
      "1096 <class 'str'>\n",
      "1631 <class 'str'>\n",
      "6344 <class 'str'>\n",
      "6577 <class 'str'>\n",
      "1865 <class 'str'>\n",
      "1060 <class 'str'>\n",
      "5025 <class 'str'>\n",
      "3339 <class 'str'>\n",
      "2769 <class 'str'>\n",
      "1863 <class 'str'>\n",
      "1757 <class 'str'>\n",
      "2549 <class 'str'>\n",
      "3904 <class 'str'>\n",
      "860 <class 'str'>\n",
      "3768 <class 'str'>\n",
      "2249 <class 'str'>\n",
      "4281 <class 'str'>\n",
      "4956 <class 'str'>\n",
      "935 <class 'str'>\n",
      "946 <class 'str'>\n",
      "266 <class 'str'>\n",
      "4122 <class 'str'>\n",
      "1050 <class 'str'>\n",
      "2768 <class 'str'>\n",
      "3852 <class 'str'>\n",
      "2796 <class 'str'>\n",
      "6142 <class 'str'>\n",
      "2032 <class 'str'>\n",
      "51 <class 'str'>\n",
      "1905 <class 'str'>\n",
      "745 <class 'str'>\n",
      "3345 <class 'str'>\n",
      "2161 <class 'str'>\n",
      "253 <class 'str'>\n",
      "3140 <class 'str'>\n",
      "3835 <class 'str'>\n",
      "565 <class 'str'>\n",
      "5559 <class 'str'>\n",
      "5788 <class 'str'>\n",
      "4340 <class 'str'>\n",
      "5563 <class 'str'>\n",
      "2652 <class 'str'>\n",
      "1878 <class 'str'>\n",
      "1259 <class 'str'>\n",
      "1121 <class 'str'>\n",
      "3630 <class 'str'>\n",
      "5776 <class 'str'>\n",
      "560 <class 'str'>\n",
      "4911 <class 'str'>\n",
      "3011 <class 'str'>\n",
      "5607 <class 'str'>\n",
      "5898 <class 'str'>\n",
      "3425 <class 'str'>\n",
      "39 <class 'str'>\n",
      "5485 <class 'str'>\n",
      "8110 <class 'str'>\n",
      "1901 <class 'str'>\n",
      "6338 <class 'str'>\n",
      "630 <class 'str'>\n",
      "96 <class 'str'>\n",
      "1667 <class 'str'>\n",
      "440 <class 'str'>\n",
      "3662 <class 'str'>\n",
      "3270 <class 'str'>\n",
      "3670 <class 'str'>\n",
      "5509 <class 'str'>\n",
      "267 <class 'str'>\n",
      "5620 <class 'str'>\n",
      "1433 <class 'str'>\n",
      "6750 <class 'str'>\n",
      "1620 <class 'str'>\n",
      "5064 <class 'str'>\n",
      "2333 <class 'str'>\n",
      "2520 <class 'str'>\n",
      "3968 <class 'str'>\n",
      "1653 <class 'str'>\n",
      "2618 <class 'str'>\n",
      "6233 <class 'str'>\n",
      "2330 <class 'str'>\n",
      "2387 <class 'str'>\n",
      "3056 <class 'str'>\n",
      "2274 <class 'str'>\n",
      "4017 <class 'str'>\n",
      "1685 <class 'str'>\n",
      "1163 <class 'str'>\n",
      "5283 <class 'str'>\n",
      "1322 <class 'str'>\n",
      "3590 <class 'str'>\n",
      "1199 <class 'str'>\n",
      "2757 <class 'str'>\n",
      "1814 <class 'str'>\n",
      "3070 <class 'str'>\n",
      "2712 <class 'str'>\n",
      "2888 <class 'str'>\n",
      "2902 <class 'str'>\n",
      "142 <class 'str'>\n",
      "7992 <class 'str'>\n",
      "1220 <class 'str'>\n",
      "3181 <class 'str'>\n",
      "3942 <class 'str'>\n",
      "1122 <class 'str'>\n",
      "3838 <class 'str'>\n",
      "2884 <class 'str'>\n",
      "2118 <class 'str'>\n",
      "6351 <class 'str'>\n",
      "5794 <class 'str'>\n",
      "1083 <class 'str'>\n",
      "1649 <class 'str'>\n",
      "727 <class 'str'>\n",
      "4861 <class 'str'>\n",
      "2715 <class 'str'>\n",
      "3842 <class 'str'>\n",
      "2528 <class 'str'>\n",
      "5223 <class 'str'>\n",
      "4575 <class 'str'>\n",
      "1771 <class 'str'>\n",
      "1928 <class 'str'>\n",
      "1171 <class 'str'>\n",
      "697 <class 'str'>\n",
      "2519 <class 'str'>\n",
      "1996 <class 'str'>\n",
      "4285 <class 'str'>\n",
      "5787 <class 'str'>\n",
      "5397 <class 'str'>\n",
      "1549 <class 'str'>\n",
      "1971 <class 'str'>\n",
      "3884 <class 'str'>\n",
      "2153 <class 'str'>\n",
      "2354 <class 'str'>\n",
      "774 <class 'str'>\n",
      "465 <class 'str'>\n",
      "3589 <class 'str'>\n",
      "2295 <class 'str'>\n",
      "6880 <class 'str'>\n",
      "2560 <class 'str'>\n",
      "3176 <class 'str'>\n",
      "277 <class 'str'>\n",
      "1764 <class 'str'>\n",
      "1152 <class 'str'>\n",
      "2239 <class 'str'>\n",
      "6647 <class 'str'>\n",
      "1766 <class 'str'>\n",
      "416 <class 'str'>\n",
      "4230 <class 'str'>\n",
      "735 <class 'str'>\n",
      "2694 <class 'str'>\n",
      "8 <class 'str'>\n",
      "3540 <class 'str'>\n",
      "7136 <class 'str'>\n",
      "239 <class 'str'>\n",
      "3876 <class 'str'>\n",
      "3638 <class 'str'>\n",
      "1642 <class 'str'>\n",
      "446 <class 'str'>\n",
      "3523 <class 'str'>\n",
      "3141 <class 'str'>\n",
      "596 <class 'str'>\n",
      "3157 <class 'str'>\n",
      "3357 <class 'str'>\n",
      "4362 <class 'str'>\n",
      "385 <class 'str'>\n",
      "6545 <class 'str'>\n",
      "579 <class 'str'>\n",
      "6583 <class 'str'>\n",
      "1061 <class 'str'>\n",
      "1348 <class 'str'>\n",
      "1260 <class 'str'>\n",
      "3303 <class 'str'>\n",
      "2681 <class 'str'>\n",
      "87 <class 'str'>\n",
      "2539 <class 'str'>\n",
      "4887 <class 'str'>\n",
      "4613 <class 'str'>\n",
      "149 <class 'str'>\n",
      "806 <class 'str'>\n",
      "5249 <class 'str'>\n",
      "31 <class 'str'>\n",
      "2486 <class 'str'>\n",
      "2397 <class 'str'>\n",
      "3302 <class 'str'>\n",
      "629 <class 'str'>\n",
      "1843 <class 'str'>\n",
      "4327 <class 'str'>\n",
      "3548 <class 'str'>\n",
      "2807 <class 'str'>\n",
      "5851 <class 'str'>\n",
      "2225 <class 'str'>\n",
      "3479 <class 'str'>\n",
      "3426 <class 'str'>\n",
      "7495 <class 'str'>\n",
      "5337 <class 'str'>\n",
      "1600 <class 'str'>\n",
      "648 <class 'str'>\n",
      "3951 <class 'str'>\n",
      "2114 <class 'str'>\n",
      "1739 <class 'str'>\n",
      "3458 <class 'str'>\n",
      "2309 <class 'str'>\n",
      "792 <class 'str'>\n",
      "668 <class 'str'>\n",
      "2468 <class 'str'>\n",
      "6286 <class 'str'>\n",
      "6345 <class 'str'>\n",
      "3420 <class 'str'>\n",
      "3671 <class 'str'>\n",
      "2427 <class 'str'>\n",
      "1108 <class 'str'>\n",
      "6291 <class 'str'>\n",
      "3439 <class 'str'>\n",
      "1691 <class 'str'>\n",
      "1158 <class 'str'>\n",
      "313 <class 'str'>\n",
      "5365 <class 'str'>\n",
      "2305 <class 'str'>\n",
      "2813 <class 'str'>\n",
      "7399 <class 'str'>\n",
      "5201 <class 'str'>\n",
      "3343 <class 'str'>\n",
      "539 <class 'str'>\n",
      "1550 <class 'str'>\n",
      "864 <class 'str'>\n",
      "2619 <class 'str'>\n",
      "1525 <class 'str'>\n",
      "1241 <class 'str'>\n",
      "1847 <class 'str'>\n",
      "3340 <class 'str'>\n",
      "7450 <class 'str'>\n",
      "6210 <class 'str'>\n",
      "5996 <class 'str'>\n",
      "5835 <class 'str'>\n",
      "351 <class 'str'>\n",
      "6386 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for val in test_data['notRepairedDamage'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eKSos90j3UFO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1750469765950,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "eKSos90j3UFO",
    "outputId": "11d1acff-9b1e-4958-8332-cba813d25720"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>35033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>10345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "gearbox\n",
       "0.0     35033\n",
       "1.0     10345\n",
       "0        1108\n",
       "15.0      485\n",
       "-         434\n",
       "        ...  \n",
       "521         1\n",
       "280         1\n",
       "480         1\n",
       "83          1\n",
       "4           1\n",
       "Name: count, Length: 224, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['gearbox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GfgwgOVi3b11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1750469774441,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "GfgwgOVi3b11",
    "outputId": "75f17cca-3334-4455-d174-0f35c24ccf2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilometer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>28869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.5</th>\n",
       "      <td>4935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "kilometer\n",
       "15.0    28869\n",
       "12.5     4935\n",
       "10.0     1944\n",
       "9.0      1689\n",
       "0.0      1641\n",
       "        ...  \n",
       "2293        1\n",
       "3210        1\n",
       "2991        1\n",
       "4511        1\n",
       "856         1\n",
       "Name: count, Length: 636, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['kilometer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k8JK2m2F3hE2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1750469778094,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "k8JK2m2F3hE2",
    "outputId": "03ba4afa-a619-421e-f04b-e0381b508d26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10522</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>795 rows × 1 columns</p>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "power\n",
       "75       2955\n",
       "15.0     2549\n",
       "0        2382\n",
       "150      2053\n",
       "60       1967\n",
       "         ... \n",
       "6600        1\n",
       "5396        1\n",
       "10522       1\n",
       "6580        1\n",
       "1973        1\n",
       "Name: count, Length: 795, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['power'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1_0LOgW4E1Ti",
   "metadata": {
    "id": "1_0LOgW4E1Ti"
   },
   "source": [
    "## 1.3 数据类别和异常值处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p2nv6Z8_9VF6",
   "metadata": {
    "id": "p2nv6Z8_9VF6"
   },
   "source": [
    "### 1.3.1 处理notRepairedDamage和gearbox字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miME65S08acq",
   "metadata": {
    "id": "miME65S08acq"
   },
   "outputs": [],
   "source": [
    "def clean_categories(col):\n",
    "    col = col.astype(str)\n",
    "    col = col.apply(lambda x: x if x in ['0.0', '1.0'] else np.nan)\n",
    "    return pd.to_numeric(col, errors='coerce').fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eIiWj_88kKv",
   "metadata": {
    "id": "1eIiWj_88kKv"
   },
   "outputs": [],
   "source": [
    "# 应用于训练集和测试集\n",
    "train_data['notRepairedDamage'] = clean_categories(train_data['notRepairedDamage'])\n",
    "train_data['gearbox'] = clean_categories(train_data['gearbox'])\n",
    "test_data['notRepairedDamage'] = clean_categories(test_data['notRepairedDamage'])\n",
    "test_data['gearbox'] = clean_categories(test_data['gearbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LZcjM7q08ul0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1750469800911,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "LZcjM7q08ul0",
    "outputId": "f8eb2284-bd11-4425-bd60-532b25c464dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>14031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "gearbox\n",
       " 0    104864\n",
       " 1     31105\n",
       "-1     14031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['gearbox'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y3z-mNLr9l2a",
   "metadata": {
    "id": "Y3z-mNLr9l2a"
   },
   "source": [
    "### 1.3.2 处理power字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ovU7MExn9sEg",
   "metadata": {
    "id": "ovU7MExn9sEg"
   },
   "outputs": [],
   "source": [
    "def clean_power(col, max_valid=600):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CEzpoAfq90xC",
   "metadata": {
    "id": "CEzpoAfq90xC"
   },
   "outputs": [],
   "source": [
    "train_data['power'] = clean_power(train_data['power'])\n",
    "test_data['power'] = clean_power(test_data['power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "INcZNsqB-AUa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1750469805599,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "INcZNsqB-AUa",
    "outputId": "222672a6-f1b7-4cbd-af98-8c4e436106ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 <class 'numpy.int64'>\n",
      "0 <class 'numpy.int64'>\n",
      "163 <class 'numpy.int64'>\n",
      "193 <class 'numpy.int64'>\n",
      "68 <class 'numpy.int64'>\n",
      "109 <class 'numpy.int64'>\n",
      "150 <class 'numpy.int64'>\n",
      "101 <class 'numpy.int64'>\n",
      "179 <class 'numpy.int64'>\n",
      "88 <class 'numpy.int64'>\n",
      "75 <class 'numpy.int64'>\n",
      "58 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n",
      "128 <class 'numpy.int64'>\n",
      "239 <class 'numpy.int64'>\n",
      "145 <class 'numpy.int64'>\n",
      "45 <class 'numpy.int64'>\n",
      "105 <class 'numpy.int64'>\n",
      "54 <class 'numpy.int64'>\n",
      "143 <class 'numpy.int64'>\n",
      "218 <class 'numpy.int64'>\n",
      "170 <class 'numpy.int64'>\n",
      "90 <class 'numpy.int64'>\n",
      "306 <class 'numpy.int64'>\n",
      "133 <class 'numpy.int64'>\n",
      "116 <class 'numpy.int64'>\n",
      "15 <class 'numpy.int64'>\n",
      "102 <class 'numpy.int64'>\n",
      "177 <class 'numpy.int64'>\n",
      "140 <class 'numpy.int64'>\n",
      "115 <class 'numpy.int64'>\n",
      "180 <class 'numpy.int64'>\n",
      "131 <class 'numpy.int64'>\n",
      "110 <class 'numpy.int64'>\n",
      "160 <class 'numpy.int64'>\n",
      "65 <class 'numpy.int64'>\n",
      "120 <class 'numpy.int64'>\n",
      "73 <class 'numpy.int64'>\n",
      "77 <class 'numpy.int64'>\n",
      "500 <class 'numpy.int64'>\n",
      "136 <class 'numpy.int64'>\n",
      "233 <class 'numpy.int64'>\n",
      "125 <class 'numpy.int64'>\n",
      "300 <class 'numpy.int64'>\n",
      "190 <class 'numpy.int64'>\n",
      "192 <class 'numpy.int64'>\n",
      "126 <class 'numpy.int64'>\n",
      "203 <class 'numpy.int64'>\n",
      "55 <class 'numpy.int64'>\n",
      "100 <class 'numpy.int64'>\n",
      "122 <class 'numpy.int64'>\n",
      "174 <class 'numpy.int64'>\n",
      "69 <class 'numpy.int64'>\n",
      "165 <class 'numpy.int64'>\n",
      "320 <class 'numpy.int64'>\n",
      "64 <class 'numpy.int64'>\n",
      "78 <class 'numpy.int64'>\n",
      "224 <class 'numpy.int64'>\n",
      "80 <class 'numpy.int64'>\n",
      "71 <class 'numpy.int64'>\n",
      "340 <class 'numpy.int64'>\n",
      "144 <class 'numpy.int64'>\n",
      "387 <class 'numpy.int64'>\n",
      "230 <class 'numpy.int64'>\n",
      "86 <class 'numpy.int64'>\n",
      "111 <class 'numpy.int64'>\n",
      "12 <class 'numpy.int64'>\n",
      "107 <class 'numpy.int64'>\n",
      "61 <class 'numpy.int64'>\n",
      "103 <class 'numpy.int64'>\n",
      "63 <class 'numpy.int64'>\n",
      "95 <class 'numpy.int64'>\n",
      "204 <class 'numpy.int64'>\n",
      "40 <class 'numpy.int64'>\n",
      "284 <class 'numpy.int64'>\n",
      "3 <class 'numpy.int64'>\n",
      "97 <class 'numpy.int64'>\n",
      "8 <class 'numpy.int64'>\n",
      "1 <class 'numpy.int64'>\n",
      "272 <class 'numpy.int64'>\n",
      "50 <class 'numpy.int64'>\n",
      "87 <class 'numpy.int64'>\n",
      "260 <class 'numpy.int64'>\n",
      "135 <class 'numpy.int64'>\n",
      "9 <class 'numpy.int64'>\n",
      "211 <class 'numpy.int64'>\n",
      "106 <class 'numpy.int64'>\n",
      "200 <class 'numpy.int64'>\n",
      "333 <class 'numpy.int64'>\n",
      "220 <class 'numpy.int64'>\n",
      "10 <class 'numpy.int64'>\n",
      "299 <class 'numpy.int64'>\n",
      "114 <class 'numpy.int64'>\n",
      "67 <class 'numpy.int64'>\n",
      "245 <class 'numpy.int64'>\n",
      "82 <class 'numpy.int64'>\n",
      "196 <class 'numpy.int64'>\n",
      "258 <class 'numpy.int64'>\n",
      "4 <class 'numpy.int64'>\n",
      "70 <class 'numpy.int64'>\n",
      "155 <class 'numpy.int64'>\n",
      "313 <class 'numpy.int64'>\n",
      "113 <class 'numpy.int64'>\n",
      "184 <class 'numpy.int64'>\n",
      "345 <class 'numpy.int64'>\n",
      "108 <class 'numpy.int64'>\n",
      "98 <class 'numpy.int64'>\n",
      "129 <class 'numpy.int64'>\n",
      "84 <class 'numpy.int64'>\n",
      "59 <class 'numpy.int64'>\n",
      "250 <class 'numpy.int64'>\n",
      "321 <class 'numpy.int64'>\n",
      "235 <class 'numpy.int64'>\n",
      "256 <class 'numpy.int64'>\n",
      "231 <class 'numpy.int64'>\n",
      "252 <class 'numpy.int64'>\n",
      "197 <class 'numpy.int64'>\n",
      "280 <class 'numpy.int64'>\n",
      "41 <class 'numpy.int64'>\n",
      "185 <class 'numpy.int64'>\n",
      "232 <class 'numpy.int64'>\n",
      "396 <class 'numpy.int64'>\n",
      "43 <class 'numpy.int64'>\n",
      "205 <class 'numpy.int64'>\n",
      "99 <class 'numpy.int64'>\n",
      "104 <class 'numpy.int64'>\n",
      "85 <class 'numpy.int64'>\n",
      "431 <class 'numpy.int64'>\n",
      "225 <class 'numpy.int64'>\n",
      "156 <class 'numpy.int64'>\n",
      "46 <class 'numpy.int64'>\n",
      "226 <class 'numpy.int64'>\n",
      "175 <class 'numpy.int64'>\n",
      "424 <class 'numpy.int64'>\n",
      "92 <class 'numpy.int64'>\n",
      "121 <class 'numpy.int64'>\n",
      "130 <class 'numpy.int64'>\n",
      "172 <class 'numpy.int64'>\n",
      "91 <class 'numpy.int64'>\n",
      "315 <class 'numpy.int64'>\n",
      "141 <class 'numpy.int64'>\n",
      "334 <class 'numpy.int64'>\n",
      "119 <class 'numpy.int64'>\n",
      "132 <class 'numpy.int64'>\n",
      "420 <class 'numpy.int64'>\n",
      "147 <class 'numpy.int64'>\n",
      "305 <class 'numpy.int64'>\n",
      "118 <class 'numpy.int64'>\n",
      "44 <class 'numpy.int64'>\n",
      "582 <class 'numpy.int64'>\n",
      "117 <class 'numpy.int64'>\n",
      "240 <class 'numpy.int64'>\n",
      "112 <class 'numpy.int64'>\n",
      "241 <class 'numpy.int64'>\n",
      "385 <class 'numpy.int64'>\n",
      "564 <class 'numpy.int64'>\n",
      "124 <class 'numpy.int64'>\n",
      "7 <class 'numpy.int64'>\n",
      "194 <class 'numpy.int64'>\n",
      "2 <class 'numpy.int64'>\n",
      "450 <class 'numpy.int64'>\n",
      "83 <class 'numpy.int64'>\n",
      "182 <class 'numpy.int64'>\n",
      "6 <class 'numpy.int64'>\n",
      "286 <class 'numpy.int64'>\n",
      "408 <class 'numpy.int64'>\n",
      "39 <class 'numpy.int64'>\n",
      "265 <class 'numpy.int64'>\n",
      "56 <class 'numpy.int64'>\n",
      "207 <class 'numpy.int64'>\n",
      "581 <class 'numpy.int64'>\n",
      "76 <class 'numpy.int64'>\n",
      "367 <class 'numpy.int64'>\n",
      "400 <class 'numpy.int64'>\n",
      "137 <class 'numpy.int64'>\n",
      "166 <class 'numpy.int64'>\n",
      "355 <class 'numpy.int64'>\n",
      "295 <class 'numpy.int64'>\n",
      "151 <class 'numpy.int64'>\n",
      "480 <class 'numpy.int64'>\n",
      "74 <class 'numpy.int64'>\n",
      "51 <class 'numpy.int64'>\n",
      "555 <class 'numpy.int64'>\n",
      "52 <class 'numpy.int64'>\n",
      "57 <class 'numpy.int64'>\n",
      "158 <class 'numpy.int64'>\n",
      "167 <class 'numpy.int64'>\n",
      "72 <class 'numpy.int64'>\n",
      "94 <class 'numpy.int64'>\n",
      "139 <class 'numpy.int64'>\n",
      "349 <class 'numpy.int64'>\n",
      "138 <class 'numpy.int64'>\n",
      "5 <class 'numpy.int64'>\n",
      "171 <class 'numpy.int64'>\n",
      "275 <class 'numpy.int64'>\n",
      "186 <class 'numpy.int64'>\n",
      "354 <class 'numpy.int64'>\n",
      "134 <class 'numpy.int64'>\n",
      "322 <class 'numpy.int64'>\n",
      "148 <class 'numpy.int64'>\n",
      "360 <class 'numpy.int64'>\n",
      "271 <class 'numpy.int64'>\n",
      "560 <class 'numpy.int64'>\n",
      "290 <class 'numpy.int64'>\n",
      "79 <class 'numpy.int64'>\n",
      "343 <class 'numpy.int64'>\n",
      "237 <class 'numpy.int64'>\n",
      "254 <class 'numpy.int64'>\n",
      "457 <class 'numpy.int64'>\n",
      "53 <class 'numpy.int64'>\n",
      "152 <class 'numpy.int64'>\n",
      "89 <class 'numpy.int64'>\n",
      "209 <class 'numpy.int64'>\n",
      "373 <class 'numpy.int64'>\n",
      "344 <class 'numpy.int64'>\n",
      "181 <class 'numpy.int64'>\n",
      "162 <class 'numpy.int64'>\n",
      "173 <class 'numpy.int64'>\n",
      "259 <class 'numpy.int64'>\n",
      "350 <class 'numpy.int64'>\n",
      "66 <class 'numpy.int64'>\n",
      "195 <class 'numpy.int64'>\n",
      "292 <class 'numpy.int64'>\n",
      "123 <class 'numpy.int64'>\n",
      "187 <class 'numpy.int64'>\n",
      "249 <class 'numpy.int64'>\n",
      "243 <class 'numpy.int64'>\n",
      "404 <class 'numpy.int64'>\n",
      "169 <class 'numpy.int64'>\n",
      "62 <class 'numpy.int64'>\n",
      "309 <class 'numpy.int64'>\n",
      "310 <class 'numpy.int64'>\n",
      "48 <class 'numpy.int64'>\n",
      "326 <class 'numpy.int64'>\n",
      "587 <class 'numpy.int64'>\n",
      "146 <class 'numpy.int64'>\n",
      "476 <class 'numpy.int64'>\n",
      "210 <class 'numpy.int64'>\n",
      "242 <class 'numpy.int64'>\n",
      "176 <class 'numpy.int64'>\n",
      "557 <class 'numpy.int64'>\n",
      "407 <class 'numpy.int64'>\n",
      "159 <class 'numpy.int64'>\n",
      "24 <class 'numpy.int64'>\n",
      "11 <class 'numpy.int64'>\n",
      "188 <class 'numpy.int64'>\n",
      "164 <class 'numpy.int64'>\n",
      "416 <class 'numpy.int64'>\n",
      "329 <class 'numpy.int64'>\n",
      "238 <class 'numpy.int64'>\n",
      "386 <class 'numpy.int64'>\n",
      "365 <class 'numpy.int64'>\n",
      "525 <class 'numpy.int64'>\n",
      "47 <class 'numpy.int64'>\n",
      "497 <class 'numpy.int64'>\n",
      "127 <class 'numpy.int64'>\n",
      "435 <class 'numpy.int64'>\n",
      "178 <class 'numpy.int64'>\n",
      "328 <class 'numpy.int64'>\n",
      "253 <class 'numpy.int64'>\n",
      "330 <class 'numpy.int64'>\n",
      "436 <class 'numpy.int64'>\n",
      "510 <class 'numpy.int64'>\n",
      "325 <class 'numpy.int64'>\n",
      "201 <class 'numpy.int64'>\n",
      "273 <class 'numpy.int64'>\n",
      "314 <class 'numpy.int64'>\n",
      "405 <class 'numpy.int64'>\n",
      "449 <class 'numpy.int64'>\n",
      "142 <class 'numpy.int64'>\n",
      "149 <class 'numpy.int64'>\n",
      "552 <class 'numpy.int64'>\n",
      "198 <class 'numpy.int64'>\n",
      "514 <class 'numpy.int64'>\n",
      "352 <class 'numpy.int64'>\n",
      "208 <class 'numpy.int64'>\n",
      "168 <class 'numpy.int64'>\n",
      "234 <class 'numpy.int64'>\n",
      "247 <class 'numpy.int64'>\n",
      "216 <class 'numpy.int64'>\n",
      "540 <class 'numpy.int64'>\n",
      "31 <class 'numpy.int64'>\n",
      "189 <class 'numpy.int64'>\n",
      "279 <class 'numpy.int64'>\n",
      "228 <class 'numpy.int64'>\n",
      "212 <class 'numpy.int64'>\n",
      "432 <class 'numpy.int64'>\n",
      "516 <class 'numpy.int64'>\n",
      "335 <class 'numpy.int64'>\n",
      "261 <class 'numpy.int64'>\n",
      "376 <class 'numpy.int64'>\n",
      "37 <class 'numpy.int64'>\n",
      "421 <class 'numpy.int64'>\n",
      "296 <class 'numpy.int64'>\n",
      "33 <class 'numpy.int64'>\n",
      "154 <class 'numpy.int64'>\n",
      "81 <class 'numpy.int64'>\n",
      "18 <class 'numpy.int64'>\n",
      "262 <class 'numpy.int64'>\n",
      "96 <class 'numpy.int64'>\n",
      "277 <class 'numpy.int64'>\n",
      "214 <class 'numpy.int64'>\n",
      "353 <class 'numpy.int64'>\n",
      "409 <class 'numpy.int64'>\n",
      "380 <class 'numpy.int64'>\n",
      "370 <class 'numpy.int64'>\n",
      "401 <class 'numpy.int64'>\n",
      "507 <class 'numpy.int64'>\n",
      "585 <class 'numpy.int64'>\n",
      "257 <class 'numpy.int64'>\n",
      "213 <class 'numpy.int64'>\n",
      "274 <class 'numpy.int64'>\n",
      "215 <class 'numpy.int64'>\n",
      "153 <class 'numpy.int64'>\n",
      "285 <class 'numpy.int64'>\n",
      "246 <class 'numpy.int64'>\n",
      "362 <class 'numpy.int64'>\n",
      "270 <class 'numpy.int64'>\n",
      "442 <class 'numpy.int64'>\n",
      "26 <class 'numpy.int64'>\n",
      "551 <class 'numpy.int64'>\n",
      "579 <class 'numpy.int64'>\n",
      "287 <class 'numpy.int64'>\n",
      "42 <class 'numpy.int64'>\n",
      "278 <class 'numpy.int64'>\n",
      "506 <class 'numpy.int64'>\n",
      "347 <class 'numpy.int64'>\n",
      "161 <class 'numpy.int64'>\n",
      "426 <class 'numpy.int64'>\n",
      "394 <class 'numpy.int64'>\n",
      "289 <class 'numpy.int64'>\n",
      "303 <class 'numpy.int64'>\n",
      "217 <class 'numpy.int64'>\n",
      "282 <class 'numpy.int64'>\n",
      "440 <class 'numpy.int64'>\n",
      "381 <class 'numpy.int64'>\n",
      "244 <class 'numpy.int64'>\n",
      "324 <class 'numpy.int64'>\n",
      "302 <class 'numpy.int64'>\n",
      "236 <class 'numpy.int64'>\n",
      "183 <class 'numpy.int64'>\n",
      "266 <class 'numpy.int64'>\n",
      "229 <class 'numpy.int64'>\n",
      "399 <class 'numpy.int64'>\n",
      "348 <class 'numpy.int64'>\n",
      "223 <class 'numpy.int64'>\n",
      "519 <class 'numpy.int64'>\n",
      "20 <class 'numpy.int64'>\n",
      "202 <class 'numpy.int64'>\n",
      "379 <class 'numpy.int64'>\n",
      "517 <class 'numpy.int64'>\n",
      "219 <class 'numpy.int64'>\n",
      "363 <class 'numpy.int64'>\n",
      "35 <class 'numpy.int64'>\n",
      "430 <class 'numpy.int64'>\n",
      "36 <class 'numpy.int64'>\n",
      "25 <class 'numpy.int64'>\n",
      "382 <class 'numpy.int64'>\n",
      "445 <class 'numpy.int64'>\n",
      "364 <class 'numpy.int64'>\n",
      "460 <class 'numpy.int64'>\n",
      "14 <class 'numpy.int64'>\n",
      "264 <class 'numpy.int64'>\n",
      "281 <class 'numpy.int64'>\n",
      "93 <class 'numpy.int64'>\n",
      "423 <class 'numpy.int64'>\n",
      "206 <class 'numpy.int64'>\n",
      "222 <class 'numpy.int64'>\n",
      "157 <class 'numpy.int64'>\n",
      "351 <class 'numpy.int64'>\n",
      "327 <class 'numpy.int64'>\n",
      "32 <class 'numpy.int64'>\n",
      "307 <class 'numpy.int64'>\n",
      "577 <class 'numpy.int64'>\n",
      "505 <class 'numpy.int64'>\n",
      "574 <class 'numpy.int64'>\n",
      "191 <class 'numpy.int64'>\n",
      "487 <class 'numpy.int64'>\n",
      "375 <class 'numpy.int64'>\n",
      "411 <class 'numpy.int64'>\n",
      "298 <class 'numpy.int64'>\n",
      "268 <class 'numpy.int64'>\n",
      "308 <class 'numpy.int64'>\n",
      "17 <class 'numpy.int64'>\n",
      "338 <class 'numpy.int64'>\n",
      "28 <class 'numpy.int64'>\n",
      "501 <class 'numpy.int64'>\n",
      "16 <class 'numpy.int64'>\n",
      "263 <class 'numpy.int64'>\n",
      "199 <class 'numpy.int64'>\n",
      "586 <class 'numpy.int64'>\n",
      "255 <class 'numpy.int64'>\n",
      "288 <class 'numpy.int64'>\n",
      "463 <class 'numpy.int64'>\n",
      "34 <class 'numpy.int64'>\n",
      "417 <class 'numpy.int64'>\n",
      "468 <class 'numpy.int64'>\n",
      "388 <class 'numpy.int64'>\n",
      "283 <class 'numpy.int64'>\n",
      "504 <class 'numpy.int64'>\n",
      "276 <class 'numpy.int64'>\n",
      "576 <class 'numpy.int64'>\n",
      "372 <class 'numpy.int64'>\n",
      "49 <class 'numpy.int64'>\n",
      "443 <class 'numpy.int64'>\n",
      "301 <class 'numpy.int64'>\n",
      "19 <class 'numpy.int64'>\n",
      "227 <class 'numpy.int64'>\n",
      "390 <class 'numpy.int64'>\n",
      "30 <class 'numpy.int64'>\n",
      "526 <class 'numpy.int64'>\n",
      "495 <class 'numpy.int64'>\n",
      "439 <class 'numpy.int64'>\n",
      "462 <class 'numpy.int64'>\n",
      "371 <class 'numpy.int64'>\n",
      "600 <class 'numpy.int64'>\n",
      "23 <class 'numpy.int64'>\n",
      "502 <class 'numpy.int64'>\n",
      "269 <class 'numpy.int64'>\n",
      "13 <class 'numpy.int64'>\n",
      "515 <class 'numpy.int64'>\n",
      "559 <class 'numpy.int64'>\n",
      "318 <class 'numpy.int64'>\n",
      "441 <class 'numpy.int64'>\n",
      "556 <class 'numpy.int64'>\n",
      "573 <class 'numpy.int64'>\n",
      "455 <class 'numpy.int64'>\n",
      "584 <class 'numpy.int64'>\n",
      "466 <class 'numpy.int64'>\n",
      "377 <class 'numpy.int64'>\n",
      "398 <class 'numpy.int64'>\n",
      "29 <class 'numpy.int64'>\n",
      "473 <class 'numpy.int64'>\n",
      "434 <class 'numpy.int64'>\n",
      "317 <class 'numpy.int64'>\n",
      "474 <class 'numpy.int64'>\n",
      "346 <class 'numpy.int64'>\n",
      "267 <class 'numpy.int64'>\n",
      "535 <class 'numpy.int64'>\n",
      "38 <class 'numpy.int64'>\n",
      "521 <class 'numpy.int64'>\n",
      "410 <class 'numpy.int64'>\n",
      "319 <class 'numpy.int64'>\n",
      "590 <class 'numpy.int64'>\n",
      "392 <class 'numpy.int64'>\n",
      "580 <class 'numpy.int64'>\n",
      "470 <class 'numpy.int64'>\n",
      "383 <class 'numpy.int64'>\n",
      "341 <class 'numpy.int64'>\n",
      "494 <class 'numpy.int64'>\n",
      "536 <class 'numpy.int64'>\n",
      "248 <class 'numpy.int64'>\n",
      "477 <class 'numpy.int64'>\n",
      "311 <class 'numpy.int64'>\n",
      "415 <class 'numpy.int64'>\n",
      "530 <class 'numpy.int64'>\n",
      "336 <class 'numpy.int64'>\n",
      "481 <class 'numpy.int64'>\n",
      "558 <class 'numpy.int64'>\n",
      "583 <class 'numpy.int64'>\n",
      "221 <class 'numpy.int64'>\n",
      "291 <class 'numpy.int64'>\n",
      "575 <class 'numpy.int64'>\n",
      "304 <class 'numpy.int64'>\n",
      "597 <class 'numpy.int64'>\n",
      "469 <class 'numpy.int64'>\n",
      "570 <class 'numpy.int64'>\n",
      "572 <class 'numpy.int64'>\n",
      "332 <class 'numpy.int64'>\n",
      "293 <class 'numpy.int64'>\n",
      "331 <class 'numpy.int64'>\n",
      "562 <class 'numpy.int64'>\n",
      "368 <class 'numpy.int64'>\n",
      "316 <class 'numpy.int64'>\n",
      "549 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['power'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q1Orzwwl-KcZ",
   "metadata": {
    "id": "Q1Orzwwl-KcZ"
   },
   "source": [
    "### 1.3.3 处理kilometer字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QVP5cM7H-Qk8",
   "metadata": {
    "id": "QVP5cM7H-Qk8"
   },
   "outputs": [],
   "source": [
    "def clean_kilometer(col, max_valid=20):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vJwhycYE_w2Q",
   "metadata": {
    "id": "vJwhycYE_w2Q"
   },
   "outputs": [],
   "source": [
    "train_data['kilometer'] = clean_kilometer(train_data['kilometer'])\n",
    "test_data['kilometer'] = clean_kilometer(test_data['kilometer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1B6S0kSA_z1v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750299935781,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "1B6S0kSA_z1v",
    "outputId": "31f2c21f-9100-4947-f98f-cbca5efda027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 <class 'numpy.int64'>\n",
      "15 <class 'numpy.int64'>\n",
      "5 <class 'numpy.int64'>\n",
      "10 <class 'numpy.int64'>\n",
      "2 <class 'numpy.int64'>\n",
      "6 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n",
      "3 <class 'numpy.int64'>\n",
      "0 <class 'numpy.int64'>\n",
      "7 <class 'numpy.int64'>\n",
      "8 <class 'numpy.int64'>\n",
      "9 <class 'numpy.int64'>\n",
      "4 <class 'numpy.int64'>\n",
      "1 <class 'numpy.int64'>\n",
      "18 <class 'numpy.int64'>\n",
      "17 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['kilometer'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58xgUUS1G8D-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1750301702693,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "58xgUUS1G8D-",
    "outputId": "20236be2-b2d4-467e-c631-5ffe6c4881d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   SaleID             150000 non-null  int64  \n",
      " 1   name               150000 non-null  int64  \n",
      " 2   regDate            150000 non-null  int64  \n",
      " 3   model              150000 non-null  float64\n",
      " 4   brand              150000 non-null  float64\n",
      " 5   bodyType           150000 non-null  float64\n",
      " 6   fuelType           150000 non-null  float64\n",
      " 7   gearbox            150000 non-null  int64  \n",
      " 8   power              150000 non-null  int64  \n",
      " 9   kilometer          150000 non-null  int64  \n",
      " 10  notRepairedDamage  150000 non-null  int64  \n",
      " 11  regionCode         150000 non-null  int64  \n",
      " 12  seller             150000 non-null  int64  \n",
      " 13  offerType          150000 non-null  float64\n",
      " 14  creatDate          150000 non-null  float64\n",
      " 15  price              150000 non-null  float64\n",
      " 16  v_0                150000 non-null  float64\n",
      " 17  v_1                150000 non-null  float64\n",
      " 18  v_2                150000 non-null  float64\n",
      " 19  v_3                150000 non-null  float64\n",
      " 20  v_4                150000 non-null  float64\n",
      " 21  v_5                150000 non-null  float64\n",
      " 22  v_6                150000 non-null  float64\n",
      " 23  v_7                150000 non-null  float64\n",
      " 24  v_8                150000 non-null  float64\n",
      " 25  v_9                150000 non-null  float64\n",
      " 26  v_10               150000 non-null  float64\n",
      " 27  v_11               150000 non-null  float64\n",
      " 28  v_12               148531 non-null  float64\n",
      " 29  v_13               146417 non-null  float64\n",
      " 30  v_14               135884 non-null  float64\n",
      "dtypes: float64(22), int64(9)\n",
      "memory usage: 35.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cW7cZqVYHIci",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1750301711330,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "cW7cZqVYHIci",
    "outputId": "e39e73b1-8755-4b65-bb53-ac579f15f6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   SaleID             50000 non-null  int64  \n",
      " 1   name               50000 non-null  int64  \n",
      " 2   regDate            50000 non-null  int64  \n",
      " 3   model              50000 non-null  float64\n",
      " 4   brand              50000 non-null  int64  \n",
      " 5   bodyType           50000 non-null  float64\n",
      " 6   fuelType           50000 non-null  float64\n",
      " 7   gearbox            50000 non-null  int64  \n",
      " 8   power              50000 non-null  int64  \n",
      " 9   kilometer          50000 non-null  int64  \n",
      " 10  notRepairedDamage  50000 non-null  int64  \n",
      " 11  regionCode         50000 non-null  int64  \n",
      " 12  seller             50000 non-null  float64\n",
      " 13  offerType          50000 non-null  float64\n",
      " 14  creatDate          50000 non-null  float64\n",
      " 15  v_0                50000 non-null  float64\n",
      " 16  v_1                50000 non-null  float64\n",
      " 17  v_2                50000 non-null  float64\n",
      " 18  v_3                50000 non-null  float64\n",
      " 19  v_4                50000 non-null  float64\n",
      " 20  v_5                50000 non-null  float64\n",
      " 21  v_6                50000 non-null  float64\n",
      " 22  v_7                50000 non-null  float64\n",
      " 23  v_8                50000 non-null  float64\n",
      " 24  v_9                50000 non-null  float64\n",
      " 25  v_10               50000 non-null  float64\n",
      " 26  v_11               50000 non-null  float64\n",
      " 27  v_12               49548 non-null  float64\n",
      " 28  v_13               48880 non-null  float64\n",
      " 29  v_14               45356 non-null  float64\n",
      "dtypes: float64(21), int64(9)\n",
      "memory usage: 11.4 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WhPk6uVYJQZa",
   "metadata": {
    "id": "WhPk6uVYJQZa"
   },
   "source": [
    "### 1.3.4 处理bodyType字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vhzn4_YMJUVQ",
   "metadata": {
    "id": "vhzn4_YMJUVQ"
   },
   "outputs": [],
   "source": [
    "def clean_bodyType(col, max_valid=7):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u_TLUuMJJkaA",
   "metadata": {
    "id": "u_TLUuMJJkaA"
   },
   "outputs": [],
   "source": [
    "train_data['bodyType'] = clean_bodyType(train_data['bodyType'])\n",
    "test_data['bodyType'] = clean_bodyType(test_data['bodyType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u4-9Z4kCJzjw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750302493378,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "u4-9Z4kCJzjw",
    "outputId": "9daec887-4198-4ece-84e1-ff2a29683fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'numpy.int64'>\n",
      "2 <class 'numpy.int64'>\n",
      "0 <class 'numpy.int64'>\n",
      "5 <class 'numpy.int64'>\n",
      "3 <class 'numpy.int64'>\n",
      "6 <class 'numpy.int64'>\n",
      "7 <class 'numpy.int64'>\n",
      "4 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['bodyType'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZhFg_r3LKVYE",
   "metadata": {
    "id": "ZhFg_r3LKVYE"
   },
   "source": [
    "### 1.3.5 处理fuelType字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "etHLIV6OKbuv",
   "metadata": {
    "id": "etHLIV6OKbuv"
   },
   "outputs": [],
   "source": [
    "def clean_fuelType(col, max_valid=6):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hnT71vtZKto9",
   "metadata": {
    "id": "hnT71vtZKto9"
   },
   "outputs": [],
   "source": [
    "train_data['fuelType'] = clean_fuelType(train_data['fuelType'])\n",
    "test_data['fuelType'] = clean_fuelType(test_data['fuelType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbFAkkhwK72M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750302719056,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "dbFAkkhwK72M",
    "outputId": "ac98e86a-0eb7-4d8a-be64-e9c2852ef0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.int64'>\n",
      "1 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n",
      "2 <class 'numpy.int64'>\n",
      "3 <class 'numpy.int64'>\n",
      "4 <class 'numpy.int64'>\n",
      "5 <class 'numpy.int64'>\n",
      "6 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['fuelType'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VxUJMDzaLHNq",
   "metadata": {
    "id": "VxUJMDzaLHNq"
   },
   "source": [
    "### 1.3.6 处理seller字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rxbdJGaZLMH4",
   "metadata": {
    "id": "rxbdJGaZLMH4"
   },
   "outputs": [],
   "source": [
    "def clean_seller(col, max_valid=1):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xl-8y2DnLW0f",
   "metadata": {
    "id": "xl-8y2DnLW0f"
   },
   "outputs": [],
   "source": [
    "train_data['seller'] = clean_seller(train_data['seller'])\n",
    "test_data['seller'] = clean_seller(test_data['seller'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oJdtg0GLLiYz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750302872554,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "oJdtg0GLLiYz",
    "outputId": "cfa79577-be13-4b11-cece-b234c31866b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n",
      "1 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['seller'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5sVdM3qLu1o",
   "metadata": {
    "id": "c5sVdM3qLu1o"
   },
   "source": [
    "### 1.3.7 处理offerType字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MPos9xCULuCB",
   "metadata": {
    "id": "MPos9xCULuCB"
   },
   "outputs": [],
   "source": [
    "def clean_offerType(col, max_valid=1):\n",
    "    col = pd.to_numeric(col, errors='coerce')\n",
    "    col = col.apply(lambda x: x if 0 <= x <= max_valid else np.nan)\n",
    "    return col.fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UDvE0_VdL7ce",
   "metadata": {
    "id": "UDvE0_VdL7ce"
   },
   "outputs": [],
   "source": [
    "train_data['offerType'] = clean_offerType(train_data['offerType'])\n",
    "test_data['offerType'] = clean_offerType(test_data['offerType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdv21XJNM2u1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750303226542,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "cdv21XJNM2u1",
    "outputId": "8a35a5c7-af6b-4c0b-fceb-ee220242c4cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.int64'>\n",
      "-1 <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for val in train_data['offerType'].unique():\n",
    "    print(val, type(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ff4ms72aHKiI",
   "metadata": {
    "id": "Ff4ms72aHKiI"
   },
   "source": [
    "## 1.4 类别变量分布检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KVsdms4fHcLQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1750301914755,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "KVsdms4fHcLQ",
    "outputId": "75de229e-1d02-44c9-ea30-89cc01c0ba4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>31674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "notRepairedDamage\n",
       " 0    105715\n",
       "-1     31674\n",
       " 1     12611\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['notRepairedDamage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GCJHkj_gH8XP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1750302507246,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "GCJHkj_gH8XP",
    "outputId": "e1891cc7-03df-441c-f868-8933bd9b5450"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyType</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "bodyType\n",
       " 0    45004\n",
       " 1    35996\n",
       " 2    30348\n",
       " 3    13498\n",
       " 4     9609\n",
       " 5     7612\n",
       " 6     6481\n",
       " 7     1289\n",
       "-1      163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['bodyType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h6HInhRDIM6R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750302724588,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "h6HInhRDIM6R",
    "outputId": "e9661a41-f8be-4f1b-beb4-b13fc271a2c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelType</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "fuelType\n",
       " 0    97414\n",
       " 1    47622\n",
       "-1     2238\n",
       " 2     2217\n",
       " 3      270\n",
       " 4      129\n",
       " 5       57\n",
       " 6       53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['fuelType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42BwqeCIUEj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750302120798,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "a42BwqeCIUEj",
    "outputId": "efa6a1cf-be4c-46f4-b60e-13be5e33b20e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gearbox</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>14031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "gearbox\n",
       " 0    104864\n",
       " 1     31105\n",
       "-1     14031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['gearbox'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gAKHa2_-IuHR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1750302878531,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "gAKHa2_-IuHR",
    "outputId": "a3087026-e145-4850-b84c-5e2d61fa8fae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seller</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "seller\n",
       " 0    146416\n",
       "-1      3583\n",
       " 1         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['seller'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mKY8lRMVI4SR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1750303243693,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "mKY8lRMVI4SR",
    "outputId": "3bb507d7-6f67-4833-8702-a958a103629b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offerType</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>14116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "offerType\n",
       " 0    135884\n",
       "-1     14116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['offerType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bvl_m2MwN2zr",
   "metadata": {
    "id": "bvl_m2MwN2zr"
   },
   "outputs": [],
   "source": [
    "# seller和offerType的类别倾斜严重, 数据几乎全为个体销售，以及主动提供报价类型, 全部删除\n",
    "del train_data['seller']\n",
    "del train_data['offerType']\n",
    "del test_data['seller']\n",
    "del test_data['offerType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qT2Gv11iN4sY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1750303486905,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "qT2Gv11iN4sY",
    "outputId": "2f9bf937-453e-4c0e-a2a0-f79d6a97a879"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-c8ba804b-be8b-40ae-9daa-14227e805743\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264777</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8ba804b-be8b-40ae-9daa-14227e805743')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c8ba804b-be8b-40ae-9daa-14227e805743 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c8ba804b-be8b-40ae-9daa-14227e805743');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-b0152054-2f2a-4499-9a52-6d767ca3cee8\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0152054-2f2a-4499-9a52-6d767ca3cee8')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-b0152054-2f2a-4499-9a52-6d767ca3cee8 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0    6.0         1         0        0     60   \n",
       "1       1    2262  20030301   40.0    1.0         2         0        0      0   \n",
       "2       2   14874  20040403  115.0   15.0         1         0        0    163   \n",
       "3       3   71865  19960908  109.0   10.0         0         0        1    193   \n",
       "4       4  111080  20120103  110.0    5.0         1         0        0     68   \n",
       "\n",
       "   kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n",
       "0         12  ...  0.235676  0.101988  0.129549  0.022816  0.097462 -2.881803   \n",
       "1         15  ...  0.264777  0.121004  0.135731  0.026597  0.020582 -4.900482   \n",
       "2         12  ...  0.251410  0.114912  0.165147  0.062173  0.027075 -4.846749   \n",
       "3         15  ...  0.274293  0.110300  0.121964  0.033395  0.000000 -4.509599   \n",
       "4          5  ...  0.228036  0.073205  0.091880  0.078819  0.121534 -1.896240   \n",
       "\n",
       "       v_11      v_12      v_13      v_14  \n",
       "0  2.804097 -2.420821  0.795292  0.914762  \n",
       "1  2.096338 -1.030483 -1.722674  0.245522  \n",
       "2  1.803559  1.565330 -0.832687 -0.229963  \n",
       "3  1.285940 -0.501868 -2.438353 -0.478699  \n",
       "4  0.910783  0.931110  2.834518  1.923482  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFQ4sziWOG0l",
   "metadata": {
    "id": "oFQ4sziWOG0l"
   },
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sq5mM4wHeax1",
   "metadata": {
    "id": "sq5mM4wHeax1"
   },
   "source": [
    "## 2.1 预测值的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BaMpvRWmewTR",
   "metadata": {
    "id": "BaMpvRWmewTR"
   },
   "source": [
    "### 2.1.1 查看预测值的skewness(偏度) and kurtosis(峰度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAUtgvvPOMV6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "executionInfo": {
     "elapsed": 1824,
     "status": "ok",
     "timestamp": 1750307975564,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "dAUtgvvPOMV6",
    "outputId": "a82972ab-806b-472e-aaa7-23845cc430f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-84-3538112527.py:1: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(train_data['price']);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: 3.259240\n",
      "Kurtosis: 17.966895\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAGwCAYAAADlimJhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYuRJREFUeJzt3XtcVHX+P/DXXJgZLs4gogwYKqZ5RTHJEdOsdTZMa2VzWzE2L0uy21dKv2SutortN/dnWbZqurFdtV1N81vL7ppL8sXMLREVNa+Zlom3wQvCAAoDM5/fHzhHjtyHgYP4ej4e80DOec85nzm6zWs/n8/5HJUQQoCIiIiIFKFWugFEREREdzKGMSIiIiIFMYwRERERKYhhjIiIiEhBDGNERERECmIYIyIiIlIQwxgRERGRgrRKN4Dq53K5cP78eXTo0AEqlUrp5hAREVEjCCFQXFyMsLAwqNX1930xjLVx58+fR3h4uNLNICIiIg+cOXMGd911V701DGNtXIcOHQBU/WUajUaFW0NERESNYbfbER4eLn2P14dhrI1zD00ajUaGMSIiottMY6YYcQI/ERERkYIYxoiIiIgUxDBGREREpCCGMSIiIiIFMYwRERERKYhhjIiIiEhBDGNERERECmIYIyIiIlJQmwhjq1evRo8ePWAwGGCxWLB79+566zdt2oS+ffvCYDAgMjISW7Zske0XQiA1NRWhoaHw9fWF1WrFiRMnZDUFBQVISEiA0WhEYGAgEhMTUVJSIu3fvn07JkyYgNDQUPj7+yMqKgrr1q1rkbYQERHRnUvxMLZx40akpKRg0aJF2LdvHwYPHozY2FhcvHix1vqdO3di8uTJSExMxP79+xEXF4e4uDgcPnxYqlm6dClWrlyJtLQ05OTkwN/fH7GxsSgrK5NqEhIScOTIEWRmZmLz5s3YsWMHkpKSZOcZNGgQPvnkExw8eBDTp0/HlClTsHnzZq+3hYiIiO5gQmHDhg0TM2fOlH53Op0iLCxMLFmypNb6X/7yl2L8+PGybRaLRfzmN78RQgjhcrmE2WwWr732mrS/sLBQ6PV68dFHHwkhhDh69KgAIPbs2SPV/Pvf/xYqlUqcO3euzraOGzdOTJ8+3attaUhRUZEAIIqKihpVT0RERMpryve3oj1jDocDubm5sFqt0ja1Wg2r1Yrs7Oxa35OdnS2rB4DY2Fip/tSpU7DZbLIak8kEi8Ui1WRnZyMwMBDR0dFSjdVqhVqtRk5OTp3tLSoqQlBQkFfbcqvy8nLY7XbZi4iIiNovRcPY5cuX4XQ6ERISItseEhICm81W63tsNlu99e6fDdV06dJFtl+r1SIoKKjO83788cfYs2cPpk+f7tW23GrJkiUwmUzSKzw8vNY6IiIiah8UnzN2O/jiiy8wffp0vPPOOxgwYECLnmv+/PkoKiqSXmfOnGnR8xEREZGyFA1jwcHB0Gg0yM/Pl23Pz8+H2Wyu9T1ms7neevfPhmpuvUGgsrISBQUFNc775Zdf4rHHHsOf/vQnTJkyxettuZVer4fRaJS9iIiIqP1SNIzpdDoMHToUWVlZ0jaXy4WsrCzExMTU+p6YmBhZPQBkZmZK9RERETCbzbIau92OnJwcqSYmJgaFhYXIzc2VarZt2waXywWLxSJt2759O8aPH49XX31VdqelN9tyO1ifk1fvi4iIiDynVboBKSkpmDp1KqKjozFs2DAsX74cpaWl0tysKVOmoGvXrliyZAkAYNasWRg9ejSWLVuG8ePHY8OGDdi7dy/efvttAIBKpcLs2bOxePFi9O7dGxEREVi4cCHCwsIQFxcHAOjXrx/Gjh2LGTNmIC0tDRUVFUhOTkZ8fDzCwsIAVA1NPvroo5g1axYmTpwozfHS6XTSJH5vtIWIiIjucK1wd2eD3nzzTdGtWzeh0+nEsGHDxK5du6R9o0ePFlOnTpXVf/zxx+Kee+4ROp1ODBgwQHz22Wey/S6XSyxcuFCEhIQIvV4vxowZI44fPy6ruXLlipg8ebIICAgQRqNRTJ8+XRQXF0v7p06dKgDUeI0ePdrrbalPW1jaYt2u0/W+iIiISK4p398qIYRQMAtSA+x2O0wmE4qKihSbP9bQUOSTlm6t1BIiIqLbQ1O+v3k3JREREZGCGMaIiIiIFMQwRkRERKQghjEiIiIiBTGMERERESmIYYyIiIhIQQxjRERERApiGCMiIiJSEMMYERERkYIYxoiIiIgUxDBGREREpCCGMSIiIiIFMYwRERERKYhhjIiIiEhBDGNERERECmIYIyIiIlIQwxgRERGRghjGiIiIiBTEMEZERESkIIYxIiIiIgUxjBEREREpiGGMiIiISEEMY0REREQKYhgjIiIiUhDDGBEREZGCGMaIiIiIFMQwRkRERKQghjEiIiIiBTGMERERESmIYYyIiIhIQQxjRERERApiGCMiIiJSEMMYERERkYIUD2OrV69Gjx49YDAYYLFYsHv37nrrN23ahL59+8JgMCAyMhJbtmyR7RdCIDU1FaGhofD19YXVasWJEydkNQUFBUhISIDRaERgYCASExNRUlIi7S8rK8O0adMQGRkJrVaLuLi4Gu2YNm0aVCpVjdeAAQOkmpdeeqnG/r59+3pwlYiIiKi9UjSMbdy4ESkpKVi0aBH27duHwYMHIzY2FhcvXqy1fufOnZg8eTISExOxf/9+xMXFIS4uDocPH5Zqli5dipUrVyItLQ05OTnw9/dHbGwsysrKpJqEhAQcOXIEmZmZ2Lx5M3bs2IGkpCRpv9PphK+vL5577jlYrdZa27JixQpcuHBBep05cwZBQUF44oknZHUDBgyQ1X311VfNuWRERETUzqiEEEKpk1ssFtx3331YtWoVAMDlciE8PBzPPvss5s2bV6N+0qRJKC0txebNm6Vtw4cPR1RUFNLS0iCEQFhYGJ5//nnMmTMHAFBUVISQkBCsWbMG8fHxOHbsGPr37489e/YgOjoaAJCRkYFx48bh7NmzCAsLk51z2rRpKCwsRHp6er2fJT09HY8//jhOnTqF7t27A6jqGUtPT8eBAwc8vUSw2+0wmUwoKiqC0Wj0+DjNsT4nr979T1q6tVJLiIiIbg9N+f5WrGfM4XAgNzdX1vOkVqthtVqRnZ1d63uys7Nr9FTFxsZK9adOnYLNZpPVmEwmWCwWqSY7OxuBgYFSEAMAq9UKtVqNnJwcjz/Pe++9B6vVKgUxtxMnTiAsLAw9e/ZEQkIC8vLqDzbl5eWw2+2yFxEREbVfioWxy5cvw+l0IiQkRLY9JCQENput1vfYbLZ6690/G6rp0qWLbL9Wq0VQUFCd523I+fPn8e9//xtPP/20bLvFYsGaNWuQkZGBt956C6dOncKoUaNQXFxc57GWLFkCk8kkvcLDwz1qExEREd0eFJ/A3x6sXbsWgYGBNSb6P/LII3jiiScwaNAgxMbGYsuWLSgsLMTHH39c57Hmz5+PoqIi6XXmzJkWbj0REREpSbEwFhwcDI1Gg/z8fNn2/Px8mM3mWt9jNpvrrXf/bKjm1hsEKisrUVBQUOd56yOEwPvvv4+nnnoKOp2u3trAwEDcc889OHnyZJ01er0eRqNR9iIiIqL2S7EwptPpMHToUGRlZUnbXC4XsrKyEBMTU+t7YmJiZPUAkJmZKdVHRETAbDbLaux2O3JycqSamJgYFBYWIjc3V6rZtm0bXC4XLBZLkz/Hl19+iZMnTyIxMbHB2pKSEnz//fcIDQ1t8nmIiIiofdIqefKUlBRMnToV0dHRGDZsGJYvX47S0lJMnz4dADBlyhR07doVS5YsAQDMmjULo0ePxrJlyzB+/Hhs2LABe/fuxdtvvw0AUKlUmD17NhYvXozevXsjIiICCxcuRFhYmDSE2K9fP4wdOxYzZsxAWloaKioqkJycjPj4eNmdlEePHoXD4UBBQQGKi4ulOyKjoqJkn+G9996DxWLBwIEDa3y+OXPm4LHHHkP37t1x/vx5LFq0CBqNBpMnT/bylSQiIqLblaJhbNKkSbh06RJSU1Nhs9kQFRWFjIwMaQJ+Xl4e1OqbnXcjRozA+vXrsWDBArz44ovo3bs30tPTZUFo7ty5KC0tRVJSEgoLCzFy5EhkZGTAYDBINevWrUNycjLGjBkDtVqNiRMnYuXKlbK2jRs3DqdPn5Z+HzJkCICqYUm3oqIifPLJJ1ixYkWtn+/s2bOYPHkyrly5gs6dO2PkyJHYtWsXOnfu3IyrRkRERO2JouuMUcO4zhgREdHt57ZYZ4yIiIiIGMaIiIiIFMUwRkRERKQghjEiIiIiBTGMERERESmIYYyIiIhIQQxj1CTXHJW4UlKudDOIiIjaDYYxajSXEHj3P6ew/P9OoPCaQ+nmEBERtQsMY9Ro39mKYbOXwSkELpcwjBEREXkDwxg12s4frkh/vl7hVLAlRERE7QfDGDVKvr0MJy+WSL9fc1Qq2BoiIqL2g2GMGiW7Wq8YAJQ52DNGRETkDQxj1KDySif2510FAIQFGgAA1zhMSURE5BUMY9SgomsVqHAKGHzU6B9qAgBcZ88YERGRVzCMUYMqXQIAoNOo4afTAOAEfiIiIm9hGKMGVThdAACtRg3fG2HsGnvGiIiIvIJhjBpU4azqGfPRqODnc6NnjGGMiIjIKxjGqEGVN3rGfKr1jHGYkoiIyDsYxqhBFTfmjGnVKvjptADYM0ZEROQtDGPUIFnP2I1hSofTJW0nIiIizzGMUYPcc8a0GjX0PmqobmznUCUREVHzMYxRgyqknjEV1CoVDJzET0RE5DUMY9Qg93CkVl31z4WT+ImIiLyHYYwa5J7A76OpGqD041pjREREXsMwRg2qPoEfgDSJnz1jREREzccwRg26OYG/qmdMGqZkzxgREVGzMYxRgypunTPmw2FKIiIib2EYowZV1jFnjMOUREREzccwRg2qqGvOmKNSsTYRERG1Fwxj1KBKp7xnzNf9SCT2jBERETUbwxg1SJozdqNnzI8T+ImIiLyGYYwaJA1Tqqt6xgycwE9EROQ1DGPUIPcE/ho9YxymJCIiajaGMWpQhTRn7JbHITmccAmhWLuIiIjaA8XD2OrVq9GjRw8YDAZYLBbs3r273vpNmzahb9++MBgMiIyMxJYtW2T7hRBITU1FaGgofH19YbVaceLECVlNQUEBEhISYDQaERgYiMTERJSUlEj7y8rKMG3aNERGRkKr1SIuLq5GO7Zv3w6VSlXjZbPZmvX52qLKag8KB27eTSkAOCpdSjWLiIioXVA0jG3cuBEpKSlYtGgR9u3bh8GDByM2NhYXL16stX7nzp2YPHkyEhMTsX//fsTFxSEuLg6HDx+WapYuXYqVK1ciLS0NOTk58Pf3R2xsLMrKyqSahIQEHDlyBJmZmdi8eTN27NiBpKQkab/T6YSvry+ee+45WK3Wej/D8ePHceHCBenVpUsXjz9fW3Xroq8+GrUUzDhvjIiIqHlUQig3zmSxWHDfffdh1apVAACXy4Xw8HA8++yzmDdvXo36SZMmobS0FJs3b5a2DR8+HFFRUUhLS4MQAmFhYXj++ecxZ84cAEBRURFCQkKwZs0axMfH49ixY+jfvz/27NmD6OhoAEBGRgbGjRuHs2fPIiwsTHbOadOmobCwEOnp6bLt27dvx0MPPYSrV68iMDDQK58PAMrLy1FeXi79brfbER4ejqKiIhiNxnquZsu5Z8G/4ah04fmf3oNOAXoAwCv/PgZ7WSVmPtQLL8T2UaRdREREbZXdbofJZGrU97diPWMOhwO5ubmynie1Wg2r1Yrs7Oxa35OdnV2jpyo2NlaqP3XqFGw2m6zGZDLBYrFINdnZ2QgMDJSCGABYrVao1Wrk5OQ0+XNERUUhNDQUP/3pT/H111836/MBwJIlS2AymaRXeHh4k9vkbZW3LG0B8PmURERE3qJYGLt8+TKcTidCQkJk20NCQmrMu3Kz2Wz11rt/NlRTfSgRALRaLYKCguo8b21CQ0ORlpaGTz75BJ988gnCw8Px4IMPYt++fR5/PgCYP38+ioqKpNeZM2ca3aaWUOl04cbNlNLQJAD4+lQt/HqNq/ATERE1i1bpBtyu+vTpgz59bg7PjRgxAt9//z3+9Kc/4a9//avHx9Xr9dDr9d5ooleUVZug754zBnB5CyIiIm9RrGcsODgYGo0G+fn5su35+fkwm821vsdsNtdb7/7ZUM2tE+grKytRUFBQ53kba9iwYTh58iQAzz5fW1RWLWxpZT1jHKYkIiLyBsXCmE6nw9ChQ5GVlSVtc7lcyMrKQkxMTK3viYmJkdUDQGZmplQfEREBs9ksq7Hb7cjJyZFqYmJiUFhYiNzcXKlm27ZtcLlcsFgszfpMBw4cQGhoqMefry1yhzGtWgW16mYYM/hU/dMp59IWREREzaLoMGVKSgqmTp2K6OhoDBs2DMuXL0dpaSmmT58OAJgyZQq6du2KJUuWAABmzZqF0aNHY9myZRg/fjw2bNiAvXv34u233wYAqFQqzJ49G4sXL0bv3r0RERGBhQsXIiwsTForrF+/fhg7dixmzJiBtLQ0VFRUIDk5GfHx8bI7KY8ePQqHw4GCggIUFxfjwIEDAKom7APA8uXLERERgQEDBqCsrAzvvvsutm3bhq1btzb6890O3GGreq8YAOi0mhv72TNGRETUHIqGsUmTJuHSpUtITU2FzWZDVFQUMjIypEnveXl5UFebpzRixAisX78eCxYswIsvvojevXsjPT0dAwcOlGrmzp2L0tJSJCUlobCwECNHjkRGRgYMBoNUs27dOiQnJ2PMmDFQq9WYOHEiVq5cKWvbuHHjcPr0aen3IUOGAKhaVBaoulvy+eefx7lz5+Dn54dBgwbh//7v//DQQw81+vPdDtw9Yz4aeSeq1DNWwZ4xIiKi5lB0nTFqWFPWKWkJuaevYuJbO9HRzwcvxPaVtu8+VYD0A+fQL9SIf88a1ertIiIiastui3XG6PZQXkfPmF7rnjPGYUoiIqLmYBijepVV1hHGOExJRETkFQxjVC932Lp1Ar+eE/iJiIi8gmGM6iX1jKnrGqZkzxgREVFzMIxRvcrq6Bkz3Fj0lcOUREREzcMwRvWqa2kLd8+Yw+mC08UbcomIiDzFMEb1cveM+dSYM3bzn04pHxZORETkMYYxqpd7gr72ljljWo0aGnVVQCspYxgjIiLyFMMY1auunjHgZu9YSTnDGBERkacYxqhe0oPCNTX/qTCMERERNR/DGNWrXFr0tWbPmPuOSg5TEhEReY5hjOpVLg1TsmeMiIioJTCMUb3KpAn8tc0Zu9EzxjBGRETkMYYxqldZfT1jN55PyWFKIiIizzGMUb3qn8DPnjEiIqLmYhijet1cgb/upS1KGcaIiIg8xjBG9XI/CPzWRV+Bm8OUxQxjREREHmMYo3rV1zNm0HJpCyIiouZiGKN61TuBn8OUREREzcYwRvWSnk1Z25yxG4u+cpiSiIjIcwxjVC+pZ6y2OWNaLm1BRETUXAxjVK96e8bcw5QOhjEiIiJPMYxRnZwugQqnAFDXoq+cwE9ERNRcDGNUJ/edlEDtYcyg5dIWREREzcUwRnWqHsZqH6as6hlzVLrguLEeGRERETUNwxjVyb3gq0alglpVM4zptDf/+XB5CyIiIs8wjFGdbj6XsmYQAwCNWiUtBsvnUxIREXmGYYzqVN+Cr258WDgREVHzMIxRncoq634Ukpu01hjDGBERkUcYxqhO0jBlLQu+uhm4vAUREVGzMIxRndwT+BvTM8blLYiIiDzDMEZ1Kpcm8Nc3Z4wPCyciImoOhjGq080J/PX0jHGYkoiIqFkUD2OrV69Gjx49YDAYYLFYsHv37nrrN23ahL59+8JgMCAyMhJbtmyR7RdCIDU1FaGhofD19YXVasWJEydkNQUFBUhISIDRaERgYCASExNRUlIi7S8rK8O0adMQGRkJrVaLuLi4Gu349NNP8dOf/hSdO3eG0WhETEwMPv/8c1nNSy+9BJVKJXv17du3iVdIOY2ZM8ZhSiIiouZRNIxt3LgRKSkpWLRoEfbt24fBgwcjNjYWFy9erLV+586dmDx5MhITE7F//37ExcUhLi4Ohw8flmqWLl2KlStXIi0tDTk5OfD390dsbCzKysqkmoSEBBw5cgSZmZnYvHkzduzYgaSkJGm/0+mEr68vnnvuOVit1lrbsmPHDvz0pz/Fli1bkJubi4ceegiPPfYY9u/fL6sbMGAALly4IL2++uqr5lyyVuVwVvWM1bXOGHBzaQsOUxIREXlGJYQQSp3cYrHgvvvuw6pVqwAALpcL4eHhePbZZzFv3rwa9ZMmTUJpaSk2b94sbRs+fDiioqKQlpYGIQTCwsLw/PPPY86cOQCAoqIihISEYM2aNYiPj8exY8fQv39/7NmzB9HR0QCAjIwMjBs3DmfPnkVYWJjsnNOmTUNhYSHS09Mb/DwDBgzApEmTkJqaCqCqZyw9PR0HDhzw5PIAAOx2O0wmE4qKimA0Gj0+jife/c8PWPzZMQy6y4T4+7rVWrP9+EVsPZqPSdHhePUXg1q1fURERG1VU76/FesZczgcyM3NlfU8qdVqWK1WZGdn1/qe7OzsGj1VsbGxUv2pU6dgs9lkNSaTCRaLRarJzs5GYGCgFMQAwGq1Qq1WIycnx+PP43K5UFxcjKCgINn2EydOICwsDD179kRCQgLy8vLqPU55eTnsdrvspZRKV1VO16q5zhgREVFLUSyMXb58GU6nEyEhIbLtISEhsNlstb7HZrPVW+/+2VBNly5dZPu1Wi2CgoLqPG9jvP766ygpKcEvf/lLaZvFYsGaNWuQkZGBt956C6dOncKoUaNQXFxc53GWLFkCk8kkvcLDwz1uU3NV3FjaorbnUrq5hyk5Z4yIiMgzik/gbw/Wr1+PP/zhD/j4449lQe+RRx7BE088gUGDBiE2NhZbtmxBYWEhPv744zqPNX/+fBQVFUmvM2fOtMZHqFXFjTljmnp6xgw+N3rGyipapU1ERETtjVapEwcHB0Oj0SA/P1+2PT8/H2azudb3mM3meuvdP/Pz8xEaGiqriYqKkmpuvUGgsrISBQUFdZ63Phs2bMDTTz+NTZs21TnZ3y0wMBD33HMPTp48WWeNXq+HXq9vcjtaQkUjhindK/DbubQFERGRRxTrGdPpdBg6dCiysrKkbS6XC1lZWYiJian1PTExMbJ6AMjMzJTqIyIiYDabZTV2ux05OTlSTUxMDAoLC5GbmyvVbNu2DS6XCxaLpUmf4aOPPsL06dPx0UcfYfz48Q3Wl5SU4Pvvv5cFxbZMGqZsTBi7zp4xIiIiTyjWMwYAKSkpmDp1KqKjozFs2DAsX74cpaWlmD59OgBgypQp6Nq1K5YsWQIAmDVrFkaPHo1ly5Zh/Pjx2LBhA/bu3Yu3334bAKBSqTB79mwsXrwYvXv3RkREBBYuXIiwsDBprbB+/fph7NixmDFjBtLS0lBRUYHk5GTEx8fL7qQ8evQoHA4HCgoKUFxcLN0R6e5hW79+PaZOnYoVK1bAYrFI8818fX1hMpkAAHPmzMFjjz2G7t274/z581i0aBE0Gg0mT57c0pfWKxozTOkr9YwxjBEREXlC0TA2adIkXLp0CampqbDZbIiKikJGRoY0AT8vLw/qaguOjhgxAuvXr8eCBQvw4osvonfv3khPT8fAgQOlmrlz56K0tBRJSUkoLCzEyJEjkZGRAYPBINWsW7cOycnJGDNmDNRqNSZOnIiVK1fK2jZu3DicPn1a+n3IkCEAqhaVBYC3334blZWVmDlzJmbOnCnVTZ06FWvWrAEAnD17FpMnT8aVK1fQuXNnjBw5Ert27ULnzp29dAVblnuYUlPPBH53z1hZhQvllU5pQj8RERE1jqLrjFHDlFxn7IVN32BT7lk83D8ED/bpUmuNSwgs/MdhCAHsXWBFcEDbmO9GRESkpNtinTFq+9zrjNU3TKlWqRCgr+pg5bwxIiKipmMYozo5GjFnDACMBh8AvKOSiIjIEwxjVCf33ZQNhbEOBvaMEREReYphjOpU2YgJ/ABg9K3qGStmzxgREVGTMYxRnRqztAVQfZiSPWNERERNxTBGdXI0cpjS6MthSiIiIk8xjFGdGnM3JcCeMSIioubwKIz98MMP3m4HtUHSMGUj54zZr3POGBERUVN5FMZ69eqFhx56CH/7299QVlbm7TZRG9HoYUr33ZTsGSMiImoyj8LYvn37MGjQIKSkpMBsNuM3v/kNdu/e7e22kcLcw5T1PSgcqN4zxjBGRETUVB6FsaioKKxYsQLnz5/H+++/jwsXLmDkyJEYOHAg3njjDVy6dMnb7SQFuIcptVz0lYiIqMU0awK/VqvF448/jk2bNuHVV1/FyZMnMWfOHISHh2PKlCm4cOGCt9pJCqh0NnICP++mJCIi8lizwtjevXvxX//1XwgNDcUbb7yBOXPm4Pvvv0dmZibOnz+PCRMmeKudpAD345DUDU3g592UREREHtN68qY33ngDH3zwAY4fP45x48bhww8/xLhx46BWV2W7iIgIrFmzBj169PBmW6mVNXnRV95NSURE1GQehbG33noLv/71rzFt2jSEhobWWtOlSxe89957zWocKcs9TNngnLEbw5TXK5xwVLqg03L5OiIiosbyKIxlZmaiW7duUk+YmxACZ86cQbdu3aDT6TB16lSvNJKUIQ1TNhDGAvQ3/xkVl1WgU4C+RdtFRETUnnjUhXH33Xfj8uXLNbYXFBQgIiKi2Y2itqGxw5RajVoKZHxYOBERUdN4FMaEELVuLykpgcFgaFaDqG1wugTcf83aBibwA1z4lYiIyFNNGqZMSUkBAKhUKqSmpsLPz0/a53Q6kZOTg6ioKK82kJTh7hUDGh6mBKoWfj1fVMZJ/ERERE3UpDC2f/9+AFU9Y4cOHYJOp5P26XQ6DB48GHPmzPFuC0kRjmphrKFhSoDLWxAREXmqSWHsiy++AABMnz4dK1asgNFobJFGkfLcd1ICjQxjXPiViIjIIx7dTfnBBx94ux3UxlRIC742vOgrwJ4xIiIiTzU6jD3++ONYs2YNjEYjHn/88XprP/3002Y3jJTlDmM+msbd43HzYeGcM0ZERNQUjQ5jJpMJqhs9JCaTqcUaRG1DxY1hykaHMd5NSURE5JFGh7HqQ5Mcpmz/bvaMNTxECQAdpEciMYwRERE1hUfrjF2/fh3Xrl2Tfj99+jSWL1+OrVu3eq1hpKymD1O6e8Y4TElERNQUHoWxCRMm4MMPPwQAFBYWYtiwYVi2bBkmTJiAt956y6sNJGU0fZiSPWNERESe8CiM7du3D6NGjQIA/O///i/MZjNOnz6NDz/8ECtXrvRqA0kZTR2mlCbwc84YERFRk3gUxq5du4YOHToAALZu3YrHH38carUaw4cPx+nTp73aQFJGk4cpDbybkoiIyBMehbFevXohPT0dZ86cweeff46HH34YAHDx4kUuBNtOuIcptU2cM1bMnjEiIqIm8SiMpaamYs6cOejRowcsFgtiYmIAVPWSDRkyxKsNJGVUVFb1jOkaOUxpujFMWepwwlHpaqCaiIiI3Dxagf8Xv/gFRo4ciQsXLmDw4MHS9jFjxuDnP/+51xpHyql0NX2YUqNWwekSuHrNgRCjoSWbR0RE1G54FMYAwGw2w2w2y7YNGzas2Q2itsEhDVM2rmdMrVaho58PLpc4cKWEYYyIiKixPApjpaWleOWVV5CVlYWLFy/C5ZIPS/3www9eaRwpp7KJE/gBIMhfh8slDhSUOlqqWURERO2OR3PGnn76abz33nsYNWoUkpOTMWvWLNmrKVavXo0ePXrAYDDAYrFg9+7d9dZv2rQJffv2hcFgQGRkJLZs2SLbL4RAamoqQkND4evrC6vVihMnTshqCgoKkJCQAKPRiMDAQCQmJqKkpETaX1ZWhmnTpiEyMhJarRZxcXG1tmX79u249957odfr0atXL6xZs6bZn6+taOrdlEBVGAOAK6XlLdImIiKi9sijnrF///vf+Oyzz3D//fc36+QbN25ESkoK0tLSYLFYsHz5csTGxuL48ePo0qVLjfqdO3di8uTJWLJkCR599FGsX78ecXFx2LdvHwYOHAgAWLp0KVauXIm1a9ciIiICCxcuRGxsLI4ePQqDoWroLCEhARcuXEBmZiYqKiowffp0JCUlYf369QAAp9MJX19fPPfcc/jkk09qbfupU6cwfvx4/Pa3v8W6deuQlZWFp59+GqGhoYiNjfXo87UlDmnR18YNUwJAJ389ALBnjIiIqAlUQgjR1DdFRERgy5Yt6NevX7NObrFYcN9992HVqlUAAJfLhfDwcDz77LOYN29ejfpJkyahtLQUmzdvlrYNHz4cUVFRSEtLgxACYWFheP755zFnzhwAQFFREUJCQrBmzRrEx8fj2LFj6N+/P/bs2YPo6GgAQEZGBsaNG4ezZ88iLCxMds5p06ahsLAQ6enpsu2/+93v8Nlnn+Hw4cPStvj4eBQWFiIjI8OjzwcA5eXlKC+/2bNkt9sRHh6OoqKiVl025IOvT+EP/zqKRweFYsTdwfXWPmnpBgBYmH4Yf911Gs/+pBeef7hPazSTiIioTbLb7TCZTI36/vZomPLll19Gamqq7PmUTeVwOJCbmwur1XqzMWo1rFYrsrOza31Pdna2rB4AYmNjpfpTp07BZrPJakwmEywWi1STnZ2NwMBAKYgBgNVqhVqtRk5OTqPb31BbPPl8ALBkyRKYTCbpFR4e3ug2eVNzhikvl7BnjIiIqLE8GqZctmwZvv/+e4SEhKBHjx7w8fGR7d+3b1+Dx7h8+TKcTidCQkJk20NCQvDtt9/W+h6bzVZrvc1mk/a7t9VXc+sQoVarRVBQkFTTGHW1xW634/r167h69WqTPx8AzJ8/HykpKdLv7p6x1lbhwTBlcEBVGCvgnDEiIqJG8yiM1TWhnZpPr9dDr9cr3QwPe8Y4Z4yIiKipPApjixYtavaJg4ODodFokJ+fL9uen59fY/0yN7PZXG+9+2d+fj5CQ0NlNVFRUVLNxYsXZceorKxEQUFBnedtSluMRiN8fX2h0Wia/PnakubdTckwRkRE1FgezRkDgMLCQrz77ruYP38+CgoKAFQNT547d65R79fpdBg6dCiysrKkbS6XC1lZWdLjlW4VExMjqweAzMxMqT4iIgJms1lWY7fbkZOTI9XExMSgsLAQubm5Us22bdvgcrlgsVga1fbGtMWTz9eWeDJM2UkapmQYIyIiaiyPesYOHjwIq9UKk8mEH3/8ETNmzEBQUBA+/fRT5OXl4cMPP2zUcVJSUjB16lRER0dj2LBhWL58OUpLSzF9+nQAwJQpU9C1a1csWbIEADBr1iyMHj0ay5Ytw/jx47Fhwwbs3bsXb7/9NgBApVJh9uzZWLx4MXr37i0tbREWFiYNrfbr1w9jx47FjBkzkJaWhoqKCiQnJyM+Pl52J+XRo0fhcDhQUFCA4uJiHDhwAACkHrbf/va3WLVqFebOnYtf//rX2LZtGz7++GN89tlnjf58bVlzesYKr1Wg0ulq9EPGiYiI7mQehbGUlBRMmzYNS5cuRYcOHaTt48aNw5NPPtno40yaNAmXLl1CamoqbDYboqKikJGRIU16z8vLg1p98wt9xIgRWL9+PRYsWIAXX3wRvXv3Rnp6urTGGADMnTsXpaWlSEpKQmFhIUaOHImMjAxpjTEAWLduHZKTkzFmzBio1WpMnDgRK1eulLVt3LhxOH36tPS7+wHo7pVAIiIi8Nlnn+G///u/sWLFCtx111149913pTXGGvP52jJ3GGtKoOrop4NKBQgBXL1Wgc4dlJ/7RkRE1NZ5tM6YyWTCvn37cPfdd6NDhw745ptv0LNnT5w+fRp9+vRBWVlZS7T1jtSUdUq8ad4nB7FhzxnMefgeaWJ+XdzrjAHAkP/ZiqvXKvD57AfQx9yhnncRERG1Xy2+zpher4fdbq+x/bvvvkPnzp09OSS1MQ4PesaAapP4S7i8BRERUWN4FMZ+9rOf4X/+539QUVEBoGquVl5eHn73u99h4sSJXm0gKePmBP6m/RPpFFDVi8Y7KomIiBrHozC2bNkylJSUoHPnzrh+/TpGjx6NXr16oUOHDvjjH//o7TaSAipv9IzpmnA3JQB08ucdlURERE3h0QR+k8mEzMxMfP311/jmm29QUlKCe++9t8bjgej2VX0Cf1NmFXKtMSIioqZpchhzuVxYs2YNPv30U/z4449QqVTS+l5CCKhUTetJobbJUW2Y0lHpavT7bvaMcc4YERFRYzRpmFIIgZ/97Gd4+umnce7cOURGRmLAgAE4ffo0pk2bhp///Oct1U5qZZXSOmNNC9dBHKYkIiJqkib1jK1ZswY7duxAVlYWHnroIdm+bdu2IS4uDh9++CGmTJni1UZS65Mv+uqst3Z9Tp7052O24qqfF4pl26svf0FEREQ3Naln7KOPPsKLL75YI4gBwE9+8hPMmzcP69at81rjSDkOD++m9NdV5fvS8kqvt4mIiKg9atI37cGDBzF27Ng69z/yyCP45ptvmt0oUp6nw5T+eg0AoIRhjIiIqFGaFMYKCgrqfZRPSEgIrl692uxGkfI8eTYlAAToq3rGrjuccDX94Q5ERER3nCZ90zqdTmi1dU8z02g0qKxkj0h7UOnhMKXfjWFKAeCao/65ZkRERNTECfxCCEybNg16fe3PKiwv53IG7cXNxyE1bZhSo1bB10eD6xVOlJZXSj1lREREVLsmfVNOnTq1wRreSdk+VEgr8Df9IQ3++hthzMFeUiIiooY0KYx98MEHLdUOamM8HaYEgAC9Dy6XOFBcxjBGRETUEI+eTUntn6fDlABg8q3K+PbrFV5tExERUXvEMEa1as4wpdHXBwDDGBERUWMwjFGtmjNMaboRxooYxoiIiBrEMEY1uFwCla6qMObJMKXRcKNnjHPGiIiIGsQwRjVUuFzSnz3pGeMwJRERUeMxjFEN7iFKwLM5Y+5hSntZBVfhJyIiagDDGNXgnrwPeDZMGaDXQgXAJfjAcCIiooYwjFENjuphTN30MKZRq9DB4F7egmGMiIioPgxjVMPNOylVUKmaHsaAm/PGeEclERFR/RjGqAb3MKUnk/fdbt5RyTBGRERUH4YxqqGiGWuMufGOSiIiosZhGKMabvaMeTZECQCmG3PGOExJRERUP4YxqsErw5S+HKYkIiJqDIYxqsG7w5S8m5KIiKg+DGNUg7tnzJM1xtxMNybwF7FnjIiIqF4MY1SDO4x5svq+m7tnzFHpQlmF0yvtIiIiao8YxqiGSi8MU+q0ahh8qt7POyqJiIjqxjBGNTi8MEwJ3FxrjEOVREREdWMYoxq8cTclUO2B4ZzET0REVKc2EcZWr16NHj16wGAwwGKxYPfu3fXWb9q0CX379oXBYEBkZCS2bNki2y+EQGpqKkJDQ+Hr6wur1YoTJ07IagoKCpCQkACj0YjAwEAkJiaipKREVnPw4EGMGjUKBoMB4eHhWLp0qWz/gw8+CJVKVeM1fvx4qWbatGk19o8dO9aTy9Rq3MOUzZkzBvCRSERERI2heBjbuHEjUlJSsGjRIuzbtw+DBw9GbGwsLl68WGv9zp07MXnyZCQmJmL//v2Ii4tDXFwcDh8+LNUsXboUK1euRFpaGnJycuDv74/Y2FiUlZVJNQkJCThy5AgyMzOxefNm7NixA0lJSdJ+u92Ohx9+GN27d0dubi5ee+01vPTSS3j77belmk8//RQXLlyQXocPH4ZGo8ETTzwha/PYsWNldR999JG3Ll+L8NYwpUkKY45mt4mIiKi9UjyMvfHGG5gxYwamT5+O/v37Iy0tDX5+fnj//fdrrV+xYgXGjh2LF154Af369cPLL7+Me++9F6tWrQJQ1Su2fPlyLFiwABMmTMCgQYPw4Ycf4vz580hPTwcAHDt2DBkZGXj33XdhsVgwcuRIvPnmm9iwYQPOnz8PAFi3bh0cDgfef/99DBgwAPHx8XjuuefwxhtvSG0JCgqC2WyWXpmZmfDz86sRxvR6vayuY8eOLXAlvccbE/gBIMhPBwC4WsqeMSIiorooGsYcDgdyc3NhtVqlbWq1GlarFdnZ2bW+Jzs7W1YPALGxsVL9qVOnYLPZZDUmkwkWi0Wqyc7ORmBgIKKjo6Uaq9UKtVqNnJwcqeaBBx6ATqeTnef48eO4evVqrW177733EB8fD39/f9n27du3o0uXLujTpw+eeeYZXLlypc5rUl5eDrvdLnu1Nm88DgkAOvpXXbuCa+wZIyIiqouiYezy5ctwOp0ICQmRbQ8JCYHNZqv1PTabrd5698+Garp06SLbr9VqERQUJKup7RjVz1Hd7t27cfjwYTz99NOy7WPHjsWHH36IrKwsvPrqq/jyyy/xyCOPwOmsfe2tJUuWwGQySa/w8PBa61qStybwd/SrGqYsvOaA0yWa3S4iIqL2SKt0A9qL9957D5GRkRg2bJhse3x8vPTnyMhIDBo0CHfffTe2b9+OMWPG1DjO/PnzkZKSIv1ut9tbPZB543FIQNUEfo1KBacQuFB0HXd19PNG84iIiNoVRXvGgoODodFokJ+fL9uen58Ps9lc63vMZnO99e6fDdXceoNAZWUlCgoKZDW1HaP6OdxKS0uxYcMGJCYm1v+BAfTs2RPBwcE4efJkrfv1ej2MRqPs1dq8NUypVqkQeKN37EzB9Wa3i4iIqD1SNIzpdDoMHToUWVlZ0jaXy4WsrCzExMTU+p6YmBhZPQBkZmZK9RERETCbzbIau92OnJwcqSYmJgaFhYXIzc2VarZt2waXywWLxSLV7NixAxUVFbLz9OnTp8YE/E2bNqG8vBy/+tWvGvzMZ8+exZUrVxAaGtpgrVK8NUwJ3Jw3dubqtWYfi4iIqD1S/G7KlJQUvPPOO1i7di2OHTuGZ555BqWlpZg+fToAYMqUKZg/f75UP2vWLGRkZGDZsmX49ttv8dJLL2Hv3r1ITk4GAKhUKsyePRuLFy/GP//5Txw6dAhTpkxBWFgY4uLiAAD9+vXD2LFjMWPGDOzevRtff/01kpOTER8fj7CwMADAk08+CZ1Oh8TERBw5cgQbN27EihUrZEOIbu+99x7i4uLQqVMn2faSkhK88MIL2LVrF3788UdkZWVhwoQJ6NWrF2JjY1vicnqFt4YpAaDjjTsqzxYwjBEREdVG8TljkyZNwqVLl5CamgqbzYaoqChkZGRIk+Xz8vKgVt8MBSNGjMD69euxYMECvPjii+jduzfS09MxcOBAqWbu3LkoLS1FUlISCgsLMXLkSGRkZMBgMEg169atQ3JyMsaMGQO1Wo2JEydi5cqV0n6TyYStW7di5syZGDp0KIKDg5GamipbiwwAjh8/jq+++gpbt26t8dk0Gg0OHjyItWvXorCwEGFhYXj44Yfx8ssvQ6/Xe+0aeluFl9YZA4Ag9zDlVQ5TEhER1UYlhOBtbm2Y3W6HyWRCUVFRq80fS/3HYXyYfRrP/qQXnn+4D9bn5Hl8rINnC7FhzxlEd++I/31mhBdbSURE1HY15ftb8WFKantaYpiSc8aIiIhqxzBGNXhzmNI9gT/fXo6yitrXViMiIrqTMYxRDZU3wlhzHxQOAP46jXScc4WcN0ZERHQrhjGqwT1MqVU3v2dMpVKho797rTEOVRIREd2KYYxqKK+8sc6Y1jv/PG7OG2PPGBER0a0YxqgGx41hSr1W45XjueeNca0xIiKimhjGqAZHZdVEe52XesaCbvSM5TGMERER1cAwRjW4hyn1Xh6mZBgjIiKqiWGManDcCGPe6hkLDqgKY6cul4JrDBMREckxjFEN7jCm98LSFgAQFKCDRq3CNYcTNnuZV45JRETUXjCMUQ3SMKWPd/55aNVqdA/yAwB8f7HUK8ckIiJqLxjGqAZpmFLjnbspAaBn5wAAwPeXSrx2TCIiovaAYYxqcC9t4a05YwBwdxd/AAxjREREt2IYoxq8PYEfAO6+0TP2wyUOUxIREVXHMEY1lN9YZ8xbS1sAN8MYe8aIiIjkGMZIxuUS0rMpvdszVjVMeaGoDCXllV47LhER0e2OYYxk3PPFAO+GsUA/3c31xjhUSUREJGEYIxn3shaAd4cpAd5RSUREVBuGMZJxVAtjOi8t+urGeWNEREQ1MYyRjLSshUYNlUrl1WO7540xjBEREd3EMEYy5RXev5PSjctbEBER1cQwRjItseCrmxTGLpfC6eIDw4mIiACGMbpFSyz46ta1oy98fTRwVLpw6jKHKomIiACGMbqFO4y1xDClRq3CgDAjAODg2SKvH5+IiOh2xDBGMuUt2DMGAIPuCgTAMEZEROTGMEYyLTlMCQCD7jIBAA6eLWyR4xMREd1uGMZIplwaptS0yPHdYezIeTsqqq32T0REdKdiGCMZ90PCvb3gq1uPTv7ooNeivNKFE/mcxE9ERMQwRjItPUypVqsQyaFKIiIiiVbpBlDb0lLrjK3PyZP+rFVXrez/6b5zqL7c2JOWbl49JxER0e2APWMkU17RcktbuHXt6AcAOFt4rcXOQUREdLtgGCOZllyB3+2uQF8AQH5ROSfxExHRHY9hjGRactFXt0A/H/jpNHAKAVtRWYudh4iI6HbQJsLY6tWr0aNHDxgMBlgsFuzevbve+k2bNqFv374wGAyIjIzEli1bZPuFEEhNTUVoaCh8fX1htVpx4sQJWU1BQQESEhJgNBoRGBiIxMRElJTI7+47ePAgRo0aBYPBgPDwcCxdulS2f82aNVCpVLKXwWBoclvaEkcLL20BACqVCuE3hipPXeZDw4mI6M6meBjbuHEjUlJSsGjRIuzbtw+DBw9GbGwsLl68WGv9zp07MXnyZCQmJmL//v2Ii4tDXFwcDh8+LNUsXboUK1euRFpaGnJycuDv74/Y2FiUld3shUlISMCRI0eQmZmJzZs3Y8eOHUhKSpL22+12PPzww+jevTtyc3Px2muv4aWXXsLbb78ta4/RaMSFCxek1+nTp2X7G9OWtkRa2qIFe8YAoHdI1UPDj+cXt+h5iIiI2jrFw9gbb7yBGTNmYPr06ejfvz/S0tLg5+eH999/v9b6FStWYOzYsXjhhRfQr18/vPzyy7j33nuxatUqAFU9UcuXL8eCBQswYcIEDBo0CB9++CHOnz+P9PR0AMCxY8eQkZGBd999FxaLBSNHjsSbb76JDRs24Pz58wCAdevWweFw4P3338eAAQMQHx+P5557Dm+88YasPSqVCmazWXqFhIRI+xrTlrZGWtqihdYZc7snpAMA4PSVUpRVOFv0XERERG2ZomHM4XAgNzcXVqtV2qZWq2G1WpGdnV3re7Kzs2X1ABAbGyvVnzp1CjabTVZjMplgsVikmuzsbAQGBiI6OlqqsVqtUKvVyMnJkWoeeOAB6HQ62XmOHz+Oq1evSttKSkrQvXt3hIeHY8KECThy5Ii0rzFtuVV5eTnsdrvs1ZrcE/hbcs4YAAQH6NHJXweXAL6/xMVfiYjozqVoGLt8+TKcTqesNwkAQkJCYLPZan2PzWart979s6GaLl26yPZrtVoEBQXJamo7RvVz9OnTB++//z7+8Y9/4G9/+xtcLhdGjBiBs2fPNrott1qyZAlMJpP0Cg8Pr7WupbiXtmjpYUrgZu/YdxyqJCKiO5jiw5S3s5iYGEyZMgVRUVEYPXo0Pv30U3Tu3Bl/+ctfPD7m/PnzUVRUJL3OnDnjxRY3rLwVlrZwuxnGSiCEaKCaiIiofVI0jAUHB0Oj0SA/P1+2PT8/H2azudb3mM3meuvdPxuqufUGgcrKShQUFMhqajtG9XPcysfHB0OGDMHJkycb3ZZb6fV6GI1G2as1tcbdlG49O/tDq1ah6HoF8ovLW/x8REREbZGiYUyn02Ho0KHIysqStrlcLmRlZSEmJqbW98TExMjqASAzM1Oqj4iIgNlsltXY7Xbk5ORINTExMSgsLERubq5Us23bNrhcLlgsFqlmx44dqKiokJ2nT58+6NixY61tczqdOHToEEJDQxvdlramvIWfTVmdj0aNnp39AQDf2ThUSUREdybFhylTUlLwzjvvYO3atTh27BieeeYZlJaWYvr06QCAKVOmYP78+VL9rFmzkJGRgWXLluHbb7/FSy+9hL179yI5ORlA1d2Ns2fPxuLFi/HPf/4Thw4dwpQpUxAWFoa4uDgAQL9+/TB27FjMmDEDu3fvxtdff43k5GTEx8cjLCwMAPDkk09Cp9MhMTERR44cwcaNG7FixQqkpKRIbfmf//kfbN26FT/88AP27duHX/3qVzh9+jSefvrpRrelrXG00tIWbn1uDFUePl/UKucjIiJqaxR/UPikSZNw6dIlpKamwmazISoqChkZGdKk97y8PKjVN4PBiBEjsH79eixYsAAvvvgievfujfT0dAwcOFCqmTt3LkpLS5GUlITCwkKMHDkSGRkZsgVZ161bh+TkZIwZMwZqtRoTJ07EypUrpf0mkwlbt27FzJkzMXToUAQHByM1NVW2FtnVq1cxY8YM2Gw2dOzYEUOHDsXOnTvRv3//JrWlLWmtpS3cBnY14bNDF3D26nX8cKkEPTsHtMp5iYiI2gqV4MzpNs1ut8NkMqGoqKhV5o89+uZ/cPicHR9Mvw8P9am643R9Tl6LnnPNzlP4Lr8Ez43pjZSf3tOi5yIiImoNTfn+VnyYktoW99IW+lbqGQOAqPBAAMA/DpzjXZVERHTHYRgjGUcrLm3h1j/UBJ1GjdNXrmH/mcJWOy8REVFbwDBGMq25tIWbTqtG/7CqLtx/7D/XauclIiJqCxjGSKY1l7aozj1U+a+DF1Bxo3eOiIjoTsAwRjIOhcLY3Z0DEBygQ0GpA1+duNyq5yYiIlISwxjJ3BymbN1/Ghq1Co8Oqlrj7e8cqiQiojsIwxhJXC6hyAR+t7ghXQEAW4/aUFJe2ernJyIiUgLDGEkc1eZqKRHGBt9lQkSwP8oqXNh6xNbq5yciIlICwxhJqoex1h6mBKoeHzUhqmqoMv3A+VY/PxERkRIYxkjini8GtN7jkG4VF1U1VPnViUu4aC9TpA1EREStiWGMJOXVnkupUqkUaUOPYH/c2y0QLgGkH+BEfiIiav8Yxkii1LIWt5o49C4AwCe5fDwSERG1f1qlG0Bth1LLWri5H0he5nBBq1bheH4xXv/8O3Tt6AsAeNLSTZF2ERERtST2jJGkvNIJQPmeMV+dRno80r68q4q2hYiIqKUxjJGkrQxTAsC93ToCAL45W4hKFx+PRERE7Zfy37rUZig9TFldry4BMBq0uOZw4tsLxUo3h4iIqMUo/61LbYZSDwmvjVqlwpAbvWO7Tl1RuDVEREQtR/lvXWozqi9t0RZYIoKgAvDDpVKuOUZERO1W2/jWpTbBvQK/XqtRuCVVAv106BtaNZF/16kChVtDRETUMhjGSFJe0TbupqxueM8gAMD+vKt8eDgREbVLbedblxTn7hlrS2Hs7s4BCA7Qo7zShb/vO6t0c4iIiLyu7XzrkuLa0t2UbmqVSuode/erU6h0cpkLIiJqX9rOty4pri2tM1bd0O4d4afT4PSVa9hy2KZ0c4iIiLyqbX3rkqLK22DPGFB1Q8GIuzsBAP78xUk+r5KIiNqVtvWtS4pytLGlLaqL6RkMf50G39qKse3bi0o3h4iIyGva3rcuKUZa2sKnbSxtUZ2vToNfxXQHAKxi7xgREbUjDGMkkZa2aIM9YwCQODICOq0a+/MKsesHrjtGRETtQ9v81iVFtMWlLarr0sGASdHhAIA/bz+pcGuIiIi8o21+65Ii2uoE/uqSHugJjVqF/5y4jG/OFCrdHCIiomZru9+61Ora0oPC6xIe5IcJUWEA2DtGRETtQ9v91qVW11bXGbvVfz14N1Qq4PMj+ThuK1a6OURERM2iVboB1HbcXIG/7d1NCQDrc/KkPw8INeLweTue3/QNnhzWTdr+pKVbbW8lIiJqs9p2Fwi1qtulZwwAftI3BABw+FwRbEVlCreGiIjIc23/W5daTXll217aojqzyYCBXU0AgKxv8xVuDRERkefaxLfu6tWr0aNHDxgMBlgsFuzevbve+k2bNqFv374wGAyIjIzEli1bZPuFEEhNTUVoaCh8fX1htVpx4sQJWU1BQQESEhJgNBoRGBiIxMRElJSUyGoOHjyIUaNGwWAwIDw8HEuXLpXtf+eddzBq1Ch07NgRHTt2hNVqrdH2adOmQaVSyV5jx45t6iVqFTcXfW0T/ywa9JO+XaACcOS8HReKrivdHCIiIo8o/q27ceNGpKSkYNGiRdi3bx8GDx6M2NhYXLxY+yNvdu7cicmTJyMxMRH79+9HXFwc4uLicPjwYalm6dKlWLlyJdLS0pCTkwN/f3/ExsairOzmcFZCQgKOHDmCzMxMbN68GTt27EBSUpK032634+GHH0b37t2Rm5uL1157DS+99BLefvttqWb79u2YPHkyvvjiC2RnZyM8PBwPP/wwzp07J2vz2LFjceHCBen10UcfeevyeZU0Z+w26BkDALPxZu8YH5FERES3K5VQ+LkyFosF9913H1atWgUAcLlcCA8Px7PPPot58+bVqJ80aRJKS0uxefNmadvw4cMRFRWFtLQ0CCEQFhaG559/HnPmzAEAFBUVISQkBGvWrEF8fDyOHTuG/v37Y8+ePYiOjgYAZGRkYNy4cTh79izCwsLw1ltv4fe//z1sNht0Oh0AYN68eUhPT8e3335b62dxOp3o2LEjVq1ahSlTpgCo6hkrLCxEenp6o65HeXk5ysvLpd/tdjvCw8NRVFQEo9HYqGN4avRrX+D0lWv439/GILpHkLS9+sT5tibfXoaVWScgACQ/1AtzYvso3SQiIiLY7XaYTKZGfX8r2gXicDiQm5sLq9UqbVOr1bBarcjOzq71PdnZ2bJ6AIiNjZXqT506BZvNJqsxmUywWCxSTXZ2NgIDA6UgBgBWqxVqtRo5OTlSzQMPPCAFMfd5jh8/jqtXr9batmvXrqGiogJBQUGy7du3b0eXLl3Qp08fPPPMM7hy5Uqd12TJkiUwmUzSKzw8vM5ab7udJvC7hRgNiLyLvWNERHT7UvRb9/Lly3A6nQgJCZFtDwkJgc1mq/U9Nput3nr3z4ZqunTpItuv1WoRFBQkq6ntGNXPcavf/e53CAsLkwXBsWPH4sMPP0RWVhZeffVVfPnll3jkkUfgdDprPcb8+fNRVFQkvc6cOVNrXUto60tb1OUnfarmjh29YMfhc0VKN4eIiKhJuM6Yl7zyyivYsGEDtm/fDoPBIG2Pj4+X/hwZGYlBgwbh7rvvxvbt2zFmzJgax9Hr9dDr9a3S5luV3XhQeFt+HFJtutzoHTt4tgjL/+87vDv1PqWbRERE1GiKfusGBwdDo9EgP1++NEF+fj7MZnOt7zGbzfXWu382VHPrDQKVlZUoKCiQ1dR2jOrncHv99dfxyiuvYOvWrRg0aFC9n7lnz54IDg7GyZNt61E+FU4XSh1VYczo66Nwa5puTN8QqAD837GLyD1d+zAyERFRW6RoGNPpdBg6dCiysrKkbS6XC1lZWYiJian1PTExMbJ6AMjMzJTqIyIiYDabZTV2ux05OTlSTUxMDAoLC5GbmyvVbNu2DS6XCxaLRarZsWMHKioqZOfp06cPOnbsKG1bunQpXn75ZWRkZMjmoNXl7NmzuHLlCkJDQxusbU326zc/p9Fw+3WYdu6gx9DuVX8vSzO+hcL3pRARETWa4uNRKSkpeOedd7B27VocO3YMzzzzDEpLSzF9+nQAwJQpUzB//nypftasWcjIyMCyZcvw7bff4qWXXsLevXuRnJwMAFCpVJg9ezYWL16Mf/7znzh06BCmTJmCsLAwxMXFAQD69euHsWPHYsaMGdi9eze+/vprJCcnIz4+HmFhVQ+hfvLJJ6HT6ZCYmIgjR45g48aNWLFiBVJSUqS2vPrqq1i4cCHef/999OjRAzabDTabTVqvrKSkBC+88AJ27dqFH3/8EVlZWZgwYQJ69eqF2NjY1ri8jVZ0I4x10GuhvU2WtrjVT/p2gU6rRs6pAuw4cVnp5hARETWK4l0gkyZNwqVLl5CamgqbzYaoqChkZGRIk+Xz8vKgVt8MByNGjMD69euxYMECvPjii+jduzfS09MxcOBAqWbu3LkoLS1FUlISCgsLMXLkSGRkZMjmcq1btw7JyckYM2YM1Go1Jk6ciJUrV0r7TSYTtm7dipkzZ2Lo0KEIDg5GamqqbC2yt956Cw6HA7/4xS9kn2nRokV46aWXoNFocPDgQaxduxaFhYUICwvDww8/jJdfflmxeWF1KbwRxm7HIUq3QD8dnhreHe99dQpLM77FyF7B0KhVSjeLiIioXoqvM0b1a8o6Jc3xxfGLmP7BHgwIM+Kz50bJ9rXldcZuFTsgBA++th3F5ZVY+Gh/JI6MULpJRER0B7pt1hmjtsM9Z8x0G/eMAUCnAD3mjesLAHj98+M4U3BN4RYRERHVj2GMAACF16rCWKDf7R3GAGDyfd0wLCII1yucePHvhziZn4iI2jSGMQJwcwL/7d4zBgBqtQqvPB4JnVaN/5y4jFd4dyUREbVhik/gp7bB3TN2O0/gB+Tz28ZHhuLv+8/hL1/+gBP5JbD2C8GTlm4Kto6IiKgm9owRgJs9Y4G+ugYqbx/39QjC+Miq9dy2fXsRf99/FvayigbeRURE1LoYxghA+xqmrO7+XsEYO6DqiQl7fryK2D/twBd8oDgREbUhDGMEACi67gDQ/sIYADxwT2c8PTICQf46XCgqw/Q1e5Cy8QAKrzmUbhoRERHDGFWRhinbwd2UtenZOQDP/aQ3nh4ZAZUK+HT/Ofz0Tzuw83uu1E9ERMpiGCMA7XeYsjqdVo0Fj/bHJ8+MwN2d/XGpuBy/ejcHK/7vBJwu3m1JRETK4N2UBODm3ZTtOYwBN++2fGp4D/zrm/PIzbuKP/3fd9iUewYT770LIUYD77gkIqJWxZ4xQlmFE+WVLgCAqZ0OU95Kp1Vj4tC78MTQu2DwUePs1etY9cVJbD1iQ0l5pdLNIyKiOwjDGEmPQlKrgADdndVZOqRbR8wacw/6hHSA0yWw/btLePC1L7BxTx4XiiUiolbBMEYorDZfTK1WKdya1mfy9cGUmO74laUbOvnrcLnEgd99cggJ7+Yg7wqfbUlERC2LYYzuiMn7DVGpVOgfZsIsa2+8OK4vDD5q7Pz+CmKX78AnuWeVbh4REbVjDGOEojtk8n5jaNVqJD1wNz6f/QAsNx42/vymbzBn0ze45uBcMiIi8r47a4IQ1UoapvRrP49Cag73HZePDQ5DgEGLbccu4n9zz2LHd5cweVg33nFJRERexZ4x4jBlHdQqFcb0DUHiyAh0MGhxsbgcf95+Eju+u4SyCqfSzSMionaCYYyqhTF2lNamZ+cAPPuT3ujdJQAVToGMIzb85PXt2LA7D+WVDGVERNQ8DGOEohvPaAz05TBlXQL0Wkwd0QMT770LJl8fnC8qw7xPD2H00u1476tTDGVEROQxdoUQhykbSa1SYWj3jhh0lwkVThfe+c8PsNnL8PLmo/gw+0f8flw//LR/CFSqO295ECIi8hx7xki2zhg1zEejhp9Oi5kP9sLPo7qig0GL01euIemvuXhkxX/w5y9OKt1EIiK6jbBnjG72jN0hj0LyFq1GjfsigjAo3ITtxy/hqxOX8a2tGD9cPoEAgxa/snS/IxfRJSKipmHPGHGYspn0Wg1iB5iR/JNe6BbkB0elC6n/OIIn/pKN47ZipZtHRERtHMMYcdFXLwkxGpD0QE/8bHAYAvRa5J6+irErduA3f92LfXlX+axLIiKqFcPYHU4IIfWMBXKYstnUKhWG9+yEzJQHMC7SDCGAz4/k4/E/78RPln2JN7Yex8mL7C0jIqKbOGfsDnfN4USlq6rHhj1j3vPFt5cwsldn3NOlA3acuIxD5wpx6nIpVm47iZXbTsJsNCD5J73wy+hw6LT8/0RERHcyfgvc4dx3Uuo0avj6aBRuTfvTxWjAL4behRcf6YdfRoejr7kDNCoVbPYyLEg/jDFvbMfHe8/AUelSuqlERKQQ9ozd4a6WVi34avT14fpYLUjvo0FUeCCiwgNxzVGJA2cKseuHApwpuI65/3sQr39+HL8a3h3De3bCwK5G+On4P00iojsF/4t/h8s5VQAA6GMOULgldw4/nRYj7g7Ga78YjA+zf8T7X59Cvr0cb2R+BwBQqYBO/np06aBHiFGPEKMBZpMB3YL80L2TH8KD/NA5QM/wTETUTjCM3eG++PYiAOChPl0Ubsmd5+/7z6GDwQczH+qFg2eLcOS8HeeuXoO9rBKXS8pxuaQcRy/U/l5fHw06d9AjyF+H4AAdgvx1MBsNuLtLAO7uXPXy1XHYmYjodsAwdgcrLa9EzqkrAICH+jKMKUWrVuPebh1xb7eOAICS8krYr1eguKwCxWWVKCqrQNG1ChSUOlBQ6kDR9Qpcr3Air+Aa8gqu1XpMlQroGuiLnp0D0DPYHz07+yMiuOoVZvLlYrRERG0Iw9gd7KuTl1HhFOjeyQ89g/2Vbg7dEKDXIkCvBeBb6/5KpwuF1ytQWl554+VEqaMSV69V4FJxGS4Wl+Oaw4mzV6/j7NXr2PHdJdn79Vq1FMyqQloAIoL9cVdHXwT6+UCvZY8aEVFrYhi7g20/fnOIkvOPbh9ajRrBAXoEB+jrrCkpr8Sl4nJpuPNyiQOXi8tRUOpAeaUL39qK8W0dTwfw02nQ0U+Hjv4+6OinQ6CfDr06ByC6R0cMDg+8ERSJiMhb2sR/VVevXo3XXnsNNpsNgwcPxptvvolhw4bVWb9p0yYsXLgQP/74I3r37o1XX30V48aNk/YLIbBo0SK88847KCwsxP3334+33noLvXv3lmoKCgrw7LPP4l//+hfUajUmTpyIFStWICDg5kT2gwcPYubMmdizZw86d+6MZ599FnPnzvV6W5QghMAX31b1mHCIsv1x965F3NLj6XQJFF5zVIWzEnlYKy6rgEtUrT13zXEd5wqv1ziuWgX0NRsxONyEzh0MCPLzgZ9eC71WDYOPpup14896HzW0ajW0ahU0ahV8NGqo1VUL46pVKmhUKmg1KvjpNPw/A0R0R1M8jG3cuBEpKSlIS0uDxWLB8uXLERsbi+PHj6NLl5ohYefOnZg8eTKWLFmCRx99FOvXr0dcXBz27duHgQMHAgCWLl2KlStXYu3atYiIiMDChQsRGxuLo0ePwmAwAAASEhJw4cIFZGZmoqKiAtOnT0dSUhLWr18PALDb7Xj44YdhtVqRlpaGQ4cO4de//jUCAwORlJTk1bYo4egFO2z2Mvj6aGCJCFKsHdS6NGoVOgXo0SlAjz7oINvnEgLlFS5cc1TeCGRVP0vKK6HTqrH3x6s4V3gdRy/YcfSC3Wtt8tGo0NGv6iYE6ae/DzoYfKBV3whuNwJd1Z+rAp1WrYJarYL7KVPux03pfTQI0GvRwVD1CtD7IMCgRYBOC62m+nFUUKvAIEhEilMJhR+YZ7FYcN9992HVqlUAAJfLhfDwcDz77LOYN29ejfpJkyahtLQUmzdvlrYNHz4cUVFRSEtLgxACYWFheP755zFnzhwAQFFREUJCQrBmzRrEx8fj2LFj6N+/P/bs2YPo6GgAQEZGBsaNG4ezZ88iLCwMb731Fn7/+9/DZrNBp9MBAObNm4f09HR8++23XmtLQ+x2O0wmE4qKimA0Gj25xLVa/cVJvPb5cVj7dcG7U++rt3Z9Tp7Xzku3t6LrFcgruAZbURlKHZW4Vl6JCqdAhdOFCqcLla6qP1c6BSpcAi6XgEtUvZwuASGAtvaETrUKsoCmUVWFvOrhr/o26c/Stqr9Ktn7bx5TrVJJn/nW/9y6f1WrVfDXaeCn08Jfr4GvTgNttZssVKj6c/XcKP1Rpaq5rdpmVbWtN7fVUldLKJWfT94GFapCsUrl7u2s2u4SVcFeCMB54+9eCNz4t1C1TdzYVvt5ajagtvbW1qbqtbJtjfxst36+mttq1smP2dDfRc3aFv/sqFlQWztuVV80UKmqjqpS3XhBVeN6u/c3lgqNL27acRunZ+cA9DF3aLiwCZry/a1oz5jD4UBubi7mz58vbVOr1bBarcjOzq71PdnZ2UhJSZFti42NRXp6OgDg1KlTsNlssFqt0n6TyQSLxYLs7GzEx8cjOzsbgYGBUhADAKvVCrVajZycHPz85z9HdnY2HnjgASmIuc/z6quv4urVq+jYsaNX2nKr8vJylJeXS78XFRUBqPpL9aau/sADPfzwQI+ABo99rZTPUqQqPgDuDlTj7kA/j4/h/o+8EFXDptcrnLhW7sS1iqreuOvllSitcKK8wgWXqKqv+fPGnyFw63/GnS4XyipdKK9worzShfJKJxyVQnrs161cACo9/jRE1B48PTICs396j1eP6f5ubUyfl6Jh7PLly3A6nQgJCZFtDwkJkXqfbmWz2Wqtt9ls0n73tvpqbh0C1Wq1CAoKktVERETUOIZ7X8eOHb3SllstWbIEf/jDH2psDw8Pr7W+uf7aIkclIiK6fSxaDixqoWMXFxfDZDLVW6P4nDGSmz9/vqy3zeVyoaCgAJ06dVJkbovdbkd4eDjOnDnj1WHSOx2va8vhtW0ZvK4th9e25Sh5bYUQKC4uRlhYWIO1ioax4OBgaDQa5Ofny7bn5+fDbDbX+h6z2Vxvvftnfn4+QkNDZTVRUVFSzcWLF2XHqKysREFBgew4tZ2n+jm80ZZb6fV66PXyJQsCAwNrrW1NRqOR/5FoAbyuLYfXtmXwurYcXtuWo9S1bahHzE3dwu2ol06nw9ChQ5GVlSVtc7lcyMrKQkxMTK3viYmJkdUDQGZmplQfEREBs9ksq7Hb7cjJyZFqYmJiUFhYiNzcXKlm27ZtcLlcsFgsUs2OHTtQUVEhO0+fPn3QsWNHr7WFiIiI7nBCYRs2bBB6vV6sWbNGHD16VCQlJYnAwEBhs9mEEEI89dRTYt68eVL9119/LbRarXj99dfFsWPHxKJFi4SPj484dOiQVPPKK6+IwMBA8Y9//EMcPHhQTJgwQURERIjr169LNWPHjhVDhgwROTk54quvvhK9e/cWkydPlvYXFhaKkJAQ8dRTT4nDhw+LDRs2CD8/P/GXv/zF621py4qKigQAUVRUpHRT2hVe15bDa9syeF1bDq9ty7ldrq3iYUwIId58803RrVs3odPpxLBhw8SuXbukfaNHjxZTp06V1X/88cfinnvuETqdTgwYMEB89tlnsv0ul0ssXLhQhISECL1eL8aMGSOOHz8uq7ly5YqYPHmyCAgIEEajUUyfPl0UFxfLar755hsxcuRIodfrRdeuXcUrr7xSo+3eaEtbVlZWJhYtWiTKysqUbkq7wuvacnhtWwava8vhtW05t8u1VXydMSIiIqI7maJzxoiIiIjudAxjRERERApiGCMiIiJSEMMYERERkYIYxqhOq1evRo8ePWAwGGCxWLB7926lm6SYJUuW4L777kOHDh3QpUsXxMXF4fjx47KasrIyzJw5E506dUJAQAAmTpxYY1HgvLw8jB8/Hn5+fujSpQteeOEFVFbKn4y4fft23HvvvdDr9ejVqxfWrFlToz3t+e/mlVdegUqlwuzZs6VtvLaeOXfuHH71q1+hU6dO8PX1RWRkJPbu3SvtF0IgNTUVoaGh8PX1hdVqxYkTJ2THKCgoQEJCAoxGIwIDA5GYmIiSkhJZzcGDBzFq1CgYDAaEh4dj6dKlNdqyadMm9O3bFwaDAZGRkdiyZUvLfOhW4HQ6sXDhQkRERMDX1xd33303Xn75ZdkzCHltG2fHjh147LHHEBYWBpVKJT3b2a0tXcfGtMVjCt7JSW3Yhg0bhE6nE++//744cuSImDFjhggMDBT5+flKN00RsbGx4oMPPhCHDx8WBw4cEOPGjRPdunUTJSUlUs1vf/tbER4eLrKyssTevXvF8OHDxYgRI6T9lZWVYuDAgcJqtYr9+/eLLVu2iODgYDF//nyp5ocffhB+fn4iJSVFHD16VLz55ptCo9GIjIwMqaY9/93s3r1b9OjRQwwaNEjMmjVL2s5r23QFBQWie/fuYtq0aSInJ0f88MMP4vPPPxcnT56Ual555RVhMplEenq6+Oabb8TPfvazWtdkHDx4sNi1a5f4z3/+I3r16iVbk7GoqEiEhISIhIQEcfjwYfHRRx8JX1/fGmsyajQasXTpUnH06FGxYMGCGmsy3k7++Mc/ik6dOonNmzeLU6dOiU2bNomAgACxYsUKqYbXtnG2bNkifv/734tPP/1UABB///vfZfvb0nVsTFs8xTBGtRo2bJiYOXOm9LvT6RRhYWFiyZIlCraq7bh48aIAIL788kshRNUiwT4+PmLTpk1SzbFjxwQAkZ2dLYSo+o+OWq2WFjQWQoi33npLGI1GUV5eLoQQYu7cuWLAgAGyc02aNEnExsZKv7fXv5vi4mLRu3dvkZmZKUaPHi2FMV5bz/zud78TI0eOrHO/y+USZrNZvPbaa9K2wsJCodfrxUcffSSEEOLo0aMCgNizZ49U8+9//1uoVCpx7tw5IYQQf/7zn0XHjh2l6+w+d58+faTff/nLX4rx48fLzm+xWMRvfvOb5n1IhYwfP178+te/lm17/PHHRUJCghCC19ZTt4axtnQdG9OW5uAwJdXgcDiQm5sLq9UqbVOr1bBarcjOzlawZW1HUVERACAoKAgAkJubi4qKCtk169u3L7p16yZds+zsbERGRiIkJESqiY2Nhd1ux5EjR6Sa6sdw17iP0Z7/bmbOnInx48fX+Py8tp755z//iejoaDzxxBPo0qULhgwZgnfeeUfaf+rUKdhsNtnnNZlMsFgssusaGBiI6OhoqcZqtUKtViMnJ0eqeeCBB6DT6aSa2NhYHD9+HFevXpVq6rv2t5sRI0YgKysL3333HQDgm2++wVdffYVHHnkEAK+tt7Sl69iYtjQHwxjVcPnyZTidTtkXGwCEhITAZrMp1Kq2w+VyYfbs2bj//vsxcOBAAIDNZoNOp6vxUPfq18xms9V6Td376qux2+24fv16u/272bBhA/bt24clS5bU2Mdr65kffvgBb731Fnr37o3PP/8czzzzDJ577jmsXbsWwM3rUt/ntdls6NKli2y/VqtFUFCQV6797XhdAWDevHmIj49H37594ePjgyFDhmD27NlISEgAwGvrLW3pOjamLc2hbfYRiO4wM2fOxOHDh/HVV18p3ZR24cyZM5g1axYyMzNhMBiUbk674XK5EB0djf/3//4fAGDIkCE4fPgw0tLSMHXqVIVbd3v7+OOPsW7dOqxfvx4DBgzAgQMHMHv2bISFhfHakkfYM0Y1BAcHQ6PR1LhbLT8/H2azWaFWtQ3JycnYvHkzvvjiC9x1113SdrPZDIfDgcLCQll99WtmNptrvabuffXVGI1G+Pr6tsu/m9zcXFy8eBH33nsvtFottFotvvzyS6xcuRJarRYhISG8th4IDQ1F//79Zdv69euHvLw8ADevS32f12w24+LFi7L9lZWVKCgo8Mq1vx2vKwC88MILUu9YZGQknnrqKfz3f/+31LPLa+sdbek6NqYtzcEwRjXodDoMHToUWVlZ0jaXy4WsrCzExMQo2DLlCCGQnJyMv//979i2bRsiIiJk+4cOHQofHx/ZNTt+/Djy8vKkaxYTE4NDhw7J/sORmZkJo9EofWnGxMTIjuGucR+jPf7djBkzBocOHcKBAwekV3R0NBISEqQ/89o23f33319j+ZXvvvsO3bt3BwBERETAbDbLPq/dbkdOTo7suhYWFiI3N1eq2bZtG1wuFywWi1SzY8cOVFRUSDWZmZno06cPOnbsKNXUd+1vN9euXYNaLf/61Gg0cLlcAHhtvaUtXcfGtKVZmn0LALVLGzZsEHq9XqxZs0YcPXpUJCUlicDAQNndaneSZ555RphMJrF9+3Zx4cIF6XXt2jWp5re//a3o1q2b2LZtm9i7d6+IiYkRMTEx0n738gsPP/ywOHDggMjIyBCdO3eudfmFF154QRw7dkysXr261uUX2vvfTfW7KYXgtfXE7t27hVarFX/84x/FiRMnxLp164Sfn5/429/+JtW88sorIjAwUPzjH/8QBw8eFBMmTKh12YAhQ4aInJwc8dVXX4nevXvLlg0oLCwUISEh4qmnnhKHDx8WGzZsEH5+fjWWDdBqteL1118Xx44dE4sWLbqtll+41dSpU0XXrl2lpS0+/fRTERwcLObOnSvV8No2TnFxsdi/f7/Yv3+/ACDeeOMNsX//fnH69GkhRNu6jo1pi6cYxqhOb775pujWrZvQ6XRi2LBhYteuXUo3STEAan198MEHUs3169fFf/3Xf4mOHTsKPz8/8fOf/1xcuHBBdpwff/xRPPLII8LX11cEBweL559/XlRUVMhqvvjiCxEVFSV0Op3o2bOn7Bxu7f3v5tYwxmvrmX/9619i4MCBQq/Xi759+4q3335btt/lcomFCxeKkJAQodfrxZgxY8Tx48dlNVeuXBGTJ08WAQEBwmg0iunTp4vi4mJZzTfffCNGjhwp9Hq96Nq1q3jllVdqtOXjjz8W99xzj9DpdGLAgAHis88+8/4HbiV2u13MmjVLdOvWTRgMBtGzZ0/x+9//XrZ0Aq9t43zxxRe1/rd16tSpQoi2dR0b0xZPqYSotmQwEREREbUqzhkjIiIiUhDDGBEREZGCGMaIiIiIFMQwRkRERKQghjEiIiIiBTGMERERESmIYYyIiIhIQQxjRERERApiGCMiamU//vgjVCoVDhw4oHRTiKgN4Ar8REStzOl04tKlSwgODoZWq1W6OUSkMIYxIqJW5HA4oNPplG4GEbUhHKYkImqGBx98EMnJyUhOTobJZEJwcDAWLlwI9//P7dGjB15++WVMmTIFRqMRSUlJtQ5THjlyBI8++iiMRiM6dOiAUaNG4fvvv5f2v/vuu+jXrx8MBgP69u2LP//5z639UYmohbB/nIiomdauXYvExETs3r0be/fuRVJSErp164YZM2YAAF5//XWkpqZi0aJFtb7/3LlzeOCBB/Dggw9i27ZtMBqN+Prrr1FZWQkAWLduHVJTU7Fq1SoMGTIE+/fvx4wZM+Dv74+pU6e22uckopbBYUoiomZ48MEHcfHiRRw5cgQqlQoAMG/ePPzzn//E0aNH0aNHDwwZMgR///vfpff8+OOPiIiIwP79+xEVFYUXX3wRGzZswPHjx+Hj41PjHL169cLLL7+MyZMnS9sWL16MLVu2YOfOnS3/IYmoRXGYkoiomYYPHy4FMQCIiYnBiRMn4HQ6AQDR0dH1vv/AgQMYNWpUrUGstLQU33//PRITExEQECC9Fi9eLBvGJKLbF4cpiYhamL+/f737fX1969xXUlICAHjnnXdgsVhk+zQaTfMbR0SKYxgjImqmnJwc2e+7du1C7969Gx2WBg0ahLVr16KioqJG71hISAjCwsLwww8/ICEhwWttJqK2g8OURETNlJeXh5SUFBw/fhwfffQR3nzzTcyaNavR709OTobdbkd8fDz27t2LEydO4K9//SuOHz8OAPjDH/6AJUuWYOXKlfjuu+9w6NAhfPDBB3jjjTda6iMRUStizxgRUTNNmTIF169fx7Bhw6DRaDBr1iwkJSU1+v2dOnXCtm3b8MILL2D06NHQaDSIiorC/fffDwB4+umn4efnh9deew0vvPAC/P39ERkZidmzZ7fQJyKi1sS7KYmImuHBBx9EVFQUli9frnRTiOg2xWFKIiIiIgUxjBEREREpiMOURERERApizxgRERGRghjGiIiIiBTEMEZERESkIIYxIiIiIgUxjBEREREpiGGMiIiISEEMY0REREQKYhgjIiIiUtD/BwTtln6e2JNBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_data['price']);\n",
    "print(\"Skewness: %f\" % train_data['price'].skew())\n",
    "print(\"Kurtosis: %f\" % train_data['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfKK27a0fF2t",
   "metadata": {
    "id": "AfKK27a0fF2t"
   },
   "source": [
    "Conlusion:   \n",
    "+ 偏度>3,说明数据大部分集中在左侧（即价格偏低）;  \n",
    "+ 峰度高说明数据集中性强（大多数车价集中在低价区）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iYCjyerkgEMb",
   "metadata": {
    "id": "iYCjyerkgEMb"
   },
   "source": [
    "### 2.1.2 查看price的直方图分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4QQr6dWifElp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1750308280669,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "4QQr6dWifElp",
    "outputId": "64efd13a-e8f7-407b-d48a-71c208efdfb1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_data['price'],histtype = 'bar', color ='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-hVuMjAKgSbv",
   "metadata": {
    "id": "-hVuMjAKgSbv"
   },
   "source": [
    "### 2.1.3 对price进行log变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4y3GFElMge2Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1750308368553,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "4y3GFElMge2Y",
    "outputId": "6f486755-b87e-4021-a290-5fdc8a52ffd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(train_data['price']), orientation = 'vertical',histtype = 'bar', color ='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wZ7qSmwTg3ef",
   "metadata": {
    "id": "wZ7qSmwTg3ef"
   },
   "source": [
    "+ 可以看到log变换之后的分布更均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F8eOv2PZhaTA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1750308971134,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "F8eOv2PZhaTA",
    "outputId": "9a11737e-6865-4085-bfe1-62a56c56921f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 对price做log变换\n",
    "train_data['log_price'] = np.log1p(train_data['price'])  # 避免 log(0) 报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MWYZ0bGrhsfX",
   "metadata": {
    "id": "MWYZ0bGrhsfX"
   },
   "source": [
    "+ 将log_price作为回归目标预测, 需要再使用np.expm1(y_pred)还原预测值为原始价格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xy-nXQZbh3Gn",
   "metadata": {
    "id": "Xy-nXQZbh3Gn"
   },
   "outputs": [],
   "source": [
    "# 保存训练集\n",
    "train_data.to_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/cleaned_train_data.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# 保存测试集\n",
    "test_data.to_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/cleaned_test_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T546YveXmCPU",
   "metadata": {
    "id": "T546YveXmCPU"
   },
   "source": [
    "## 2.2 数值特征的相关性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lcqyR5simI1D",
   "metadata": {
    "id": "lcqyR5simI1D"
   },
   "outputs": [],
   "source": [
    "numeric_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14', \"price\", \"log_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YBXqQDXJmvTQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1750310034175,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "YBXqQDXJmvTQ",
    "outputId": "b012ce1f-be1a-4101-b3d1-c29303974c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_price    1.000000\n",
      "v_0          0.811132\n",
      "price        0.682859\n",
      "v_12         0.651727\n",
      "power        0.638410\n",
      "v_5          0.491399\n",
      "kilometer    0.310073\n",
      "v_2          0.089060\n",
      "v_14         0.056244\n",
      "v_13         0.024355\n",
      "v_1         -0.019695\n",
      "v_4         -0.161670\n",
      "v_6         -0.247532\n",
      "v_7         -0.265672\n",
      "v_11        -0.270104\n",
      "v_8         -0.283529\n",
      "v_10        -0.305617\n",
      "v_9         -0.433657\n",
      "v_3         -0.612190\n",
      "Name: log_price, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_numeric = train_data[numeric_features]\n",
    "correlation = price_numeric.corr()\n",
    "print(correlation['log_price'].sort_values(ascending = False),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhoGZDXQm_RC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1750310140972,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "xhoGZDXQm_RC",
    "outputId": "ca7e6454-fcc9-43d6-9e41-0b5eb7452c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Correlation of Numeric Features with log_Price'}>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAJLCAYAAACMmRDOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAl+FJREFUeJzs3XlcVNX/P/DXDMsMgmyiIKbgiuCOW2gqIKaYhGkmgeJum6W5lJS5VEb2ca+01NSsQSs0s0DMFNwTlzBXEpVcENwSxGVA5vz+8Md8HRkQGO6MM7yePe4jOfee9z13mIE355x7rkwIIUBEREREZklu6gYQERERUeUxmSMiIiIyY0zmiIiIiMwYkzkiIiIiM8ZkjoiIiMiMMZkjIiIiMmNM5oiIiIjMGJM5IiIiIjPGZI6IiIjIjDGZIyIiIjJjTOaIiIiIyvDll1/C29sbSqUSnTt3RmpqapnHL1y4ED4+PrCzs0P9+vXx9ttv4969e5K1j8kcERERUSl++OEHTJw4ETNmzMDhw4fRpk0b9O7dG1euXNF7fFxcHKZOnYoZM2bg5MmT+Oabb/DDDz/gvffek6yNMiGEkCw6ERERkRnr3LkzOnbsiC+++AIAoNFoUL9+fbz55puYOnVqiePHjRuHkydPYtu2bdqySZMmYf/+/di9e7ckbWTPHBEREVUbarUaeXl5OptardZ7bEFBAQ4dOoSQkBBtmVwuR0hICPbt26e3TpcuXXDo0CHtUOzZs2eRmJiIvn37Vv3F/H/WkkUmIiIiKofCa2eNdq7YL9Zg1qxZOmUzZszAzJkzSxx77do1FBUVwd3dXafc3d0dp06d0hs/MjIS165dwzPPPAMhBO7fv49XX31V0mFW9swRERFRtRETE4Pc3FydLSYmpsrip6Sk4JNPPsGSJUtw+PBhbNiwAQkJCfjoo4+q7ByPYs8cERERmZamyGinUigUUCgU5TrWzc0NVlZWyMnJ0SnPycmBh4eH3joffPABhg4ditGjRwMAWrVqhdu3b2Ps2LF4//33IZdXfT8ae+aIiIiI9LC1tUX79u11bmbQaDTYtm0bAgIC9Na5c+dOiYTNysoKACDVPafsmSMiIiLTEhpTt6BUEydOxLBhw9ChQwd06tQJCxcuxO3btzFixAgAQHR0NOrVq4fY2FgAQFhYGObPn4927dqhc+fOyMjIwAcffICwsDBtUlfVmMwRERERlWLw4MG4evUqpk+fjuzsbLRt2xZJSUnamyLOnz+v0xM3bdo0yGQyTJs2DZcuXULt2rURFhaG2bNnS9ZGrjNHREREJlV4+aTRzmVT19do5zIWzpkjIiIiMmMcZiUiIiKTEk/wnDlzwJ45IiIiIjPGnjkiIiIyLQ175gzBnjkiIiIiM8aeOSIiIjItzpkzCHvmiIiIiMwYe+aIiIjItIz4bFZLxJ45IiIiIjPGnjkiIiIyLc6ZMwh75oiIiIjMGJM5IiIiIjPGYVYiIiIyLS4abBD2zBERERGZMfbMERERkUkJ3gBhEPbMEREREZkx9swRERGRaXHOnEHYM0dERERkxtgzR0RERKbFOXMGYc8cERERkRljzxwRERGZlqbI1C0wa+yZIyIiIjJj7JkjIiIi0+KcOYOwZ450yGQyBAYGmv05pLZ48WK0aNECNWrUgEwmw8KFC03dJLNgCd97qryZM2dCJpMhJSVF0jql8fb2hre3t8FxzEFgYCBkMpmpm0FGwmSuChw6dAijRo1C06ZNYW9vDzs7OzRu3BhDhw7F1q1bTd08o7P0HyLr1q3D+PHjoVAoMH78eMyYMQNPP/10mXWKXxOlUol///1X7zHNmze36NdNSsW/8Evb+vfvb5R2DB8+HDKZDJmZmUY5nyXIzMyETCbD8OHDTd0Ukyp+HR7ebG1tUb9+fURGRuLvv/82dROlpdEYb7NAHGY1gEajweTJk7FgwQJYW1sjODgYzz//PGxsbHD27FkkJCTg+++/x4cffogPPvjA1M19Ypw8eRI1atQwdTMq7bffftP+39PTs0J11Wo1pk2bhu+++06Kpj3xpP7eDxw4EC1btixR3rx5c8nOSeU3btw4REREoEGDBqZuyhOrcePGGDJkCAAgPz8ff/75J9auXYsNGzZg27Zt6Nq1a7nirFmzBnfu3JGyqfQEYTJngGnTpmHBggVo27Yt4uPj0bhxY539d+/exRdffIHr16+bqIVPJnP/xZqVlQUAFU7kgAc/qOPi4jBlyhS0bt26qpv2xJP6e//iiy8iIiJC0nNQ5bm5ucHNzc3UzXiiNWnSBDNnztQpmzZtGmbPno3333+/3MPNZpcwc86cQTjMWkkZGRn47LPPUKtWLSQlJZVI5ADAzs4OU6ZMwaxZs3TKr127hgkTJqBhw4ZQKBSoU6cOXnrpJRw7dqxEjOJhm7Nnz2LevHnw8/ODQqHQDkkUzwG5efMmxo0bh/r168Pa2hqrV6/Wxvj7778RERGBunXrwtbWFl5eXnjzzTfLnWT+888/eOedd+Dv749atWpBqVSiWbNmmDp1KvLz83WOlclk2LFjh/bfxdvDQyilzZuqzOty7tw5LF68GM2bN4dCoYCXlxdmzZoFTQW70n/99VcEBQXByckJdnZ2aNOmDebPn4/79+9rj1m9ejVkMhmSk5NLXF95ffzxx9BoNHj33XfLdXxZ84WK2/Pw9/rhIauTJ0+iX79+cHZ2houLC15++WVcu3YNALBv3z707NkTjo6OcHFxwejRo3H79m29bdi5cyfCwsLg5uYGhUKBpk2bYtq0aSX+6k9JSYFMJsPMmTOxd+9ePPvss3B2dtZ5fUr73hcUFGDBggXo2LEjatasCQcHB/j5+WHixIn477//yvValZcQAitXrkTXrl3h6OiIGjVqoEOHDli5cmWJY7OysrTD6HXq1IFCoYC3tzdef/11XLlyRedYb29vfPvttwCAhg0bat8bxdf7uOFEfa9N8fD8vXv3MG3aNDRu3Bg2NjY6v+zPnTuH0aNHo0GDBlAoFKhbty6GDx+udzj/8OHDePHFF7XH1q5dGx07dsTs2bMf+7otWrQIMpkM8fHxOuUTJkyATCbDM888o1NefL0jRozQlj36fl69ejUaNmwIAPj22291PlP63vNxcXFo27Yt7OzsULduXYwfPx537959bNsf5/bt25gxYwaaN28OpVIJV1dXPPfcc9izZ4/e469du4axY8eiTp06qFGjBjp27Iiff/5Z72eyKrz55psAgAMHDmjLit8vly5dQnR0NDw8PCCXy7WvW1nTXX755Rc8++yz2p/n3t7eGDp0aImftQUFBZg/fz78/f1hb2+PmjVrolu3bti0aVOVXh8Zjj1zlbR69WoUFRXhlVdegbu7e5nHKhQK7b+vXr2KgIAAnDlzBoGBgYiIiMC5c+cQHx+PhIQEbNmypcQPReDBh/nPP//Ec889h7CwMNSpU0e7T61WIzg4GPn5+Xj++edhbW2tbdOmTZvw0ksvQS6XIzw8HPXr18eJEyfwxRdfYMuWLdi/fz9cXFzKbP+GDRvwzTffICgoCIGBgdBoNPjzzz8xZ84c7NixAzt37oSNjQ0AYMaMGVi9ejX+/fdfzJgxQxujbdu2ZZ6jsq/LlClTsGPHDvTr1w+9e/fGxo0bMXPmTBQUFJTrFxQAzJ8/H5MmTYKrqysiIyNhb2+PTZs2YdKkSdi1axc2bNgAmUyGtm3blnp95RUYGIjQ0FBs3rwZycnJCAoKqnCM8jh37hy6dOmCDh06YPTo0Th48CDWrVuHCxcu4NNPP8Wzzz6LXr16YezYsUhJScE333wDjUZTIqFZunQp3njjDTg7O2vfdwcPHsTs2bORnJyM5ORk2Nra6tTZu3cvPvnkEwQFBWHs2LE4f/58mW29e/cuevXqhT179qBp06YYMWIEFAoFTp8+ja+//hrR0dGPfY+WlxACUVFRWLt2LZo2bYrIyEjY2tpi69atGDVqFE6cOIG5c+dqj9+5cyfmzZuHnj17onPnzrCxscFff/2FpUuXYsuWLTh8+DCcnJwAPEhqVq9ejSNHjmD8+PFwdnYGgCqZcD9w4EAcOXIEffr0gbOzszYB2r9/P3r37o3bt2+jX79+aNq0KTIzM6FSqbB582bs27cPjRo1AgCkpaWhS5cusLKyQnh4OLy8vHDz5k2cOHECy5Ytw/vvv19mG4rfq8nJyXjxxRe15cV/3KSmpuL27duwt7fXKS/rPd62bVuMHz8eixYtQps2bXTmNj76un3xxRdISkpCeHg4goODkZSUhMWLF+PatWtQqVTleBX1u3fvHoKDg5Gamgp/f39MmDABOTk5+OGHH7BlyxasXbsWgwYN0h6fn5+PHj164MSJE+jSpQu6d++OixcvIiIiAr179650O8rj0eTs+vXrCAgIgKurKyIiInDv3j04OjqWGWPSpEmYP38+XF1d0b9/f9SpUwcXLlzAH3/8gfbt22unKajVavTp0wcpKSlo27YtRo0ahcLCQiQkJCA8PByff/45xo0bV3UXZ6Fz2YxGUKUEBgYKAOKPP/6oUL0RI0YIACImJkanPCEhQQAQTZo0EUVFRdryYcOGCQDiqaeeEv/++2+JeF5eXgKA6N27t7hz547OvmvXrglHR0dRr149kZmZqbNv7dq1AoAYN26cTjkA0aNHD52yixcvCrVaXeLcs2bNEgDE999/r1Peo0cPUdZbS985Kvu6NGzYUGRlZWnLr169KpydnUXNmjX1tvlRGRkZwtraWtSpU0ecP39eW37v3j3xzDPPCABizZo1Fbo+fYrrXL58WRw5ckTI5XLRsWNHodFotMf4+PiUiDtjxgwBQCQnJ5eIuWrVKgFArFq1Slt27tw5AUAAEAsXLtSWazQa0bdvXwFAODs7i40bN2r3FRQUiNatWwtra2uRnZ2tLT9+/LiwtrYWbdq0EdeuXdM5d2xsrAAg5s6dqy1LTk7WnnvlypV6Xwd93/tJkyYJAGLo0KHi/v37Ovtu3rwpbt26pTfWw4pfp4EDB4oZM2aU2O7evSuEEGLZsmUCgBgxYoQoKCjQ1ler1SIsLEwAEAcPHtSW5+Tk6D3/t99+KwCIjz/+WKe8+H157ty5EnWKvzfDhg3Tew36Xpvi903btm3F9evXdfYVFBQIb29vUbNmTXH48GGdfbt27RJWVlaiX79+2rKJEycKADrf+2KPfn/10Wg0olatWsLX11ennkwmEz179hQAxJYtW7T7hg4dKgDofK70vZ8f97oU13FychKnTp3Slt+5c0c0a9ZMyOVycenSpce2X4gHPy+9vLx0yop/jkVFRel8Hg8fPixsbW2Fs7OzyMvL05ZPmzZNABBjx47VifPHH39o3/8PfybLq/h16N27d4l906dPFwBEUFCQtqz4XCNGjCjxuRFC/8+pX3/9VQAQrVq1KvE9Lyws1Pn8v/feewKA+OCDD3Rel7y8PNGhQwdha2tb7te9PO4dSTLaZomYzFVS8+bNBQCdHy6Po1arhVKpFLVq1RK3b98usb9Xr14CgNi5c6e2rPiXw6JFi/TGLE7mjhw5UmLf/Pnz9SYjxfz9/YWbm5tOmb5fKKW5fv26ACCGDx+uU17RZM6Q10Vf0lC87++//37sNXz44YcCgJgzZ06JfXv27BEARHBwcIWuT5+HkzkhhIiOjhYAxA8//KA9piqTucaNG+v8ABZCiDVr1pT4hVCs+HXYvn27tuytt94q8boXKyoqErVr1xbt27fXlhUnc/7+/qW+Do9+7wsLC0XNmjWFk5OTuHHjRqn1Hqf4dSpt+++//4QQQrRu3VrY29uX+MNHCCH+/vtvAUBMmjTpsefTaDTC0dFRBAYG6pRLlcz98ssvJY7fsGGDACA+/PBDvfEGDBgg5HK5yM3NFUL8XzL3cMJVUQMHDtR5H8fHx2vfnwqFQrz77rvaY5966inRqFEjnfqGJHPTp08vdd+mTZvK1X59yVyjRo2EjY2NuHDhQonjx4wZU+JnqLe3t7C1tdVJfIo9++yzBidzjRs31v4RMnnyZNGtWzcBQCiVSrF3717t8QCEra2tuHr1qt54+n5OhYaGlvic61NUVCRcXFz0/hwRQohNmzYJAOLzzz+v8HWWhsmcYTjMakSnTp3CvXv3EBQUpPeOvqCgIGzduhVpaWno1q2bzr5OnTqVGlepVKJVq1Ylyv/8808AD4Zizpw5U2L/vXv3cO3aNVy7dq3MSclCCKxatQqrV6/GsWPHkJubqzMnrfiGgMoy5HVp3759ieOfeuopAMDNmzcfe+6//voLAPTO4woICIBSqURaWtrjL6KCPvroI/zwww+YNm0aBgwYAGvrqv0otm7dusSQTN26dQHoH/Iu3vfw97L4/bNlyxZs27atRB0bGxucOnWqRHnHjh3L3c5Tp07h1q1bCAkJqZKh1LVr15Z6A8SdO3dw9OhReHp6Ys6cOSX2FxYWatv0sA0bNuDrr7/G4cOH8d9//6Go6P8eO2Toe7+89H3+i78/6enpJSbMA0B2djY0Gg3++ecfdOjQAS+99BIWLlyIF154AYMHD0avXr3QvXt31KtXr9ztCAoKwvr165GcnIyXX34ZycnJqFmzJp555hk8/fTT2qHVjIwMXLx4EaNGjarcBeth6Gddn7y8PJw9exa+vr7aWA8LCgrC8uXLkZaWhqFDhyIvLw+ZmZnw8/PTO72ma9eu+P333yvVlmJnzpzRzrO2sbGBu7s7IiMjMXXq1BI/5xs2bFihG0pSU1OhUCjQo0ePMo9LT0/Hf//9B09PzxJzvoEH02KAkp8VQwjBx3kZgslcJXl4eODUqVO4dOkSfHx8ylUnLy8PAEqdY1f8C7X4uIeVNS+vTp06eie63rhxAwDw5Zdfltmu27dvl/kD4a233sIXX3yB+vXr4/nnn0fdunW18wBnzZoFtVpdZvzHMeR10Tc/pDgxeviXbmXOLZPJ4O7ujkuXLj02TkU1aNAAb7zxBubPn49ly5bh9ddfr9L4Zb0uZe0rTmiA/3v/lHfuYbHHzSF9WG5uLgBUKKGorP/++w9CCFy6dEnvL6hiD98IMm/ePEyePBm1a9fGs88+i6eeegp2dnYAgIULFxr83i8vfa9p8ffncfPFiq+nc+fOSElJwSeffIK4uDisWrUKwIPke86cOeWav/nwvLniZK579+6wtrZGUFAQPvroI+Tl5ZVrvlxFGfpZ16eiP3uK///wnOWHVeS9X5revXsjKSmpXMdW9Hy5ubmoV68e5PKy730sfm8dP34cx48fL/W40m6aIuNjMldJXbt2RUpKCrZt24bg4OBy1Sn+YZSTk6N3f3Z2ts5xDyvrjsnS9hXHOXr0qN61t8rjypUr+PLLL9G6dWvs27dPp+csOzu7zF+K5WXI61KV5/by8tLZJ4RATk6OJOcFgPfffx8rV67Ehx9+iOjoaL3HFP/Qffiu2mLFiZBUiq87Ly8PNWvWLHe9itzdW3yTgBQJ86OKr6d9+/Y4ePDgY4+/f/8+PvroI9StWxdpaWk6v8CFEPjss88qdH5Dvpf6XtPi6/n111/Rr1+/crWhW7du2Lx5M+7evYv9+/fj119/xZIlS/Dcc8/h2LFj2pslSlPcI5WcnIwrV67gxIkTGDlyJIAHidvMmTOxa9cu7R2VUt3gU1Uq+rOn+P+P3slcrLQ4UqnoIuPOzs7aHtuyErri6xw4cGCJu5clw6VJDMKlSSpp+PDhsLKywrJly7RdzqUp/uu9+Lb3AwcO6F3MsfgH4OPu/Cyvzp07A3iwDEVlnT17FkIIhISElBgC3bVrl946VlZWAMr/17KxX5eHtWvXTuccD9u/fz/u3bsnyXkBwNXVFe+++y5ycnIwb948vccUDz3qS3aKh4ilUvz+KR7Ok4KPjw8cHR1x4MCBKl+C5FE1a9aEr68vTp48Wa5huWvXriE3NxcBAQElemIOHjyod0mMst77ZSWulfleGvL5trOzQ2BgIObNm4f33nsPd+/eLffTagIDA5GRkaFd+Lr4j9mnn34adnZ22L59O5KTk9G0adNyrcVY0Z8XVcnR0RGNGjVCRkaG3u/Loz97HB0d4e3tjYyMDL0J3d69e6VsrsE6deoEtVqtXT6qNL6+vnB0dMTBgwd1euvpycVkrpKaNGmCd955B9euXUNoaCjOnTtX4ph79+5h/vz52vkstra22rW+YmNjdY5NSkrCli1b0KRJk3Kv8P04I0aMQM2aNfH+++/r7Sq/c+fOY39RF/dW7d27V2ee3MWLFxETE6O3jqurKwDgwoUL5WqnsV+Xh0VGRsLa2hrz58/Xmf9UUFCgXQtOyscMjR8/HvXq1cO8efP0JhjF88/WrFmj8/rv27fPoOUYyuP111+HtbU13nzzTb3Li9y8edPghNLa2hqvvPIKcnNzMX78+BK/0HNzc0usZWiIt956C3fu3MGYMWP0DhGdO3dO+yiuOnXqwM7ODocPH9b5I+O///7Trvv1qLLe+46OjvDx8cHu3buRkZGhLb9161apn6WyhIeHo0GDBpg/fz527txZYn9hYSF2796t/Xrfvn24d+9eieOKe5OUSmW5zlvc2zZnzhy4urqiTZs2AB58jrt27YrvvvsOly9fLnevnIuLC2QyWbl/XlS1YcOGobCwEDExMRBCaMv//vtvrF69Gk5OTjpLpkRFRaGgoKDE0kQpKSnYsmWLsZpdKW+88QaABz93iodSi92/f1/7XrC2tsZrr72Gf//9F5MnT9ab0B07dqzUHspK4eO8DMJhVgN8/PHHuHfvHhYsWAAfHx8EBwejZcuWsLGxwblz5/DHH3/g+vXr+Pjjj7V1itdm+/jjj7F371507twZmZmZ+Omnn1CjRg2sWrXqsfMZyqt27draNZLatGmDPn36oHnz5lCr1cjMzMSOHTvQpUuXMudn1K1bFwMHDsT69evRoUMH9OzZEzk5Ofjtt9/Qs2dPvTdWBAcHIz4+HgMHDkRoaCiUSiXatGmDsLCwUs9jzNflYY0bN8acOXMwadIktG7dGi+99BLs7e3x66+/Ij09HeHh4dpH60jBzs4OM2fOxJgxY3Dr1q0S+59++ml07doV27dvR0BAALp3745///0Xv/zyC8LCwvDzzz9L1raWLVtiyZIleO211+Dj44O+ffuicePGuHXrFs6ePYsdO3Zg+PDh+Oqrrww6z4cffog///wT3333Hf7880+EhoZCoVDg7NmzSEpKwu7du6usd/SVV17Bn3/+iW+//RZ79uxBSEgIPD09kZOTg1OnTmH//v2Ii4uDt7c35HI5Xn/9dcybN0/7/s3Ly8PmzZvh5eWlt9cpODgYc+fOxdixYzFw4EDY29vDy8sLQ4cOBfBgja+xY8ciICAAgwYNgkajwebNmyt000gxhUKB+Ph4hIaGokePHggODkarVq0gk8nw77//YteuXahVq5Z2kvqcOXO0c9waNmwIpVKJw4cPY9u2bWjUqBFeeOGFcp23OEm7evUqXnjhBZ3PZVBQEP744w+d4x7HwcEBHTt2xM6dOzF06FA0bdoUcrkcQ4cOLTH1QQrvvPMOEhIS8N133+HkyZPo2bMnrly5gh9++AH379/H8uXLdaYZvPvuu1i/fj2++uorHDt2DN26dcPFixfx448/IiwsDL/++qskP6uqQt++fTF58mTMnTsXTZs2xQsvvIA6derg0qVL2LZtGyZPnowJEyYAeDAf+vDhw1i8eDESEhLQvXt37bFHjx7FkSNHsG/fvlLnD5KRmfJWWktx4MABMXLkSNGkSRNhZ2cnFAqF8Pb2FpGRkWLr1q0ljr969ap46623hJeXl7CxsRFubm7ixRdfFEePHi1xbFlLHQih/1b7R506dUqMGjVKeHl5CVtbW+Hi4iJatWol3nrrLZGamqpzLPQsj3Dr1i0xadIk4e3tLRQKhWjatKn46KOPREFBgd7jCwsLxTvvvCMaNGggrK2tSyw7oK9OVb4uZS3nUZpffvlF9OjRQ9SsWVMoFArRqlUrMW/ePFFYWFji2KpYmuRh9+/fF76+vtplNB517do1ER0dLVxdXYWdnZ14+umnxZYtW8pcmkTfMg/FS4fMmDGjxD59sYqlpqaKiIgI4enpqf2++Pv7i6lTp4qTJ0+WK36x0r739+7dE3PnzhVt27YVdnZ2wsHBQfj5+YlJkyZplxUpS/H3fO3atY89VgghfvjhBxESEiJcXFyEjY2NqFevnggMDBTz5s3TWeqhoKBAzJ49WzRt2lQoFArRoEEDMWnSJHHr1q1SP3ufffaZaNq0qbCxsdF7vV9++aV2f4MGDcT06dNL/SyV57128eJFMX78eG0bHR0dha+vrxg9erTYtm2b9rikpCQRHR0tfHx8RM2aNbWv8XvvvVfq8halqVevnt6lKfbu3at9H+t7r5f22UxPTxd9+/YVzs7OQiaT6RxT0eV5ylLa9yw/P1988MEHolmzZtq15UJDQ8WuXbv0xrly5YoYNWqUcHNzE0qlUrRv315s2LBBzJ07VwAQP//8c7na87Cy1pnTp7TPUrGy3jvr168XQUFBwsnJSfv7aujQoeLYsWM6x92/f198/fXXomvXrsLR0VH7GejTp49YunSpyM/PL/f1Pc7dgz8bbbNEMiEe6lcmIiKiShkyZAhUKhVOnDgBX19fUzfHrNw7tNFo51K272+0cxkLh1mJiIgq4PLly9plS4rt2LED69atg4+PDxO5ytBwnTlDMJkjIiKqgL59+8LOzg5t27aFvb09Tpw4gaSkJFhZWeHzzz83dfOoGmIyR0REVAHDhg2DSqXCunXrcOvWLTg7OyMsLAwxMTHaJWMA6H0yhz4TJkzQLl1TbXGdOYNwzhwREZEEyruo77lz5+Dt7S1tY55w91J/Mtq5lJ0GGe1cxsKeOSIiIgmwr6QCLHT9N2N5MhfDISIiIqJyYc+cRAqvnZUs9r2Px0sW2zqggyRxM6ftlyQuAChrSPe4mcW5tSSL7SSsJIs9rvlFyWIfTKv7+IMqwV5W8pmlVSVP2EgWO8tGuu+jlH9tS/dqA9Gf1Jck7qr3pXtKRKvCkk/HqCod1vaRLLbMrvzPTa4o5dODJYtdAufMGYQ9c0RERERmjD1zREREZFqcM2cQ9swRERERmTEmc0RERERmjMOsREREZFocZjUIe+aIiIiIzBiTuXIqKCgwdROIiIgskhBFRtsq48svv4S3tzeUSiU6d+6M1NTUMo+/efMm3njjDdStWxcKhQLNmjVDYmJipc5dHk9MMhcYGIhx48Zh3LhxcHJygpubGz744APtCtr//fcfoqOj4eLigho1aiA0NBSnT58G8GCV7dq1ayM+Pl4br23btqhb9//Ww9q9ezcUCgXu3LkD4MELPXr0aNSuXRuOjo4IDg7GkSNHtMfPnDkTbdu2xYoVK9CwYUMolUpjvAxERET0BPnhhx8wceJEzJgxA4cPH0abNm3Qu3dvXLlyRe/xBQUF6NWrFzIzMxEfH4/09HQsX74c9erVk6yNT0wyBwDffvstrK2tkZqaikWLFmH+/PlYsWIFAGD48OE4ePAgNm3ahH379kEIgb59+6KwsBAymQzdu3dHSkoKgAeJ38mTJ3H37l2cOnUKALBjxw507NgRNWrUAAAMGjQIV65cwebNm3Ho0CH4+/ujZ8+euHHjhrY9GRkZWL9+PTZs2IC0tDSjvhZERETVhkZjvK2C5s+fjzFjxmDEiBHw8/PDV199hRo1amDlypV6j1+5ciVu3LiBjRs3omvXrvD29kaPHj3Qpk0bQ1+lUj1RN0DUr18fCxYsgEwmg4+PD44ePYoFCxYgMDAQmzZtwp49e9ClSxcAgEqlQv369bFx40YMGjQIgYGB+PrrrwEAO3fuRLt27eDh4YGUlBQ0b94cKSkp6NGjB4AHvXSpqam4cuUKFAoFAGDu3LnYuHEj4uPjMXbsWAAPsus1a9agdu3aJng1iIiIqKqp1Wqo1WqdMoVCoc0HHlZQUIBDhw4hJiZGWyaXyxESEoJ9+/bpjb9p0yYEBATgjTfewC+//ILatWsjMjIS7777LqyspHlizBPVM/f0009DJpNpvw4ICMDp06dx4sQJWFtbo3Pnztp9tWrVgo+PD06ePAkA6NGjB06cOIGrV69ix44dCAwMRGBgIFJSUlBYWIi9e/ciMDAQAHDkyBHk5+ejVq1acHBw0G7nzp3DmTNntOfw8vIqVyKnVquRl5ensz36RiEiIqJSCI3RttjYWDg5OelssbGxept17do1FBUVwd3dXafc3d0d2dnZeuucPXsW8fHxKCoqQmJiIj744APMmzcPH3/8cZW/bMWeqJ45Q7Rq1Qqurq7YsWMHduzYgdmzZ8PDwwNz5szBgQMHUFhYqO3Vy8/PR926dbXDsg9zdnbW/tve3r5c546NjcWsWbN0yqZNeQvT35HuGapERERUcTExMZg4caJOmb5eucrSaDSoU6cOli1bBisrK7Rv3x6XLl3C//73P8yYMaPKzvOwJyqZ279f92Hsf/75J5o2bQo/Pz/cv38f+/fv1yZk169fR3p6Ovz8/AAAMpkM3bp1wy+//ILjx4/jmWeeQY0aNaBWq/H111+jQ4cO2uTM398f2dnZsLa2hre3t8Ht1vfGkN+6ZHBcIiKiasGI68yVNqSqj5ubG6ysrJCTk6NTnpOTAw8PD7116tatCxsbG50hVV9fX2RnZ6OgoAC2traVb3wpnqhh1vPnz2PixIlIT0/H2rVr8fnnn2P8+PFo2rQpwsPDMWbMGOzevRtHjhzBkCFDUK9ePYSHh2vrBwYGYu3atWjbti0cHBwgl8vRvXt3qFQq7Xw5AAgJCUFAQAD69++P33//HZmZmdi7dy/ef/99HDx4sMLtVigUcHR01NmqMssnIiIi47O1tUX79u2xbds2bZlGo8G2bdsQEBCgt07Xrl2RkZEBzUMJ6j///IO6detKksgBT1gyFx0djbt376JTp0544403MH78eO3NCKtWrUL79u3Rr18/BAQEQAiBxMRE2NjYaOv36NEDRUVF2rlxwIME79EymUyGxMREdO/eHSNGjECzZs0QERGBf//9t8S4OBEREUnMiHPmKmrixIlYvnw5vv32W5w8eRKvvfYabt++jREjRgB4kLs8fIPEa6+9hhs3bmD8+PH4559/kJCQgE8++QRvvPFGlb1cj3qihlltbGywcOFCLF26tMQ+FxcXrFmzpsz6bdu21a5LV2zChAmYMGFCiWNr1qyJxYsXY/HixXpjzZw5EzNnzix324mIiMjyDB48GFevXsX06dORnZ2Ntm3bIikpSdv5c/78ecjl/9c3Vr9+fWzZsgVvv/02WrdujXr16mH8+PF49913JWvjE5XMERERUTX0hD+btfihBvrou5kyICAAf/75p8St+j9P1DArEREREVXME9Mzpy+zJSIiomqgEnPZ6P+wZ46IiIjIjD0xPXNERERUTT3hc+aedOyZIyIiIjJj7JmTyL2PpXuUl3LaIsliF50/Jkncq7ekiQsAPxZK9zfJp4Oke8buL6ryPS6uMuQ1JAuNTFtpfmy43JfmAdQAkGUre/xBlXRZXiRZ7IEF0r3/PDzyJIu9bJo0cWtJ91LjnpDu/Zcc8YdksbsPL5AsNp4eLF3sR7FnziDsmSMiIiIyY0zmiIiIiMwYh1mJiIjItLg0iUHYM0dERERkxiqUzAUGBup9zikADB8+HP379y/XsURERERaGo3xNgtUZT1zixYtwurVq6sqXJVZvXo1nJ2dTd0MIiIiIklU2Zw5Jyenqgr1RCoqKoJMJoNczpFpIiKiKsU5cwYxKDNJSEiAk5MTVCpViWHWR/3333+Ijo6Gi4sLatSogdDQUJw+fVq7v7gH7bfffoOPjw9q1KiBF198EXfu3MG3334Lb29vuLi44K233kJR0f8tNqRWqzF58mTUq1cP9vb26Ny5s/Y5rykpKRgxYgRyc3Mhk8kgk8kwc+bMx9Z7uD2bNm2Cn58fFAoFzp8/b8jLRURERFTlKt0zFxcXh1dffRVxcXHo168ftm7dWubxw4cPx+nTp7Fp0yY4Ojri3XffRd++fXHixAnY2NgAAO7cuYPFixdj3bp1uHXrFgYMGIAXXngBzs7OSExMxNmzZzFw4EB07doVgwc/WMxw3LhxOHHiBNatWwdPT0/8/PPP6NOnD44ePYouXbpg4cKFmD59OtLT0wEADg4Oj63XtGlTbXvmzJmDFStWoFatWqhTp05lXy4iIiIqjYXOZTOWSiVzX375Jd5//338+uuv6NGjx2OPL07i9uzZgy5dugAAVCoV6tevj40bN2LQoEEAgMLCQixduhSNGzcGALz44ov47rvvkJOTAwcHB/j5+SEoKAjJyckYPHgwzp8/j1WrVuH8+fPw9PQEAEyePBlJSUlYtWoVPvnkEzg5OUEmk8HDw0PbnvLUK27PkiVL0KZNmzKvT61WQ63WXam94H4RFNbSrShOREREBFQimYuPj8eVK1ewZ88edOzYsVx1Tp48CWtra3Tu3FlbVqtWLfj4+ODkyZPasho1amgTOQBwd3eHt7e3tjetuOzKlSsAgKNHj6KoqAjNmjXTOZ9arUatWrVKbU9569na2qJ169aPvb7Y2FjMmjVLp2xq56Z472mfx9YlIiKq9jhnziAVTubatWuHw4cPY+XKlejQoQNksqp75mHxcGsxmUymt0zz/7tj8/PzYWVlhUOHDsHKSrcX7OEE8FHlrWdnZ1eu64uJicHEiRN1ygrei3hsPSIiIiJDVTiZa9y4MebNm4fAwEBYWVnhiy++eGwdX19f3L9/H/v379cOs16/fh3p6enw8/OreKv/v3bt2qGoqAhXrlxBt27d9B5ja2urc8NEeetVhEKhgEKh0Cm7xSFWIiKi8uGcOYNU6m7WZs2aITk5GevXry/XwsBNmzZFeHg4xowZg927d+PIkSMYMmQI6tWrh/Dw8Mo0QduOqKgoREdHY8OGDTh37hxSU1MRGxuLhIQEAIC3tzfy8/Oxbds2XLt2DXfu3ClXPSIiIiJzUOmlSXx8fLB9+3asXbsWkyZNeuzxq1atQvv27dGvXz8EBARACIHExMQSw6gVtWrVKkRHR2PSpEnw8fFB//79ceDAATRo0AAA0KVLF7z66qsYPHgwateujc8++6xc9YiIiMhI+AQIg8iEEMLUjbBEtyaESRZbOW2RZLGLzh+TJG5q3+8kiQsAPyqlW8j500EFksX+RWUvWezQzhcki/3jwfqSxHW5L92Poiybqpvb+6jL8qLHH1RJAwvUjz+okjw88iSLvfGax+MPqoRa9yUJCwBwLyqULHYhpHv/dR8u3c8ohzkbJIv9qLs/fmi0c9m9NN1o5zKWKnsCBBEREVGlsF/JIHw2FREREZEZY88cERERmZaFzmUzFvbMEREREZkxJnNEREREZozDrERERGRaHGY1CJM5iVgHdJAstlTLhwCAVYOWksSVQbo7lZoXGbZWYVn2r5EsNOpCuiUFlE83kix21l9StVu65RvyZdK9/3Ik/D5moIZkse9nSTcwE9lKmqVxLp92lCQuAFy7aydZ7C6vSPfetn1rrmSxyXwwmSMiIiLTEuyZMwTnzBERERGZMfbMERERkWlxzpxB2DNHREREZMbYM0dERESmxcd5GYQ9c3qkpKTA398fCoUCTZo0werVq03dJCIiIiK9mMw94ty5c3juuecQFBSEtLQ0TJgwAaNHj8aWLVtM3TQiIiLLpNEYb7NAFpnMLVu2DJ6entA88k0LDw/HyJEjy6z71VdfoWHDhpg3bx58fX0xbtw4vPjii1iwYIGUTSYiIiKqFItM5gYNGoTr168jOTlZW3bjxg0kJSUhKiqqzLr79u1DSEiITlnv3r2xb98+SdpKRERU7bFnziAWmcy5uLggNDQUcXFx2rL4+Hi4ubkhKCiozLrZ2dlwd3fXKXN3d0deXh7u3r2rt45arUZeXp7Opi68b/iFEBERET2GRSZzABAVFYX169dDrVYDAFQqFSIiIiCXV/0lx8bGwsnJSWf738ZdVX4eIiIiiyQ0xtsskMUmc2FhYRBCICEhARcuXMCuXbseO8QKAB4eHsjJydEpy8nJgaOjI+zs9D+7LyYmBrm5uTrblP7dquQ6iIiIiMpisevMKZVKDBgwACqVChkZGfDx8YG/v/9j6wUEBCAxMVGnbOvWrQgICCi1jkKhgEKh0Cm7a2OxLy0REVGVEhquM2cIi+2ZAx4MtSYkJGDlypXl6pUDgFdffRVnz57FO++8g1OnTmHJkiX48ccf8fbbb0vcWiIiIqKKs+juo+DgYLi6uiI9PR2RkZHlqtOwYUMkJCTg7bffxqJFi/DUU09hxYoV6N27t8StJSIiqqYs9C5TY7HoZE4ulyMrK6vC9QIDA/HXX39J0CIiIiKiqmXRyRwRERGZAQu9y9RYLHrOnD4tWrSAg4OD3k2lUpm6eUREREQVUu165hITE1FYWKh336OLBRMRERE96apdMufl5WXqJhAREdHDuDSJQardMCsRERGRJal2PXNERET0hOHSJAaRCSHYtymBk037Shb76i17yWLLIM3b4eljn0kSFwDufTxestg5vxdIFrtALd3fUkUa6Trdm/0eI0ncM31mSxIXAKxspPtF4d5eLVnsyF1KyWL/cvgLyWIfbj1Zkrj2Suk+j3KZdL8KpXz/SflzpNW5XyWL/ag7n79utHPVeHOJ0c5lLBxmJSIiItPSaIy3VcKXX34Jb29vKJVKdO7cGampqeWqt27dOshkMvTv379S5y0vJnNEREREpfjhhx8wceJEzJgxA4cPH0abNm3Qu3dvXLlypcx6mZmZmDx5Mrp16yZ5G5nMERERkWkJYbytgubPn48xY8ZgxIgR8PPzw1dffYUaNWpg5cqVpdYpKipCVFQUZs2ahUaNGhnyypQLkzkiIiKqNtRqNfLy8nQ2tVr/3NeCggIcOnQIISEh2jK5XI6QkBDs27ev1HN8+OGHqFOnDkaNGlXl7deHyRwRERGZlhHnzMXGxsLJyUlni42N1dusa9euoaioqMRDBdzd3ZGdna23zu7du/HNN99g+fLlVf4ylYbJ3EMuX76MyMhINGvWDHK5HBMmTDB1k4iIiKgKxcTEIDc3V2eLiamau/Rv3bqFoUOHYvny5XBzc6uSmOXBdeYeolarUbt2bUybNg0LFiwwdXOIiIiqByM+AUKhUEChUJTrWDc3N1hZWSEnJ0enPCcnBx4eHiWOP3PmDDIzMxEWFqYt0/z/O2itra2Rnp6Oxo0bG9B6/SyuZ27ZsmXw9PTUvnjFwsPDMXLkyDLrent7Y9GiRYiOjoaTk5OUzSQiIqInnK2tLdq3b49t27ZpyzQaDbZt24aAgIASxzdv3hxHjx5FWlqadnv++ecRFBSEtLQ01K9fX5J2WlzP3KBBg/Dmm28iOTkZPXv2BADcuHEDSUlJSExMNHHriIiIqATx5D4BYuLEiRg2bBg6dOiATp06YeHChbh9+zZGjBgBAIiOjka9evUQGxsLpVKJli1b6tR3dnYGgBLlVcnikjkXFxeEhoYiLi5Om8zFx8fDzc0NQUFBkpxTrVaXuBOmQBTBVmYlyfmIiIjIOAYPHoyrV69i+vTpyM7ORtu2bZGUlKS9KeL8+fOQy0070Glxw6wAEBUVhfXr12sTLJVKhYiICMlebH13xiy7cVaScxEREVkcjTDeVgnjxo3Dv//+C7Vajf3796Nz587afSkpKVi9enWpdVevXo2NGzdW6rzlZZHJXFhYGIQQSEhIwIULF7Br1y5ERUVJdj59d8aMdZV+kUAiIiIiixtmBQClUokBAwZApVIhIyMDPj4+8Pf3l+x8+u6M4RArERFR+YhKPjOVHrDIZA54MNTar18/HD9+HEOGDCl3vbS0NABAfn4+rl69irS0NNja2sLPz0+ilhIRERFVnsUmc8HBwXB1dUV6ejoiIyPLXa9du3bafx86dAhxcXHw8vJCZmamBK0kIiIiMozFJnNyuRxZWVkVricq8RBeIiIiMoARFw22RBZ5AwQRERFRdVGtkrkWLVrAwcFB76ZSqUzdPCIioupJaIy3WSCLHWbVJzExEYWFhXr3FS/+R0RERGROqlUy5+XlZeomEBER0aM4Z84g1WqYlYiIiMjSVKueOSIiInoCcdFggzCZk4iyhv65eVXhx0LpOlSbF9lIErftx+MliQsAymmLJIs9f+NUyWKP0agli32+wF6y2A1XzJUkrsLuviRxAUBuJeEvivvSDQ+NLHSRLPbRdm9LFrv14o6SxD3zzp+SxAUAj5b5ksVWtKkrWeybW69IFpvMB5M5IiIiMi3OmTMI58wRERERmTH2zBEREZFpWej6b8bCnjkiIiIiM8aeOSIiIjItzpkzCHvmHrFhwwb06tULtWvXhqOjIwICArBlyxZTN4uIiIhILyZzj9i5cyd69eqFxMREHDp0CEFBQQgLC8Nff/1l6qYRERFZJKHRGG2zRBaZzC1btgyenp7QPPJNCw8Px8iRI8usu3DhQrzzzjvo2LEjmjZtik8++QRNmzbFr7/+KmWTiYiIiCrFIpO5QYMG4fr160hOTtaW3bhxA0lJSYiKiqpQLI1Gg1u3bsHV1bWqm0lERETAgzlzxtoskEUmcy4uLggNDUVcXJy2LD4+Hm5ubggKCqpQrLlz5yI/Px8vvfRSqceo1Wrk5eXpbGoL7colIiKiJ4tFJnMAEBUVhfXr10OtfvDIJJVKhYiICMjl5b/kuLg4zJo1Cz/++CPq1KlT6nGxsbFwcnLS2ZZeOWfwNRAREVUL7JkziMUmc2FhYRBCICEhARcuXMCuXbsqNMS6bt06jB49Gj/++CNCQkLKPDYmJga5ubk622t1Ghp6CURERESPZbHrzCmVSgwYMAAqlQoZGRnw8fGBv79/uequXbsWI0eOxLp16/Dcc8899niFQgGFQqFTdr0CPYBERERElWWxyRzwYKi1X79+OH78OIYMGVKuOnFxcRg2bBgWLVqEzp07Izs7GwBgZ2cHJycnKZtLRERUPfFxXgax6O6j4OBguLq6Ij09HZGRkeWqs2zZMty/fx9vvPEG6tatq93Gjx8vcWuJiIiIKs6ie+bkcjmysrIqVCclJUWaxhAREZF+FnpjgrFYdM8cERERkaWrdslcixYt4ODgoHdTqVSmbh4REVG1IzTCaJslsuhhVn0SExNRWFiod5+7u7uRW0NERERkmGqXzHl5eZm6CURERPQwC+0xM5ZqN8xKREREZEmqXc+csSzOrSVZ7E8HqSWLvX+NNHFzfi+QJjCA+RunShZ70cFPJYt9qqN0y914KfIli33pF/3TFAwlNFaSxAWA+/dtJItdcES6H6PBnS5KFlv5XPkWUa+MmpFLJYm7vHbFnq1dEW0OS/f+i/4zU7LY7jaOksXeJllkPfg8c4OwZ46IiIjIjLFnjoiIiEyLc+YMwp45IiIiIjPGnjkiIiIyLfbMGYQ9c0RERERmjD1zREREZFJCsGfOEOyZe8Tu3bvRtWtX1KpVC3Z2dmjevDkWLFhg6mYRERER6cWeuUfY29tj3LhxaN26Nezt7bF792688sorsLe3x9ixY03dPCIiIsvDOXMGscieuWXLlsHT0xOaRxYhDA8Px8iRI8us265dO7z88sto0aIFvL29MWTIEPTu3Ru7du2SsslERERElWKRydygQYNw/fp1JCcna8tu3LiBpKQkREVFVSjWX3/9hb1796JHjx5V3UwiIiIig1nkMKuLiwtCQ0MRFxeHnj17AgDi4+Ph5uaGoKDyPQ7mqaeewtWrV3H//n3MnDkTo0ePLvVYtVoNtVr3EVv3RRGsZdI9HoaIiMhicJjVIBbZMwcAUVFRWL9+vTbJUqlUiIiIgFxevkvetWsXDh48iK+++goLFy7E2rVrSz02NjYWTk5OOtuB3JNVch1EREREZbHYZC4sLAxCCCQkJODChQvYtWtXhYZYGzZsiFatWmHMmDF4++23MXPmzFKPjYmJQW5urs7W0cm3Cq6CiIjI8gmNMNpmiSxymBUAlEolBgwYAJVKhYyMDPj4+MDf379SsTQaTYlh1IcpFAooFAqdMg6xEhERkTFYbDIHPBhq7devH44fP44hQ4aUq86XX36JBg0aoHnz5gCAnTt3Yu7cuXjrrbekbCoREVH1ZaE9ZsZi0clccHAwXF1dkZ6ejsjIyHLV0Wg0iImJwblz52BtbY3GjRtjzpw5eOWVVyRuLREREVHFWXQyJ5fLkZWVVaE6b775Jt58802JWkREREQlaB5/CJXOYm+AICIiIqoOql0y16JFCzg4OOjdVCqVqZtHRERU7Tzpd7N++eWX8Pb2hlKpROfOnZGamlrqscuXL0e3bt3g4uICFxcXhISElHl8VbDoYVZ9EhMTUVhYqHefu7u7kVtDRERET7IffvgBEydOxFdffYXOnTtj4cKF6N27N9LT01GnTp0Sx6ekpODll19Gly5doFQqMWfOHDz77LM4fvw46tWrJ0kbq10y5+XlZeomEBER0cOe4LtZ58+fjzFjxmDEiBEAgK+++goJCQlYuXIlpk6dWuL4R0f5VqxYgfXr12Pbtm2Ijo6WpI3VbpiViIiIqi+1Wo28vDydrbS1ZAsKCnDo0CGEhIRoy+RyOUJCQrBv375yne/OnTsoLCyEq6trlbRfn2rXM2csTkK6RYN/UdlLFrsuCiSJW6CW7q02RlP6gs6GOtVxvGSxmx9YJFns5BbvSRb7KetbksR1dLsrSVwAkEn4Z6s6X7r3dt6/tpLFLvrpsGSxN7l0kyRuryMfShIXAH5tOU2y2LGyhpLF1tyXSRbbqIx4N2tsbCxmzZqlUzZjxgy9T3q6du0aioqKSkzDcnd3x6lTp8p1vnfffReenp46CWFVYzJHRERE1UZMTAwmTpyoU/boU5yqyqeffop169YhJSUFSqVSknMATOaIiIjIxIz5zFR9j+AsjZubG6ysrJCTk6NTnpOTAw8PjzLrzp07F59++in++OMPtG7dutLtLQ/OmSMiIiLSw9bWFu3bt8e2bdu0ZRqNBtu2bUNAQECp9T777DN89NFHSEpKQocOHSRvJ3vmiIiIyLSe4CdATJw4EcOGDUOHDh3QqVMnLFy4ELdv39be3RodHY169eohNjYWADBnzhxMnz4dcXFx8Pb2RnZ2NgBo17SVApM5IiIiolIMHjwYV69exfTp05GdnY22bdsiKSlJe1PE+fPnIZf/30Dn0qVLUVBQgBdffFEnTmk3WVQFJnNl2LNnD3r06IGWLVsiLS3N1M0hIiKySMacM1cZ48aNw7hx4/TuS0lJ0fk6MzNT+gY9gnPmSnHz5k1ER0ejZ8+epm4KERERUaksMplbtmwZPD09odHoDsKHh4dj5MiR5Yrx6quvIjIysswJjkRERESmZpHJ3KBBg3D9+nUkJydry27cuIGkpCRERUU9tv6qVatw9uxZzJgxQ8pmEhEREfDgBghjbRbIIpM5FxcXhIaGIi4uTlsWHx8PNzc3BAUFlVn39OnTmDp1Kr7//ntYW3NKIRERET3ZLDKZA4CoqCisX79e+7w1lUqFiIgInTtOHlVUVITIyEjMmjULzZo1K/e59D3n7b4oMvgaiIiIqgOhMd5miSw2mQsLC4MQAgkJCbhw4QJ27dr12CHWW7du4eDBgxg3bhysra1hbW2NDz/8EEeOHIG1tTW2b9+ut15sbCycnJx0tt25x6W4LCIiIiIdFjuOqFQqMWDAAKhUKmRkZMDHxwf+/v5l1nF0dMTRo0d1ypYsWYLt27cjPj4eDRvqf1iyvue8fdZyrGEXQEREVF1YaI+ZsVhsMgc8GGrt168fjh8/jiFDhjz2eLlcjpYtW+qU1alTB0qlskT5w/Q9581aZlW5RhMRERFVgEUnc8HBwXB1dUV6ejoiIyNN3RwiIiLSw1LnshmLxc6ZAx70tGVlZUEIgUaNGlUqxsyZM/n0ByIiInpiWXTPHBEREZkB9swZxKJ75vRp0aIFHBwc9G4qlcrUzSMiIiKqkGrXM5eYmIjCwkK9+9zd3Y3cGiIiIuKcOcNUu2TOy8vL1E0gIiIiqjLVLpkjIiKiJwt75gxT7ebMEREREVkS9sxJZFzzi5LFlteQLDSUT1duCZfHOfPVXUniAsD5AnvJYnsp8iWLndziPcliBx3/RLLY8a0/kCSuw7+OksQFgB7hNySL7eLrLVnsrGWZksXOPOEqWexmtf6TJO7vLd6XJC4AuMv0z6WuCg0bXZcstssbz0gW25jYM2cY9swRERERmTH2zBEREZFpCZmpW2DW2DNHREREZMaYzBERERGZMQ6zEhERkUnxBgjDsGfuESkpKZDJZCW27OxsUzeNiIiIqAT2zJUiPT0djo7/t1RCnTp1TNgaIiIiyyU0vAHCEBbZM7ds2TJ4enpCo9Httw0PD8fIkSPLFaNOnTrw8PDQbnK5Rb5UREREZOYsMkMZNGgQrl+/juTkZG3ZjRs3kJSUhKioqHLFaNu2LerWrYtevXphz549UjWViIio2hMa422WyCKTORcXF4SGhiIuLk5bFh8fDzc3NwQFBZVZt27duvjqq6+wfv16rF+/HvXr10dgYCAOHz5cah21Wo28vDydTa2x0HcMERERPVEsMpkDgKioKKxfvx5qtRoAoFKpEBER8djhUh8fH7zyyito3749unTpgpUrV6JLly5YsGBBqXViY2Ph5OSksy06e75Kr4eIiMhSCSEz2maJLDaZCwsLgxACCQkJuHDhAnbt2lXuIdZHderUCRkZGaXuj4mJQW5urs42vlGDyjadiIiIqNws9m5WpVKJAQMGQKVSISMjAz4+PvD3969UrLS0NNStW7fU/QqFAgqFQqesgDdMEBERlYulzmUzFotN5oAHQ639+vXD8ePHMWTIkHLVWbhwIRo2bIgWLVrg3r17WLFiBbZv347ff/9d4tYSERERVZxFJ3PBwcFwdXVFeno6IiMjy1WnoKAAkyZNwqVLl1CjRg20bt0af/zxx2NvnCAiIqLK4TpzhrHoZE4ulyMrK6tCdd555x288847ErWIiIiIqGpZdDJHRERETz4hTN0C81btZum3aNECDg4OejeVSmXq5hERERFVSLXrmUtMTERhYaHefe7u7kZuDREREXHOnGGqXTLn5eVl6iYQERERVZlql8wRERHRk4U9c4apdnPmiIiIiCyJTAjeQyKFJPcIyWJn2krXoZplJc3b4f2tb0gSFwAKV8yVLPalX+5KFruoULq/pY7cdZYs9ot/fyRJ3OPtJ0gSFwDkMul+zDV5u55ksW/E/SNZ7FrTn5cs9qnXkiWLLRUb6yLJYt++ZytZ7L/lNSSLPebi95LFftS5Nr2Mdq6GR7Ya7VzGwp45IiIiIjPGZI6IiIjIjPEGCCIiIjIp3gBhGPbMEREREZkx9swRERGRSQnBnjlDsGfuEWq1Gu+//z68vLygUCjg7e2NlStXmrpZRERERHqxZ+4RL730EnJycvDNN9+gSZMmuHz5MjQajambRUREZLEEf80axOKSuWXLlmHmzJm4ePEi5PL/63gMDw9HrVq1yuxlS0pKwo4dO3D27Fm4uroCALy9vaVuMhEREVGlWdww66BBg3D9+nUkJ//fopU3btxAUlISoqKiyqy7adMmdOjQAZ999hnq1auHZs2aYfLkybh7V7qFY4mIiKo7jZAZbbNEFtcz5+LigtDQUMTFxaFnz54AgPj4eLi5uSEoKKjMumfPnsXu3buhVCrx888/49q1a3j99ddx/fp1rFq1qtR6arUaarVap6xAFMFWZmX4BRERERGVweJ65gAgKioK69ev1yZYKpUKEREROsOu+mg0GshkMqhUKnTq1Al9+/bF/Pnz8e2335bZOxcbGwsnJyed7cfbJ6v0moiIiCyVEDKjbZbIIpO5sLAwCCGQkJCACxcuYNeuXY8dYgWAunXrol69enByctKW+fr6QgiBixcvllovJiYGubm5OttL9r5Vci1EREREZbHIZE6pVGLAgAFQqVRYu3YtfHx84O/v/9h6Xbt2RVZWFvLz87Vl//zzD+RyOZ566qlS6ykUCjg6OupsHGIlIiIqH6GRGW2rjC+//BLe3t5QKpXo3LkzUlNTyzz+p59+QvPmzaFUKtGqVSskJiZW6rzlZZHJHPBgqDUhIQErV64sV68cAERGRqJWrVoYMWIETpw4gZ07d2LKlCkYOXIk7OzsJG4xERERPWl++OEHTJw4ETNmzMDhw4fRpk0b9O7dG1euXNF7/N69e/Hyyy9j1KhR+Ouvv9C/f3/0798fx44dk6yNFpvMBQcHw9XVFenp6YiMjCxXHQcHB2zduhU3b95Ehw4dEBUVhbCwMCxevFji1hIREVVfQhhvq6j58+djzJgxGDFiBPz8/PDVV1+hRo0apS51tmjRIvTp0wdTpkyBr68vPvroI/j7++OLL74w8FUqncXdzVpMLpcjKyurwvWaN2+OrVu3StAiIiIiMjV9K1AoFAooFIoSxxYUFODQoUOIiYnRlsnlcoSEhGDfvn164+/btw8TJ07UKevduzc2btxoeONLYbE9c0RERGQejDlnTt8KFLGxsXrbde3aNRQVFcHd3V2n3N3dHdnZ2XrrZGdnV+j4qlCtkrkWLVrAwcFB76ZSqUzdPCIiIpKYvhUoHu55M0cWO8yqT2JiIgoLC/XuezSLJiIiIuMw5pMZShtS1cfNzQ1WVlbIycnRKc/JyYGHh4feOh4eHhU6vipUq545Ly8vNGnSRO9Ws2ZNUzePiIiIniC2trZo3749tm3bpi3TaDTYtm0bAgIC9NYJCAjQOR4Atm7dWurxVaFa9cwRERERVcTEiRMxbNgwdOjQAZ06dcLChQtx+/ZtjBgxAgAQHR2NevXqaefdjR8/Hj169MC8efPw3HPPYd26dTh48CCWLVsmWRuZzBEREZFJPcmP2Ro8eDCuXr2K6dOnIzs7G23btkVSUpJ2etb58+d1HhfapUsXxMXFYdq0aXjvvffQtGlTbNy4ES1btpSsjTIhKrPqCj3OLo8XJYudJSvfWH9l/GctzQequ+1/ksQFAIXdfcliFxZI9yQPB5d7ksX+61/p5oDWV9yWJG6LQwsliSu1/FdGShb70l8OksW2ttZIFruOrzTvkU+PeEoSFwDe65rz+IMqKT3ZWbLYf1nVkCz2qxe+lyz2o442DDPauVqd+9Vo5zIW9swRERGRSbFbyTDV6gYIIiIiIkvDnjkiIiIyKWMuTWKJ2DNHREREZMbYM0dEREQm9STfzWoO2DP3iOHDh0Mmk5XYWrRoYeqmEREREZXAZO4RixYtwuXLl7XbhQsX4OrqikGDBpm6aURERBZJCONtlsgik7lly5bB09MTGo3uOkrh4eEYObLsNaGcnJzg4eGh3Q4ePIj//vtPu9IzERER0ZPEIpO5QYMG4fr160hOTtaW3bhxA0lJSYiKiqpQrG+++QYhISHw8vKq6mYSERERHtzNaqzNEllkMufi4oLQ0FDExcVpy+Lj4+Hm5oagoKByx8nKysLmzZsxevToMo9Tq9XIy8vT2QpEUaXbT0RERFReFpnMAUBUVBTWr18PtVoNAFCpVIiIiNB5ftrjfPvtt3B2dkb//v3LPC42NhZOTk462/e30w1pPhERUbUhhMxomyWy2GQuLCwMQggkJCTgwoUL2LVrV4WGWIUQWLlyJYYOHQpbW9syj42JiUFubq7ONsTex9BLICIiInosi11nTqlUYsCAAVCpVMjIyICPjw/8/f3LXX/Hjh3IyMjAqFGjHnusQqGAQqHQKbOVSfeAdiIiIktiqXPZjMVikzngwVBrv379cPz4cQwZMqRCdb/55ht07twZLVu2lKh1RERERIaz2GFWAAgODoarqyvS09MRGRlZ7nq5ublYv359uXrliIiIyDDCiJslsuieOblcjqysrArXc3Jywp07dyRoEREREVHVsuhkjoiIiJ58nDNnGIseZtWnRYsWcHBw0LupVCpTN4+IiIioQqpdz1xiYiIKCwv17nN3dzdya4iIiIgMU+2SOT6Wi4iI6MliqYv5Gku1G2YlIiIisiTVrmeOiIiIniwaUzfAzDGZk0iesJEsdpatdN3R+TJpVuGxspHuoyq3ki72/fvSfR9lEvaL9wi/IVnszC1lP96uulG+HCJZbIczOySLfeeWdN/Hq+k1JIn7ftBVSeICwNX90n3WCzTSfdgL+bAhApM5IiIiMjEBzpkzBOfMEREREZkx9swRERGRSWks9TlbRsKeOSIiIiIzxp45IiIiMikN58wZhD1zj1CpVGjTpg1q1KiBunXrYuTIkbh+/bqpm0VERESkF5O5h+zZswfR0dEYNWoUjh8/jp9++gmpqakYM2aMqZtGRERksQRkRtsskcUlc8uWLYOnpyc0Gt21x8LDwzFy5Mgy6+7btw/e3t5466230LBhQzzzzDN45ZVXkJqaKmWTiYiIiCrN4pK5QYMG4fr160hOTtaW3bhxA0lJSYiKiiqzbkBAAC5cuIDExEQIIZCTk4P4+Hj07dtX6mYTERFVWxojbpbI4pI5FxcXhIaGIi4uTlsWHx8PNzc3BAUFlVm3a9euUKlUGDx4MGxtbeHh4QEnJyd8+eWXZdZTq9XIy8vT2QpFUZVcDxEREVFZLC6ZA4CoqCisX78earUawIObGiIiIiCXl325J06cwPjx4zF9+nQcOnQISUlJyMzMxKuvvlpmvdjYWDg5OelsP94+UWXXQ0REZMk4Z84wFpnMhYWFQQiBhIQEXLhwAbt27XrsECvwICnr2rUrpkyZgtatW6N3795YsmQJVq5cicuXL5daLyYmBrm5uTrbS/Z+VXlJRERERHpZ5DpzSqUSAwYMgEqlQkZGBnx8fODv7//Yenfu3IG1te5LYmX14CnGQpS+PLVCoYBCodAps5Hx6cdERETlYalz2YzFIpM54MFQa79+/XD8+HEMGTKkXHXCwsIwZswYLF26FL1798bly5cxYcIEdOrUCZ6enhK3mIiIiKjiLDaZCw4OhqurK9LT0xEZGVmuOsOHD8etW7fwxRdfYNKkSXB2dkZwcDDmzJkjcWuJiIiIKsdikzm5XI6srKwK13vzzTfx5ptvStAiIiIi0ofDrIaxyBsgiIiIiKqLapXMtWjRAg4ODno3lUpl6uYRERFVS1yaxDAWO8yqT2JiIgoLC/Xuc3d3N3JriIiIiAxXrZI5Ly8vUzeBiIiIHqGxzA4zo6lWw6xERERElqZa9cwZU5aNdIsGX5ZL99zXHBRIEte9vVqSuACA+6Uv6GyogiPSfUTU+dLFdvH1lix2Ez9p/oTOf2WkJHEBQPlyiGSxrQPLt/RRZdT6Y7dkse3S8yWLnXPOUZK4Wbul677Zf8dVstge4r5ksU9b6Z86ZG40FjqXzVjYM0dERERkxtgzR0RERCYl3fhK9cCeOSIiIiIzxp45IiIiMik+AcIw7JkjIiIiMmPsmSMiIiKT0sh4N6sh2DP3iC+//BK+vr6ws7ODj48P1qxZY+omEREREZWKPXMPWbp0KWJiYrB8+XJ07NgRqampGDNmDFxcXBAWFmbq5hEREVkk3s1qGIvrmVu2bBk8PT2h0ehOpwwPD8fIkWUvSvrdd9/hlVdeweDBg9GoUSNERERg7NixmDNnjpRNJiIiIjN348YNREVFwdHREc7Ozhg1ahTy80tfnPvGjRt488034ePjAzs7OzRo0ABvvfUWcnNzK3xui0vmBg0ahOvXryM5OVlbduPGDSQlJSEqKqrMumq1GkqlUqfMzs4OqampKCy0jFW2iYiInjQaI25SiYqKwvHjx7F161b89ttv2LlzJ8aOHVvq8VlZWcjKysLcuXNx7NgxrF69GklJSRg1alSFz21xw6wuLi4IDQ1FXFwcevbsCQCIj4+Hm5sbgoKCyqzbu3dvrFixAv3794e/vz8OHTqEFStWoLCwENeuXUPdunX11lOr1VCrdR9XVSiKYCOT7pFeREREVHH6fmcrFAooFIpKxzx58iSSkpJw4MABdOjQAQDw+eefo2/fvpg7dy48PT1L1GnZsiXWr1+v/bpx48aYPXs2hgwZgvv378PauvwpmsX1zAEPsuP169drv1kqlQoRERGQy8u+3A8++AChoaF4+umnYWNjg/DwcAwbNgwAyqwbGxsLJycnnW3zreNVd0FEREQWTCMz3qbvd3ZsbKxB7d+3bx+cnZ21iRwAhISEQC6XY//+/eWOk5ubC0dHxwolcoCFJnNhYWEQQiAhIQEXLlzArl27HjvECjwYUl25ciXu3LmDzMxMnD9/Ht7e3qhZsyZq165dar2YmBjk5ubqbKE1W1TlJREREVEV0Pc7OyYmxqCY2dnZqFOnjk6ZtbU1XF1dkZ2dXa4Y165dw0cffVTm0GxpLG6YFQCUSiUGDBgAlUqFjIwM+Pj4wN/fv9z1bWxs8NRTTwEA1q1bh379+pXZM6eve5ZDrERERE+eigypTp069bE3QZ48edLgNuXl5eG5556Dn58fZs6cWeH6FpnMAQ+GWvv164fjx49jyJAh5arzzz//IDU1FZ07d8Z///2H+fPn49ixY/j2228lbi0REVH1pcGTuWjwpEmTMHz48DKPadSoETw8PHDlyhWd8vv37+PGjRvw8PAos/6tW7fQp08f1KxZEz///DNsbGwq3E6LTeaCg4Ph6uqK9PR0REZGlqtOUVER5s2bh/T0dNjY2CAoKAh79+6Ft7e3tI0lIiKiJ07t2rXLnGZVLCAgADdv3sShQ4fQvn17AMD27duh0WjQuXPnUuvl5eWhd+/eUCgU2LRpU4kVNcrLYpM5uVyOrKysCtXx9fXFX3/9JVGLiIiISB9zXzTY19cXffr0wZgxY/DVV1+hsLAQ48aNQ0REhPZO1kuXLqFnz55Ys2YNOnXqhLy8PDz77LO4c+cOvv/+e+Tl5SEvLw/AgyTSyqr807UsNpkjIiIiMhaVSoVx48ahZ8+ekMvlGDhwIBYvXqzdX1hYiPT0dNy5cwcAcPjwYe2drk2aNNGJde7cuQqNClarZK5Fixb4999/9e77+uuvy3XHKxEREVUtzZM5Za5CXF1dERcXV+p+b29vCPF/fZCBgYE6XxuiWiVziYmJpT7Jwd3d3citISIiIjJctUrmvLy8TN0EIiIieoSUj9mqDixy0WAiIiKi6qJa9cwZk5RZ8sAC9eMPqqQM1JAkbuSuu5LEBYCRhS6SxQ7udFGy2Hn/2koWO2tZpmSxlTX1T1Uw1M2rDpLEBQCHMzski13rj92SxVZ+vESy2B93eF+y2D3uSnNvYmNlriRxAaCby1XJYu/87/FLW1SWl4V0aZn73aymxp45IiIiIjPGnjkiIiIyKUu4m9WU2DNHREREZMbYM0dEREQmZSFT/0yGPXNEREREZow9c0RERGRS7JkzTLXqmbt8+TIiIyPRrFkzyOVyTJgwQe9xP/30E5o3bw6lUolWrVohMTHRuA0lIiIiKqdqlcyp1WrUrl0b06ZNQ5s2bfQes3fvXrz88ssYNWoU/vrrL/Tv3x/9+/fHsWPHjNxaIiKi6kHIjLdZIrNL5pYtWwZPT09oNLqdsuHh4Rg5cmSZdb29vbFo0SJER0fDyclJ7zGLFi1Cnz59MGXKFPj6+uKjjz6Cv78/vvjiiyq7BiIiIqKqYnbJ3KBBg3D9+nUkJydry27cuIGkpCRERUUZHH/fvn0ICQnRKevduzf27dtncGwiIiKiqmZ2yZyLiwtCQ0MRFxenLYuPj4ebmxuCgoIMjp+dnQ13d3edMnd3d2RnZ5daR61WIy8vT2crFEUGt4WIiKg60Bhxs0Rml8wBQFRUFNavXw+1+sEzSlUqFSIiIiCXm+ZyYmNj4eTkpLMl3jpukrYQERFR9WKWyVxYWBiEEEhISMCFCxewa9euKhliBQAPDw/k5OTolOXk5MDDw6PUOjExMcjNzdXZ+tZsUSXtISIisnTsmTOMWSZzSqUSAwYMgEqlwtq1a+Hj4wN/f/8qiR0QEIBt27bplG3duhUBAQGl1lEoFHB0dNTZbGRWVdIeIiIiorKY7aLBUVFR6NevH44fP44hQ4aUu15aWhoAID8/H1evXkVaWhpsbW3h5+cHABg/fjx69OiBefPm4bnnnsO6detw8OBBLFu2TIrLICIiqvaEqRtg5sw2mQsODoarqyvS09MRGRlZ7nrt2rXT/vvQoUOIi4uDl5cXMjMzAQBdunRBXFwcpk2bhvfeew9NmzbFxo0b0bJly6q+BCIiIiKDmW0yJ5fLkZWVVeF6Qjw+/x80aBAGDRpUmWYRERFRBWksdDFfYzHLOXNERERE9IBFJXMtWrSAg4OD3k2lUpm6eURERKQH72Y1jNkOs+qTmJiIwsJCvfseXQiYiIiIyBJYVDLn5eVl6iYQERFRBVlqj5mxWNQwKxEREVF1Y1E9c0+S+xLG9vDIkyz2/Sxp8vtfDn8hSVwAONrubcliK5+rmsWo9Sn66bBksTNPuEoWu+X/ekgSN//t3yWJCwB3btlKFtsuPV+y2B93eF+62AdnSxZ7bIcpksSdWUP/NJqqYKOU7nnaWbekW0XNxUJuA+U6c4ZhzxwRERGRGWPPHBEREZmUhXQwmgx75oiIiIjMGHvmiIiIyKR4N6th2DNHREREZMaqVTJ3+fJlREZGolmzZpDL5ZgwYUKJY44fP46BAwfC29sbMpkMCxcuNHo7iYiIqhNhxM0SVatkTq1Wo3bt2pg2bRratGmj95g7d+6gUaNG+PTTT+Hh4WHkFhIRERFVjNklc8uWLYOnpyc0Gt0R9vDwcIwcObLMut7e3li0aBGio6Ph5OSk95iOHTvif//7HyIiIqBQKKqs3URERERSMLtkbtCgQbh+/TqSk5O1ZTdu3EBSUhKioqJM2DIiIiKqDA2E0TZLZHbJnIuLC0JDQxEXF6cti4+Ph5ubG4KCgkzYMiIiIiLjM7tkDgCioqKwfv16qNVqAIBKpUJERATkctNcjlqtRl5ens5WKKR7NAwREZEl0Rhxs0RmmcyFhYVBCIGEhARcuHABu3btMukQa2xsLJycnHS2pFvHTdYeIiIiqj7MMplTKpUYMGAAVCoV1q5dCx8fH/j7S/dA9MeJiYlBbm6uztanZguTtYeIiMiccGkSw5jtEyCioqLQr18/HD9+HEOGDCl3vbS0NABAfn4+rl69irS0NNja2sLPzw8AUFBQgBMnTmj/fenSJaSlpcHBwQFNmjTRG1OhUJS489VGZlWJqyIiIiKqGLNN5oKDg+Hq6or09HRERkaWu167du20/z506BDi4uLg5eWFzMxMAEBWVpbOMXPnzsXcuXPRo0cPpKSkVFXziYiI6P+z1LlsxmK2yZxcLkdWVlaF6wlRdiert7f3Y48hIiIielKYbTJHRERElkEjM3ULzJtZ3gBRmhYtWsDBwUHvplKpTN08IiIioipnUT1ziYmJKCws1LvP3d3dyK0hIiKi8rDUJzMYi0Ulc15eXqZuAhEREZFRWVQyR0REROaH/XKGsag5c0RERETVDXvmJBL9SX3JYi+bJlloRLa6IEncw60nSxIXAFov7ihZ7JqRSyWLvcmlm2Sxm9X6T7LYp15LliSuV7vbksQFgKvpNSSLnXPOUbLYPe5K118xtsMUyWIvO/g/SeKe6/a6JHEBQH1Xul+HU3a/I1lsTXaGZLGNievMGYY9c0RERERmjD1zREREZFK8m9Uw7JkjIiIiMtCNGzcQFRUFR0dHODs7Y9SoUcjPzy9XXSEEQkNDIZPJsHHjxgqfm8kcERERkYGioqJw/PhxbN26Fb/99ht27tyJsWPHlqvuwoULIZNV/jEYHGYlIiIikzLmIKtarYZardYpUygUUCgUlY558uRJJCUl4cCBA+jQoQMA4PPPP0ffvn0xd+5ceHp6llo3LS0N8+bNw8GDB1G3bt1Knb9a9cxdvnwZkZGRaNasGeRyOSZMmFDimOXLl6Nbt25wcXGBi4sLQkJCkJqaavzGEhERUZWLjY2Fk5OTzhYbG2tQzH379sHZ2VmbyAFASEgI5HI59u/fX2q9O3fuIDIyEl9++SU8PDwqff5qlcyp1WrUrl0b06ZNQ5s2bfQek5KSgpdffhnJycnYt28f6tevj2effRaXLl0ycmuJiIiqB40Rt5iYGOTm5upsMTExBrU/OzsbderU0SmztraGq6srsrOzS6339ttvo0uXLggPDzfo/GaXzC1btgyenp7QaHRXpQkPD8fIkSPLrOvt7Y1FixYhOjoaTk5Oeo9RqVR4/fXX0bZtWzRv3hwrVqyARqPBtm3bquwaiIiIyDQUCgUcHR11ttKGWKdOnQqZTFbmdurUqUq1Y9OmTdi+fTsWLlxowNU8YHZz5gYNGoQ333wTycnJ6NmzJ4AHd5AkJSUhMTGxys93584dFBYWwtXVtcpjExER0ZO7NMmkSZMwfPjwMo9p1KgRPDw8cOXKFZ3y+/fv48aNG6UOn27fvh1nzpyBs7OzTvnAgQPRrVs3pKSklLudZpfMubi4IDQ0FHFxcdpkLj4+Hm5ubggKCqry87377rvw9PRESEhIqcfom0ypKbwPhY3ZvbxERET0/9WuXRu1a9d+7HEBAQG4efMmDh06hPbt2wN4kKxpNBp07txZb52pU6di9OjROmWtWrXCggULEBYWVqF2mt0wK/Dg9t/169drEyiVSoWIiAjI5VV7OZ9++inWrVuHn3/+GUqlstTj9E2m/N9v+6q0LURERJZKGHGTgq+vL/r06YMxY8YgNTUVe/bswbhx4xAREaG9k/XSpUto3ry59qZKDw8PtGzZUmcDgAYNGqBhw4YVOr9ZJnNhYWEQQiAhIQEXLlzArl27EBUVVaXnmDt3Lj799FP8/vvvaN26dZnH6ptMOaVfQJW2h4iIiJ5cKpUKzZs3R8+ePdG3b18888wzWLZsmXZ/YWEh0tPTcefOnSo/t1mOAyqVSgwYMAAqlQoZGRnw8fGBv79/lcX/7LPPMHv2bGzZskXnNuPS6Fuf5i6HWImIiMpF8/hDnniurq6Ii4srdb+3tzeEKLtv8HH7S2O2GUdUVBT69euH48ePY8iQIeWul5aWBgDIz8/H1atXkZaWBltbW/j5+QEA5syZg+nTpyMuLg7e3t7aW4odHBzg4OBQ5ddBREREZAizTeaCg4Ph6uqK9PR0REZGlrteu3bttP8+dOgQ4uLi4OXlhczMTADA0qVLUVBQgBdffFGn3owZMzBz5syqaDoRERE9RDyhd7OaC7NN5uRyObKysipc73FdmMVJHREREZE5MNtkjoiIiCyDJcyZMyWzvJu1NC1atNDObXt0U6lUpm4eERERUZWzqJ65xMREFBYW6t3n7u5u5NYQERFReTypT4AwFxaVzHl5eZm6CURERERGZVHJHBEREZkf9ssZxqLmzBERERFVNzJR2eWGqUxL6pd/IeOKciySLDRa2+ZKElcuN8+32QG1s2Sxhxz5ULLYv7d4X7LYnoqqfxQNAKyV15AkLgC8H3RVsthZu20liy23ku5zo6yhf35xVVDflWbQp+GuJZLEBYDTnd+ULHaRRrp+E4VSuu9js5NJksV+1Cveg4x2rq8zfzLauYyFPXNEREREZozJHBEREZEZ4w0QREREZFJcNNgw7JkjIiIiMmPsmSMiIiKTElycxCDVqmfu8uXLiIyMRLNmzSCXyzFhwoQSx2zYsAEdOnSAs7Mz7O3t0bZtW3z33XfGbywRERFROVSrnjm1Wo3atWtj2rRpWLBggd5jXF1d8f7776N58+awtbXFb7/9hhEjRqBOnTro3bu3kVtMRERk+ThnzjBm1zO3bNkyeHp6QqPR/daHh4dj5MiRZdb19vbGokWLEB0dDScnJ73HBAYG4oUXXoCvry8aN26M8ePHo3Xr1ti9e3eVXQMRERFRVTG7ZG7QoEG4fv06kpOTtWU3btxAUlISoqKiqvRcQghs27YN6enp6N69e5XGJiIiogeEEf+zRGY3zOri4oLQ0FDExcWhZ8+eAID4+Hi4ubkhKCioSs6Rm5uLevXqQa1Ww8rKCkuWLEGvXr1KPV6tVkOtVuuUFYoi2MisqqQ9RERERKUxu545AIiKisL69eu1CZRKpUJERATk8qq5nJo1ayItLQ0HDhzA7NmzMXHiRKSkpJR6fGxsLJycnHS23/OOV0lbiIiILJ3GiJslMstkLiwsDEIIJCQk4MKFC9i1a1eVDrHK5XI0adIEbdu2xaRJk/Diiy8iNja21ONjYmKQm5ursz3r2KLK2kNERERUGrMbZgUApVKJAQMGQKVSISMjAz4+PvD395fsfBqNpsQw6sMUCgUUCoVOGYdYiYiIykcjLHMum7GYZTIHPBhq7devH44fP44hQ4aUu15aWhoAID8/H1evXkVaWhpsbW3h5+cH4MGQaYcOHdC4cWOo1WokJibiu+++w9KlS6W4DCIiIiKDmG0yFxwcDFdXV6SnpyMyMrLc9dq1a6f996FDhxAXFwcvLy9kZmYCAG7fvo3XX38dFy9ehJ2dHZo3b47vv/8egwcPrupLICIiIsBC7zE1HrNN5uRyObKysipcTzymK/fjjz/Gxx9/XNlmERERERmV2SZzREREZBk07JsziFnezVqaFi1awMHBQe+mUqlM3TwiIiKiKmdRPXOJiYkoLCzUu8/d3d3IrSEiIqLysNQnMxiLRSVzXl5epm4CERERkVFZ1DArERERUXVjUT1zREREZH4s9TFbxsJkTiKtCu9JFvuekO7pEtfu2kkS18PhtiRxAcCjZb5ksdsclu61/rXlNMliu8v0zx2tCjbWRZLEfS8gR5K4AHB1v41ksfffcZUsdjeXq5LFtlFK830EAPVdaX61nO78piRxAaDp/s8li/1v99cki21tyzSImMwRERGRiXFpEsNwzhwRERGRGWPPHBEREZkUlyYxDHvmiIiIiMwYe+aIiIjIpHgbh2GqVc/c5cuXERkZiWbNmkEul2PChAllHr9u3TrIZDL079/fKO0jIiIiqqhqlcyp1WrUrl0b06ZNQ5s2bco8NjMzE5MnT0a3bt2M1DoiIqLqSQhhtM0SmV0yt2zZMnh6ekKj0e2UDQ8Px8iRI8us6+3tjUWLFiE6OhpOTk6lHldUVISoqCjMmjULjRo1qpJ2ExEREUnB7JK5QYMG4fr160hOTtaW3bhxA0lJSYiKiqqSc3z44YeoU6cORo0aVSXxiIiIqHQaCKNtlsjsboBwcXFBaGgo4uLi0LNnTwBAfHw83NzcEBQUZHD83bt345tvvkFaWlq566jVaqjVap2yAlEEW5l0Tw8gIiIiAsywZw4AoqKisH79em0CpVKpEBERAbncsMu5desWhg4diuXLl8PNza3c9WJjY+Hk5KSzfX873aC2EBERVRcaI26WyOx65gAgLCwMQggkJCSgY8eO2LVrFxYsWGBw3DNnziAzMxNhYWHasuK5edbW1khPT0fjxo1L1IuJicHEiRN1yg40HWZwe4iIiIgexyyTOaVSiQEDBkClUiEjIwM+Pj7w9/c3OG7z5s1x9OhRnbJp06bh1q1bWLRoEerXr6+3nkKhgEKh0CnjECsREVH58AkQhjHLZA54MNTar18/HD9+HEOGDCl3veK5cPn5+bh69SrS0tJga2sLPz8/KJVKtGzZUud4Z2dnAChRTkRERPQkMNtkLjg4GK6urkhPT0dkZGS567Vr107770OHDiEuLg5eXl7IzMyUoJVERET0OJZ6l6mxmG0yJ5fLkZWVVeF6FV0wcPXq1RU+BxEREZGxmG0yR0RERJbBUp/MYCxmuTRJaVq0aAEHBwe9m0qlMnXziIiIiKqcRfXMJSYmorCwUO8+d3d3I7eGiIiISHoW1TPn5eWFJk2a6N1q1qxp6uYRERGRHpawaPCNGzcQFRUFR0dHODs7Y9SoUcjPz39svX379iE4OBj29vZwdHRE9+7dcffu3Qqd26KSOSIiIiJTiIqKwvHjx7F161b89ttv2LlzJ8aOHVtmnX379qFPnz549tlnkZqaigMHDmDcuHEVfqKVTHDWoSTuJq+QLHZyxB+Sxe7xijRxL/6YK01gAE+95CRZ7M5fZ0oWO1bWULLY7RtlSxb7QqaLZLGlUqCR7u/W20K62SqXraWLnWUt3Y/+KbvfkSRuevdpksQFADu7Aslie+1cKllsTdZpyWIrWveWLPajnq3fx2jn+jXjlxLPU9e3+H9FnDx5En5+fjhw4AA6dOgAAEhKSkLfvn1x8eJFeHp66q339NNPo1evXvjoo48qfW6APXNERERUjeh7nnpsbKxBMfft2wdnZ2dtIgcAISEhkMvl2L9/v946V65cwf79+1GnTh106dIF7u7u6NGjB3bv3l3h81vUDRBERERkfoy5aLC+56kb0isHANnZ2ahTp45OmbW1NVxdXZGdrX+k5OzZswCAmTNnYu7cuWjbti3WrFmDnj174tixY2jatGm5z8+eOSIiIqo2FAoFHB0ddbbSkrmpU6dCJpOVuZ06dapS7dBoHtyO8corr2DEiBFo164dFixYAB8fH6xcubJCsdgzR0RERCb1pE7fnzRpEoYPH17mMY0aNYKHhweuXLmiU37//n3cuHEDHh4eeuvVrVsXAODn56dT7uvri/Pnz1eonUzmiIiIiPSoXbs2ateu/djjAgICcPPmTRw6dAjt27cHAGzfvh0ajQadO3fWW8fb2xuenp5IT0/XKf/nn38QGhpaoXZa/DBrZmYmZDIZ0tLSTN0UIiIi0kMDYbRNCr6+vujTpw/GjBmD1NRU7NmzB+PGjUNERIT2TtZLly6hefPmSE1NBQDIZDJMmTIFixcvRnx8PDIyMvDBBx/g1KlTGDVqVIXOb/E9c/Xr18fly5fh5uZm6qYQERGRhVKpVBg3bhx69uwJuVyOgQMHYvHixdr9hYWFSE9Px507d7RlEyZMwL179/D222/jxo0baNOmDbZu3YrGjRtX6NwWncwVFBTA1ta21PFqIiIiMj1hxLtZpeLq6oq4uLhS93t7e+udGzh16lRMnTrVoHOb1TBrYGAgxo0bh3HjxsHJyQlubm744IMPtC+Ot7c3PvroI0RHR8PR0RFjx47VO8x6/Phx9OvXD46OjqhZsya6deuGM2fOaPevWLECvr6+UCqVaN68OZYsWWLsSyUiIiIqF7Prmfv2228xatQopKam4uDBgxg7diwaNGiAMWPGAADmzp2L6dOnY8aMGXrrX7p0Cd27d0dgYCC2b98OR0dH7NmzB/fv3wfwoJt0+vTp+OKLL9CuXTv89ddfGDNmDOzt7TFs2DCjXScREVF1oXlC72Y1F2aXzNWvXx8LFiyATCaDj48Pjh49igULFmiTueDgYEyaNEl7fGZmpk79L7/8Ek5OTli3bh1sbGwAAM2aNdPunzFjBubNm4cBAwYAABo2bIgTJ07g66+/LjWZU6vVJR4NoikohMLWxuDrJSIiIiqLWQ2zAg+eYyaTybRfBwQE4PTp0ygqKgIAnUdp6JOWloZu3bppE7mH3b59G2fOnMGoUaPg4OCg3T7++GOdYdhH6Xs0yP/iNlfyComIiKoXYcTNEpldz9zj2Nvbl7nfzs6u1H35+fkAgOXLl5dYF8bKyqrUevoeDaLZp3pcU4mIiIgMZnbJ3KMPrP3zzz/RtGnTMpOth7Vu3RrffvstCgsLS/TOubu7w9PTE2fPnkVUVFS526RQKEo8CuQuh1iJiIjKxZjPZrVEZjfMev78eUycOBHp6elYu3YtPv/8c4wfP77c9ceNG4e8vDxERETg4MGDOH36NL777jvtCsyzZs1CbGwsFi9ejH/++QdHjx7FqlWrMH/+fKkuiYiIiKjSzK5nLjo6Gnfv3kWnTp1gZWWF8ePHY+zYseWuX6tWLWzfvh1TpkxBjx49YGVlhbZt26Jr164AgNGjR6NGjRr43//+hylTpsDe3h6tWrXChAkTJLoiIiIiosozu2TOxsYGCxcuxNKlS0vse/TOVUD/In2tW7fGli1bSj1HZGQkIiMjDW4rERERPR6HWQ1jdsOsRERERPR/zK5njoiIiCyLvsdcUfmZVTKXkpJi6iYQERERPVHMKpkjIiIiy8M5c4bhnDkiIiIiM8aeOYnI7GpKFrv78ALJYtu+NVeSuAXflX8twIq6ufWKZLHdbRwli625L3v8QZXk8sYzksVOePecJHGLpHs5UFi+NcUr5bRVoWSxvTSShYaLRroXXJOdIUlchVK619raVroXW5N1WrLYcs+mksU2JsGeOYOwZ46IiIjIjLFnjoiIiEyKd7Mahj1zRERERGaMPXNERERkUryb1TDsmSMiIiIyY5VO5gIDA83i4fPe3t5YuHChqZtBREREpRBCGG2zRBY/zHrgwAHY29ubuhlEREREkrDYZK6goAC2traoXbu2qZtCREREZeCcOcNUyZy5//77D9HR0XBxcUGNGjUQGhqK06d1F0lcvnw56tevjxo1auCFF17A/Pnz4ezsXK74M2fORNu2bfH1119rY7z00kvIzc3VHjN8+HD0798fs2fPhqenJ3x8fACUHGa9efMmXnnlFbi7u0OpVKJly5b47bfftPt3796Nbt26wc7ODvXr18dbb72F27dvV/7FISIiIpJQlSRzw4cPx8GDB7Fp0ybs27cPQgj07dsXhYUPVuves2cPXn31VYwfPx5paWno1asXZs+eXaFzZGRk4Mcff8Svv/6KpKQk/PXXX3j99dd1jtm2bRvS09OxdetWnQStmEajQWhoKPbs2YPvv/8eJ06cwKeffgorqwfLw585cwZ9+vTBwIED8ffff+OHH37A7t27MW7cuEq+MkRERPQ4woj/WSKDh1lPnz6NTZs2Yc+ePejSpQsAQKVSoX79+ti4cSMGDRqEzz//HKGhoZg8eTIAoFmzZti7d6/ehKs09+7dw5o1a1CvXj0AwOeff47nnnsO8+bNg4eHBwDA3t4eK1asgK2trd4Yf/zxB1JTU3Hy5Ek0a9YMANCoUSPt/tjYWERFRWlv7GjatCkWL16MHj16YOnSpVAqlXrjqtVqqNVqnTJRUAiFrU25r4+IiIioMgzumTt58iSsra3RuXNnbVmtWrXg4+ODkydPAgDS09PRqVMnnXqPfv04DRo00CZyABAQEACNRoP09HRtWatWrUpN5AAgLS0NTz31lDaRe9SRI0ewevVqODg4aLfevXtDo9Hg3LnSn0cZGxsLJycnne1/azZW6PqIiIiqK40QRtsskUXdAPG4u1bt7OzK3J+fn49XXnkFb731Vol9DRo0KLVeTEwMJk6cqFMm0jaVeS4iIiKiqmBwMufr64v79+9j//792mHW69evIz09HX5+fgAAHx8fHDhwQKfeo18/zvnz55GVlQVPT08AwJ9//gm5XK690aE8WrdujYsXL+Kff/7R2zvn7++PEydOoEmTJhVqm0KhgEKh0Cm7xyFWIiIiMgKDh1mbNm2K8PBwjBkzBrt378aRI0cwZMgQ1KtXD+Hh4QCAN998E4mJiZg/fz5Onz6Nr7/+Gps3b4ZMJiv3eZRKJYYNG4YjR45g165deOutt/DSSy9p58uVR48ePdC9e3cMHDgQW7duxblz57B582YkJSUBAN59913s3bsX48aNQ1paGk6fPo1ffvmFN0AQERFJiDdAGKZK7mZdtWoV2rdvj379+iEgIABCCCQmJsLG5kHvVNeuXfHVV19h/vz5aNOmDZKSkvD222+XekOBPk2aNMGAAQPQt29fPPvss2jdujWWLFlS4bauX78eHTt2xMsvvww/Pz+88847KCoqAvCg527Hjh34559/0K1bN7Rr1w7Tp0/X9gYSERERPWkqPcyakpKi/beLiwvWrFlT5vFjxozBmDFjdL6u6HDma6+9htdee03vvtWrV+stz8zM1Pna1dUVK1euLPUcHTt2xO+//16hdhEREVHlWeqNCcZitBsg5s6di169esHe3h6bN2/Gt99+W6meNSIiIiL6P0ZL5lJTU/HZZ5/h1q1baNSoERYvXozRo0cDAFq0aIF///1Xb72vv/7aWE0kIiIiE7DUuWzGYrRk7scffyx1X2JiovZpEY9yd3dHzZo1MXPmTIlaRkRERGS+noh15ry8vEzdBCIiIjIRzpkzTJXczUpEREREJiLIpO7duydmzJgh7t27x9hmHNsc28zYlhPbHNvM2MaNLWWbq0ITN3+jbZZIJgT7Nk0pLy8PTk5OyM3NhaOjI2ObaWxzbDNjW05sc2wzYxs3tpRtrgpNa7c32rlOXz1ktHMZyxMxZ46IiIiqL86ZMwznzBERERGZMfbMERERkUlxnTnDsGfOxBQKBWbMmAGFQsHYZhzbHNvM2JYT2xzbzNjGjS1lm8n0eAMEERERmVTDWm2Mdq5z148Y7VzGwp45IiIiIjPGOXNERERkUhrOmTMIe+aIiIiIzBiTOSIiIiIzxmFWIiIiMinei2kY9swRERERmTEmcxZECIHz58/j3r17kp1DrVZDrVZLFp/0S0lJwd27d03djHJTq9U4c+aMWb5XcnJykJ2dXWXxioqKkJOTg6tXr1ZZTDKtc+fO4f79+6ZuhkXRQBhts0RM5kygsLAQ1tbWOHbsWJXGFUKgSZMmuHDhQpXG3bp1K/r27QsXFxfUqFEDNWrUgIuLC/r27Ys//vijSs/1sJMnT6JRo0aVrn/kyBF8/PHHWLJkCa5du6azLy8vDyNHjqx07BUrVmDYsGFYtWoVAOCHH36Ar68vGjVqhBkzZlQ6bmmeffZZZGZmGhTjypUrOl+npaVh2LBh6Nq1K1588UWkpKRUKu7q1auxb98+AMC9e/cwatQo2Nvbo1mzZnBwcMCrr75a6aSuVatW+Oijj6r8PQ0AN27cwIsvvogGDRrgtddeQ1FREUaPHo26deuiXr166NKlCy5fvlzp+AkJCejevTvs7e3h6ekJDw8PODs7Y+jQoTh//rxBbT9x4gRef/11tGvXDnXr1kXdunXRrl07vP766zhx4oRBscty5swZBAcHV6ru5cuX8f333yMxMREFBQU6+27fvo0PP/yw0u3aunUrZsyYge3btwMAdu7cidDQUAQHB2s/o1XJx8cHp0+frtKY3333Hbp27QpPT0/8+++/AICFCxfil19+qZL4BQUFSE9PZxJqqQSZRMOGDUVaWlqVx/Xz8xP79u2rsnirV68W1tbWIiIiQqxatUokJiaKxMREsWrVKvHyyy8LGxsbsWbNmio738PS0tKEXC6vVN0tW7YIW1tb0aJFC9GgQQNRq1YtsX37du3+7OzsSsdesGCBsLe3FwMGDBB169YVH3/8sahVq5b4+OOPxaxZs4Sjo6P4+uuvKxW7Xbt2ejeZTCZ8fX21X1eGXC4XOTk5Qggh9uzZI2xsbESPHj3ElClTRK9evYS1tbXYsWNHheM2bNhQ/Pnnn0IIISZPniy8vb3Fhg0bxMmTJ8XGjRtFs2bNxJQpUyrVZplMJmrVqiWsrKxE7969RXx8vCgsLKxUrEeNHDlStGzZUnz++eeiR48eIjw8XLRu3Vrs3r1b7N27V3Ts2FFER0dXKvaaNWtEzZo1xaRJk8T7778vPDw8xNSpU8XSpUtFjx49hJubm/jnn38qFTsxMVHY2tqKp59+WsyYMUMsWbJELFmyRMyYMUN06dJFKBQKkZSUVKnYj1PZz2RqaqpwdnYWjo6Ows7OTjRp0kQcO3ZMu9+Qz+N3330nrK2thb+/v3BwcBCrVq0Szs7OYvTo0WLkyJHC1tZW/PTTT5WK/cILL+jd5HK5CAkJ0X5tqCVLlgg3Nzfx8ccfCzs7O3HmzBkhhBCrVq0SgYGBBsW+ffu2GDlypLCyshJWVlba2OPGjROxsbEGt72qeDr7GW2TyvXr10VkZKSoWbOmcHJyEiNHjhS3bt0qs87ly5fFkCFDhLu7u6hRo4Zo166diI+Pr/C5+QQIE/nmm2+wYcMGfPfdd3B1da2yuL/++is+++wzLF26FC1btjQ4XrNmzTB+/Hi88cYbevcvWbIECxYsqNRfqRMnTixz/9WrVxEXF4eioqIKx+7SpQuCgoIwe/ZsCCHwv//9Dx999BF++ukn9OnTBzk5OfD09KxUbF9fX3zwwQeIjIzEX3/9hU6dOuGrr77CqFGjADz43i5duhQHDx6scGwbGxuEhITg6aef1pYJIfDRRx/h1VdfRZ06dQCgUr1/crkc2dnZqFOnDp599lnUr18f33zzjXb/hAkTcPToUWzbtq1CcZVKJf755x80aNAAPj4+WLRoEfr06aPdv3PnTgwdOlTb21DRNl+8eBGpqalYuXIlNm/eDBcXF0RHR2PUqFHw9fWtcMxinp6eiI+PR5cuXZCTk4O6detiy5Yt6NWrFwBgz549GDx4MC5evFjh2L6+vpg5cyYGDx4MADh48CBeeOEFnD9/HjKZDBERESgoKMCGDRsqHLtNmzYIDw8vtSdr5syZ2LBhA/7+++8Kx168eHGZ+y9duoS5c+dW+HPTq1cv1K9fHytWrMDt27fx7rvv4scff8TWrVvRrl07gz6P7dq1w4gRI/DWW29h27ZtCAsLw+zZs/H2228DAObNm4eff/4Zu3fvrnBsuVyO7t27o2HDhjrla9aswfPPPw9nZ2cAMLj3z8/PD5988gn69++PmjVr4siRI2jUqBGOHTuGwMDAEiMLFTF+/Hjs2bMHCxcuRJ8+ffD333+jUaNG+OWXXzBz5kz89ddfBrW9qtRzaWG0c13677gkcUNDQ3H58mV8/fXXKCwsxIgRI9CxY0fExcWVWufZZ5/FzZs38cUXX8DNzQ1xcXGYMWMGDh48iHbt2pX/5JXJPslwbdu2FQ4ODkKhUIhmzZqV6ImpLGdnZ2FrayvkcrlQKpXCxcVFZ6sohUIhTp06Ver+U6dOCaVSWam2yuVy4e/vLwIDA/VuHTp0qPRf646OjiIjI0OnTKVSCXt7e/Hrr78a1BNgZ2cn/v33X+3XCoVCp5fh9OnTwtnZuVKxd+/eLRo3biymT58uioqKtOXW1tbi+PHjlYpZTCaTaXvm6tatW6IH99ixY8LNza3Ccb28vLS9nvXq1RMHDhzQ2X/ixAlhb29vcJuFECIrK0t88sknomnTpkIul4uAgADxzTffVCp2jRo1RGZmpvZrGxsbcfToUe3XZ8+erXS77ezsxLlz53TKrK2txaVLl4QQQuzfv7/S7xGlUinZZ1ImkwlPT0/h7e2td/P09KzU58bFxUWkp6frlMXGxgoXFxeRmppq0OfR3t5enD17Vvu1jY2NOHLkiPbrkydPilq1alUq9tq1a8VTTz0lVq5cqVNeFZ/HhymVSu170cHBQdt79s8//1T6e1msQYMG2s/6w7FPnz4tatasaVDsquTh5Gu0TQonTpwQAHR+/m3evFnIZDLt514fe3v7EqNbrq6uYvny5RU6P5cmMZH+/ftLEnfhwoVVGq9Fixb45ptv8Nlnn+ndv3LlSvj5+VUqdpMmTfD2229jyJAhevenpaWhffv2lYqtUChw8+ZNnbLIyEjI5XIMHjwY8+bNq1RcAKhRowZu376t/bp27dpwcHDQOaay81K6du2KQ4cO4dVXX0WXLl2gUqnQuHHjSrf1Ubdu3YJSqYRSqSzxwG2lUok7d+5UOGZUVBTef/99JCYmYujQofjwww8RFxcHBwcH3LlzBzNnzkTXrl0r1V6ZTKbzdd26dRETE4OYmBikpKTgm2++wVtvvVWp+Y9NmzbFb7/9hjfeeAObN2+GUqnE77//ru3R3rJlS4kemfLy9vbGwYMH4e3tDQA4fPgw5HI53N3dAQCurq4oLCysdOyEhAT4+Pjo3Z+QkAAvL69Kxfby8sKcOXPw0ksv6d1vyGfy0Ruzpk6dCmtrazz77LNYuXJlpWICD3qzH56Dp1AodD6PCoWi0jcPRURE4Omnn8aQIUPw22+/YcWKFXBxcal0W0vTsGFDpKWllfi+JSUlGdT7DDwY4Sju0X/Y7du3S3y+qgt9N/IpFIoSPxMrYt++fXB2dkaHDh20ZSEhIZDL5di/fz9eeOEFvfW6dOmCH374Ac899xycnZ3x448/4t69ewgMDKzQ+ZnMmYgUk+QBYNiwYVUab968eejXrx+SkpIQEhKi/WWUk5ODbdu24ezZs0hISKhU7A4dOuDQoUOlJnMymazSaw+1bdsWycnJJX7xREREQAhh0OvUvHlz/P3339ofso9Ozj916pT2l3hlODk5Ye3atVi1ahWeeeYZzJo1q8p+6DZr1gzAg6HbR7vxjx8/Dk9PzwrHnDFjBo4dO4ZGjRqhQ4cO2LVrF9zd3VGvXj1kZWWhVq1a2Lp1a6XaW9b3PzAwEIGBgcjLy6tU7ClTpmDYsGFYuHAhLly4gO+//x7jx4/H/v37IZfLsWHDBsyfP79Ssd944w2MHj0aBw4cgFKpxIoVKzB06FBYWVkBAPbv36/9XlTUhx9+iMjISKSkpOj9TCYlJZU5rFOW9u3b49ChQ6Umc5X9TLZs2RJ79+5F69atdconT54MjUaDl19+uVLtBR78UXjq1Cltcnvp0iXUrFlTu//MmTN46qmnKh3f29sbO3fuxKxZs9CmTRssX768ypOgiRMn4o033sC9e/cghEBqairWrl2L2NhYrFixwqDYHTp0QEJCAt58800A//cH0ooVKxAQEGBw26uKMOJdprGxsZg1a5ZO2YwZMzBz5sxKxyyewvIwa2truLq6lnl3/I8//ojBgwejVq1asLa2Ro0aNfDzzz+jSZMmFTo/kzkTunnzJuLj43HmzBlMmTIFrq6uOHz4sPYXYWWdOXMGq1atwpkzZ7Bo0SLUqVMHmzdvRoMGDdCiRcXmJQQGBuLYsWNYunQp/vzzT+2b0sPDA6GhoXj11VcrnbjMmzevzLsc27RpA41GU6nYr732Gnbu3Kl338svvwwhBJYvX16p2HPmzIG9vX2p+8+fP49XXnmlUrEfNmLECDzzzDOIioqqkjvQkpOTdb6uW7euztfnzp3D2LFjKxzX1tYWv/zyC5KSkvDrr7/CysoKGo0GdevWRdeuXREZGVnm61WWYcOGwc7OrsxjHB0dKxU7KioK3t7e+PPPPxEQEIAuXbrAz88Pn376Ke7cuYNly5ZVOul/4403IJfL8f3330OtVmP48OH44IMPtPs7depU6YRr0KBBqFevHhYvXox58+bpfCYDAgKQkpJS6V/SH374YZm9s35+fjh37lyF40ZHR2PHjh149dVXS+x75513IITAV199VeG4APDee+/p9JY9+n44ePBgqclpecnlcsyaNQu9evVCdHR0peb2lWX06NGws7PDtGnTcOfOHURGRsLT0xOLFi1CRESEQbE/+eQThIaG4sSJE7h//z4WLVqEEydOYO/evdixY0cVXYF5iYmJKTFnu7ReualTp2LOnDllxjt58mSl2/LBBx/g5s2b+OOPP+Dm5oaNGzfipZdewq5du9CqVatyx+ENECby999/IyQkBE5OTsjMzER6ejoaNWqEadOm4fz581izZk2l4u7YsQOhoaHo2rUrdu7cqV3e49NPP8XBgwcRHx9fxVeia+3atXj++ecr/cubsUvSaDS4desWHB0dS/QIPMntNnZcxiZjyM/Px5kzZ+Dr6wtbW9sqj3/nzh3k5+frHRqtrDNnzuDTTz/FkSNHkJ+fD39/f7z77rsVShak5u7U3Gjnysk9Ve5jr169iuvXr5d5TKNGjfD9999j0qRJ+O+//7Tl9+/fh1KpxE8//aR3mPXMmTNo0qQJjh07ptPREhISgiZNmlToDxwmcyYSEhICf39/fPbZZzp3L+3duxeRkZGVXlMsICAAgwYNwsSJE3XipqamYsCAAZW6M68iHB0dkZaWZtD6cIxt2bHNsc3mHJuefMWLEDdt2lSn/PTp07CxsTFo2oa5eFKTufI6efIk/Pz8cPDgQe30nt9//x19+vTBxYsX9U5hOXr0KFq3bo0TJ07ozI3s3bs3vLy8sGzZsnKfn4sGm8iBAwf0DsXVq1fPoNXnjx49qvcvgDp16hh0e3t5Sfm3AWNbRmxzbLM5xTZ0sW1TxDbHNldl7OHDh2Pv3r0lyvfv34/hw4cbFDsxMRFbtmwpUb5lyxZs3rzZoNhVydyfAOHr64s+ffpgzJgxSE1NxZ49ezBu3DhERERoE7lLly6hefPmSE1NBfBg/nWTJk3wyiuvIDU1FWfOnMG8efOwdevWCt8kyWTORBQKhd6J2//88w9q165d6bjOzs56V63/66+/DJqHR0TmoaCgoFJr+pkytjm2uSpj//XXX3rv+H766aeRlpZmUOypU6fqneMnhMDUqVMNik26VCoVmjdvjp49e6Jv37545plndHrXCgsLkZ6erp2XamNjg8TERNSuXRthYWFo3bo11qxZg2+//RZ9+/at0Ll5A4SJPP/88/jwww/x448/Anhwh9H58+fx7rvvYuDAgZWOGxERgXfffRc//fQTZDIZNBoN9uzZg8mTJyM6Orqqmk9EJlKexbaftNjm2GapYz9MJpPh1q1bJcpzc3MNvtni9OnTepePat68OTIyMgyKXZUsYcaXq6trmTc2eXt7l7jOpk2bYv369Qafm8mcicybNw8vvvgi6tSpg7t376JHjx7Izs5GQEAAZs+eXem4n3zyCd544w3Ur18fRUVF8PPzQ1FRESIjIzFt2rQqvAIiMoVFixahbdu2pd7Fm5+f/8TFNsc2Sx37Yd27d0dsbCzWrl2rXb6mqKgIsbGxeOaZZwyK7eTkhLNnz5aYd5eRkcEbbiwIkzkTcXJywtatW7F79278/fff2juMQkJCDIpra2uL5cuXY/r06Th69Cjy8/PRrl27EhNricg8SbnYtlSxzbHNUsd+2Jw5c9C9e3f4+PigW7duAIBdu3YhLy8P27dvNyh2eHg4JkyYgJ9//lm7AHlGRgYmTZqE559/3uC2VxWNBfTMmRLnzJlI8WrozzzzDF5//XW88847BidywP+tE1W/fn307dsXL730Epo2bYq7d++W+izH8hg9ejRSUlIee5yXlxdsbGwYuxrGNsc2m2Ps4sW2S2PIYttSxTbHNksd+2F+fn74+++/8dJLL+HKlSu4desWoqOjcerUKYOfsf3ZZ5/B3t4ezZs3R8OGDdGwYUP4+vqiVq1amDt3rsFtpycDlyYxEaVSiU6dOqFHjx4ICgpCQEDAYxdHLQ8rKytcvny5xBpF169fR506dSo9/yI8PBxbtmxB7dq1ERERgSFDhqBNmzYGt5exLSe2ObbZHGNnZ2dDrVZX+pFdpohtjm2WOrYxCSGwdetWHDlyBHZ2dmjdujW6d+9u6mbpcHGo2BMPDPFf/pMzV7DKVOhJrlRldu3aJWbPni169eol7O3thUKhEF27dhXvvfee+P333ysdVyaTiStXrpQo37ZtW6Ueov6wGzduiK+//lr06NFDyOVy4efnJ2bPnl3igeKMXX1jm2ObzTl2ecTFxYn8/Hyzim2Oba5o7CNHjoiioiLtv8vaqoP/1979x1RVv3EAf1+QH8oXuJBgG1+YCAqtcCnNMlhA1gZkF8VZUwisCdLcdcKstjZKtsw/GqL4K7CrLNPbhjAYlwhcgDoXVxRjMhSB9Is60dQor5Je4H7/cN5JV0vuPfecew7v18Y/h+NzHsbU534+5/M8ap8I0b6UiCtzLmBkZATt7e0oKyvDgQMHMDY2NuEVtICAAKhUKvzxxx82kwJGR0dhMpmQl5eHnTt3CpLz5cuXodfrsXfvXvT29goyboqxlRVbjjnLOfaTyLHZsRxznmhsNzc36zxPNze3J27ZqlSqCf9/UFpaitzcXHh7e6O0tPQf7123bt2EYjsLV+YcwwMQEjp//jxaW1utX/fu3cPixYuRmJg44Vhbt26FxWLBBx98gKKiIvj7+1u/5+npiZkzZwo2VNlsNuPkyZMwGo24ePGiddA3YzO2s+My9sQ58/O6s2LLMeeJxr5w4YK1p6g9827/SUlJCTIyMuDt7Y2SkpIn3qdSqVymmHNWM9/JgsWcREJCQjA8PIzExEQkJibik08+wdy5c21mbz6thwPBw8PDERcXhylThP/VtrS04ODBg6iqqsLY2BjS09NhMBjw+uuvMzZjyzZnOccm+Xr4Hp7ZbEZRUREKCwsRHh4uSOxHi0OhC0VyTSzmJBIUFIRz585hcHAQg4ODuHbtGoaHhzFt2jSH4iYkJKC/vx/79u1Df38/tm3bhuDgYDQ0NCAsLGzcMN+JCAkJwa1bt5CcnIzy8nK8/fbb8PLycihXxlZWbDnmLOfYpAweHh6oqqpCYWGh4LHNZjOio6NhMBjGzf50RXzjyzEs5iTyyy+/YGhoCEePHsWRI0fw6aeforu7Gy+++CKSkpLsbhx85MgRpKSkIC4uDkePHsWmTZsQHByMzs5O6HQ6HDp0yK64GzduxPLly6FWq+3684yt/NhyzFnOsUk5lixZgpqaGuTn5wsa18PDw9oGi5SNByBcwM2bN9Ha2ora2lro9Xq7DkA8tHDhQixfvhwFBQXw9fVFZ2cnZs2ahRMnTiA9PR2XL18WOHsicmWP/jsgl9hyzNmR2F988QWKi4uxaNEixMbG2kxmcOS9ti+//BLnz5/HN99845TXb4Tyn2nCbDE/DdNd5W09u+5vVuGqq6utBx+6u7sRGBiI+Ph4FBcXIyEhwe64Z86ceexsuODgYNy4ccORlInIhaxevRqZmZn/emDK3mbHzogtx5ydHRsAdDod1Go1Tp06ZdOk2NFDCu3t7fjpp5/Q1NSEmJgYm0Kxurra7tjkOljMSSQvLw+vvfYacnNzkZCQgJiYGEHiqtVqXL161eZF2tOnTyMkJESQZxCR9H777TckJyf/a0Pirq4ul4ktx5ydHRsYf0jh4WaZvYfh/k6tVmPZsmWCxHImC0+zOoTbrAqzYcMGGI1GVFZWYs6cOejo6MC1a9eQlZWFrKwsfP7551KnSEQC+f3331FZWYmDBw/i2LFjiI6ORkZGBlauXGkzWN1VYssxZ2fHBh6szpWUlKC3txcAMHv2bKxfvx6rV692OLYc+EybKdqz7ty9KNqzxMJiTkKjo6OoqanB2bNnATyYz5eWlgZ3d3e7Y96/fx9r165FRUUFRkdHMWXKFIyOjmLlypWoqKhwKDYRuS45NjuWY87OiP3ZZ59hy5Yt0Gq11n6gP//8M3bs2IH8/HyH5mo/dP36dfT09AAAoqKibEY+Sm3qVPFGpg0P/0+0Z4mF26wS6evrQ2pqKq5cuYKoqCgAwObNmxEaGor6+npERETYFdfT0xN79uxBYWEhurq6YDKZMG/ePMyePVvI9InIhcix2bEcc3ZW7N27d2PPnj1YsWKF9ZpGo8HcuXOh1WodKub+/PNPrF27Ft9//731YJ27uzveffdd7Ny5c1yDeZIvN6kTmKzWrVuHiIgIXLp0CR0dHejo6MDAwADCw8MF6cgdFhaG1NRUvPPOOyzkiBSqpaUFOTk5mDFjBlatWgU/Pz8YDAZBTq07K7Ycc3Z2bLPZjJdeesnmemxsrMOrfjk5OTAajTAYDBgaGsLQ0BAMBgNOnjyJNWvWOBRbSBaLRbQvJeI2q0R8fHzQ1tZmc/Chs7MTcXFxMJlMdsW1WCw4dOgQWlpacP36dYyNjY37Pk8uESnDow2JMzIynNbsWMjYcszZ2bEBQKvVwsPDA1u2bBl3fcOGDRgeHnZopraPjw8aGxsRHx8/7vqxY8eQnJyMO3fu2B1bSN7eYaI966+/BkR7lli4zSoRLy8v3L592+a6yWSCp6en3XHXr1+PsrIyJCUlYcaMGYKdiCIi1yLHZsdyzNnZsR/S6XRoamrCK6+8AgAwGo0YGBhAVlYWCgoKrPf9veD7N88888xjt1L9/f0REBDgWNIC4mlWx3BlTiJZWVno6OiATqfDggULADz4y5uTk4PY2FhUVFTYFTcwMBDfffcdUlNTBcyWiIicJSkp6anuU6lUaG5unlDs8vJyVFZWYv/+/Xj22WcBAIODg8jOzkZ6errLbLV6eYeK9qx7f10S7VliYTEnkaGhIWRnZ6Ours7aZNJsNiMtLQ0VFRV2v5QaHh6OhoYGREdHC5kuERHJ0Lx589DX14d79+4hLOzBVubAwAC8vLxs3qfu6OiQIkUAgKfXf0V71v17ypuExG1WiajVatTW1qKvrw/d3d0AHrQmiYyMdCjuxo0bUVRUhL1792Lq1KlCpEpERDK1ZMkSqVMgEXBlTkLOaBI5PDyMpUuX4vjx45g5c6bNaBkpP3kREZFr0uv10Gg0NuO+xOLhKd6EIvP9K6I9SyxcmZPIk5pE5ufnY2BgwO6+QtnZ2Th16hQyMzN5AIKIiJ7KmjVr8PLLL2PWrFlSp0J24MqcRIKCglBaWjquSSTw4NORVqvFjRs37Ir7pGPoRERET+Lr64vOzk7JijmuzDmGK3MScVaTyNDQUPj5+TmSGhERkai4quQYToCQyHvvvYfdu3fbXC8vL0dGRobdcYuLi/Hxxx/j4sWLDmRHREREcsFtVolotVp8++23CA0NfWyTyEcPLkykSWRAQADu3r2LkZERTJs2zeYAxK1bt4T5AYiISDGk3mYlx3CbVSJdXV2YP38+AKC/vx8AMH36dEyfPh1dXV3W+yZ6gGHr1q2C5UhERESujytzREREk9wLL7yAhoYGhIaKN4mBhMNiToFGR0dRU1ODs2fPAgCef/55aDQauLu7S5wZERERCY3FnML09fUhNTUVV65cQVRUFACgp6cHoaGhqK+vR0REhMQZEhGRWAICAh77uo5KpYK3tzciIyOxatUqvP/++xJkR0JhMacwqampsFgsOHDgAAIDAwEAN2/eRGZmJtzc3FBfXy9xhkREJJaSkhJs2rQJKSkpWLBgAQDgxIkT+PHHH5Gfn48LFy5g//792L59O3JyciTOluzFYk5hfHx80NbWhpiYmHHXOzs7ERcXB5PJJFFmREQktmXLluHNN99EXl7euOtlZWVoampCVVUVtm/fjvLycpw5c0aiLMlR7DOnMF5eXrh9+7bNdZPJBE9PTwkyIiIiqTQ2NuKNN96wub5o0SI0NjYCeLCj8+uvv4qdGgmIxZzCLF68GLm5uTAajbBYLLBYLGhra0NeXh40Go3U6RERkYgCAwNRV1dnc72urs76Ks6dO3fg6+srdmokIPaZU5jS0lJkZ2dj4cKF1obBIyMj0Gg02LZtm8TZERGRmAoLC/Hhhx+ipaXF+s5ce3s7fvjhB3z99dcAgMOHDyMhIUHKNMlBfGdOoXp7e3Hu3DkAwHPPPYfIyEiJMyIiIikcP34cO3bsQE9PDwAgKioKWq0Wr776qsSZkVBYzBERERHJGLdZFaCgoOCp753InFciIpI/NpJXPhZzCnD69Omnum+ic16JiEjeHtdIfvPmzWwkrzDcZiUiIlIoNpKfHFjMERERKRQbyU8O3GZVgPT0dFRUVMDPzw9Lly79x+3U6upqETMjIiIpsZH85MBiTgH8/f2tBZxarX7ifXxnjohocnnYSF6n01n7zBmNRjaSVxhusyqMXq/HihUrHvu9jz76CF999ZXIGRERkVSGhoaQnZ2Nuro6ayN5s9mMtLQ07Nu37x8XAEg+WMwpjFqthl6vR0pKyrjrBQUF0Ov1uHr1qkSZERGRVPr6+qytSdhIXnlYzClMfX09MjIyYDAYEB8fDwDQarWoqqpCc3MzoqOjJc6QiIicib1HJx++M6cwb731Fnbt2gWNRoPDhw9Dp9OhtrYWra2tmDNnjtTpERGRk7H36OTDlTmF2rVrFwoKChAUFISWlhYuqRMRESkUizkFeNKSemVlJebPnz+uwzeX1ImIiJSFxZwCJCUlPdV9KpUKzc3NTs6GiIiIxMRijoiIiEjG3KROgIiIiIjsx2KOiIiISMZYzBERERHJGIs5IiIiIhljMUdEREQkYyzmiIiIiGSMxRwRERGRjP0fa1PQjXSSSjEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 热力图可视化相关性\n",
    "f , ax = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "plt.title('Correlation of Numeric Features with log_Price',y=1,size=14)\n",
    "\n",
    "sns.heatmap(correlation,square = True,  vmax=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WQ32OnuQnu75",
   "metadata": {
    "id": "WQ32OnuQnu75"
   },
   "source": [
    "+ 可以用与log_price的|相关性|作为筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AF8wRf87XL-q",
   "metadata": {
    "id": "AF8wRf87XL-q"
   },
   "source": [
    "# 3. 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tG8JYoNVXONl",
   "metadata": {
    "id": "tG8JYoNVXONl"
   },
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "train_data = pd.read_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/cleaned_train_data.csv')\n",
    "test_data = pd.read_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kOVJUyWSX2Az",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750496359346,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "kOVJUyWSX2Az",
    "outputId": "044a651f-c223-42f0-a0ab-037d4ed62c96"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ca7f3914-72a1-4cf8-bdc1-f6436c0a539d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>7.523481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>8.188967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "      <td>8.736007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "      <td>7.783641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "      <td>8.556606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca7f3914-72a1-4cf8-bdc1-f6436c0a539d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ca7f3914-72a1-4cf8-bdc1-f6436c0a539d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ca7f3914-72a1-4cf8-bdc1-f6436c0a539d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-8b8f88a2-6d0c-42c3-b7cb-91b8798c2a16\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b8f88a2-6d0c-42c3-b7cb-91b8798c2a16')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-8b8f88a2-6d0c-42c3-b7cb-91b8798c2a16 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0    6.0         1         0        0     60   \n",
       "1       1    2262  20030301   40.0    1.0         2         0        0      0   \n",
       "2       2   14874  20040403  115.0   15.0         1         0        0    163   \n",
       "3       3   71865  19960908  109.0   10.0         0         0        1    193   \n",
       "4       4  111080  20120103  110.0    5.0         1         0        0     68   \n",
       "\n",
       "   kilometer  ...       v_6       v_7       v_8       v_9      v_10      v_11  \\\n",
       "0         12  ...  0.101988  0.129549  0.022816  0.097462 -2.881803  2.804097   \n",
       "1         15  ...  0.121004  0.135731  0.026597  0.020582 -4.900482  2.096338   \n",
       "2         12  ...  0.114912  0.165147  0.062173  0.027075 -4.846749  1.803559   \n",
       "3         15  ...  0.110300  0.121964  0.033395  0.000000 -4.509599  1.285940   \n",
       "4          5  ...  0.073205  0.091880  0.078819  0.121534 -1.896240  0.910783   \n",
       "\n",
       "       v_12      v_13      v_14  log_price  \n",
       "0 -2.420821  0.795292  0.914762   7.523481  \n",
       "1 -1.030483 -1.722674  0.245522   8.188967  \n",
       "2  1.565330 -0.832687 -0.229963   8.736007  \n",
       "3 -0.501868 -2.438353 -0.478699   7.783641  \n",
       "4  0.931110  2.834518  1.923482   8.556606  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zo0DA3JlX8_1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1750496360937,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "Zo0DA3JlX8_1",
    "outputId": "3ccb79fa-2ebe-4564-aad1-641f925294d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
       "       'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',\n",
       "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
       "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14',\n",
       "       'log_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-7R9khihYdCJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1750496362292,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "-7R9khihYdCJ",
    "outputId": "16dd052e-d05c-4695-c98e-0d77d9bb21b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test_data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1163f0fe-0d00-4525-a8c1-8ffe05f402ae\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>66932</td>\n",
       "      <td>20111212</td>\n",
       "      <td>222.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264405</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.106558</td>\n",
       "      <td>0.078867</td>\n",
       "      <td>-7.050969</td>\n",
       "      <td>-0.854626</td>\n",
       "      <td>4.800151</td>\n",
       "      <td>0.620011</td>\n",
       "      <td>-3.664654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150001</td>\n",
       "      <td>174960</td>\n",
       "      <td>19990211</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096733</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>0.052383</td>\n",
       "      <td>3.679418</td>\n",
       "      <td>-0.729039</td>\n",
       "      <td>-3.796107</td>\n",
       "      <td>-1.541230</td>\n",
       "      <td>-0.757055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150002</td>\n",
       "      <td>5356</td>\n",
       "      <td>20090304</td>\n",
       "      <td>82.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260216</td>\n",
       "      <td>0.112081</td>\n",
       "      <td>0.078082</td>\n",
       "      <td>0.062078</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>-4.926690</td>\n",
       "      <td>1.001106</td>\n",
       "      <td>0.826562</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.754033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150003</td>\n",
       "      <td>50688</td>\n",
       "      <td>20100405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260466</td>\n",
       "      <td>0.106727</td>\n",
       "      <td>0.081146</td>\n",
       "      <td>0.075971</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>-4.864637</td>\n",
       "      <td>0.505493</td>\n",
       "      <td>1.870379</td>\n",
       "      <td>0.366038</td>\n",
       "      <td>1.312775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150004</td>\n",
       "      <td>161428</td>\n",
       "      <td>19970703</td>\n",
       "      <td>26.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077806</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.081709</td>\n",
       "      <td>3.616475</td>\n",
       "      <td>-0.673236</td>\n",
       "      <td>-3.197685</td>\n",
       "      <td>-0.025678</td>\n",
       "      <td>-0.101290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1163f0fe-0d00-4525-a8c1-8ffe05f402ae')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1163f0fe-0d00-4525-a8c1-8ffe05f402ae button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1163f0fe-0d00-4525-a8c1-8ffe05f402ae');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-7db11e14-1325-4324-b9b0-ad8880e6a037\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7db11e14-1325-4324-b9b0-ad8880e6a037')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-7db11e14-1325-4324-b9b0-ad8880e6a037 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0  150000   66932  20111212  222.0      4         5         1        1    313   \n",
       "1  150001  174960  19990211   19.0     21         0         0        0     75   \n",
       "2  150002    5356  20090304   82.0     21         0         0        0    109   \n",
       "3  150003   50688  20100405    0.0      0         0         0        1    160   \n",
       "4  150004  161428  19970703   26.0     14         2         0        0     75   \n",
       "\n",
       "   kilometer  ...       v_5       v_6       v_7       v_8       v_9      v_10  \\\n",
       "0         15  ...  0.264405  0.121800  0.070899  0.106558  0.078867 -7.050969   \n",
       "1         12  ...  0.261745  0.000000  0.096733  0.013705  0.052383  3.679418   \n",
       "2          7  ...  0.260216  0.112081  0.078082  0.062078  0.050540 -4.926690   \n",
       "3          7  ...  0.260466  0.106727  0.081146  0.075971  0.048268 -4.864637   \n",
       "4         15  ...  0.250999  0.000000  0.077806  0.028600  0.081709  3.616475   \n",
       "\n",
       "       v_11      v_12      v_13      v_14  \n",
       "0 -0.854626  4.800151  0.620011 -3.664654  \n",
       "1 -0.729039 -3.796107 -1.541230 -0.757055  \n",
       "2  1.001106  0.826562  0.138226  0.754033  \n",
       "3  0.505493  1.870379  0.366038  1.312775  \n",
       "4 -0.673236 -3.197685 -0.025678 -0.101290  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cOORMDQ0YTyz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750496364032,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "cOORMDQ0YTyz",
    "outputId": "99d4177a-1a8d-452c-96ec-f61ef4379543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
       "       'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',\n",
       "       'creatDate', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7',\n",
       "       'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ks4Kb8qkc409",
   "metadata": {
    "id": "Ks4Kb8qkc409"
   },
   "outputs": [],
   "source": [
    "# 训练集和测试集放在一起，方便构造特征\n",
    "# 构造新特征列train来区分训练集和测试集\n",
    "train_data['train']=1\n",
    "test_data['train']=0\n",
    "data = pd.concat([train_data, test_data], ignore_index=True) # 会根据所有列名自动对齐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QrkiXJj8cdQ_",
   "metadata": {
    "id": "QrkiXJj8cdQ_"
   },
   "source": [
    "## 3.1 构造汽车使用时间used_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H0Jk-G5SdOs2",
   "metadata": {
    "id": "H0Jk-G5SdOs2"
   },
   "outputs": [],
   "source": [
    "# 使用时间：data['creatDate'] - data['regDate']构造used_time，一般来说价格与使用时间成反比\n",
    "# 但数据里有时间出错的格式，所以需要 errors='coerce'，能强制将报错值设置为null\n",
    "data['used_time'] = (pd.to_datetime(data['creatDate'], format='%Y%m%d', errors='coerce') -\n",
    "                            pd.to_datetime(data['regDate'], format='%Y%m%d', errors='coerce')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wG65f4aHgIAC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1750496368664,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "wG65f4aHgIAC",
    "outputId": "28c00a37-2987-4429-8690-f0dd34aa49a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(26957)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除缺失数据占总样本量过大,不建议删除, 选择进行缺失值填充\n",
    "data['used_time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E_hehyUUfAc1",
   "metadata": {
    "id": "E_hehyUUfAc1"
   },
   "outputs": [],
   "source": [
    "# 用-1填充缺失值used_time中的null - 用于树模型的训练\n",
    "data['used_time'] = data['used_time'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ge5f_DXhfPvq",
   "metadata": {
    "id": "Ge5f_DXhfPvq"
   },
   "outputs": [],
   "source": [
    "# 用均值填充缺失值used_time中的null - 用于线性模型和神经网络的训练\n",
    "data['used_time_meanfill'] = data['used_time'].fillna(data['used_time'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pj4NmtB0hw5Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1750496371773,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "Pj4NmtB0hw5Z",
    "outputId": "981f870f-6138-403a-d497-1a41f9799006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
       "       'gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode',\n",
       "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
       "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14',\n",
       "       'log_price', 'train', 'used_time', 'used_time_meanfill'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvMAXSx3imE8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1750496373264,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "pvMAXSx3imE8",
    "outputId": "5c65dcf9-0c79-4f1c-f426-75acfe35071b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f4d20701-de86-491f-af80-deef8e71d669\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "      <th>log_price</th>\n",
       "      <th>train</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>7.523481</td>\n",
       "      <td>1</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>4385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>8.188967</td>\n",
       "      <td>1</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>4757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "      <td>8.736007</td>\n",
       "      <td>1</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>4382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "      <td>7.783641</td>\n",
       "      <td>1</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "      <td>8.556606</td>\n",
       "      <td>1</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>1531.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4d20701-de86-491f-af80-deef8e71d669')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f4d20701-de86-491f-af80-deef8e71d669 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f4d20701-de86-491f-af80-deef8e71d669');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-2cdc71b9-979e-476e-b106-a05cf2f4f9c4\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2cdc71b9-979e-476e-b106-a05cf2f4f9c4')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-2cdc71b9-979e-476e-b106-a05cf2f4f9c4 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0    6.0         1         0        0     60   \n",
       "1       1    2262  20030301   40.0    1.0         2         0        0      0   \n",
       "2       2   14874  20040403  115.0   15.0         1         0        0    163   \n",
       "3       3   71865  19960908  109.0   10.0         0         0        1    193   \n",
       "4       4  111080  20120103  110.0    5.0         1         0        0     68   \n",
       "\n",
       "   kilometer  ...       v_9      v_10      v_11      v_12      v_13      v_14  \\\n",
       "0         12  ...  0.097462 -2.881803  2.804097 -2.420821  0.795292  0.914762   \n",
       "1         15  ...  0.020582 -4.900482  2.096338 -1.030483 -1.722674  0.245522   \n",
       "2         12  ...  0.027075 -4.846749  1.803559  1.565330 -0.832687 -0.229963   \n",
       "3         15  ...  0.000000 -4.509599  1.285940 -0.501868 -2.438353 -0.478699   \n",
       "4          5  ...  0.121534 -1.896240  0.910783  0.931110  2.834518  1.923482   \n",
       "\n",
       "   log_price  train  used_time  used_time_meanfill  \n",
       "0   7.523481      1     4385.0              4385.0  \n",
       "1   8.188967      1     4757.0              4757.0  \n",
       "2   8.736007      1     4382.0              4382.0  \n",
       "3   7.783641      1     7125.0              7125.0  \n",
       "4   8.556606      1     1531.0              1531.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V03atfMAjnoI",
   "metadata": {
    "id": "V03atfMAjnoI"
   },
   "source": [
    "## 3.2 构造与汽车品牌相关的特征\n",
    "+ 一定程度上能反映品牌溢价、市场主流程度等间接语义\n",
    "+ 只在训练集上构造\n",
    "+ 相当于让模型学习一些关于品牌的特点，比如宝马是一个比较高端的品牌，大众是一个比较中等的品牌等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K2CmRso4jJBN",
   "metadata": {
    "id": "K2CmRso4jJBN"
   },
   "outputs": [],
   "source": [
    "# 要以 train 的数据计算统计量\n",
    "train_gb = train_data.groupby(\"brand\")\n",
    "all_info = {}\n",
    "for kind, kind_data in train_gb:\n",
    "    info = {}\n",
    "    kind_data = kind_data[kind_data['price'] > 0]\n",
    "    info['brand_amount'] = len(kind_data)\n",
    "    info['brand_price_max'] = kind_data.price.max()\n",
    "    info['brand_price_median'] = kind_data.price.median()\n",
    "    info['brand_price_min'] = kind_data.price.min()\n",
    "    info['brand_price_sum'] = kind_data.price.sum()\n",
    "    info['brand_price_std'] = kind_data.price.std()\n",
    "    info['brand_price_average'] = round(kind_data.price.sum() / (len(kind_data) + 1), 2)\n",
    "    all_info[kind] = info\n",
    "brand_fe = pd.DataFrame(all_info).T.reset_index().rename(columns={\"index\": \"brand\"})\n",
    "data = data.merge(brand_fe, how='left', on='brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hHdsTMQPpn2R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1750496376639,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "hHdsTMQPpn2R",
    "outputId": "8a5b13ca-a652-4911-bf1a-036d350de97e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-353f45dd-7bdc-4ee2-9245-8245be78c2a9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>...</th>\n",
       "      <th>train</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "      <th>brand_amount</th>\n",
       "      <th>brand_price_max</th>\n",
       "      <th>brand_price_median</th>\n",
       "      <th>brand_price_min</th>\n",
       "      <th>brand_price_sum</th>\n",
       "      <th>brand_price_std</th>\n",
       "      <th>brand_price_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>10076.0</td>\n",
       "      <td>59900.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>3.468970e+07</td>\n",
       "      <td>4656.121118</td>\n",
       "      <td>3442.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>13702.0</td>\n",
       "      <td>99900.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.234055e+08</td>\n",
       "      <td>9450.843699</td>\n",
       "      <td>9005.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>3.381581</td>\n",
       "      <td>1.387650e+07</td>\n",
       "      <td>5634.345867</td>\n",
       "      <td>9556.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>14147.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.476178</td>\n",
       "      <td>1.158543e+08</td>\n",
       "      <td>9046.159956</td>\n",
       "      <td>8188.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>4609.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1.151239</td>\n",
       "      <td>1.462294e+07</td>\n",
       "      <td>3381.498842</td>\n",
       "      <td>3172.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-353f45dd-7bdc-4ee2-9245-8245be78c2a9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-353f45dd-7bdc-4ee2-9245-8245be78c2a9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-353f45dd-7bdc-4ee2-9245-8245be78c2a9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-40fb4a48-a43f-46e1-a633-65cf81478d50\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40fb4a48-a43f-46e1-a633-65cf81478d50')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-40fb4a48-a43f-46e1-a633-65cf81478d50 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736  20040402   30.0    6.0         1         0        0     60   \n",
       "1       1    2262  20030301   40.0    1.0         2         0        0      0   \n",
       "2       2   14874  20040403  115.0   15.0         1         0        0    163   \n",
       "3       3   71865  19960908  109.0   10.0         0         0        1    193   \n",
       "4       4  111080  20120103  110.0    5.0         1         0        0     68   \n",
       "\n",
       "   kilometer  ...  train  used_time  used_time_meanfill  brand_amount  \\\n",
       "0         12  ...      1     4385.0              4385.0       10076.0   \n",
       "1         15  ...      1     4757.0              4757.0       13702.0   \n",
       "2         12  ...      1     4382.0              4382.0        1451.0   \n",
       "3         15  ...      1     7125.0              7125.0       14147.0   \n",
       "4          5  ...      1     1531.0              1531.0        4609.0   \n",
       "\n",
       "   brand_price_max  brand_price_median  brand_price_min  brand_price_sum  \\\n",
       "0          59900.0              1650.0         0.216981     3.468970e+07   \n",
       "1          99900.0              6100.0         0.011300     1.234055e+08   \n",
       "2          45000.0              8500.0         3.381581     1.387650e+07   \n",
       "3          98000.0              5000.0         0.476178     1.158543e+08   \n",
       "4          31500.0              2200.0         1.151239     1.462294e+07   \n",
       "\n",
       "   brand_price_std  brand_price_average  \n",
       "0      4656.121118              3442.46  \n",
       "1      9450.843699              9005.73  \n",
       "2      5634.345867              9556.82  \n",
       "3      9046.159956              8188.74  \n",
       "4      3381.498842              3172.01  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xMfNId8pp69V",
   "metadata": {
    "id": "xMfNId8pp69V"
   },
   "outputs": [],
   "source": [
    "data = data.drop(['creatDate','regDate','regionCode'],axis = 1) # 删除不需要的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D5sEa5kpqRB3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750496379054,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "D5sEa5kpqRB3",
    "outputId": "6a699a04-9852-4b15-cb90-c02a3394aa1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox',\n",
       "       'power', 'kilometer', 'notRepairedDamage', 'price', 'v_0', 'v_1', 'v_2',\n",
       "       'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',\n",
       "       'v_13', 'v_14', 'log_price', 'train', 'used_time', 'used_time_meanfill',\n",
       "       'brand_amount', 'brand_price_max', 'brand_price_median',\n",
       "       'brand_price_min', 'brand_price_sum', 'brand_price_std',\n",
       "       'brand_price_average'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8xNOeo8dr_bt",
   "metadata": {
    "id": "8xNOeo8dr_bt"
   },
   "source": [
    "## 3.3 对power做分桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1TrDQIg0sFQA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750496380417,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "1TrDQIg0sFQA",
    "outputId": "3edfccb4-2fe6-4242-bf3d-d0559cce9f82"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"data[['power_bin', 'power']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"power_bin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79,\n        \"min\": 0,\n        \"max\": 193,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          68,\n          163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-11e2265d-d899-49e1-ba65-987af80d8dc8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_bin</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11e2265d-d899-49e1-ba65-987af80d8dc8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-11e2265d-d899-49e1-ba65-987af80d8dc8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-11e2265d-d899-49e1-ba65-987af80d8dc8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-35829eed-f169-447b-936c-5b4c08b183a7\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35829eed-f169-447b-936c-5b4c08b183a7')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-35829eed-f169-447b-936c-5b4c08b183a7 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  power_bin  power\n",
       "0         1     60\n",
       "1         0      0\n",
       "2         4    163\n",
       "3         4    193\n",
       "4         1     68"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为什么要做数据分桶？\n",
    "# 1. 离散后稀疏向量内积乘法运算速度更快，计算结果也方便存储，容易扩展；\n",
    "# 2. 离散后的特征对异常值更具鲁棒性，如 age>30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；\n",
    "# 3. LR 属于广义线性模型，表达能力有限，经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；\n",
    "# 4. 离散后特征可以进行特征交叉，提升表达能力，由 M+N 个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；\n",
    "# 5. 特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化\n",
    "# 当然还有很多原因，LightGBM 在改进 XGBoost 时就增加了数据分桶，增强了模型的泛化性\n",
    "\n",
    "bins = [0, 50, 80, 120, 160, 200, 250, np.inf]\n",
    "labels = list(range(len(bins) - 1))\n",
    "data['power_bin'] = pd.cut(data['power'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "data[['power_bin', 'power']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FDIcGKq7HSai",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1750496396420,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "FDIcGKq7HSai",
    "outputId": "e3bcc831-2a74-4db3-942d-e3a1d0b0b708"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60,   0, 163, 193,  68, 109, 150, 101, 179,  88,  75,  58,  -1,\n",
       "       128, 239, 145,  45, 105,  54, 143, 218, 170,  90, 306, 133, 116,\n",
       "        15, 102, 177, 140, 115, 180, 131, 110, 160,  65, 120,  73,  77,\n",
       "       500, 136, 233, 125, 300, 190, 192, 126, 203,  55, 100, 122, 174,\n",
       "        69, 165, 320,  64,  78, 224,  80,  71, 340, 144, 387, 230,  86,\n",
       "       111,  12, 107,  61, 103,  63,  95, 204,  40, 284,   3,  97,   8,\n",
       "         1, 272,  50,  87, 260, 135,   9, 211, 106, 200, 333, 220,  10,\n",
       "       299, 114,  67, 245,  82, 196, 258,   4,  70, 155, 313, 113, 184,\n",
       "       345, 108,  98, 129,  84,  59, 250, 321, 235, 256, 231, 252, 197,\n",
       "       280,  41, 185, 232, 396,  43, 205,  99, 104,  85, 431, 225, 156,\n",
       "        46, 226, 175, 424,  92, 121, 130, 172,  91, 315, 141, 334, 119,\n",
       "       132, 420, 147, 305, 118,  44, 582, 117, 240, 112, 241, 385, 564,\n",
       "       124,   7, 194,   2, 450,  83, 182,   6, 286, 408,  39, 265,  56,\n",
       "       207, 581,  76, 367, 400, 137, 166, 355, 295, 151, 480,  74,  51,\n",
       "       555,  52,  57, 158, 167,  72,  94, 139, 349, 138,   5, 171, 275,\n",
       "       186, 354, 134, 322, 148, 360, 271, 560, 290,  79, 343, 237, 254,\n",
       "       457,  53, 152,  89, 209, 373, 344, 181, 162, 173, 259, 350,  66,\n",
       "       195, 292, 123, 187, 249, 243, 404, 169,  62, 309, 310,  48, 326,\n",
       "       587, 146, 476, 210, 242, 176, 557, 407, 159,  24,  11, 188, 164,\n",
       "       416, 329, 238, 386, 365, 525,  47, 497, 127, 435, 178, 328, 253,\n",
       "       330, 436, 510, 325, 201, 273, 314, 405, 449, 142, 149, 552, 198,\n",
       "       514, 352, 208, 168, 234, 247, 216, 540,  31, 189, 279, 228, 212,\n",
       "       432, 516, 335, 261, 376,  37, 421, 296,  33, 154,  81,  18, 262,\n",
       "        96, 277, 214, 353, 409, 380, 370, 401, 507, 585, 257, 213, 274,\n",
       "       215, 153, 285, 246, 362, 270, 442,  26, 551, 579, 287,  42, 278,\n",
       "       506, 347, 161, 426, 394, 289, 303, 217, 282, 440, 381, 244, 324,\n",
       "       302, 236, 183, 266, 229, 399, 348, 223, 519,  20, 202, 379, 517,\n",
       "       219, 363,  35, 430,  36,  25, 382, 445, 364, 460,  14, 264, 281,\n",
       "        93, 423, 206, 222, 157, 351, 327,  32, 307, 577, 505, 574, 191,\n",
       "       487, 375, 411, 298, 268, 308,  17, 338,  28, 501,  16, 263, 199,\n",
       "       586, 255, 288, 463,  34, 417, 468, 388, 283, 504, 276, 576, 372,\n",
       "        49, 443, 301,  19, 227, 390,  30, 526, 495, 439, 462, 371, 600,\n",
       "        23, 502, 269,  13, 515, 559, 318, 441, 556, 573, 455, 584, 466,\n",
       "       377, 398,  29, 473, 434, 317, 474, 346, 267, 535,  38, 521, 410,\n",
       "       319, 590, 392, 580, 470, 383, 341, 494, 536, 248, 477, 311, 415,\n",
       "       530, 336, 481, 558, 583, 221, 291, 575, 304, 597, 469, 570, 572,\n",
       "       332, 293, 331, 562, 368, 316, 549, 374, 358, 453, 486, 475, 538,\n",
       "       479, 339, 465, 509, 402, 428, 489, 437, 542, 482, 529, 369, 490])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['power'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6H8prlbMJPI0",
   "metadata": {
    "id": "6H8prlbMJPI0"
   },
   "outputs": [],
   "source": [
    "# 用均值填充power中的负值\n",
    "data['power'] = data['power'].replace(-1, np.nan)  # 把 -1 还原为缺失值\n",
    "data['power'] = data['power'].fillna(data['power'].mean())  # 用均值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YCqjLM_zI73A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1750496399275,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "YCqjLM_zI73A",
    "outputId": "867414e6-03ae-4761-a584-7acddd965042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60.        ,   0.        , 163.        , 193.        ,\n",
       "        68.        , 109.        , 150.        , 101.        ,\n",
       "       179.        ,  88.        ,  75.        ,  58.        ,\n",
       "       113.18754227, 128.        , 239.        , 145.        ,\n",
       "        45.        , 105.        ,  54.        , 143.        ,\n",
       "       218.        , 170.        ,  90.        , 306.        ,\n",
       "       133.        , 116.        ,  15.        , 102.        ,\n",
       "       177.        , 140.        , 115.        , 180.        ,\n",
       "       131.        , 110.        , 160.        ,  65.        ,\n",
       "       120.        ,  73.        ,  77.        , 500.        ,\n",
       "       136.        , 233.        , 125.        , 300.        ,\n",
       "       190.        , 192.        , 126.        , 203.        ,\n",
       "        55.        , 100.        , 122.        , 174.        ,\n",
       "        69.        , 165.        , 320.        ,  64.        ,\n",
       "        78.        , 224.        ,  80.        ,  71.        ,\n",
       "       340.        , 144.        , 387.        , 230.        ,\n",
       "        86.        , 111.        ,  12.        , 107.        ,\n",
       "        61.        , 103.        ,  63.        ,  95.        ,\n",
       "       204.        ,  40.        , 284.        ,   3.        ,\n",
       "        97.        ,   8.        ,   1.        , 272.        ,\n",
       "        50.        ,  87.        , 260.        , 135.        ,\n",
       "         9.        , 211.        , 106.        , 200.        ,\n",
       "       333.        , 220.        ,  10.        , 299.        ,\n",
       "       114.        ,  67.        , 245.        ,  82.        ,\n",
       "       196.        , 258.        ,   4.        ,  70.        ,\n",
       "       155.        , 313.        , 113.        , 184.        ,\n",
       "       345.        , 108.        ,  98.        , 129.        ,\n",
       "        84.        ,  59.        , 250.        , 321.        ,\n",
       "       235.        , 256.        , 231.        , 252.        ,\n",
       "       197.        , 280.        ,  41.        , 185.        ,\n",
       "       232.        , 396.        ,  43.        , 205.        ,\n",
       "        99.        , 104.        ,  85.        , 431.        ,\n",
       "       225.        , 156.        ,  46.        , 226.        ,\n",
       "       175.        , 424.        ,  92.        , 121.        ,\n",
       "       130.        , 172.        ,  91.        , 315.        ,\n",
       "       141.        , 334.        , 119.        , 132.        ,\n",
       "       420.        , 147.        , 305.        , 118.        ,\n",
       "        44.        , 582.        , 117.        , 240.        ,\n",
       "       112.        , 241.        , 385.        , 564.        ,\n",
       "       124.        ,   7.        , 194.        ,   2.        ,\n",
       "       450.        ,  83.        , 182.        ,   6.        ,\n",
       "       286.        , 408.        ,  39.        , 265.        ,\n",
       "        56.        , 207.        , 581.        ,  76.        ,\n",
       "       367.        , 400.        , 137.        , 166.        ,\n",
       "       355.        , 295.        , 151.        , 480.        ,\n",
       "        74.        ,  51.        , 555.        ,  52.        ,\n",
       "        57.        , 158.        , 167.        ,  72.        ,\n",
       "        94.        , 139.        , 349.        , 138.        ,\n",
       "         5.        , 171.        , 275.        , 186.        ,\n",
       "       354.        , 134.        , 322.        , 148.        ,\n",
       "       360.        , 271.        , 560.        , 290.        ,\n",
       "        79.        , 343.        , 237.        , 254.        ,\n",
       "       457.        ,  53.        , 152.        ,  89.        ,\n",
       "       209.        , 373.        , 344.        , 181.        ,\n",
       "       162.        , 173.        , 259.        , 350.        ,\n",
       "        66.        , 195.        , 292.        , 123.        ,\n",
       "       187.        , 249.        , 243.        , 404.        ,\n",
       "       169.        ,  62.        , 309.        , 310.        ,\n",
       "        48.        , 326.        , 587.        , 146.        ,\n",
       "       476.        , 210.        , 242.        , 176.        ,\n",
       "       557.        , 407.        , 159.        ,  24.        ,\n",
       "        11.        , 188.        , 164.        , 416.        ,\n",
       "       329.        , 238.        , 386.        , 365.        ,\n",
       "       525.        ,  47.        , 497.        , 127.        ,\n",
       "       435.        , 178.        , 328.        , 253.        ,\n",
       "       330.        , 436.        , 510.        , 325.        ,\n",
       "       201.        , 273.        , 314.        , 405.        ,\n",
       "       449.        , 142.        , 149.        , 552.        ,\n",
       "       198.        , 514.        , 352.        , 208.        ,\n",
       "       168.        , 234.        , 247.        , 216.        ,\n",
       "       540.        ,  31.        , 189.        , 279.        ,\n",
       "       228.        , 212.        , 432.        , 516.        ,\n",
       "       335.        , 261.        , 376.        ,  37.        ,\n",
       "       421.        , 296.        ,  33.        , 154.        ,\n",
       "        81.        ,  18.        , 262.        ,  96.        ,\n",
       "       277.        , 214.        , 353.        , 409.        ,\n",
       "       380.        , 370.        , 401.        , 507.        ,\n",
       "       585.        , 257.        , 213.        , 274.        ,\n",
       "       215.        , 153.        , 285.        , 246.        ,\n",
       "       362.        , 270.        , 442.        ,  26.        ,\n",
       "       551.        , 579.        , 287.        ,  42.        ,\n",
       "       278.        , 506.        , 347.        , 161.        ,\n",
       "       426.        , 394.        , 289.        , 303.        ,\n",
       "       217.        , 282.        , 440.        , 381.        ,\n",
       "       244.        , 324.        , 302.        , 236.        ,\n",
       "       183.        , 266.        , 229.        , 399.        ,\n",
       "       348.        , 223.        , 519.        ,  20.        ,\n",
       "       202.        , 379.        , 517.        , 219.        ,\n",
       "       363.        ,  35.        , 430.        ,  36.        ,\n",
       "        25.        , 382.        , 445.        , 364.        ,\n",
       "       460.        ,  14.        , 264.        , 281.        ,\n",
       "        93.        , 423.        , 206.        , 222.        ,\n",
       "       157.        , 351.        , 327.        ,  32.        ,\n",
       "       307.        , 577.        , 505.        , 574.        ,\n",
       "       191.        , 487.        , 375.        , 411.        ,\n",
       "       298.        , 268.        , 308.        ,  17.        ,\n",
       "       338.        ,  28.        , 501.        ,  16.        ,\n",
       "       263.        , 199.        , 586.        , 255.        ,\n",
       "       288.        , 463.        ,  34.        , 417.        ,\n",
       "       468.        , 388.        , 283.        , 504.        ,\n",
       "       276.        , 576.        , 372.        ,  49.        ,\n",
       "       443.        , 301.        ,  19.        , 227.        ,\n",
       "       390.        ,  30.        , 526.        , 495.        ,\n",
       "       439.        , 462.        , 371.        , 600.        ,\n",
       "        23.        , 502.        , 269.        ,  13.        ,\n",
       "       515.        , 559.        , 318.        , 441.        ,\n",
       "       556.        , 573.        , 455.        , 584.        ,\n",
       "       466.        , 377.        , 398.        ,  29.        ,\n",
       "       473.        , 434.        , 317.        , 474.        ,\n",
       "       346.        , 267.        , 535.        ,  38.        ,\n",
       "       521.        , 410.        , 319.        , 590.        ,\n",
       "       392.        , 580.        , 470.        , 383.        ,\n",
       "       341.        , 494.        , 536.        , 248.        ,\n",
       "       477.        , 311.        , 415.        , 530.        ,\n",
       "       336.        , 481.        , 558.        , 583.        ,\n",
       "       221.        , 291.        , 575.        , 304.        ,\n",
       "       597.        , 469.        , 570.        , 572.        ,\n",
       "       332.        , 293.        , 331.        , 562.        ,\n",
       "       368.        , 316.        , 549.        , 374.        ,\n",
       "       358.        , 453.        , 486.        , 475.        ,\n",
       "       538.        , 479.        , 339.        , 465.        ,\n",
       "       509.        , 402.        , 428.        , 489.        ,\n",
       "       437.        , 542.        , 482.        , 529.        ,\n",
       "       369.        , 490.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['power'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6DN8f6RbtXu4",
   "metadata": {
    "id": "6DN8f6RbtXu4"
   },
   "outputs": [],
   "source": [
    "# 导出树模型所需的数据集\n",
    "# 用于树模型的数值特征不需要进行归一化, 原因如下：\n",
    "# 1. 树模型按数值分裂(它关注的是“大小关系”，不关心数值的绝对量纲)\n",
    "# 2. 特征分布对模型影响不大(不依赖梯度传播或距离计算)\n",
    "data.to_csv('/content/drive/My Drive/推荐系统项目-二手车价格预测/data_for_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JQNUl4P2uqdq",
   "metadata": {
    "id": "JQNUl4P2uqdq"
   },
   "source": [
    "## 3.4 对数值特征做归一化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p9pmKmcxCS1y",
   "metadata": {
    "id": "p9pmKmcxCS1y"
   },
   "source": [
    "### 3.4.1 对power取log再做归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NRqzt8LRJ4nH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1750496425351,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "NRqzt8LRJ4nH",
    "outputId": "ac11da59-8191-452b-a2c2-9b41200019c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['power'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wXwXwVFqJz24",
   "metadata": {
    "id": "wXwXwVFqJz24"
   },
   "outputs": [],
   "source": [
    "data['power'] = np.log1p(data['power'])  # 等价于 np.log(data['power'] + 1)\n",
    "data['power'] = (data['power'] - data['power'].min()) / (data['power'].max() - data['power'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k0msOcEzpwg7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1750496430531,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "k0msOcEzpwg7",
    "outputId": "e2fb23fa-cae3-4908-ebaa-4e6405f3cc92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['power'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OUeEUwB0DKuz",
   "metadata": {
    "id": "OUeEUwB0DKuz"
   },
   "source": [
    "### 3.4.2 对所有数值特征做归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ieJgMuYUu2Yg",
   "metadata": {
    "id": "ieJgMuYUu2Yg"
   },
   "outputs": [],
   "source": [
    "def min_max_normalize(df, cols):\n",
    "    \"\"\"\n",
    "    对指定列进行min-max归一化处理（归一到[0,1]之间）\n",
    "    :param df: pandas.DataFrame, 原始数据\n",
    "    :param cols: list[str], 要归一化的列名列表\n",
    "    :return: 归一化后的DataFrame（原地修改）\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8W5Yu2HxxGfd",
   "metadata": {
    "id": "8W5Yu2HxxGfd"
   },
   "outputs": [],
   "source": [
    "num_cols = ['kilometer', \"used_time_meanfill\",'brand_amount','brand_price_average','brand_price_max','brand_price_median','brand_price_min', 'brand_price_std', 'brand_price_sum']\n",
    "data = min_max_normalize(data, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VKTjp3iiyXOH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1750496436840,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "VKTjp3iiyXOH",
    "outputId": "7315c9da-f800-4294-d845-da7bdefc5877"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-58bd9f76-1f3f-46c3-82ac-f66fff1ab800\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th>...</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "      <th>brand_amount</th>\n",
       "      <th>brand_price_max</th>\n",
       "      <th>brand_price_median</th>\n",
       "      <th>brand_price_min</th>\n",
       "      <th>brand_price_sum</th>\n",
       "      <th>brand_price_std</th>\n",
       "      <th>brand_price_average</th>\n",
       "      <th>power_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642465</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>0.475550</td>\n",
       "      <td>0.323856</td>\n",
       "      <td>0.587030</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.210398</td>\n",
       "      <td>0.179469</td>\n",
       "      <td>0.073866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.440481</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.189387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.391788</td>\n",
       "      <td>0.238992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>0.475225</td>\n",
       "      <td>0.046444</td>\n",
       "      <td>0.433578</td>\n",
       "      <td>0.274346</td>\n",
       "      <td>0.094849</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>0.222787</td>\n",
       "      <td>0.255350</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>0.772634</td>\n",
       "      <td>0.454794</td>\n",
       "      <td>0.979413</td>\n",
       "      <td>0.150448</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.702942</td>\n",
       "      <td>0.373868</td>\n",
       "      <td>0.214743</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>0.166106</td>\n",
       "      <td>0.148017</td>\n",
       "      <td>0.294545</td>\n",
       "      <td>0.051329</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.088624</td>\n",
       "      <td>0.123027</td>\n",
       "      <td>0.065839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58bd9f76-1f3f-46c3-82ac-f66fff1ab800')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-58bd9f76-1f3f-46c3-82ac-f66fff1ab800 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-58bd9f76-1f3f-46c3-82ac-f66fff1ab800');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-cd719470-e7e5-45b4-b0ef-ffdf90060f5c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd719470-e7e5-45b4-b0ef-ffdf90060f5c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-cd719470-e7e5-45b4-b0ef-ffdf90060f5c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name  model  brand  bodyType  fuelType  gearbox     power  \\\n",
       "0       0     736   30.0    6.0         1         0        0  0.642465   \n",
       "1       1    2262   40.0    1.0         2         0        0  0.000000   \n",
       "2       2   14874  115.0   15.0         1         0        0  0.797029   \n",
       "3       3   71865  109.0   10.0         0         0        1  0.823284   \n",
       "4       4  111080  110.0    5.0         1         0        0  0.661724   \n",
       "\n",
       "   kilometer  notRepairedDamage  ...  used_time  used_time_meanfill  \\\n",
       "0   0.684211                  0  ...     4385.0            0.475550   \n",
       "1   0.842105                 -1  ...     4757.0            0.515884   \n",
       "2   0.684211                  0  ...     4382.0            0.475225   \n",
       "3   0.842105                  0  ...     7125.0            0.772634   \n",
       "4   0.315789                  0  ...     1531.0            0.166106   \n",
       "\n",
       "   brand_amount  brand_price_max  brand_price_median  brand_price_min  \\\n",
       "0      0.323856         0.587030            0.031860         0.005788   \n",
       "1      0.440481         0.998980            0.189387         0.000000   \n",
       "2      0.046444         0.433578            0.274346         0.094849   \n",
       "3      0.454794         0.979413            0.150448         0.013083   \n",
       "4      0.148017         0.294545            0.051329         0.032081   \n",
       "\n",
       "   brand_price_sum  brand_price_std  brand_price_average  power_bin  \n",
       "0         0.210398         0.179469             0.073866          1  \n",
       "1         0.748766         0.391788             0.238992          0  \n",
       "2         0.084094         0.222787             0.255350          4  \n",
       "3         0.702942         0.373868             0.214743          4  \n",
       "4         0.088624         0.123027             0.065839          1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnhk4_Mbzgj7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1750496448793,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "rnhk4_Mbzgj7",
    "outputId": "eae1955d-5ef7-49d7-ca10-e67318932b4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox',\n",
       "       'power', 'kilometer', 'notRepairedDamage', 'price', 'v_0', 'v_1', 'v_2',\n",
       "       'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',\n",
       "       'v_13', 'v_14', 'log_price', 'train', 'used_time', 'used_time_meanfill',\n",
       "       'brand_amount', 'brand_price_max', 'brand_price_median',\n",
       "       'brand_price_min', 'brand_price_sum', 'brand_price_std',\n",
       "       'brand_price_average', 'power_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8g3jwv3jznwR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750496456452,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "8g3jwv3jznwR",
    "outputId": "d4db9f22-46ea-46a5-bc26-a516f4528462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 38)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yBzO0HOSzySs",
   "metadata": {
    "id": "yBzO0HOSzySs"
   },
   "source": [
    "## 3.5 对类别特征做one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F-KTzoCr3hTT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1750496458073,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "F-KTzoCr3hTT",
    "outputId": "c21c5801-d4de-472a-b71a-ca921352e0aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['brand'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ds-Q3zoc338p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1750496459449,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "ds-Q3zoc338p",
    "outputId": "7e09d226-8195-4870-9916-c81446231871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IMSt3OG1zx11",
   "metadata": {
    "id": "IMSt3OG1zx11"
   },
   "outputs": [],
   "source": [
    "data_for_lr = pd.get_dummies(data, columns=[\"model\", \"brand\", \"bodyType\", \"fuelType\", 'gearbox', 'notRepairedDamage', 'power_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQzpXmEf4gde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750496468647,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "sQzpXmEf4gde",
    "outputId": "3ae86964-ec7a-4913-e1cc-55de7227f5dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 349)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'power', 'kilometer', 'price', 'v_0', 'v_1', 'v_2',\n",
       "       'v_3', 'v_4',\n",
       "       ...\n",
       "       'notRepairedDamage_-1', 'notRepairedDamage_0', 'notRepairedDamage_1',\n",
       "       'power_bin_0', 'power_bin_1', 'power_bin_2', 'power_bin_3',\n",
       "       'power_bin_4', 'power_bin_5', 'power_bin_6'],\n",
       "      dtype='object', length=349)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_for_lr.shape)\n",
    "data_for_lr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j9jGUO4c4tgL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1750496472225,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "j9jGUO4c4tgL",
    "outputId": "914c605f-d0dd-43e0-905d-61e125171954"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data_for_lr"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a539cbb4-a802-4b41-a5c4-712becb13076\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>price</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>...</th>\n",
       "      <th>notRepairedDamage_-1</th>\n",
       "      <th>notRepairedDamage_0</th>\n",
       "      <th>notRepairedDamage_1</th>\n",
       "      <th>power_bin_0</th>\n",
       "      <th>power_bin_1</th>\n",
       "      <th>power_bin_2</th>\n",
       "      <th>power_bin_3</th>\n",
       "      <th>power_bin_4</th>\n",
       "      <th>power_bin_5</th>\n",
       "      <th>power_bin_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>0.642465</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>43.357796</td>\n",
       "      <td>3.966344</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>2.159744</td>\n",
       "      <td>1.143786</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>45.305273</td>\n",
       "      <td>5.236112</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>1.380657</td>\n",
       "      <td>-1.422165</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>45.978359</td>\n",
       "      <td>4.823792</td>\n",
       "      <td>1.319524</td>\n",
       "      <td>-0.998467</td>\n",
       "      <td>-0.996911</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>45.687478</td>\n",
       "      <td>4.492574</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>-2.228079</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>44.383511</td>\n",
       "      <td>2.031433</td>\n",
       "      <td>0.572169</td>\n",
       "      <td>-1.571239</td>\n",
       "      <td>2.246088</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 349 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a539cbb4-a802-4b41-a5c4-712becb13076')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a539cbb4-a802-4b41-a5c4-712becb13076 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a539cbb4-a802-4b41-a5c4-712becb13076');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-feb3db98-5f2b-401d-8b24-d966456c0b06\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-feb3db98-5f2b-401d-8b24-d966456c0b06')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-feb3db98-5f2b-401d-8b24-d966456c0b06 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name     power  kilometer   price        v_0       v_1       v_2  \\\n",
       "0       0     736  0.642465   0.684211  1850.0  43.357796  3.966344  0.050257   \n",
       "1       1    2262  0.000000   0.842105  3600.0  45.305273  5.236112  0.137925   \n",
       "2       2   14874  0.797029   0.684211  6222.0  45.978359  4.823792  1.319524   \n",
       "3       3   71865  0.823284   0.842105  2400.0  45.687478  4.492574 -0.050616   \n",
       "4       4  111080  0.661724   0.315789  5200.0  44.383511  2.031433  0.572169   \n",
       "\n",
       "        v_3       v_4  ...  notRepairedDamage_-1  notRepairedDamage_0  \\\n",
       "0  2.159744  1.143786  ...                 False                 True   \n",
       "1  1.380657 -1.422165  ...                  True                False   \n",
       "2 -0.998467 -0.996911  ...                 False                 True   \n",
       "3  0.883600 -2.228079  ...                 False                 True   \n",
       "4 -1.571239  2.246088  ...                 False                 True   \n",
       "\n",
       "   notRepairedDamage_1  power_bin_0  power_bin_1  power_bin_2  power_bin_3  \\\n",
       "0                False        False         True        False        False   \n",
       "1                False         True        False        False        False   \n",
       "2                False        False        False        False        False   \n",
       "3                False        False        False        False        False   \n",
       "4                False        False         True        False        False   \n",
       "\n",
       "   power_bin_4  power_bin_5  power_bin_6  \n",
       "0        False        False        False  \n",
       "1        False        False        False  \n",
       "2         True        False        False  \n",
       "3         True        False        False  \n",
       "4        False        False        False  \n",
       "\n",
       "[5 rows x 349 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dP3VA02x6qlD",
   "metadata": {
    "id": "dP3VA02x6qlD"
   },
   "outputs": [],
   "source": [
    "# LR使用的数据集\n",
    "data_for_lr.to_csv('/content/drive/My Drive/推荐系统项目-二手车价格预测/data_for_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k4wkZkMl62NQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750496541153,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "k4wkZkMl62NQ",
    "outputId": "70718abb-6baa-4b76-edf8-336441e0e790"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "data"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-214c6f34-1db3-4b95-8fb4-1138f0b579d6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th>...</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "      <th>brand_amount</th>\n",
       "      <th>brand_price_max</th>\n",
       "      <th>brand_price_median</th>\n",
       "      <th>brand_price_min</th>\n",
       "      <th>brand_price_sum</th>\n",
       "      <th>brand_price_std</th>\n",
       "      <th>brand_price_average</th>\n",
       "      <th>power_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.642465</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>0.475550</td>\n",
       "      <td>0.323856</td>\n",
       "      <td>0.587030</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.210398</td>\n",
       "      <td>0.179469</td>\n",
       "      <td>0.073866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.440481</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.189387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748766</td>\n",
       "      <td>0.391788</td>\n",
       "      <td>0.238992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>0.475225</td>\n",
       "      <td>0.046444</td>\n",
       "      <td>0.433578</td>\n",
       "      <td>0.274346</td>\n",
       "      <td>0.094849</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>0.222787</td>\n",
       "      <td>0.255350</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>0.772634</td>\n",
       "      <td>0.454794</td>\n",
       "      <td>0.979413</td>\n",
       "      <td>0.150448</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.702942</td>\n",
       "      <td>0.373868</td>\n",
       "      <td>0.214743</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>0.166106</td>\n",
       "      <td>0.148017</td>\n",
       "      <td>0.294545</td>\n",
       "      <td>0.051329</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.088624</td>\n",
       "      <td>0.123027</td>\n",
       "      <td>0.065839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-214c6f34-1db3-4b95-8fb4-1138f0b579d6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-214c6f34-1db3-4b95-8fb4-1138f0b579d6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-214c6f34-1db3-4b95-8fb4-1138f0b579d6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-c05dfe96-845c-4ec5-88fd-4e1a6528577a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c05dfe96-845c-4ec5-88fd-4e1a6528577a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-c05dfe96-845c-4ec5-88fd-4e1a6528577a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   SaleID    name  model  brand  bodyType  fuelType  gearbox     power  \\\n",
       "0       0     736   30.0    6.0         1         0        0  0.642465   \n",
       "1       1    2262   40.0    1.0         2         0        0  0.000000   \n",
       "2       2   14874  115.0   15.0         1         0        0  0.797029   \n",
       "3       3   71865  109.0   10.0         0         0        1  0.823284   \n",
       "4       4  111080  110.0    5.0         1         0        0  0.661724   \n",
       "\n",
       "   kilometer  notRepairedDamage  ...  used_time  used_time_meanfill  \\\n",
       "0   0.684211                  0  ...     4385.0            0.475550   \n",
       "1   0.842105                 -1  ...     4757.0            0.515884   \n",
       "2   0.684211                  0  ...     4382.0            0.475225   \n",
       "3   0.842105                  0  ...     7125.0            0.772634   \n",
       "4   0.315789                  0  ...     1531.0            0.166106   \n",
       "\n",
       "   brand_amount  brand_price_max  brand_price_median  brand_price_min  \\\n",
       "0      0.323856         0.587030            0.031860         0.005788   \n",
       "1      0.440481         0.998980            0.189387         0.000000   \n",
       "2      0.046444         0.433578            0.274346         0.094849   \n",
       "3      0.454794         0.979413            0.150448         0.013083   \n",
       "4      0.148017         0.294545            0.051329         0.032081   \n",
       "\n",
       "   brand_price_sum  brand_price_std  brand_price_average  power_bin  \n",
       "0         0.210398         0.179469             0.073866          1  \n",
       "1         0.748766         0.391788             0.238992          0  \n",
       "2         0.084094         0.222787             0.255350          4  \n",
       "3         0.702942         0.373868             0.214743          4  \n",
       "4         0.088624         0.123027             0.065839          1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RCzXyGUw7WGj",
   "metadata": {
    "id": "RCzXyGUw7WGj"
   },
   "outputs": [],
   "source": [
    "# DNN使用的数据集\n",
    "# 不需要对类别特征做one-hot编码,而是在DNN中做Embedding\n",
    "data.to_csv(r'/content/drive/My Drive/推荐系统项目-二手车价格预测/data_for_DNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JMDumCiGOvsS",
   "metadata": {
    "id": "JMDumCiGOvsS"
   },
   "source": [
    "# 4. 模型建立"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91oGY_EyQcJC",
   "metadata": {
    "id": "91oGY_EyQcJC"
   },
   "source": [
    "## 4.1 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "bdM2DPI5vl07",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750592384352,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "bdM2DPI5vl07"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ygN_SiVDVCTI",
   "metadata": {
    "executionInfo": {
     "elapsed": 13564,
     "status": "ok",
     "timestamp": 1750592400261,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "ygN_SiVDVCTI"
   },
   "outputs": [],
   "source": [
    "data_for_lr = pd.read_csv(r\"D:\\推荐系统资料\\白泽老师\\data_for_lr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "7VCxYDObO3WD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1750592400324,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "7VCxYDObO3WD",
    "outputId": "1c820252-43ed-4932-9f36-fc96c719e56d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>price</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>...</th>\n",
       "      <th>notRepairedDamage_-1</th>\n",
       "      <th>notRepairedDamage_0</th>\n",
       "      <th>notRepairedDamage_1</th>\n",
       "      <th>power_bin_0</th>\n",
       "      <th>power_bin_1</th>\n",
       "      <th>power_bin_2</th>\n",
       "      <th>power_bin_3</th>\n",
       "      <th>power_bin_4</th>\n",
       "      <th>power_bin_5</th>\n",
       "      <th>power_bin_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>0.642465</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>43.357796</td>\n",
       "      <td>3.966344</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>2.159744</td>\n",
       "      <td>1.143786</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>45.305273</td>\n",
       "      <td>5.236112</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>1.380657</td>\n",
       "      <td>-1.422165</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>45.978359</td>\n",
       "      <td>4.823792</td>\n",
       "      <td>1.319524</td>\n",
       "      <td>-0.998467</td>\n",
       "      <td>-0.996911</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>0.823284</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>45.687478</td>\n",
       "      <td>4.492574</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>-2.228079</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>0.661724</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>44.383511</td>\n",
       "      <td>2.031433</td>\n",
       "      <td>0.572169</td>\n",
       "      <td>-1.571239</td>\n",
       "      <td>2.246088</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name     power  kilometer   price        v_0       v_1       v_2  \\\n",
       "0       0     736  0.642465   0.684211  1850.0  43.357796  3.966344  0.050257   \n",
       "1       1    2262  0.000000   0.842105  3600.0  45.305273  5.236112  0.137925   \n",
       "2       2   14874  0.797029   0.684211  6222.0  45.978359  4.823792  1.319524   \n",
       "3       3   71865  0.823284   0.842105  2400.0  45.687478  4.492574 -0.050616   \n",
       "4       4  111080  0.661724   0.315789  5200.0  44.383511  2.031433  0.572169   \n",
       "\n",
       "        v_3       v_4  ...  notRepairedDamage_-1  notRepairedDamage_0  \\\n",
       "0  2.159744  1.143786  ...                 False                 True   \n",
       "1  1.380657 -1.422165  ...                  True                False   \n",
       "2 -0.998467 -0.996911  ...                 False                 True   \n",
       "3  0.883600 -2.228079  ...                 False                 True   \n",
       "4 -1.571239  2.246088  ...                 False                 True   \n",
       "\n",
       "   notRepairedDamage_1  power_bin_0  power_bin_1  power_bin_2  power_bin_3  \\\n",
       "0                False        False         True        False        False   \n",
       "1                False         True        False        False        False   \n",
       "2                False        False        False        False        False   \n",
       "3                False        False        False        False        False   \n",
       "4                False        False         True        False        False   \n",
       "\n",
       "   power_bin_4  power_bin_5  power_bin_6  \n",
       "0        False        False        False  \n",
       "1        False        False        False  \n",
       "2         True        False        False  \n",
       "3         True        False        False  \n",
       "4        False        False        False  \n",
       "\n",
       "[5 rows x 349 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5645adf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 349)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "WIRG-7IlQh7j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1750592415820,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "WIRG-7IlQh7j",
    "outputId": "ad177aff-cee6-4a31-bd05-9bbea227f267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_price      51563\n",
       "price          50000\n",
       "v_14           18760\n",
       "v_13            4703\n",
       "v_12            1921\n",
       "               ...  \n",
       "model_87.0         0\n",
       "model_86.0         0\n",
       "model_85.0         0\n",
       "model_84.0         0\n",
       "power_bin_6        0\n",
       "Length: 349, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_lr.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "OC-DHAXKV5Wy",
   "metadata": {
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1750592419056,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "OC-DHAXKV5Wy"
   },
   "outputs": [],
   "source": [
    "train_data = data_for_lr[data_for_lr['train'] == 1].drop(columns=['train']).reset_index(drop=True)\n",
    "test_data = data_for_lr[data_for_lr['train'] == 0].drop(columns=['train']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "VORf2qW9WO5R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1750592421563,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "VORf2qW9WO5R",
    "outputId": "c1ec95dc-0a46-4759-af40-b46adc28ecfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v_14           14116\n",
       "v_13            3583\n",
       "log_price       1563\n",
       "v_12            1469\n",
       "SaleID             0\n",
       "               ...  \n",
       "model_87.0         0\n",
       "model_86.0         0\n",
       "model_85.0         0\n",
       "model_84.0         0\n",
       "power_bin_6        0\n",
       "Length: 348, dtype: int64"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "pDKDQpwHWVNI",
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1750592423291,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "pDKDQpwHWVNI"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "AREWh6-BWtaX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1750592424126,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "AREWh6-BWtaX",
    "outputId": "6c62209c-8969-47ee-c3cd-f365d2b7e7fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135884, 348)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "3X4apt2wW71w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750592425072,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "3X4apt2wW71w",
    "outputId": "d8b62563-1ef1-4366-aed4-4985980c31ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'power', 'kilometer', 'price', 'v_0', 'v_1', 'v_2',\n",
       "       'v_3', 'v_4',\n",
       "       ...\n",
       "       'notRepairedDamage_-1', 'notRepairedDamage_0', 'notRepairedDamage_1',\n",
       "       'power_bin_0', 'power_bin_1', 'power_bin_2', 'power_bin_3',\n",
       "       'power_bin_4', 'power_bin_5', 'power_bin_6'],\n",
       "      dtype='object', length=348)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "KCzVt0I3XDE1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750507843771,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "KCzVt0I3XDE1",
    "outputId": "44d2a4d2-f5cc-4f15-dc44-7fb287ca5da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'log_price' in train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "33158d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"used_time_meanfill\" in train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UfyT1uARSVV0",
   "metadata": {
    "id": "UfyT1uARSVV0"
   },
   "source": [
    "### 4.1.1 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "kHtDKSxqaPkz",
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1750592430604,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "kHtDKSxqaPkz"
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['price', 'log_price', 'used_time_meanfill', 'power'])\n",
    "y = train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "g_h00FnryFG4",
   "metadata": {
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1750592431963,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "g_h00FnryFG4"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "csFzkG4c0a4B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1750592433096,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "csFzkG4c0a4B",
    "outputId": "9997bc8a-383c-4b2b-c815-1734ae732975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108707, 344), (27177, 344))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LnrVqRNabaFA",
   "metadata": {
    "id": "LnrVqRNabaFA"
   },
   "source": [
    "### 4.1.2 模型训练 - Linear regression - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "AVadk86yZuIP",
   "metadata": {
    "executionInfo": {
     "elapsed": 3260,
     "status": "ok",
     "timestamp": 1750590028333,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "AVadk86yZuIP"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "6yRo4AFjTku2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1750590030025,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "6yRo4AFjTku2",
    "outputId": "885b895d-0423-49cd-87f1-84f5ee66cc5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2158.4201111777506"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid, model.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4YET7G7ibhtG",
   "metadata": {
    "id": "4YET7G7ibhtG"
   },
   "source": [
    "### 4.1.3 模型训练 - Lasso(L1正则化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "xJQQk86UdVR0",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1750590035993,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "xJQQk86UdVR0"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "245ae102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Lasso</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.0001)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Lasso</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.0001)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 GridSearchCV 对 Lasso 回归调参\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "JnlBJ3PvdkNm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1750510067334,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "JnlBJ3PvdkNm",
    "outputId": "f182b3b1-df40-45a3-f4fe-88512e3732a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0001\n",
      "Validation MAE: 2206.9882828130044\n"
     ]
    }
   ],
   "source": [
    "# 最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 验证集预测与评估\n",
    "y_pred = best_model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "\n",
    "print(\"Best alpha:\", grid_search.best_params_['alpha'])\n",
    "print(\"Validation MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_yKzIZ5rfW7b",
   "metadata": {
    "id": "_yKzIZ5rfW7b"
   },
   "source": [
    "### 4.1.4 模型训练 - Ridge(L2正则化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "QVtD84rpfuQW",
   "metadata": {
    "id": "QVtD84rpfuQW"
   },
   "outputs": [],
   "source": [
    "param_grid_ridge = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "dRthycANf5Fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "executionInfo": {
     "elapsed": 36655,
     "status": "ok",
     "timestamp": 1750510151401,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "dRthycANf5Fc",
    "outputId": "37d070b2-ff57-4c42-e52e-48a55fd68dd1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Ridge</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.0001)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ridge</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.0001)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 GridSearchCV 对 Ridge 回归调参\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "VFPcnxcQf_QD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1750510362776,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "VFPcnxcQf_QD",
    "outputId": "5b17d539-c997-4ac7-cd4f-ab3f806a29bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0001\n",
      "Validation MAE: 2158.5890005617603\n"
     ]
    }
   ],
   "source": [
    "# 最佳模型\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 验证集预测与评估\n",
    "y_pred = best_model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "\n",
    "print(\"Best alpha:\", grid_search.best_params_['alpha'])\n",
    "print(\"Validation MAE:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xknEiUqhjKhJ",
   "metadata": {
    "id": "xknEiUqhjKhJ"
   },
   "source": [
    "## 4.2 XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "129d14fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\recbole\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\envs\\recbole\\lib\\site-packages (from xgboost) (1.15.1)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/150.0 MB 3.3 MB/s eta 0:00:46\n",
      "   ---------------------------------------- 1.0/150.0 MB 2.5 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 1.3/150.0 MB 2.3 MB/s eta 0:01:05\n",
      "   ---------------------------------------- 1.8/150.0 MB 2.2 MB/s eta 0:01:08\n",
      "    --------------------------------------- 2.4/150.0 MB 2.1 MB/s eta 0:01:10\n",
      "    --------------------------------------- 2.6/150.0 MB 2.2 MB/s eta 0:01:09\n",
      "    --------------------------------------- 3.1/150.0 MB 2.0 MB/s eta 0:01:12\n",
      "    --------------------------------------- 3.4/150.0 MB 2.0 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 3.9/150.0 MB 2.0 MB/s eta 0:01:13\n",
      "   - -------------------------------------- 4.2/150.0 MB 1.9 MB/s eta 0:01:16\n",
      "   - -------------------------------------- 4.5/150.0 MB 2.0 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 5.0/150.0 MB 2.0 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 5.2/150.0 MB 2.0 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 5.5/150.0 MB 1.9 MB/s eta 0:01:16\n",
      "   - -------------------------------------- 6.0/150.0 MB 1.9 MB/s eta 0:01:16\n",
      "   - -------------------------------------- 6.6/150.0 MB 2.0 MB/s eta 0:01:14\n",
      "   - -------------------------------------- 7.1/150.0 MB 2.0 MB/s eta 0:01:12\n",
      "   - -------------------------------------- 7.3/150.0 MB 2.0 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 7.6/150.0 MB 1.9 MB/s eta 0:01:14\n",
      "   -- ------------------------------------- 8.1/150.0 MB 1.9 MB/s eta 0:01:14\n",
      "   -- ------------------------------------- 8.7/150.0 MB 1.9 MB/s eta 0:01:13\n",
      "   -- ------------------------------------- 9.2/150.0 MB 2.0 MB/s eta 0:01:12\n",
      "   -- ------------------------------------- 9.7/150.0 MB 2.0 MB/s eta 0:01:11\n",
      "   -- ------------------------------------- 10.2/150.0 MB 2.0 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 10.5/150.0 MB 2.0 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 10.7/150.0 MB 2.0 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 11.0/150.0 MB 2.0 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 11.5/150.0 MB 2.0 MB/s eta 0:01:11\n",
      "   --- ------------------------------------ 12.1/150.0 MB 2.0 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 12.6/150.0 MB 2.0 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 13.1/150.0 MB 2.0 MB/s eta 0:01:09\n",
      "   --- ------------------------------------ 13.6/150.0 MB 2.0 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 14.2/150.0 MB 2.0 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 14.9/150.0 MB 2.1 MB/s eta 0:01:05\n",
      "   ---- ----------------------------------- 15.7/150.0 MB 2.1 MB/s eta 0:01:03\n",
      "   ---- ----------------------------------- 16.5/150.0 MB 2.2 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 16.8/150.0 MB 2.2 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 17.3/150.0 MB 2.2 MB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 17.8/150.0 MB 2.2 MB/s eta 0:01:01\n",
      "   ---- ----------------------------------- 18.4/150.0 MB 2.2 MB/s eta 0:01:01\n",
      "   ----- ---------------------------------- 18.9/150.0 MB 2.2 MB/s eta 0:01:00\n",
      "   ----- ---------------------------------- 19.4/150.0 MB 2.2 MB/s eta 0:01:00\n",
      "   ----- ---------------------------------- 19.9/150.0 MB 2.2 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 20.4/150.0 MB 2.2 MB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 21.0/150.0 MB 2.2 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 21.5/150.0 MB 2.3 MB/s eta 0:00:58\n",
      "   ----- ---------------------------------- 22.0/150.0 MB 2.2 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 22.5/150.0 MB 2.3 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 23.1/150.0 MB 2.3 MB/s eta 0:00:57\n",
      "   ------ --------------------------------- 23.6/150.0 MB 2.3 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 24.1/150.0 MB 2.3 MB/s eta 0:00:56\n",
      "   ------ --------------------------------- 24.6/150.0 MB 2.3 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 25.2/150.0 MB 2.3 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 25.7/150.0 MB 2.3 MB/s eta 0:00:55\n",
      "   ------ --------------------------------- 26.2/150.0 MB 2.3 MB/s eta 0:00:55\n",
      "   ------- -------------------------------- 26.7/150.0 MB 2.3 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 27.3/150.0 MB 2.3 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 27.8/150.0 MB 2.3 MB/s eta 0:00:54\n",
      "   ------- -------------------------------- 28.3/150.0 MB 2.3 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 28.8/150.0 MB 2.3 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 29.4/150.0 MB 2.3 MB/s eta 0:00:53\n",
      "   ------- -------------------------------- 29.9/150.0 MB 2.3 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 30.4/150.0 MB 2.3 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 30.9/150.0 MB 2.3 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 31.5/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 32.2/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 32.8/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 33.0/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 33.3/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 33.8/150.0 MB 2.3 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 34.3/150.0 MB 2.3 MB/s eta 0:00:50\n",
      "   --------- ------------------------------ 34.9/150.0 MB 2.3 MB/s eta 0:00:50\n",
      "   --------- ------------------------------ 35.4/150.0 MB 2.3 MB/s eta 0:00:50\n",
      "   --------- ------------------------------ 35.9/150.0 MB 2.3 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 36.4/150.0 MB 2.3 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 37.0/150.0 MB 2.3 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 37.7/150.0 MB 2.3 MB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 38.3/150.0 MB 2.4 MB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 38.8/150.0 MB 2.4 MB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 39.3/150.0 MB 2.4 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 39.8/150.0 MB 2.4 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 40.4/150.0 MB 2.4 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 40.9/150.0 MB 2.4 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 41.4/150.0 MB 2.4 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 42.2/150.0 MB 2.4 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 42.7/150.0 MB 2.4 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 43.3/150.0 MB 2.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 43.8/150.0 MB 2.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 2.4 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 44.8/150.0 MB 2.4 MB/s eta 0:00:45\n",
      "   ------------ --------------------------- 45.4/150.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 45.9/150.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 46.4/150.0 MB 2.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 47.2/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 47.7/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 48.2/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 48.5/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 48.8/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 49.3/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 49.5/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 49.8/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 50.3/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 50.6/150.0 MB 2.4 MB/s eta 0:00:43\n",
      "   ------------- -------------------------- 51.1/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 51.6/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   ------------- -------------------------- 52.2/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 52.7/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 53.0/150.0 MB 2.4 MB/s eta 0:00:42\n",
      "   -------------- ------------------------- 53.5/150.0 MB 2.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 54.0/150.0 MB 2.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 54.5/150.0 MB 2.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 55.1/150.0 MB 2.4 MB/s eta 0:00:41\n",
      "   -------------- ------------------------- 55.6/150.0 MB 2.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 56.4/150.0 MB 2.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 56.9/150.0 MB 2.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 57.1/150.0 MB 2.4 MB/s eta 0:00:40\n",
      "   --------------- ------------------------ 57.9/150.0 MB 2.4 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 58.5/150.0 MB 2.4 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 59.0/150.0 MB 2.4 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 59.5/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 59.8/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 60.3/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 60.8/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 61.1/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 61.6/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 62.1/150.0 MB 2.4 MB/s eta 0:00:38\n",
      "   ---------------- ----------------------- 62.9/150.0 MB 2.4 MB/s eta 0:00:37\n",
      "   ---------------- ----------------------- 63.4/150.0 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 64.0/150.0 MB 2.4 MB/s eta 0:00:37\n",
      "   ----------------- ---------------------- 64.5/150.0 MB 2.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 65.0/150.0 MB 2.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 65.5/150.0 MB 2.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 66.1/150.0 MB 2.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 66.3/150.0 MB 2.4 MB/s eta 0:00:36\n",
      "   ----------------- ---------------------- 66.8/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ----------------- ---------------------- 67.4/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 67.9/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 68.2/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 68.7/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 69.2/150.0 MB 2.4 MB/s eta 0:00:35\n",
      "   ------------------ --------------------- 69.7/150.0 MB 2.4 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 70.3/150.0 MB 2.4 MB/s eta 0:00:34\n",
      "   ------------------ --------------------- 70.8/150.0 MB 2.4 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 71.3/150.0 MB 2.4 MB/s eta 0:00:34\n",
      "   ------------------- -------------------- 71.8/150.0 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 72.4/150.0 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 72.6/150.0 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 73.1/150.0 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 73.7/150.0 MB 2.4 MB/s eta 0:00:33\n",
      "   ------------------- -------------------- 73.9/150.0 MB 2.4 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 74.4/150.0 MB 2.4 MB/s eta 0:00:32\n",
      "   ------------------- -------------------- 74.7/150.0 MB 2.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 75.2/150.0 MB 2.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 75.8/150.0 MB 2.4 MB/s eta 0:00:32\n",
      "   -------------------- ------------------- 76.3/150.0 MB 2.4 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 76.8/150.0 MB 2.4 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 77.3/150.0 MB 2.4 MB/s eta 0:00:31\n",
      "   -------------------- ------------------- 77.9/150.0 MB 2.4 MB/s eta 0:00:30\n",
      "   -------------------- ------------------- 78.4/150.0 MB 2.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 78.9/150.0 MB 2.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 79.4/150.0 MB 2.4 MB/s eta 0:00:30\n",
      "   --------------------- ------------------ 80.0/150.0 MB 2.4 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 80.2/150.0 MB 2.4 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 81.0/150.0 MB 2.4 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 81.5/150.0 MB 2.4 MB/s eta 0:00:29\n",
      "   --------------------- ------------------ 82.1/150.0 MB 2.4 MB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 82.6/150.0 MB 2.4 MB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 83.1/150.0 MB 2.4 MB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 83.6/150.0 MB 2.4 MB/s eta 0:00:28\n",
      "   ---------------------- ----------------- 84.1/150.0 MB 2.4 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 84.7/150.0 MB 2.5 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 85.2/150.0 MB 2.5 MB/s eta 0:00:27\n",
      "   ---------------------- ----------------- 85.7/150.0 MB 2.5 MB/s eta 0:00:27\n",
      "   ----------------------- ---------------- 86.2/150.0 MB 2.5 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 86.8/150.0 MB 2.5 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 87.0/150.0 MB 2.5 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 87.6/150.0 MB 2.5 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 88.1/150.0 MB 2.4 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 88.9/150.0 MB 2.4 MB/s eta 0:00:26\n",
      "   ----------------------- ---------------- 89.1/150.0 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 89.7/150.0 MB 2.4 MB/s eta 0:00:25\n",
      "   ----------------------- ---------------- 89.9/150.0 MB 2.4 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 90.4/150.0 MB 2.4 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 91.2/150.0 MB 2.4 MB/s eta 0:00:25\n",
      "   ------------------------ --------------- 91.8/150.0 MB 2.4 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 92.5/150.0 MB 2.4 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 93.1/150.0 MB 2.4 MB/s eta 0:00:24\n",
      "   ------------------------ --------------- 93.6/150.0 MB 2.4 MB/s eta 0:00:24\n",
      "   ------------------------- -------------- 94.1/150.0 MB 2.4 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 94.9/150.0 MB 2.4 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 95.2/150.0 MB 2.4 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 95.9/150.0 MB 2.4 MB/s eta 0:00:23\n",
      "   ------------------------- -------------- 96.5/150.0 MB 2.4 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 97.0/150.0 MB 2.4 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 97.5/150.0 MB 2.4 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 98.0/150.0 MB 2.4 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 98.6/150.0 MB 2.4 MB/s eta 0:00:22\n",
      "   -------------------------- ------------- 99.1/150.0 MB 2.4 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 99.6/150.0 MB 2.4 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 100.1/150.0 MB 2.5 MB/s eta 0:00:21\n",
      "   -------------------------- ------------- 100.9/150.0 MB 2.5 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 101.4/150.0 MB 2.5 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 102.0/150.0 MB 2.5 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 102.5/150.0 MB 2.5 MB/s eta 0:00:20\n",
      "   --------------------------- ------------ 103.3/150.0 MB 2.5 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 103.8/150.0 MB 2.5 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 104.3/150.0 MB 2.5 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 104.9/150.0 MB 2.5 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 105.4/150.0 MB 2.5 MB/s eta 0:00:19\n",
      "   ---------------------------- ----------- 106.2/150.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 106.7/150.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 107.2/150.0 MB 2.5 MB/s eta 0:00:18\n",
      "   ---------------------------- ----------- 107.7/150.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 108.0/150.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 108.8/150.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 109.3/150.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 109.8/150.0 MB 2.5 MB/s eta 0:00:17\n",
      "   ----------------------------- ---------- 110.4/150.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 110.9/150.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 111.7/150.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 112.2/150.0 MB 2.5 MB/s eta 0:00:16\n",
      "   ------------------------------ --------- 112.7/150.0 MB 2.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 113.0/150.0 MB 2.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 113.5/150.0 MB 2.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 114.3/150.0 MB 2.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 114.8/150.0 MB 2.5 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 115.6/150.0 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 116.1/150.0 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 116.7/150.0 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 117.4/150.0 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------------------------- -------- 118.0/150.0 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 118.5/150.0 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 119.0/150.0 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 119.5/150.0 MB 2.5 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 120.3/150.0 MB 2.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 120.8/150.0 MB 2.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 121.4/150.0 MB 2.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 121.9/150.0 MB 2.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 122.4/150.0 MB 2.5 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 122.9/150.0 MB 2.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 123.7/150.0 MB 2.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 124.3/150.0 MB 2.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 124.8/150.0 MB 2.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 125.3/150.0 MB 2.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 125.8/150.0 MB 2.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 126.6/150.0 MB 2.5 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 127.1/150.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 127.7/150.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 128.5/150.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 129.0/150.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 129.2/150.0 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 129.8/150.0 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 130.3/150.0 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 131.1/150.0 MB 2.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 131.3/150.0 MB 2.6 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 132.1/150.0 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 132.6/150.0 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 133.2/150.0 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 133.7/150.0 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 134.5/150.0 MB 2.6 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 135.0/150.0 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 135.5/150.0 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 136.1/150.0 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 136.6/150.0 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 137.1/150.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 137.6/150.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 138.4/150.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 138.9/150.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 139.5/150.0 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 140.0/150.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 140.8/150.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 141.3/150.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 141.8/150.0 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 142.3/150.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 142.9/150.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 143.4/150.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 143.9/150.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 144.4/150.0 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 145.0/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.5/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 146.0/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  146.3/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  146.8/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  147.1/150.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  147.6/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.1/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.6/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.2/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.7/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "vHfoRrrEjYxs",
   "metadata": {
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1750589821780,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "vHfoRrrEjYxs"
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "OE7towYFjdn7",
   "metadata": {
    "executionInfo": {
     "elapsed": 3661,
     "status": "ok",
     "timestamp": 1750589826294,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "OE7towYFjdn7"
   },
   "outputs": [],
   "source": [
    "data_for_tree = pd.read_csv(r\"D:\\推荐系统资料\\白泽老师\\data_for_tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "jJofGzQRkA3U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1750589827642,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "jJofGzQRkA3U",
    "outputId": "2869ff8a-89e0-4f4e-a1fb-3489b09077e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th>...</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "      <th>brand_amount</th>\n",
       "      <th>brand_price_max</th>\n",
       "      <th>brand_price_median</th>\n",
       "      <th>brand_price_min</th>\n",
       "      <th>brand_price_sum</th>\n",
       "      <th>brand_price_std</th>\n",
       "      <th>brand_price_average</th>\n",
       "      <th>power_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>10076.0</td>\n",
       "      <td>59900.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>3.468970e+07</td>\n",
       "      <td>4656.121118</td>\n",
       "      <td>3442.46</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>13702.0</td>\n",
       "      <td>99900.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.234055e+08</td>\n",
       "      <td>9450.843699</td>\n",
       "      <td>9005.73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>3.381581</td>\n",
       "      <td>1.387650e+07</td>\n",
       "      <td>5634.345867</td>\n",
       "      <td>9556.82</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>14147.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.476178</td>\n",
       "      <td>1.158543e+08</td>\n",
       "      <td>9046.159956</td>\n",
       "      <td>8188.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>4609.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1.151239</td>\n",
       "      <td>1.462294e+07</td>\n",
       "      <td>3381.498842</td>\n",
       "      <td>3172.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736   30.0    6.0         1         0        0   60.0   \n",
       "1       1    2262   40.0    1.0         2         0        0    0.0   \n",
       "2       2   14874  115.0   15.0         1         0        0  163.0   \n",
       "3       3   71865  109.0   10.0         0         0        1  193.0   \n",
       "4       4  111080  110.0    5.0         1         0        0   68.0   \n",
       "\n",
       "   kilometer  notRepairedDamage  ...  used_time  used_time_meanfill  \\\n",
       "0         12                  0  ...     4385.0              4385.0   \n",
       "1         15                 -1  ...     4757.0              4757.0   \n",
       "2         12                  0  ...     4382.0              4382.0   \n",
       "3         15                  0  ...     7125.0              7125.0   \n",
       "4          5                  0  ...     1531.0              1531.0   \n",
       "\n",
       "   brand_amount  brand_price_max  brand_price_median  brand_price_min  \\\n",
       "0       10076.0          59900.0              1650.0         0.216981   \n",
       "1       13702.0          99900.0              6100.0         0.011300   \n",
       "2        1451.0          45000.0              8500.0         3.381581   \n",
       "3       14147.0          98000.0              5000.0         0.476178   \n",
       "4        4609.0          31500.0              2200.0         1.151239   \n",
       "\n",
       "   brand_price_sum  brand_price_std  brand_price_average  power_bin  \n",
       "0     3.468970e+07      4656.121118              3442.46        1.0  \n",
       "1     1.234055e+08      9450.843699              9005.73        0.0  \n",
       "2     1.387650e+07      5634.345867              9556.82        4.0  \n",
       "3     1.158543e+08      9046.159956              8188.74        4.0  \n",
       "4     1.462294e+07      3381.498842              3172.01        1.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eG62SS06k08S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1750589829461,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "eG62SS06k08S",
    "outputId": "393b2839-9684-4af1-ed28-a2344789a530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_price              51563\n",
       "price                  50000\n",
       "v_14                   18760\n",
       "v_13                    4703\n",
       "power_bin               3335\n",
       "v_12                    1921\n",
       "v_11                       0\n",
       "train                      0\n",
       "used_time                  0\n",
       "used_time_meanfill         0\n",
       "v_9                        0\n",
       "brand_amount               0\n",
       "brand_price_max            0\n",
       "brand_price_median         0\n",
       "brand_price_min            0\n",
       "brand_price_sum            0\n",
       "brand_price_std            0\n",
       "brand_price_average        0\n",
       "v_10                       0\n",
       "SaleID                     0\n",
       "name                       0\n",
       "v_7                        0\n",
       "model                      0\n",
       "brand                      0\n",
       "bodyType                   0\n",
       "fuelType                   0\n",
       "gearbox                    0\n",
       "power                      0\n",
       "kilometer                  0\n",
       "notRepairedDamage          0\n",
       "v_0                        0\n",
       "v_1                        0\n",
       "v_2                        0\n",
       "v_3                        0\n",
       "v_4                        0\n",
       "v_5                        0\n",
       "v_6                        0\n",
       "v_8                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_tree.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "Hf_zADqpk56o",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1750589843528,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "Hf_zADqpk56o"
   },
   "outputs": [],
   "source": [
    "# 拆分训练集和测试集\n",
    "train_data1 = data_for_tree[data_for_tree['train'] == 1].drop(columns=['train', \"used_time\", \"SaleID\"])\n",
    "test_data1 = data_for_tree[data_for_tree['train'] == 0].drop(columns=['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "qajBr0xllLLa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1750589844979,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "qajBr0xllLLa",
    "outputId": "40eb99e3-48ea-4715-9783-203ca39d6817"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v_14                   14116\n",
       "v_13                    3583\n",
       "power_bin               2555\n",
       "log_price               1563\n",
       "v_12                    1469\n",
       "used_time_meanfill         0\n",
       "v_10                       0\n",
       "v_11                       0\n",
       "brand_amount               0\n",
       "v_8                        0\n",
       "brand_price_max            0\n",
       "brand_price_median         0\n",
       "brand_price_min            0\n",
       "brand_price_sum            0\n",
       "brand_price_std            0\n",
       "brand_price_average        0\n",
       "v_9                        0\n",
       "name                       0\n",
       "model                      0\n",
       "notRepairedDamage          0\n",
       "brand                      0\n",
       "bodyType                   0\n",
       "fuelType                   0\n",
       "gearbox                    0\n",
       "power                      0\n",
       "kilometer                  0\n",
       "price                      0\n",
       "v_6                        0\n",
       "v_0                        0\n",
       "v_1                        0\n",
       "v_2                        0\n",
       "v_3                        0\n",
       "v_4                        0\n",
       "v_5                        0\n",
       "v_7                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "O0hL8qeRlvVI",
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1750589847982,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "O0hL8qeRlvVI"
   },
   "outputs": [],
   "source": [
    "train_data1 = train_data1.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "P-qxo5FZl2Am",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1750589848923,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "P-qxo5FZl2Am",
    "outputId": "d6af39d7-d3fc-401d-ac4f-b44be3e54fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135770, 35)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9Iay_Jdel5zE",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750589878152,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "9Iay_Jdel5zE"
   },
   "outputs": [],
   "source": [
    "test_data1 = test_data1.drop(columns=['price', \"log_price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HyQFpmpwmDQ9",
   "metadata": {
    "id": "HyQFpmpwmDQ9"
   },
   "source": [
    "### 4.2.1 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "I34_6ZMVmFsu",
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1750589886511,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "I34_6ZMVmFsu"
   },
   "outputs": [],
   "source": [
    "X1 = train_data1.drop(columns=['price', \"log_price\"])\n",
    "y1 = train_data1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "nmPlVPzrmQAS",
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1750589887775,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "nmPlVPzrmQAS"
   },
   "outputs": [],
   "source": [
    "X1_train, X1_valid, y1_train, y1_valid = train_test_split(X1, y1, test_size=0.2, random_state=327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "Tw5usE0omYwL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1750589889413,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "Tw5usE0omYwL",
    "outputId": "afda094b-42c2-421d-90e7-e444f2ade7ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108616, 33), (27154, 33))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.shape, X1_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4BkJJBxIoAZb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1750589890739,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "4BkJJBxIoAZb",
    "outputId": "3548076f-cb44-4fd1-8a21-860364ddcea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108616,), (27154,))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train.shape, y1_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CW9paY_6mnqU",
   "metadata": {
    "id": "CW9paY_6mnqU"
   },
   "source": [
    "### 4.2.2 模型训练 - XGBRegressor - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "mSkTMASlnIKe",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1750589896857,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "mSkTMASlnIKe"
   },
   "outputs": [],
   "source": [
    "model_xgb = XGBRegressor(n_estimators = 100, objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "gIjBYusKnYzd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1928,
     "status": "ok",
     "timestamp": 1750589905289,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "gIjBYusKnYzd"
   },
   "outputs": [],
   "source": [
    "model_xgb = model_xgb.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "uNPCHGg3oJFV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1750589912047,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "uNPCHGg3oJFV",
    "outputId": "07bcf087-a4e4-42e3-8efa-919c95fd7c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644.757535817996"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y1_valid, model_xgb.predict(X1_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UfmoeB-SoSt8",
   "metadata": {
    "id": "UfmoeB-SoSt8"
   },
   "source": [
    "### 4.2.3 GridSearch调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0CKqpbnQ-KC",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1750556266525,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "B0CKqpbnQ-KC"
   },
   "outputs": [],
   "source": [
    "model_xgb1 = XGBRegressor(n_estimators = 100, objective='reg:squarederror', device='cuda:0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VVI9zjiioZzb",
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1750556267419,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "VVI9zjiioZzb"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3,5,10,15,20],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o-9yNmzDo2R-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 3316534,
     "status": "ok",
     "timestamp": 1750559966615,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "o-9yNmzDo2R-",
    "outputId": "2e1a6802-e83c-4ce3-a9f5-c15c657254dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=&#x27;cuda:0&#x27;,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=No...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 10, 15, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=&#x27;cuda:0&#x27;,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=No...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 10, 15, 20],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda:0&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda:0&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device='cuda:0',\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=No...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.3],\n",
       "                         'max_depth': [3, 5, 10, 15, 20],\n",
       "                         'n_estimators': [100, 200], 'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(model_xgb1, param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid_search.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g_J-8ZCtg5SW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750560159817,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "g_J-8ZCtg5SW",
    "outputId": "8c504552-018e-4bc5-83dd-04687fac6aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1HBBAQpBo-hL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1750560867610,
     "user": {
      "displayName": "Lijia huang",
      "userId": "03111498663409370253"
     },
     "user_tz": -600
    },
    "id": "1HBBAQpBo-hL",
    "outputId": "b1826b0b-4fdd-4082-8f10-4342c7c05bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE of best_model_xgb1: 558.9517199724282\n"
     ]
    }
   ],
   "source": [
    "# 验证集预测与评估\n",
    "best_model_xgb1 = XGBRegressor(\n",
    "    n_estimators=200,       \n",
    "    learning_rate=0.1,      \n",
    "    max_depth=10,           \n",
    "    subsample=1.0,          \n",
    "    objective='reg:squarederror',  \n",
    "    random_state=27        \n",
    ")\n",
    "best_model_xgb1 = best_model_xgb1.fit(X1_train, y1_train)\n",
    "y1_pred = best_model_xgb1.predict(X1_valid)\n",
    "mae = mean_absolute_error(y1_valid, y1_pred)\n",
    "print(\"Validation MAE of best_model_xgb1:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olh4RBknYG6W",
   "metadata": {
    "id": "olh4RBknYG6W"
   },
   "source": [
    "## 4.3 FM\n",
    "+ 用的data_for_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9cf0c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a1171",
   "metadata": {},
   "source": [
    "### 4.3.1 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9aca889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_tree = pd.read_csv(r\"D:\\推荐系统资料\\白泽老师\\data_for_tree.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "512f2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th>...</th>\n",
       "      <th>used_time</th>\n",
       "      <th>used_time_meanfill</th>\n",
       "      <th>brand_amount</th>\n",
       "      <th>brand_price_max</th>\n",
       "      <th>brand_price_median</th>\n",
       "      <th>brand_price_min</th>\n",
       "      <th>brand_price_sum</th>\n",
       "      <th>brand_price_std</th>\n",
       "      <th>brand_price_average</th>\n",
       "      <th>power_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>4385.0</td>\n",
       "      <td>10076.0</td>\n",
       "      <td>59900.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>0.216981</td>\n",
       "      <td>3.468970e+07</td>\n",
       "      <td>4656.121118</td>\n",
       "      <td>3442.46</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>13702.0</td>\n",
       "      <td>99900.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.234055e+08</td>\n",
       "      <td>9450.843699</td>\n",
       "      <td>9005.73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>3.381581</td>\n",
       "      <td>1.387650e+07</td>\n",
       "      <td>5634.345867</td>\n",
       "      <td>9556.82</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>14147.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.476178</td>\n",
       "      <td>1.158543e+08</td>\n",
       "      <td>9046.159956</td>\n",
       "      <td>8188.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>4609.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1.151239</td>\n",
       "      <td>1.462294e+07</td>\n",
       "      <td>3381.498842</td>\n",
       "      <td>3172.01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name  model  brand  bodyType  fuelType  gearbox  power  \\\n",
       "0       0     736   30.0    6.0         1         0        0   60.0   \n",
       "1       1    2262   40.0    1.0         2         0        0    0.0   \n",
       "2       2   14874  115.0   15.0         1         0        0  163.0   \n",
       "3       3   71865  109.0   10.0         0         0        1  193.0   \n",
       "4       4  111080  110.0    5.0         1         0        0   68.0   \n",
       "\n",
       "   kilometer  notRepairedDamage  ...  used_time  used_time_meanfill  \\\n",
       "0         12                  0  ...     4385.0              4385.0   \n",
       "1         15                 -1  ...     4757.0              4757.0   \n",
       "2         12                  0  ...     4382.0              4382.0   \n",
       "3         15                  0  ...     7125.0              7125.0   \n",
       "4          5                  0  ...     1531.0              1531.0   \n",
       "\n",
       "   brand_amount  brand_price_max  brand_price_median  brand_price_min  \\\n",
       "0       10076.0          59900.0              1650.0         0.216981   \n",
       "1       13702.0          99900.0              6100.0         0.011300   \n",
       "2        1451.0          45000.0              8500.0         3.381581   \n",
       "3       14147.0          98000.0              5000.0         0.476178   \n",
       "4        4609.0          31500.0              2200.0         1.151239   \n",
       "\n",
       "   brand_price_sum  brand_price_std  brand_price_average  power_bin  \n",
       "0     3.468970e+07      4656.121118              3442.46        1.0  \n",
       "1     1.234055e+08      9450.843699              9005.73        0.0  \n",
       "2     1.387650e+07      5634.345867              9556.82        4.0  \n",
       "3     1.158543e+08      9046.159956              8188.74        4.0  \n",
       "4     1.462294e+07      3381.498842              3172.01        1.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cdb08d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SaleID', 'name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox',\n",
       "       'power', 'kilometer', 'notRepairedDamage', 'price', 'v_0', 'v_1', 'v_2',\n",
       "       'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',\n",
       "       'v_13', 'v_14', 'log_price', 'train', 'used_time', 'used_time_meanfill',\n",
       "       'brand_amount', 'brand_price_max', 'brand_price_median',\n",
       "       'brand_price_min', 'brand_price_sum', 'brand_price_std',\n",
       "       'brand_price_average', 'power_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_tree.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "932ca7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target是'price'\n",
    "dense_cols = ['name','power', 'kilometer', 'v_0', 'v_1', 'v_2',\n",
    "       'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',\n",
    "       'v_13', 'v_14', 'used_time_meanfill',\n",
    "       'brand_amount', 'brand_price_max', 'brand_price_median',\n",
    "       'brand_price_min', 'brand_price_sum', 'brand_price_std',\n",
    "       'brand_price_average']  \n",
    "sparse_cols =[\"model\", \"brand\", \"bodyType\", \"fuelType\",'gearbox','notRepairedDamage']  # 类别特征列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f93ead5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_for_tree.dropna(subset=dense_cols + sparse_cols + ['price']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8230f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化 dense 特征\n",
    "scaler = StandardScaler()\n",
    "dense_feat = scaler.fit_transform(df[dense_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0b0f7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码 sparse 特征\n",
    "for col in sparse_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "sparse_feat = pd.get_dummies(df[sparse_cols]).values  # one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "524e5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接全部特征\n",
    "X2 = np.hstack([dense_feat, sparse_feat]).astype(np.float32)\n",
    "y2 = df['price'].values.reshape(-1, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "88e05ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "01a67bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转 Tensor\n",
    "X_train2 = torch.tensor(X_train2)\n",
    "X_val2 = torch.tensor(X_val2)\n",
    "y_train2 = torch.tensor(y_train2)\n",
    "y_val2 = torch.tensor(y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2ad32381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([108707, 32]),\n",
       " torch.Size([27177, 32]),\n",
       " torch.Size([108707, 1]),\n",
       " torch.Size([27177, 1]))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_val2.shape, y_train2.shape, y_val2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d163f6",
   "metadata": {},
   "source": [
    "### 4.3.2 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7186b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    \"\"\"FM part\"\"\"\n",
    "    def __init__(self, latent_dim, fea_num):\n",
    "        \"\"\"\n",
    "        latent_dim: 每个特征的隐向量维度(embedding维度)\n",
    "        fea_num: 输入特征总数(dense + sparse 拼接之后的特征数)\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        # 定义三个矩阵， 一个是全局偏置，一个是一阶权重矩阵， 一个是二阶交叉矩阵，注意这里的参数由于是可学习参数，需要用nn.Parameter进行定义\n",
    "        self.w0 = nn.Parameter(torch.zeros([1,]))  # 标量，全局偏置\n",
    "        self.w1 = nn.Parameter(torch.rand([fea_num, 1]))  # 一阶权重向量 W, [fea_num, 1]\n",
    "        self.w2 = nn.Parameter(torch.rand([fea_num, latent_dim])) # 二阶隐向量 V, [fea_num, latent_dim]，为每个特征学习的隐向量\n",
    "        \n",
    "    def forward(self, inputs):  # inputs shape - [batch_size, fea_num]\n",
    "        # 一阶交叉 - 全局偏置+每个特征的线性加权\n",
    "        first_order = self.w0 + torch.mm(inputs, self.w1)   # shape - [batch_size, 1]\n",
    "        # 二阶交叉 - 这个用FM的最终化简公式,相比原始公式更容易实现\n",
    "        second_order = 1/2 * torch.sum(\n",
    "            torch.pow(torch.mm(inputs, self.w2), 2) - torch.mm(torch.pow(inputs,2), torch.pow(self.w2, 2)),\n",
    "            dim = 1,\n",
    "            keepdim = True\n",
    "        )         # shape - [batch_size, 1]\n",
    "        \n",
    "        return first_order + second_order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dc1895dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 46607464.0000, Val MSE: 44787608.0000, Val MAE: 4470.2676\n",
      "Epoch 20, Train Loss: 31145216.0000, Val MSE: 30038532.0000, Val MAE: 3584.0796\n",
      "Epoch 30, Train Loss: 17391900.0000, Val MSE: 16343912.0000, Val MAE: 2821.6106\n",
      "Epoch 40, Train Loss: 12911821.0000, Val MSE: 12905206.0000, Val MAE: 2550.0310\n",
      "Epoch 50, Train Loss: 12184037.0000, Val MSE: 11913060.0000, Val MAE: 2466.3369\n",
      "Epoch 60, Train Loss: 11036961.0000, Val MSE: 10861978.0000, Val MAE: 2311.3525\n",
      "Epoch 70, Train Loss: 10490945.0000, Val MSE: 10373454.0000, Val MAE: 2227.8374\n",
      "Epoch 80, Train Loss: 9907650.0000, Val MSE: 9769973.0000, Val MAE: 2128.4319\n",
      "Epoch 90, Train Loss: 9386865.0000, Val MSE: 9241510.0000, Val MAE: 2032.3973\n",
      "Epoch 100, Train Loss: 8947921.0000, Val MSE: 8830319.0000, Val MAE: 1947.7252\n",
      "Epoch 110, Train Loss: 8618262.0000, Val MSE: 8527561.0000, Val MAE: 1895.2852\n",
      "Epoch 120, Train Loss: 8358071.0000, Val MSE: 8289335.0000, Val MAE: 1857.7263\n",
      "Epoch 130, Train Loss: 8123600.5000, Val MSE: 8076824.5000, Val MAE: 1825.1847\n",
      "Epoch 140, Train Loss: 7913248.0000, Val MSE: 7881153.5000, Val MAE: 1797.3693\n",
      "Epoch 150, Train Loss: 7734371.0000, Val MSE: 7712828.0000, Val MAE: 1773.6648\n",
      "Epoch 160, Train Loss: 7587648.5000, Val MSE: 7575741.5000, Val MAE: 1751.9315\n",
      "Epoch 170, Train Loss: 7467365.0000, Val MSE: 7465960.5000, Val MAE: 1731.0437\n",
      "Epoch 180, Train Loss: 7369117.5000, Val MSE: 7378996.0000, Val MAE: 1712.6713\n",
      "Epoch 190, Train Loss: 7290346.0000, Val MSE: 7309546.0000, Val MAE: 1698.3251\n",
      "Epoch 200, Train Loss: 7227760.5000, Val MSE: 7254215.5000, Val MAE: 1687.7112\n",
      "Epoch 210, Train Loss: 7178000.5000, Val MSE: 7210281.5000, Val MAE: 1679.9712\n",
      "Epoch 220, Train Loss: 7137871.0000, Val MSE: 7174660.5000, Val MAE: 1674.1005\n",
      "Epoch 230, Train Loss: 7104650.0000, Val MSE: 7145001.0000, Val MAE: 1669.4440\n",
      "Epoch 240, Train Loss: 7076295.0000, Val MSE: 7119412.5000, Val MAE: 1665.7162\n",
      "Epoch 250, Train Loss: 7051424.5000, Val MSE: 7096631.5000, Val MAE: 1662.6633\n",
      "Epoch 260, Train Loss: 7029154.5000, Val MSE: 7075903.5000, Val MAE: 1660.1108\n",
      "Epoch 270, Train Loss: 7008921.5000, Val MSE: 7056757.5000, Val MAE: 1657.9561\n",
      "Epoch 280, Train Loss: 6990339.5000, Val MSE: 7038881.0000, Val MAE: 1656.1171\n",
      "Epoch 290, Train Loss: 6973131.0000, Val MSE: 7022073.0000, Val MAE: 1654.5320\n",
      "Epoch 300, Train Loss: 6957083.0000, Val MSE: 7006192.0000, Val MAE: 1653.1442\n",
      "Epoch 310, Train Loss: 6942021.0000, Val MSE: 6991118.5000, Val MAE: 1651.9164\n",
      "Epoch 320, Train Loss: 6927804.0000, Val MSE: 6976754.0000, Val MAE: 1650.7944\n",
      "Epoch 330, Train Loss: 6914313.5000, Val MSE: 6963002.5000, Val MAE: 1649.7581\n",
      "Epoch 340, Train Loss: 6901449.0000, Val MSE: 6949784.5000, Val MAE: 1648.7887\n",
      "Epoch 350, Train Loss: 6889122.5000, Val MSE: 6937027.5000, Val MAE: 1647.8749\n",
      "Epoch 360, Train Loss: 6877257.0000, Val MSE: 6924664.0000, Val MAE: 1647.0082\n",
      "Epoch 370, Train Loss: 6865787.0000, Val MSE: 6912635.5000, Val MAE: 1646.1665\n",
      "Epoch 380, Train Loss: 6854648.5000, Val MSE: 6900892.5000, Val MAE: 1645.3523\n",
      "Epoch 390, Train Loss: 6844085.0000, Val MSE: 6890450.5000, Val MAE: 1645.4646\n",
      "Epoch 400, Train Loss: 6889273.5000, Val MSE: 6878689.0000, Val MAE: 1644.3557\n",
      "Epoch 410, Train Loss: 6843638.0000, Val MSE: 6895253.0000, Val MAE: 1639.5242\n",
      "Epoch 420, Train Loss: 6812941.5000, Val MSE: 6864579.5000, Val MAE: 1646.3812\n",
      "Epoch 430, Train Loss: 6804311.0000, Val MSE: 6844637.5000, Val MAE: 1640.6595\n",
      "Epoch 440, Train Loss: 6794181.0000, Val MSE: 6834782.5000, Val MAE: 1639.2708\n",
      "Epoch 450, Train Loss: 6782507.5000, Val MSE: 6823782.5000, Val MAE: 1640.0109\n",
      "Epoch 460, Train Loss: 6772678.0000, Val MSE: 6812693.5000, Val MAE: 1638.9232\n",
      "Epoch 470, Train Loss: 6762442.0000, Val MSE: 6801455.0000, Val MAE: 1637.5369\n",
      "Epoch 480, Train Loss: 6752293.5000, Val MSE: 6790400.5000, Val MAE: 1636.4536\n",
      "Epoch 490, Train Loss: 6742131.5000, Val MSE: 6779277.0000, Val MAE: 1635.4618\n",
      "Epoch 500, Train Loss: 6731908.5000, Val MSE: 6768091.5000, Val MAE: 1634.4453\n",
      "Epoch 510, Train Loss: 6721617.0000, Val MSE: 6756799.5000, Val MAE: 1633.3478\n",
      "Epoch 520, Train Loss: 6711261.0000, Val MSE: 6745411.0000, Val MAE: 1632.1318\n",
      "Epoch 530, Train Loss: 6700849.0000, Val MSE: 6733970.5000, Val MAE: 1630.9664\n",
      "Epoch 540, Train Loss: 6690392.5000, Val MSE: 6722462.0000, Val MAE: 1629.7657\n",
      "Epoch 550, Train Loss: 6679908.5000, Val MSE: 6710916.0000, Val MAE: 1628.5909\n",
      "Epoch 560, Train Loss: 6669417.0000, Val MSE: 6699349.5000, Val MAE: 1627.4447\n",
      "Epoch 570, Train Loss: 6659408.0000, Val MSE: 6688910.0000, Val MAE: 1627.4600\n",
      "Epoch 580, Train Loss: 6831893.0000, Val MSE: 6797955.5000, Val MAE: 1651.5715\n",
      "Epoch 590, Train Loss: 6677067.5000, Val MSE: 6667727.5000, Val MAE: 1625.6747\n",
      "Epoch 600, Train Loss: 6633949.0000, Val MSE: 6668205.0000, Val MAE: 1619.4843\n",
      "Epoch 610, Train Loss: 6622886.0000, Val MSE: 6642236.5000, Val MAE: 1620.9117\n",
      "Epoch 620, Train Loss: 6608798.5000, Val MSE: 6633754.0000, Val MAE: 1622.2539\n",
      "Epoch 630, Train Loss: 6599351.0000, Val MSE: 6620988.0000, Val MAE: 1620.0964\n",
      "Epoch 640, Train Loss: 6588843.5000, Val MSE: 6609252.5000, Val MAE: 1618.1948\n",
      "Epoch 650, Train Loss: 6578946.0000, Val MSE: 6598183.0000, Val MAE: 1616.8619\n",
      "Epoch 660, Train Loss: 6569319.0000, Val MSE: 6587235.0000, Val MAE: 1615.7799\n",
      "Epoch 670, Train Loss: 6559833.5000, Val MSE: 6576386.5000, Val MAE: 1614.7053\n",
      "Epoch 680, Train Loss: 6550483.0000, Val MSE: 6565611.5000, Val MAE: 1613.5072\n",
      "Epoch 690, Train Loss: 6541304.0000, Val MSE: 6555000.0000, Val MAE: 1612.2988\n",
      "Epoch 700, Train Loss: 6532277.0000, Val MSE: 6544580.0000, Val MAE: 1611.3094\n",
      "Epoch 710, Train Loss: 6523413.0000, Val MSE: 6534308.0000, Val MAE: 1610.1930\n",
      "Epoch 720, Train Loss: 6514718.0000, Val MSE: 6524226.5000, Val MAE: 1609.1554\n",
      "Epoch 730, Train Loss: 6506199.0000, Val MSE: 6514335.5000, Val MAE: 1608.0332\n",
      "Epoch 740, Train Loss: 6500471.0000, Val MSE: 6509423.5000, Val MAE: 1605.5380\n",
      "Epoch 750, Train Loss: 6532383.5000, Val MSE: 6496987.5000, Val MAE: 1606.8796\n",
      "Epoch 760, Train Loss: 6483652.0000, Val MSE: 6515065.0000, Val MAE: 1614.5613\n",
      "Epoch 770, Train Loss: 6492190.0000, Val MSE: 6486643.0000, Val MAE: 1608.6772\n",
      "Epoch 780, Train Loss: 6467414.0000, Val MSE: 6470021.5000, Val MAE: 1602.5261\n",
      "Epoch 790, Train Loss: 6460389.5000, Val MSE: 6462441.0000, Val MAE: 1601.2244\n",
      "Epoch 800, Train Loss: 6452594.0000, Val MSE: 6452434.0000, Val MAE: 1600.9467\n",
      "Epoch 810, Train Loss: 6444575.5000, Val MSE: 6443673.0000, Val MAE: 1600.3911\n",
      "Epoch 820, Train Loss: 6437044.0000, Val MSE: 6435313.5000, Val MAE: 1599.6315\n",
      "Epoch 830, Train Loss: 6429681.0000, Val MSE: 6427048.5000, Val MAE: 1598.7493\n",
      "Epoch 840, Train Loss: 6422374.5000, Val MSE: 6418864.5000, Val MAE: 1597.9017\n",
      "Epoch 850, Train Loss: 6415123.5000, Val MSE: 6410744.0000, Val MAE: 1597.1095\n",
      "Epoch 860, Train Loss: 6407886.0000, Val MSE: 6402713.0000, Val MAE: 1596.2119\n",
      "Epoch 870, Train Loss: 6400646.5000, Val MSE: 6394716.0000, Val MAE: 1595.1932\n",
      "Epoch 880, Train Loss: 6393389.0000, Val MSE: 6386726.5000, Val MAE: 1594.2766\n",
      "Epoch 890, Train Loss: 6386099.0000, Val MSE: 6378756.0000, Val MAE: 1593.2659\n",
      "Epoch 900, Train Loss: 6378767.0000, Val MSE: 6370783.0000, Val MAE: 1592.2411\n",
      "Epoch 910, Train Loss: 6371390.5000, Val MSE: 6362837.5000, Val MAE: 1591.1143\n",
      "Epoch 920, Train Loss: 6366647.0000, Val MSE: 6360150.0000, Val MAE: 1589.1075\n",
      "Epoch 930, Train Loss: 6465624.5000, Val MSE: 6365632.0000, Val MAE: 1586.7574\n",
      "Epoch 940, Train Loss: 6373509.0000, Val MSE: 6338917.0000, Val MAE: 1587.7827\n",
      "Epoch 950, Train Loss: 6341828.0000, Val MSE: 6339295.0000, Val MAE: 1590.7109\n",
      "Epoch 960, Train Loss: 6338681.5000, Val MSE: 6328789.0000, Val MAE: 1588.8469\n",
      "Epoch 970, Train Loss: 6328184.0000, Val MSE: 6315867.0000, Val MAE: 1585.4427\n",
      "Epoch 980, Train Loss: 6318398.0000, Val MSE: 6307124.0000, Val MAE: 1583.4658\n",
      "Epoch 990, Train Loss: 6309864.5000, Val MSE: 6298775.0000, Val MAE: 1582.0969\n",
      "Epoch 1000, Train Loss: 6301512.0000, Val MSE: 6290287.5000, Val MAE: 1580.8948\n",
      "Epoch 1010, Train Loss: 6293066.5000, Val MSE: 6281695.0000, Val MAE: 1579.6459\n",
      "Epoch 1020, Train Loss: 6284478.5000, Val MSE: 6273042.0000, Val MAE: 1578.2870\n",
      "Epoch 1030, Train Loss: 6275778.0000, Val MSE: 6264347.5000, Val MAE: 1576.8140\n",
      "Epoch 1040, Train Loss: 6266965.0000, Val MSE: 6255566.5000, Val MAE: 1575.3375\n",
      "Epoch 1050, Train Loss: 6258036.0000, Val MSE: 6246685.0000, Val MAE: 1573.9434\n",
      "Epoch 1060, Train Loss: 6249004.5000, Val MSE: 6237764.5000, Val MAE: 1572.4637\n",
      "Epoch 1070, Train Loss: 6239886.5000, Val MSE: 6228804.0000, Val MAE: 1570.9875\n",
      "Epoch 1080, Train Loss: 6230699.5000, Val MSE: 6219823.0000, Val MAE: 1569.4780\n",
      "Epoch 1090, Train Loss: 6221465.5000, Val MSE: 6210834.5000, Val MAE: 1567.9714\n",
      "Epoch 1100, Train Loss: 6212207.0000, Val MSE: 6201859.0000, Val MAE: 1566.4673\n",
      "Epoch 1110, Train Loss: 6202955.0000, Val MSE: 6192907.0000, Val MAE: 1565.0081\n",
      "Epoch 1120, Train Loss: 6194655.5000, Val MSE: 6185223.0000, Val MAE: 1564.6331\n",
      "Epoch 1130, Train Loss: 6444072.5000, Val MSE: 6377454.5000, Val MAE: 1600.5428\n",
      "Epoch 1140, Train Loss: 6251531.0000, Val MSE: 6211929.5000, Val MAE: 1573.4077\n",
      "Epoch 1150, Train Loss: 6174687.5000, Val MSE: 6159955.5000, Val MAE: 1558.1733\n",
      "Epoch 1160, Train Loss: 6162717.5000, Val MSE: 6159776.5000, Val MAE: 1555.7114\n",
      "Epoch 1170, Train Loss: 6152490.0000, Val MSE: 6143580.0000, Val MAE: 1555.5378\n",
      "Epoch 1180, Train Loss: 6141344.0000, Val MSE: 6135498.5000, Val MAE: 1555.4719\n",
      "Epoch 1190, Train Loss: 6133260.0000, Val MSE: 6127592.5000, Val MAE: 1554.1339\n",
      "Epoch 1200, Train Loss: 6125146.5000, Val MSE: 6119622.0000, Val MAE: 1552.6016\n",
      "Epoch 1210, Train Loss: 6117180.0000, Val MSE: 6112000.0000, Val MAE: 1551.1995\n",
      "Epoch 1220, Train Loss: 6109455.0000, Val MSE: 6104627.5000, Val MAE: 1549.9580\n",
      "Epoch 1230, Train Loss: 6101943.0000, Val MSE: 6097397.5000, Val MAE: 1548.7743\n",
      "Epoch 1240, Train Loss: 6094622.0000, Val MSE: 6090325.5000, Val MAE: 1547.6382\n",
      "Epoch 1250, Train Loss: 6087484.0000, Val MSE: 6083373.0000, Val MAE: 1546.5192\n",
      "Epoch 1260, Train Loss: 6080512.5000, Val MSE: 6076565.0000, Val MAE: 1545.4515\n",
      "Epoch 1270, Train Loss: 6073696.0000, Val MSE: 6069855.5000, Val MAE: 1544.4531\n",
      "Epoch 1280, Train Loss: 6067021.5000, Val MSE: 6063249.5000, Val MAE: 1543.4897\n",
      "Epoch 1290, Train Loss: 6060477.5000, Val MSE: 6056748.5000, Val MAE: 1542.5292\n",
      "Epoch 1300, Train Loss: 6054052.0000, Val MSE: 6050322.0000, Val MAE: 1541.6025\n",
      "Epoch 1310, Train Loss: 6047729.5000, Val MSE: 6043969.5000, Val MAE: 1540.6838\n",
      "Epoch 1320, Train Loss: 6041502.5000, Val MSE: 6037678.0000, Val MAE: 1539.7791\n",
      "Epoch 1330, Train Loss: 6035357.0000, Val MSE: 6031441.5000, Val MAE: 1538.8781\n",
      "Epoch 1340, Train Loss: 6029284.5000, Val MSE: 6025250.0000, Val MAE: 1537.9866\n",
      "Epoch 1350, Train Loss: 6023275.0000, Val MSE: 6019087.5000, Val MAE: 1537.1289\n",
      "Epoch 1360, Train Loss: 6017549.0000, Val MSE: 6013150.5000, Val MAE: 1536.7427\n",
      "Epoch 1370, Train Loss: 6100681.5000, Val MSE: 6144055.0000, Val MAE: 1564.6472\n",
      "Epoch 1380, Train Loss: 6067233.5000, Val MSE: 6006241.0000, Val MAE: 1529.5442\n",
      "Epoch 1390, Train Loss: 6008999.0000, Val MSE: 5996116.5000, Val MAE: 1534.1547\n",
      "Epoch 1400, Train Loss: 5995980.5000, Val MSE: 6001699.5000, Val MAE: 1539.0310\n",
      "Epoch 1410, Train Loss: 5992074.0000, Val MSE: 5987776.0000, Val MAE: 1534.5406\n",
      "Epoch 1420, Train Loss: 5984487.5000, Val MSE: 5978480.0000, Val MAE: 1531.4983\n",
      "Epoch 1430, Train Loss: 5977764.5000, Val MSE: 5972860.5000, Val MAE: 1530.6055\n",
      "Epoch 1440, Train Loss: 5971851.0000, Val MSE: 5967042.5000, Val MAE: 1529.7375\n",
      "Epoch 1450, Train Loss: 5966162.0000, Val MSE: 5960983.5000, Val MAE: 1528.7003\n",
      "Epoch 1460, Train Loss: 5960526.0000, Val MSE: 5955014.0000, Val MAE: 1527.7648\n",
      "Epoch 1470, Train Loss: 5954919.5000, Val MSE: 5949169.0000, Val MAE: 1526.8711\n",
      "Epoch 1480, Train Loss: 5949336.0000, Val MSE: 5943372.5000, Val MAE: 1525.9701\n",
      "Epoch 1490, Train Loss: 5943777.0000, Val MSE: 5937610.0000, Val MAE: 1525.0643\n",
      "Epoch 1500, Train Loss: 5938233.5000, Val MSE: 5931875.0000, Val MAE: 1524.2089\n",
      "Epoch 1510, Train Loss: 5932708.0000, Val MSE: 5926173.0000, Val MAE: 1523.3986\n",
      "Epoch 1520, Train Loss: 5927202.0000, Val MSE: 5920502.5000, Val MAE: 1522.5541\n",
      "Epoch 1530, Train Loss: 5921715.5000, Val MSE: 5914864.0000, Val MAE: 1521.7136\n",
      "Epoch 1540, Train Loss: 5916253.0000, Val MSE: 5909259.0000, Val MAE: 1520.8840\n",
      "Epoch 1550, Train Loss: 5910813.5000, Val MSE: 5903691.5000, Val MAE: 1520.0498\n",
      "Epoch 1560, Train Loss: 5905399.5000, Val MSE: 5898166.5000, Val MAE: 1519.2233\n",
      "Epoch 1570, Train Loss: 5900013.5000, Val MSE: 5892690.0000, Val MAE: 1518.4075\n",
      "Epoch 1580, Train Loss: 5894658.0000, Val MSE: 5887256.0000, Val MAE: 1517.6046\n",
      "Epoch 1590, Train Loss: 5889337.5000, Val MSE: 5881879.0000, Val MAE: 1516.8662\n",
      "Epoch 1600, Train Loss: 5884362.0000, Val MSE: 5877025.5000, Val MAE: 1516.8380\n",
      "Epoch 1610, Train Loss: 5930546.5000, Val MSE: 5951298.0000, Val MAE: 1536.0985\n",
      "Epoch 1620, Train Loss: 5951554.0000, Val MSE: 5947952.5000, Val MAE: 1515.1792\n",
      "Epoch 1630, Train Loss: 5887105.0000, Val MSE: 5889206.0000, Val MAE: 1514.9728\n",
      "Epoch 1640, Train Loss: 5872489.0000, Val MSE: 5869859.0000, Val MAE: 1515.1622\n",
      "Epoch 1650, Train Loss: 5862139.0000, Val MSE: 5857909.5000, Val MAE: 1513.5765\n",
      "Epoch 1660, Train Loss: 5854795.5000, Val MSE: 5848947.5000, Val MAE: 1511.4906\n",
      "Epoch 1670, Train Loss: 5849047.0000, Val MSE: 5842573.5000, Val MAE: 1510.0371\n",
      "Epoch 1680, Train Loss: 5843768.0000, Val MSE: 5837456.5000, Val MAE: 1509.7710\n",
      "Epoch 1690, Train Loss: 5838799.5000, Val MSE: 5832370.0000, Val MAE: 1509.1364\n",
      "Epoch 1700, Train Loss: 5833976.5000, Val MSE: 5827193.0000, Val MAE: 1508.2339\n",
      "Epoch 1710, Train Loss: 5829188.5000, Val MSE: 5822528.5000, Val MAE: 1507.6873\n",
      "Epoch 1720, Train Loss: 5824438.5000, Val MSE: 5817818.0000, Val MAE: 1506.8558\n",
      "Epoch 1730, Train Loss: 5819743.0000, Val MSE: 5813220.0000, Val MAE: 1506.1254\n",
      "Epoch 1740, Train Loss: 5815090.0000, Val MSE: 5808622.5000, Val MAE: 1505.4689\n",
      "Epoch 1750, Train Loss: 5810480.0000, Val MSE: 5804114.0000, Val MAE: 1504.7947\n",
      "Epoch 1760, Train Loss: 5805920.5000, Val MSE: 5799766.0000, Val MAE: 1504.2546\n",
      "Epoch 1770, Train Loss: 5801976.0000, Val MSE: 5797940.5000, Val MAE: 1505.7168\n",
      "Epoch 1780, Train Loss: 5883404.0000, Val MSE: 5897022.0000, Val MAE: 1536.4554\n",
      "Epoch 1790, Train Loss: 5794179.5000, Val MSE: 5806154.5000, Val MAE: 1510.8726\n",
      "Epoch 1800, Train Loss: 5788719.5000, Val MSE: 5789701.0000, Val MAE: 1506.6766\n",
      "Epoch 1810, Train Loss: 5784132.5000, Val MSE: 5782276.5000, Val MAE: 1503.1245\n",
      "Epoch 1820, Train Loss: 5779669.0000, Val MSE: 5775716.0000, Val MAE: 1501.6801\n",
      "Epoch 1830, Train Loss: 5775412.0000, Val MSE: 5770487.0000, Val MAE: 1499.8339\n",
      "Epoch 1840, Train Loss: 5771268.5000, Val MSE: 5765827.0000, Val MAE: 1498.4666\n",
      "Epoch 1850, Train Loss: 5767040.0000, Val MSE: 5761514.0000, Val MAE: 1497.6370\n",
      "Epoch 1860, Train Loss: 5762829.0000, Val MSE: 5757594.0000, Val MAE: 1497.1447\n",
      "Epoch 1870, Train Loss: 5758914.0000, Val MSE: 5754292.0000, Val MAE: 1496.4812\n",
      "Epoch 1880, Train Loss: 5769512.0000, Val MSE: 5774057.0000, Val MAE: 1495.9528\n",
      "Epoch 1890, Train Loss: 5770805.5000, Val MSE: 5746164.5000, Val MAE: 1492.7886\n",
      "Epoch 1900, Train Loss: 5768388.0000, Val MSE: 5763349.0000, Val MAE: 1490.0736\n",
      "Epoch 1910, Train Loss: 5743769.0000, Val MSE: 5740462.5000, Val MAE: 1493.5129\n",
      "Epoch 1920, Train Loss: 5742363.0000, Val MSE: 5738130.5000, Val MAE: 1496.9141\n",
      "Epoch 1930, Train Loss: 5735005.0000, Val MSE: 5732410.5000, Val MAE: 1495.0428\n",
      "Epoch 1940, Train Loss: 5731284.0000, Val MSE: 5727483.5000, Val MAE: 1491.9945\n",
      "Epoch 1950, Train Loss: 5726936.0000, Val MSE: 5723170.5000, Val MAE: 1491.8733\n",
      "Epoch 1960, Train Loss: 5723077.0000, Val MSE: 5719384.0000, Val MAE: 1491.5737\n",
      "Epoch 1970, Train Loss: 5719213.5000, Val MSE: 5715496.0000, Val MAE: 1490.4119\n",
      "Epoch 1980, Train Loss: 5715369.0000, Val MSE: 5711961.5000, Val MAE: 1490.3345\n",
      "Epoch 1990, Train Loss: 5711544.5000, Val MSE: 5708064.5000, Val MAE: 1489.4158\n",
      "Epoch 2000, Train Loss: 5707743.5000, Val MSE: 5704362.0000, Val MAE: 1488.8798\n",
      "Epoch 2010, Train Loss: 5703957.5000, Val MSE: 5700703.5000, Val MAE: 1488.3693\n",
      "Epoch 2020, Train Loss: 5700191.0000, Val MSE: 5697026.0000, Val MAE: 1487.8063\n",
      "Epoch 2030, Train Loss: 5696461.0000, Val MSE: 5693502.0000, Val MAE: 1487.5037\n",
      "Epoch 2040, Train Loss: 5694098.5000, Val MSE: 5692970.5000, Val MAE: 1489.7394\n",
      "Epoch 2050, Train Loss: 5804078.5000, Val MSE: 5828591.5000, Val MAE: 1522.1698\n",
      "Epoch 2060, Train Loss: 5725601.5000, Val MSE: 5716082.5000, Val MAE: 1488.2668\n",
      "Epoch 2070, Train Loss: 5687355.5000, Val MSE: 5680381.0000, Val MAE: 1482.0800\n",
      "Epoch 2080, Train Loss: 5684476.0000, Val MSE: 5676500.0000, Val MAE: 1484.2731\n",
      "Epoch 2090, Train Loss: 5676106.0000, Val MSE: 5672084.0000, Val MAE: 1482.9396\n",
      "Epoch 2100, Train Loss: 5671531.5000, Val MSE: 5668146.5000, Val MAE: 1481.1627\n",
      "Epoch 2110, Train Loss: 5667207.5000, Val MSE: 5664628.5000, Val MAE: 1481.7471\n",
      "Epoch 2120, Train Loss: 5663660.5000, Val MSE: 5661764.0000, Val MAE: 1482.2313\n",
      "Epoch 2130, Train Loss: 5660027.0000, Val MSE: 5658267.5000, Val MAE: 1481.2756\n",
      "Epoch 2140, Train Loss: 5656404.0000, Val MSE: 5654436.5000, Val MAE: 1480.7039\n",
      "Epoch 2150, Train Loss: 5652816.0000, Val MSE: 5650806.5000, Val MAE: 1479.8546\n",
      "Epoch 2160, Train Loss: 5649240.5000, Val MSE: 5647445.0000, Val MAE: 1479.5427\n",
      "Epoch 2170, Train Loss: 5645673.0000, Val MSE: 5643855.5000, Val MAE: 1478.8319\n",
      "Epoch 2180, Train Loss: 5642117.5000, Val MSE: 5640374.5000, Val MAE: 1478.2307\n",
      "Epoch 2190, Train Loss: 5638569.0000, Val MSE: 5636858.0000, Val MAE: 1477.5933\n",
      "Epoch 2200, Train Loss: 5635050.0000, Val MSE: 5633364.0000, Val MAE: 1476.7828\n",
      "Epoch 2210, Train Loss: 5632900.0000, Val MSE: 5631399.0000, Val MAE: 1474.0497\n",
      "Epoch 2220, Train Loss: 5773089.5000, Val MSE: 5800989.0000, Val MAE: 1475.3599\n",
      "Epoch 2230, Train Loss: 5674968.5000, Val MSE: 5635293.5000, Val MAE: 1480.4993\n",
      "Epoch 2240, Train Loss: 5642267.5000, Val MSE: 5633499.0000, Val MAE: 1481.7256\n",
      "Epoch 2250, Train Loss: 5623669.5000, Val MSE: 5623015.0000, Val MAE: 1479.1682\n",
      "Epoch 2260, Train Loss: 5616238.5000, Val MSE: 5616873.0000, Val MAE: 1476.8190\n",
      "Epoch 2270, Train Loss: 5611499.0000, Val MSE: 5612118.5000, Val MAE: 1474.7001\n",
      "Epoch 2280, Train Loss: 5607469.5000, Val MSE: 5607108.0000, Val MAE: 1472.6852\n",
      "Epoch 2290, Train Loss: 5604070.5000, Val MSE: 5602948.0000, Val MAE: 1471.4227\n",
      "Epoch 2300, Train Loss: 5600554.5000, Val MSE: 5599558.5000, Val MAE: 1471.0054\n",
      "Epoch 2310, Train Loss: 5597122.0000, Val MSE: 5596546.0000, Val MAE: 1470.8101\n",
      "Epoch 2320, Train Loss: 5593690.0000, Val MSE: 5593114.5000, Val MAE: 1470.1713\n",
      "Epoch 2330, Train Loss: 5590281.0000, Val MSE: 5589580.5000, Val MAE: 1469.4493\n",
      "Epoch 2340, Train Loss: 5586874.0000, Val MSE: 5586343.5000, Val MAE: 1468.9893\n",
      "Epoch 2350, Train Loss: 5583474.0000, Val MSE: 5582903.0000, Val MAE: 1468.3369\n",
      "Epoch 2360, Train Loss: 5580080.0000, Val MSE: 5579594.0000, Val MAE: 1467.7996\n",
      "Epoch 2370, Train Loss: 5576690.5000, Val MSE: 5576213.5000, Val MAE: 1467.1901\n",
      "Epoch 2380, Train Loss: 5573307.5000, Val MSE: 5572876.0000, Val MAE: 1466.6053\n",
      "Epoch 2390, Train Loss: 5569929.0000, Val MSE: 5569537.5000, Val MAE: 1466.0120\n",
      "Epoch 2400, Train Loss: 5566559.0000, Val MSE: 5566152.5000, Val MAE: 1465.2994\n",
      "Epoch 2410, Train Loss: 5563552.5000, Val MSE: 5562729.0000, Val MAE: 1463.2067\n",
      "Epoch 2420, Train Loss: 5645872.5000, Val MSE: 5679610.5000, Val MAE: 1456.2484\n",
      "Epoch 2430, Train Loss: 5598830.5000, Val MSE: 5585596.0000, Val MAE: 1473.7788\n",
      "Epoch 2440, Train Loss: 5555153.0000, Val MSE: 5561136.0000, Val MAE: 1460.1230\n",
      "Epoch 2450, Train Loss: 5561883.0000, Val MSE: 5553608.5000, Val MAE: 1457.9948\n",
      "Epoch 2460, Train Loss: 5548196.0000, Val MSE: 5549741.5000, Val MAE: 1462.1914\n",
      "Epoch 2470, Train Loss: 5544442.0000, Val MSE: 5546517.0000, Val MAE: 1462.8694\n",
      "Epoch 2480, Train Loss: 5540632.0000, Val MSE: 5540752.5000, Val MAE: 1461.1697\n",
      "Epoch 2490, Train Loss: 5537023.0000, Val MSE: 5537123.0000, Val MAE: 1460.0714\n",
      "Epoch 2500, Train Loss: 5533757.5000, Val MSE: 5533794.5000, Val MAE: 1459.2031\n",
      "Epoch 2510, Train Loss: 5530455.5000, Val MSE: 5530663.0000, Val MAE: 1458.8298\n",
      "Epoch 2520, Train Loss: 5527170.0000, Val MSE: 5527508.5000, Val MAE: 1458.5243\n",
      "Epoch 2530, Train Loss: 5523896.0000, Val MSE: 5524279.5000, Val MAE: 1457.8737\n",
      "Epoch 2540, Train Loss: 5520631.0000, Val MSE: 5521050.0000, Val MAE: 1457.3707\n",
      "Epoch 2550, Train Loss: 5517369.0000, Val MSE: 5517797.5000, Val MAE: 1456.7400\n",
      "Epoch 2560, Train Loss: 5514111.0000, Val MSE: 5514563.5000, Val MAE: 1456.1912\n",
      "Epoch 2570, Train Loss: 5510856.0000, Val MSE: 5511331.0000, Val MAE: 1455.6042\n",
      "Epoch 2580, Train Loss: 5507604.5000, Val MSE: 5508104.5000, Val MAE: 1455.0143\n",
      "Epoch 2590, Train Loss: 5504355.0000, Val MSE: 5504883.0000, Val MAE: 1454.4165\n",
      "Epoch 2600, Train Loss: 5501117.5000, Val MSE: 5501659.0000, Val MAE: 1453.6886\n",
      "Epoch 2610, Train Loss: 5498727.0000, Val MSE: 5499553.5000, Val MAE: 1451.4918\n",
      "Epoch 2620, Train Loss: 5658393.0000, Val MSE: 5718156.5000, Val MAE: 1457.2993\n",
      "Epoch 2630, Train Loss: 5552173.0000, Val MSE: 5497892.5000, Val MAE: 1457.1588\n",
      "Epoch 2640, Train Loss: 5508558.5000, Val MSE: 5490934.0000, Val MAE: 1453.8804\n",
      "Epoch 2650, Train Loss: 5489619.5000, Val MSE: 5486154.5000, Val MAE: 1450.6345\n",
      "Epoch 2660, Train Loss: 5483040.5000, Val MSE: 5483055.0000, Val MAE: 1449.4186\n",
      "Epoch 2670, Train Loss: 5479319.5000, Val MSE: 5479804.0000, Val MAE: 1449.2079\n",
      "Epoch 2680, Train Loss: 5476066.5000, Val MSE: 5476909.5000, Val MAE: 1449.2297\n",
      "Epoch 2690, Train Loss: 5472855.5000, Val MSE: 5474096.5000, Val MAE: 1449.0795\n",
      "Epoch 2700, Train Loss: 5469596.0000, Val MSE: 5470990.0000, Val MAE: 1448.6088\n",
      "Epoch 2710, Train Loss: 5466349.0000, Val MSE: 5467667.0000, Val MAE: 1447.8162\n",
      "Epoch 2720, Train Loss: 5463176.0000, Val MSE: 5464395.5000, Val MAE: 1446.8966\n",
      "Epoch 2730, Train Loss: 5460003.5000, Val MSE: 5461207.5000, Val MAE: 1446.2427\n",
      "Epoch 2740, Train Loss: 5456833.0000, Val MSE: 5458094.0000, Val MAE: 1445.8116\n",
      "Epoch 2750, Train Loss: 5453665.5000, Val MSE: 5454933.5000, Val MAE: 1445.2063\n",
      "Epoch 2760, Train Loss: 5450500.0000, Val MSE: 5451771.5000, Val MAE: 1444.5808\n",
      "Epoch 2770, Train Loss: 5447335.0000, Val MSE: 5448637.0000, Val MAE: 1444.0280\n",
      "Epoch 2780, Train Loss: 5444171.0000, Val MSE: 5445488.5000, Val MAE: 1443.4191\n",
      "Epoch 2790, Train Loss: 5441008.5000, Val MSE: 5442349.0000, Val MAE: 1442.8361\n",
      "Epoch 2800, Train Loss: 5437847.5000, Val MSE: 5439209.5000, Val MAE: 1442.2422\n",
      "Epoch 2810, Train Loss: 5434686.0000, Val MSE: 5436076.5000, Val MAE: 1441.6547\n",
      "Epoch 2820, Train Loss: 5431526.5000, Val MSE: 5432942.5000, Val MAE: 1441.0660\n",
      "Epoch 2830, Train Loss: 5428367.5000, Val MSE: 5429833.0000, Val MAE: 1440.5377\n",
      "Epoch 2840, Train Loss: 5425380.5000, Val MSE: 5427312.5000, Val MAE: 1440.9817\n",
      "Epoch 2850, Train Loss: 5489291.5000, Val MSE: 5543178.0000, Val MAE: 1471.3417\n",
      "Epoch 2860, Train Loss: 5580993.0000, Val MSE: 5536848.0000, Val MAE: 1438.3646\n",
      "Epoch 2870, Train Loss: 5468060.5000, Val MSE: 5443047.5000, Val MAE: 1440.3772\n",
      "Epoch 2880, Train Loss: 5420517.0000, Val MSE: 5415224.0000, Val MAE: 1438.5203\n",
      "Epoch 2890, Train Loss: 5411313.5000, Val MSE: 5415573.5000, Val MAE: 1439.1292\n",
      "Epoch 2900, Train Loss: 5408393.5000, Val MSE: 5411041.5000, Val MAE: 1438.8809\n",
      "Epoch 2910, Train Loss: 5404709.0000, Val MSE: 5407560.0000, Val MAE: 1437.7280\n",
      "Epoch 2920, Train Loss: 5401204.0000, Val MSE: 5403433.0000, Val MAE: 1435.9893\n",
      "Epoch 2930, Train Loss: 5397893.0000, Val MSE: 5399884.5000, Val MAE: 1434.8727\n",
      "Epoch 2940, Train Loss: 5394753.0000, Val MSE: 5396691.5000, Val MAE: 1434.1841\n",
      "Epoch 2950, Train Loss: 5391633.0000, Val MSE: 5393639.0000, Val MAE: 1433.5300\n",
      "Epoch 2960, Train Loss: 5388535.5000, Val MSE: 5390541.0000, Val MAE: 1432.8411\n",
      "Epoch 2970, Train Loss: 5385448.0000, Val MSE: 5387428.0000, Val MAE: 1432.1444\n",
      "Epoch 2980, Train Loss: 5382360.0000, Val MSE: 5384331.5000, Val MAE: 1431.5254\n",
      "Epoch 2990, Train Loss: 5379273.5000, Val MSE: 5381260.0000, Val MAE: 1430.9735\n",
      "Epoch 3000, Train Loss: 5376188.0000, Val MSE: 5378183.0000, Val MAE: 1430.3774\n",
      "Epoch 3010, Train Loss: 5373103.0000, Val MSE: 5375098.5000, Val MAE: 1429.7445\n",
      "Epoch 3020, Train Loss: 5370019.0000, Val MSE: 5372032.5000, Val MAE: 1429.1582\n",
      "Epoch 3030, Train Loss: 5366935.0000, Val MSE: 5368957.5000, Val MAE: 1428.5385\n",
      "Epoch 3040, Train Loss: 5363853.0000, Val MSE: 5365892.5000, Val MAE: 1427.9386\n",
      "Epoch 3050, Train Loss: 5360771.0000, Val MSE: 5362825.5000, Val MAE: 1427.3263\n",
      "Epoch 3060, Train Loss: 5357690.0000, Val MSE: 5359765.0000, Val MAE: 1426.7144\n",
      "Epoch 3070, Train Loss: 5354611.0000, Val MSE: 5356697.5000, Val MAE: 1426.0847\n",
      "Epoch 3080, Train Loss: 5351535.0000, Val MSE: 5353619.0000, Val MAE: 1425.3864\n",
      "Epoch 3090, Train Loss: 5348636.5000, Val MSE: 5350576.5000, Val MAE: 1423.8469\n",
      "Epoch 3100, Train Loss: 5386243.5000, Val MSE: 5411087.0000, Val MAE: 1416.2812\n",
      "Epoch 3110, Train Loss: 5409740.0000, Val MSE: 5472388.0000, Val MAE: 1456.0988\n",
      "Epoch 3120, Train Loss: 5353591.5000, Val MSE: 5378827.5000, Val MAE: 1437.0317\n",
      "Epoch 3130, Train Loss: 5345804.0000, Val MSE: 5355209.0000, Val MAE: 1429.6171\n",
      "Epoch 3140, Train Loss: 5339028.5000, Val MSE: 5341944.0000, Val MAE: 1425.8499\n",
      "Epoch 3150, Train Loss: 5332574.0000, Val MSE: 5335414.5000, Val MAE: 1424.0616\n",
      "Epoch 3160, Train Loss: 5328288.5000, Val MSE: 5331643.0000, Val MAE: 1422.6956\n",
      "Epoch 3170, Train Loss: 5324873.0000, Val MSE: 5327952.5000, Val MAE: 1421.2400\n",
      "Epoch 3180, Train Loss: 5321766.0000, Val MSE: 5324462.5000, Val MAE: 1419.9210\n",
      "Epoch 3190, Train Loss: 5318773.5000, Val MSE: 5321212.5000, Val MAE: 1418.8186\n",
      "Epoch 3200, Train Loss: 5315751.5000, Val MSE: 5318189.5000, Val MAE: 1418.0900\n",
      "Epoch 3210, Train Loss: 5312739.0000, Val MSE: 5315196.0000, Val MAE: 1417.6782\n",
      "Epoch 3220, Train Loss: 5309740.5000, Val MSE: 5312208.0000, Val MAE: 1417.1663\n",
      "Epoch 3230, Train Loss: 5306743.0000, Val MSE: 5309181.5000, Val MAE: 1416.4487\n",
      "Epoch 3240, Train Loss: 5303748.5000, Val MSE: 5306194.5000, Val MAE: 1415.8712\n",
      "Epoch 3250, Train Loss: 5300759.0000, Val MSE: 5303208.5000, Val MAE: 1415.2643\n",
      "Epoch 3260, Train Loss: 5297772.0000, Val MSE: 5300229.5000, Val MAE: 1414.6626\n",
      "Epoch 3270, Train Loss: 5294787.0000, Val MSE: 5297254.5000, Val MAE: 1414.0527\n",
      "Epoch 3280, Train Loss: 5291806.5000, Val MSE: 5294288.0000, Val MAE: 1413.4629\n",
      "Epoch 3290, Train Loss: 5288828.0000, Val MSE: 5291327.5000, Val MAE: 1412.8701\n",
      "Epoch 3300, Train Loss: 5285853.5000, Val MSE: 5288372.0000, Val MAE: 1412.2819\n",
      "Epoch 3310, Train Loss: 5282885.0000, Val MSE: 5285447.5000, Val MAE: 1411.7926\n",
      "Epoch 3320, Train Loss: 5280323.5000, Val MSE: 5283505.0000, Val MAE: 1412.6761\n",
      "Epoch 3330, Train Loss: 5401558.0000, Val MSE: 5476192.5000, Val MAE: 1454.3009\n",
      "Epoch 3340, Train Loss: 5409491.0000, Val MSE: 5321695.5000, Val MAE: 1408.8434\n",
      "Epoch 3350, Train Loss: 5301810.5000, Val MSE: 5286771.5000, Val MAE: 1414.1337\n",
      "Epoch 3360, Train Loss: 5276652.5000, Val MSE: 5278565.5000, Val MAE: 1414.2715\n",
      "Epoch 3370, Train Loss: 5267318.0000, Val MSE: 5270151.0000, Val MAE: 1410.1406\n",
      "Epoch 3380, Train Loss: 5263283.0000, Val MSE: 5266324.5000, Val MAE: 1407.9900\n",
      "Epoch 3390, Train Loss: 5260567.0000, Val MSE: 5263322.5000, Val MAE: 1407.1357\n",
      "Epoch 3400, Train Loss: 5257443.0000, Val MSE: 5260122.0000, Val MAE: 1406.5933\n",
      "Epoch 3410, Train Loss: 5254435.0000, Val MSE: 5257219.5000, Val MAE: 1406.0249\n",
      "Epoch 3420, Train Loss: 5251543.0000, Val MSE: 5254312.5000, Val MAE: 1405.3317\n",
      "Epoch 3430, Train Loss: 5248679.0000, Val MSE: 5251445.5000, Val MAE: 1404.6442\n",
      "Epoch 3440, Train Loss: 5245812.5000, Val MSE: 5248561.5000, Val MAE: 1404.0356\n",
      "Epoch 3450, Train Loss: 5242951.5000, Val MSE: 5245684.5000, Val MAE: 1403.5042\n",
      "Epoch 3460, Train Loss: 5240099.0000, Val MSE: 5242836.5000, Val MAE: 1402.9579\n",
      "Epoch 3470, Train Loss: 5237249.0000, Val MSE: 5239994.5000, Val MAE: 1402.3574\n",
      "Epoch 3480, Train Loss: 5234403.5000, Val MSE: 5237168.5000, Val MAE: 1401.7919\n",
      "Epoch 3490, Train Loss: 5231564.0000, Val MSE: 5234344.5000, Val MAE: 1401.2411\n",
      "Epoch 3500, Train Loss: 5228729.0000, Val MSE: 5231522.0000, Val MAE: 1400.6498\n",
      "Epoch 3510, Train Loss: 5225897.0000, Val MSE: 5228709.5000, Val MAE: 1400.0875\n",
      "Epoch 3520, Train Loss: 5223071.0000, Val MSE: 5225906.0000, Val MAE: 1399.5190\n",
      "Epoch 3530, Train Loss: 5220249.5000, Val MSE: 5223104.5000, Val MAE: 1398.9424\n",
      "Epoch 3540, Train Loss: 5217433.0000, Val MSE: 5220311.0000, Val MAE: 1398.3735\n",
      "Epoch 3550, Train Loss: 5214620.0000, Val MSE: 5217522.0000, Val MAE: 1397.7849\n",
      "Epoch 3560, Train Loss: 5211831.0000, Val MSE: 5214755.0000, Val MAE: 1397.0118\n",
      "Epoch 3570, Train Loss: 5211957.5000, Val MSE: 5216621.0000, Val MAE: 1393.9988\n",
      "Epoch 3580, Train Loss: 5563658.0000, Val MSE: 5504796.0000, Val MAE: 1403.9376\n",
      "Epoch 3590, Train Loss: 5261020.5000, Val MSE: 5290262.0000, Val MAE: 1397.2739\n",
      "Epoch 3600, Train Loss: 5234086.5000, Val MSE: 5225739.5000, Val MAE: 1394.8622\n",
      "Epoch 3610, Train Loss: 5205616.5000, Val MSE: 5201872.5000, Val MAE: 1393.8210\n",
      "Epoch 3620, Train Loss: 5195889.5000, Val MSE: 5199459.5000, Val MAE: 1394.3325\n",
      "Epoch 3630, Train Loss: 5193782.0000, Val MSE: 5197123.5000, Val MAE: 1394.0829\n",
      "Epoch 3640, Train Loss: 5190917.0000, Val MSE: 5193927.5000, Val MAE: 1393.2908\n",
      "Epoch 3650, Train Loss: 5187896.0000, Val MSE: 5190914.0000, Val MAE: 1392.5177\n",
      "Epoch 3660, Train Loss: 5185066.0000, Val MSE: 5188060.5000, Val MAE: 1391.7999\n",
      "Epoch 3670, Train Loss: 5182323.0000, Val MSE: 5185434.5000, Val MAE: 1391.2847\n",
      "Epoch 3680, Train Loss: 5179614.5000, Val MSE: 5182768.5000, Val MAE: 1390.8191\n",
      "Epoch 3690, Train Loss: 5176921.0000, Val MSE: 5180076.0000, Val MAE: 1390.2285\n",
      "Epoch 3700, Train Loss: 5174237.5000, Val MSE: 5177426.5000, Val MAE: 1389.7014\n",
      "Epoch 3710, Train Loss: 5171560.5000, Val MSE: 5174783.5000, Val MAE: 1389.1635\n",
      "Epoch 3720, Train Loss: 5168889.5000, Val MSE: 5172140.5000, Val MAE: 1388.6361\n",
      "Epoch 3730, Train Loss: 5166224.0000, Val MSE: 5169487.5000, Val MAE: 1388.0961\n",
      "Epoch 3740, Train Loss: 5163563.5000, Val MSE: 5166855.5000, Val MAE: 1387.5645\n",
      "Epoch 3750, Train Loss: 5160907.5000, Val MSE: 5164230.0000, Val MAE: 1387.0262\n",
      "Epoch 3760, Train Loss: 5158257.0000, Val MSE: 5161595.5000, Val MAE: 1386.4541\n",
      "Epoch 3770, Train Loss: 5155650.0000, Val MSE: 5158877.5000, Val MAE: 1385.4615\n",
      "Epoch 3780, Train Loss: 5161403.5000, Val MSE: 5168098.5000, Val MAE: 1379.7997\n",
      "Epoch 3790, Train Loss: 5230549.5000, Val MSE: 5221608.5000, Val MAE: 1397.8735\n",
      "Epoch 3800, Train Loss: 5153924.5000, Val MSE: 5172852.0000, Val MAE: 1392.0416\n",
      "Epoch 3810, Train Loss: 5160088.0000, Val MSE: 5162782.5000, Val MAE: 1392.8938\n",
      "Epoch 3820, Train Loss: 5145017.5000, Val MSE: 5146856.0000, Val MAE: 1383.4497\n",
      "Epoch 3830, Train Loss: 5140667.5000, Val MSE: 5144217.5000, Val MAE: 1380.8983\n",
      "Epoch 3840, Train Loss: 5138285.5000, Val MSE: 5141689.0000, Val MAE: 1382.7738\n",
      "Epoch 3850, Train Loss: 5135470.5000, Val MSE: 5138753.5000, Val MAE: 1380.9023\n",
      "Epoch 3860, Train Loss: 5132770.5000, Val MSE: 5136306.5000, Val MAE: 1381.4673\n",
      "Epoch 3870, Train Loss: 5130157.5000, Val MSE: 5133754.0000, Val MAE: 1380.4352\n",
      "Epoch 3880, Train Loss: 5127579.0000, Val MSE: 5131269.0000, Val MAE: 1380.3021\n",
      "Epoch 3890, Train Loss: 5125047.0000, Val MSE: 5128804.5000, Val MAE: 1379.9420\n",
      "Epoch 3900, Train Loss: 5122522.0000, Val MSE: 5126350.5000, Val MAE: 1379.5546\n",
      "Epoch 3910, Train Loss: 5120214.5000, Val MSE: 5124236.5000, Val MAE: 1379.7937\n",
      "Epoch 3920, Train Loss: 5130356.0000, Val MSE: 5140932.5000, Val MAE: 1387.2972\n",
      "Epoch 3930, Train Loss: 5247277.5000, Val MSE: 5169213.0000, Val MAE: 1394.4589\n",
      "Epoch 3940, Train Loss: 5128197.0000, Val MSE: 5151618.0000, Val MAE: 1391.3344\n",
      "Epoch 3950, Train Loss: 5115192.0000, Val MSE: 5113993.0000, Val MAE: 1376.7960\n",
      "Epoch 3960, Train Loss: 5114702.0000, Val MSE: 5116450.0000, Val MAE: 1373.1685\n",
      "Epoch 3970, Train Loss: 5105515.5000, Val MSE: 5110339.0000, Val MAE: 1374.4591\n",
      "Epoch 3980, Train Loss: 5103815.0000, Val MSE: 5107819.5000, Val MAE: 1376.6554\n",
      "Epoch 3990, Train Loss: 5100483.5000, Val MSE: 5104733.5000, Val MAE: 1375.3074\n",
      "Epoch 4000, Train Loss: 5098130.5000, Val MSE: 5102287.5000, Val MAE: 1373.8336\n",
      "Epoch 4010, Train Loss: 5095644.0000, Val MSE: 5099891.0000, Val MAE: 1374.2382\n",
      "Epoch 4020, Train Loss: 5093176.0000, Val MSE: 5097418.5000, Val MAE: 1373.2856\n",
      "Epoch 4030, Train Loss: 5090736.0000, Val MSE: 5095053.0000, Val MAE: 1373.1094\n",
      "Epoch 4040, Train Loss: 5088306.5000, Val MSE: 5092640.5000, Val MAE: 1372.3969\n",
      "Epoch 4050, Train Loss: 5085883.5000, Val MSE: 5090277.0000, Val MAE: 1372.0187\n",
      "Epoch 4060, Train Loss: 5083471.5000, Val MSE: 5087915.5000, Val MAE: 1371.5895\n",
      "Epoch 4070, Train Loss: 5081066.0000, Val MSE: 5085568.0000, Val MAE: 1371.1730\n",
      "Epoch 4080, Train Loss: 5078733.0000, Val MSE: 5083345.5000, Val MAE: 1371.1248\n",
      "Epoch 4090, Train Loss: 5081270.5000, Val MSE: 5088926.5000, Val MAE: 1375.6101\n",
      "Epoch 4100, Train Loss: 5347359.0000, Val MSE: 5294953.5000, Val MAE: 1416.2853\n",
      "Epoch 4110, Train Loss: 5072293.5000, Val MSE: 5097540.0000, Val MAE: 1379.7238\n",
      "Epoch 4120, Train Loss: 5078042.0000, Val MSE: 5074222.0000, Val MAE: 1369.0259\n",
      "Epoch 4130, Train Loss: 5075456.0000, Val MSE: 5074269.5000, Val MAE: 1365.9473\n",
      "Epoch 4140, Train Loss: 5068376.0000, Val MSE: 5072278.5000, Val MAE: 1365.1675\n",
      "Epoch 4150, Train Loss: 5062887.5000, Val MSE: 5068256.0000, Val MAE: 1365.7145\n",
      "Epoch 4160, Train Loss: 5060420.5000, Val MSE: 5065134.0000, Val MAE: 1366.9919\n",
      "Epoch 4170, Train Loss: 5058096.0000, Val MSE: 5063115.5000, Val MAE: 1367.1808\n",
      "Epoch 4180, Train Loss: 5055650.0000, Val MSE: 5060583.0000, Val MAE: 1365.9095\n",
      "Epoch 4190, Train Loss: 5053343.5000, Val MSE: 5058313.5000, Val MAE: 1365.2761\n",
      "Epoch 4200, Train Loss: 5051045.0000, Val MSE: 5056077.0000, Val MAE: 1365.2017\n",
      "Epoch 4210, Train Loss: 5048748.0000, Val MSE: 5053812.0000, Val MAE: 1364.5436\n",
      "Epoch 4220, Train Loss: 5046461.5000, Val MSE: 5051577.0000, Val MAE: 1364.1876\n",
      "Epoch 4230, Train Loss: 5044182.0000, Val MSE: 5049342.5000, Val MAE: 1363.6664\n",
      "Epoch 4240, Train Loss: 5041908.5000, Val MSE: 5047136.0000, Val MAE: 1363.2852\n",
      "Epoch 4250, Train Loss: 5039642.0000, Val MSE: 5044933.5000, Val MAE: 1362.8441\n",
      "Epoch 4260, Train Loss: 5037390.5000, Val MSE: 5042832.0000, Val MAE: 1362.5325\n",
      "Epoch 4270, Train Loss: 5037258.0000, Val MSE: 5045912.0000, Val MAE: 1365.5984\n",
      "Epoch 4280, Train Loss: 5104055.0000, Val MSE: 5070047.5000, Val MAE: 1367.7694\n",
      "Epoch 4290, Train Loss: 5061729.0000, Val MSE: 5046120.0000, Val MAE: 1363.7931\n",
      "Epoch 4300, Train Loss: 5035376.5000, Val MSE: 5038203.5000, Val MAE: 1362.9950\n",
      "Epoch 4310, Train Loss: 5027477.5000, Val MSE: 5034042.0000, Val MAE: 1357.0605\n",
      "Epoch 4320, Train Loss: 5026120.5000, Val MSE: 5030799.0000, Val MAE: 1357.3489\n",
      "Epoch 4330, Train Loss: 5022634.0000, Val MSE: 5027766.0000, Val MAE: 1358.6899\n",
      "Epoch 4340, Train Loss: 5020222.0000, Val MSE: 5025804.0000, Val MAE: 1359.2452\n",
      "Epoch 4350, Train Loss: 5020373.5000, Val MSE: 5026989.0000, Val MAE: 1361.5784\n",
      "Epoch 4360, Train Loss: 5131099.0000, Val MSE: 5159843.0000, Val MAE: 1391.4000\n",
      "Epoch 4370, Train Loss: 5078008.0000, Val MSE: 5082702.0000, Val MAE: 1352.1150\n",
      "Epoch 4380, Train Loss: 5016887.5000, Val MSE: 5017650.0000, Val MAE: 1356.9707\n",
      "Epoch 4390, Train Loss: 5016758.5000, Val MSE: 5023296.5000, Val MAE: 1362.3093\n",
      "Epoch 4400, Train Loss: 5008791.0000, Val MSE: 5013602.5000, Val MAE: 1355.7905\n",
      "Epoch 4410, Train Loss: 5005603.5000, Val MSE: 5012313.0000, Val MAE: 1354.7170\n",
      "Epoch 4420, Train Loss: 5003701.5000, Val MSE: 5009820.5000, Val MAE: 1356.6510\n",
      "Epoch 4430, Train Loss: 5001329.5000, Val MSE: 5007465.0000, Val MAE: 1354.5919\n",
      "Epoch 4440, Train Loss: 4999126.5000, Val MSE: 5005366.5000, Val MAE: 1355.0470\n",
      "Epoch 4450, Train Loss: 4997010.5000, Val MSE: 5003325.0000, Val MAE: 1354.0576\n",
      "Epoch 4460, Train Loss: 4994910.5000, Val MSE: 5001284.5000, Val MAE: 1354.0538\n",
      "Epoch 4470, Train Loss: 4992835.5000, Val MSE: 4999268.5000, Val MAE: 1353.5603\n",
      "Epoch 4480, Train Loss: 4990769.5000, Val MSE: 4997273.5000, Val MAE: 1353.0537\n",
      "Epoch 4490, Train Loss: 4988717.0000, Val MSE: 4995288.0000, Val MAE: 1352.5435\n",
      "Epoch 4500, Train Loss: 4986826.0000, Val MSE: 4993538.5000, Val MAE: 1351.5216\n",
      "Epoch 4510, Train Loss: 4997819.0000, Val MSE: 5011726.0000, Val MAE: 1346.8632\n",
      "Epoch 4520, Train Loss: 5124302.0000, Val MSE: 5032379.5000, Val MAE: 1343.6244\n",
      "Epoch 4530, Train Loss: 5021956.0000, Val MSE: 5041123.0000, Val MAE: 1344.2784\n",
      "Epoch 4540, Train Loss: 4979684.0000, Val MSE: 4993995.5000, Val MAE: 1346.1427\n",
      "Epoch 4550, Train Loss: 4979173.5000, Val MSE: 4983709.5000, Val MAE: 1350.0569\n",
      "Epoch 4560, Train Loss: 4977796.0000, Val MSE: 4983474.0000, Val MAE: 1352.3212\n",
      "Epoch 4570, Train Loss: 4973339.5000, Val MSE: 4980846.5000, Val MAE: 1351.2500\n",
      "Epoch 4580, Train Loss: 4971147.5000, Val MSE: 4978190.0000, Val MAE: 1349.0474\n",
      "Epoch 4590, Train Loss: 4969088.0000, Val MSE: 4976280.0000, Val MAE: 1348.2618\n",
      "Epoch 4600, Train Loss: 4967080.5000, Val MSE: 4974192.5000, Val MAE: 1348.5771\n",
      "Epoch 4610, Train Loss: 4965083.5000, Val MSE: 4972269.5000, Val MAE: 1348.0209\n",
      "Epoch 4620, Train Loss: 4963134.0000, Val MSE: 4970370.5000, Val MAE: 1347.4916\n",
      "Epoch 4630, Train Loss: 4961187.5000, Val MSE: 4968499.5000, Val MAE: 1347.3115\n",
      "Epoch 4640, Train Loss: 4959247.0000, Val MSE: 4966620.5000, Val MAE: 1346.7853\n",
      "Epoch 4650, Train Loss: 4957312.0000, Val MSE: 4964760.5000, Val MAE: 1346.4728\n",
      "Epoch 4660, Train Loss: 4955383.0000, Val MSE: 4962902.5000, Val MAE: 1346.1056\n",
      "Epoch 4670, Train Loss: 4953460.5000, Val MSE: 4961056.0000, Val MAE: 1345.7064\n",
      "Epoch 4680, Train Loss: 4951542.5000, Val MSE: 4959212.0000, Val MAE: 1345.3185\n",
      "Epoch 4690, Train Loss: 4949631.0000, Val MSE: 4957375.0000, Val MAE: 1344.9302\n",
      "Epoch 4700, Train Loss: 4947727.5000, Val MSE: 4955545.0000, Val MAE: 1344.4652\n",
      "Epoch 4710, Train Loss: 4946081.5000, Val MSE: 4954095.5000, Val MAE: 1343.0300\n",
      "Epoch 4720, Train Loss: 5014696.0000, Val MSE: 5069504.0000, Val MAE: 1337.3572\n",
      "Epoch 4730, Train Loss: 5114633.0000, Val MSE: 5127757.5000, Val MAE: 1387.8105\n",
      "Epoch 4740, Train Loss: 5005666.0000, Val MSE: 5000256.5000, Val MAE: 1363.2628\n",
      "Epoch 4750, Train Loss: 4959740.5000, Val MSE: 4951825.5000, Val MAE: 1347.7495\n",
      "Epoch 4760, Train Loss: 4938640.5000, Val MSE: 4945209.5000, Val MAE: 1341.0273\n",
      "Epoch 4770, Train Loss: 4935377.0000, Val MSE: 4945013.5000, Val MAE: 1339.3167\n",
      "Epoch 4780, Train Loss: 4933928.5000, Val MSE: 4942259.5000, Val MAE: 1339.6337\n",
      "Epoch 4790, Train Loss: 4931911.5000, Val MSE: 4939955.5000, Val MAE: 1340.0334\n",
      "Epoch 4800, Train Loss: 4929912.5000, Val MSE: 4938049.5000, Val MAE: 1340.1482\n",
      "Epoch 4810, Train Loss: 4928030.0000, Val MSE: 4936220.5000, Val MAE: 1340.0575\n",
      "Epoch 4820, Train Loss: 4926204.0000, Val MSE: 4934461.0000, Val MAE: 1339.8734\n",
      "Epoch 4830, Train Loss: 4924405.0000, Val MSE: 4932752.0000, Val MAE: 1339.6475\n",
      "Epoch 4840, Train Loss: 4922621.5000, Val MSE: 4931037.0000, Val MAE: 1339.3988\n",
      "Epoch 4850, Train Loss: 4920846.5000, Val MSE: 4929334.0000, Val MAE: 1339.1151\n",
      "Epoch 4860, Train Loss: 4919074.0000, Val MSE: 4927630.5000, Val MAE: 1338.7593\n",
      "Epoch 4870, Train Loss: 4917309.0000, Val MSE: 4925935.0000, Val MAE: 1338.3683\n",
      "Epoch 4880, Train Loss: 4915549.0000, Val MSE: 4924243.5000, Val MAE: 1338.0052\n",
      "Epoch 4890, Train Loss: 4913794.0000, Val MSE: 4922571.5000, Val MAE: 1337.6776\n",
      "Epoch 4900, Train Loss: 4912044.0000, Val MSE: 4920902.0000, Val MAE: 1337.3250\n",
      "Epoch 4910, Train Loss: 4910301.5000, Val MSE: 4919259.5000, Val MAE: 1336.9888\n",
      "Epoch 4920, Train Loss: 4908633.5000, Val MSE: 4917889.0000, Val MAE: 1336.8223\n",
      "Epoch 4930, Train Loss: 4915848.0000, Val MSE: 4933282.5000, Val MAE: 1342.1377\n",
      "Epoch 4940, Train Loss: 4951449.5000, Val MSE: 4937643.5000, Val MAE: 1328.7452\n",
      "Epoch 4950, Train Loss: 4913211.0000, Val MSE: 4914033.5000, Val MAE: 1335.5621\n",
      "Epoch 4960, Train Loss: 4907541.0000, Val MSE: 4914832.5000, Val MAE: 1339.1759\n",
      "Epoch 4970, Train Loss: 4903287.5000, Val MSE: 4911461.0000, Val MAE: 1333.4271\n",
      "Epoch 4980, Train Loss: 4899579.5000, Val MSE: 4908434.5000, Val MAE: 1335.6284\n",
      "Epoch 4990, Train Loss: 4897302.5000, Val MSE: 4906588.5000, Val MAE: 1334.2562\n",
      "Epoch 5000, Train Loss: 4895449.0000, Val MSE: 4905002.0000, Val MAE: 1334.6542\n",
      "Epoch 5010, Train Loss: 4893673.5000, Val MSE: 4903386.5000, Val MAE: 1333.6177\n",
      "Epoch 5020, Train Loss: 4891940.5000, Val MSE: 4901613.5000, Val MAE: 1333.4888\n",
      "Epoch 5030, Train Loss: 4890309.0000, Val MSE: 4899945.0000, Val MAE: 1333.0566\n",
      "Epoch 5040, Train Loss: 4888666.0000, Val MSE: 4898393.5000, Val MAE: 1332.7671\n",
      "Epoch 5050, Train Loss: 4887175.5000, Val MSE: 4897004.5000, Val MAE: 1333.0518\n",
      "Epoch 5060, Train Loss: 4891879.0000, Val MSE: 4904099.5000, Val MAE: 1337.7390\n",
      "Epoch 5070, Train Loss: 5084419.0000, Val MSE: 5058787.0000, Val MAE: 1371.6625\n",
      "Epoch 5080, Train Loss: 4909783.0000, Val MSE: 4896365.5000, Val MAE: 1326.9281\n",
      "Epoch 5090, Train Loss: 4894322.5000, Val MSE: 4908248.5000, Val MAE: 1324.7363\n",
      "Epoch 5100, Train Loss: 4881328.5000, Val MSE: 4889541.0000, Val MAE: 1330.9664\n",
      "Epoch 5110, Train Loss: 4879754.0000, Val MSE: 4890547.5000, Val MAE: 1333.9951\n",
      "Epoch 5120, Train Loss: 4876600.0000, Val MSE: 4886673.5000, Val MAE: 1329.7618\n",
      "Epoch 5130, Train Loss: 4874476.5000, Val MSE: 4884793.5000, Val MAE: 1329.0461\n",
      "Epoch 5140, Train Loss: 4872955.0000, Val MSE: 4883193.5000, Val MAE: 1329.8185\n",
      "Epoch 5150, Train Loss: 4871359.5000, Val MSE: 4881780.0000, Val MAE: 1328.7413\n",
      "Epoch 5160, Train Loss: 4869765.5000, Val MSE: 4880154.5000, Val MAE: 1328.9739\n",
      "Epoch 5170, Train Loss: 4868195.0000, Val MSE: 4878679.0000, Val MAE: 1328.2639\n",
      "Epoch 5180, Train Loss: 4866638.5000, Val MSE: 4877196.0000, Val MAE: 1328.1207\n",
      "Epoch 5190, Train Loss: 4865095.0000, Val MSE: 4875711.5000, Val MAE: 1327.8655\n",
      "Epoch 5200, Train Loss: 4863552.5000, Val MSE: 4874238.5000, Val MAE: 1327.5247\n",
      "Epoch 5210, Train Loss: 4862018.5000, Val MSE: 4872782.5000, Val MAE: 1327.2974\n",
      "Epoch 5220, Train Loss: 4860570.0000, Val MSE: 4871406.0000, Val MAE: 1327.5011\n",
      "Epoch 5230, Train Loss: 4865245.5000, Val MSE: 4879034.5000, Val MAE: 1332.9703\n",
      "Epoch 5240, Train Loss: 5131657.0000, Val MSE: 5070560.5000, Val MAE: 1373.9443\n",
      "Epoch 5250, Train Loss: 4859670.0000, Val MSE: 4887525.5000, Val MAE: 1334.2291\n",
      "Epoch 5260, Train Loss: 4864770.5000, Val MSE: 4865558.5000, Val MAE: 1324.3987\n",
      "Epoch 5270, Train Loss: 4862232.0000, Val MSE: 4868786.0000, Val MAE: 1324.2227\n",
      "Epoch 5280, Train Loss: 4854939.0000, Val MSE: 4866389.0000, Val MAE: 1322.9187\n",
      "Epoch 5290, Train Loss: 4850447.5000, Val MSE: 4862403.0000, Val MAE: 1323.8545\n",
      "Epoch 5300, Train Loss: 4849069.5000, Val MSE: 4859982.0000, Val MAE: 1324.6344\n",
      "Epoch 5310, Train Loss: 4847506.5000, Val MSE: 4858567.5000, Val MAE: 1324.7203\n",
      "Epoch 5320, Train Loss: 4845938.5000, Val MSE: 4857128.5000, Val MAE: 1323.7205\n",
      "Epoch 5330, Train Loss: 4844478.0000, Val MSE: 4855767.0000, Val MAE: 1323.3942\n",
      "Epoch 5340, Train Loss: 4843028.0000, Val MSE: 4854316.5000, Val MAE: 1323.3954\n",
      "Epoch 5350, Train Loss: 4841579.5000, Val MSE: 4852978.0000, Val MAE: 1323.0012\n",
      "Epoch 5360, Train Loss: 4840170.5000, Val MSE: 4851732.5000, Val MAE: 1323.0586\n",
      "Epoch 5370, Train Loss: 4840951.5000, Val MSE: 4854824.5000, Val MAE: 1326.6163\n",
      "Epoch 5380, Train Loss: 4912290.5000, Val MSE: 4906068.0000, Val MAE: 1347.6647\n",
      "Epoch 5390, Train Loss: 4836391.5000, Val MSE: 4857055.5000, Val MAE: 1328.6602\n",
      "Epoch 5400, Train Loss: 4838340.5000, Val MSE: 4846274.0000, Val MAE: 1320.6184\n",
      "Epoch 5410, Train Loss: 4836072.0000, Val MSE: 4846115.5000, Val MAE: 1319.3074\n",
      "Epoch 5420, Train Loss: 4832094.5000, Val MSE: 4843820.5000, Val MAE: 1319.6284\n",
      "Epoch 5430, Train Loss: 4830523.5000, Val MSE: 4842255.5000, Val MAE: 1320.7727\n",
      "Epoch 5440, Train Loss: 4829122.0000, Val MSE: 4841186.5000, Val MAE: 1321.0129\n",
      "Epoch 5450, Train Loss: 4827648.0000, Val MSE: 4839540.5000, Val MAE: 1320.0216\n",
      "Epoch 5460, Train Loss: 4826258.0000, Val MSE: 4838196.0000, Val MAE: 1319.7045\n",
      "Epoch 5470, Train Loss: 4825023.0000, Val MSE: 4837071.0000, Val MAE: 1320.3599\n",
      "Epoch 5480, Train Loss: 4844913.0000, Val MSE: 4868346.5000, Val MAE: 1332.0353\n",
      "Epoch 5490, Train Loss: 4849035.0000, Val MSE: 4853951.5000, Val MAE: 1323.6674\n",
      "Epoch 5500, Train Loss: 4859831.0000, Val MSE: 4856425.5000, Val MAE: 1333.0483\n",
      "Epoch 5510, Train Loss: 4829438.0000, Val MSE: 4845277.5000, Val MAE: 1328.3983\n",
      "Epoch 5520, Train Loss: 4820605.0000, Val MSE: 4837554.5000, Val MAE: 1324.5060\n",
      "Epoch 5530, Train Loss: 4817775.5000, Val MSE: 4832477.5000, Val MAE: 1320.9674\n",
      "Epoch 5540, Train Loss: 4816223.0000, Val MSE: 4829281.0000, Val MAE: 1318.5146\n",
      "Epoch 5550, Train Loss: 4814754.5000, Val MSE: 4827304.0000, Val MAE: 1317.2589\n",
      "Epoch 5560, Train Loss: 4813260.0000, Val MSE: 4825778.5000, Val MAE: 1316.9188\n",
      "Epoch 5570, Train Loss: 4811953.5000, Val MSE: 4824281.5000, Val MAE: 1316.9630\n",
      "Epoch 5580, Train Loss: 4810654.0000, Val MSE: 4822948.5000, Val MAE: 1316.5865\n",
      "Epoch 5590, Train Loss: 4809360.5000, Val MSE: 4821720.5000, Val MAE: 1316.0929\n",
      "Epoch 5600, Train Loss: 4808067.0000, Val MSE: 4820502.5000, Val MAE: 1315.9679\n",
      "Epoch 5610, Train Loss: 4806783.0000, Val MSE: 4819305.5000, Val MAE: 1315.7314\n",
      "Epoch 5620, Train Loss: 4805502.0000, Val MSE: 4818077.5000, Val MAE: 1315.4368\n",
      "Epoch 5630, Train Loss: 4804226.5000, Val MSE: 4816856.5000, Val MAE: 1315.1731\n",
      "Epoch 5640, Train Loss: 4802953.0000, Val MSE: 4815654.5000, Val MAE: 1314.9316\n",
      "Epoch 5650, Train Loss: 4801685.0000, Val MSE: 4814444.0000, Val MAE: 1314.6479\n",
      "Epoch 5660, Train Loss: 4800420.5000, Val MSE: 4813242.5000, Val MAE: 1314.3931\n",
      "Epoch 5670, Train Loss: 4799158.0000, Val MSE: 4812044.5000, Val MAE: 1314.1335\n",
      "Epoch 5680, Train Loss: 4797901.0000, Val MSE: 4810849.5000, Val MAE: 1313.8685\n",
      "Epoch 5690, Train Loss: 4796647.5000, Val MSE: 4809657.5000, Val MAE: 1313.5669\n",
      "Epoch 5700, Train Loss: 4795431.0000, Val MSE: 4808526.0000, Val MAE: 1312.8712\n",
      "Epoch 5710, Train Loss: 4800683.0000, Val MSE: 4818393.5000, Val MAE: 1307.3960\n",
      "Epoch 5720, Train Loss: 5102452.5000, Val MSE: 4976966.5000, Val MAE: 1314.7551\n",
      "Epoch 5730, Train Loss: 4855096.0000, Val MSE: 4851805.5000, Val MAE: 1305.6708\n",
      "Epoch 5740, Train Loss: 4793526.5000, Val MSE: 4815459.0000, Val MAE: 1316.1007\n",
      "Epoch 5750, Train Loss: 4794882.5000, Val MSE: 4812948.0000, Val MAE: 1318.3583\n",
      "Epoch 5760, Train Loss: 4790711.0000, Val MSE: 4802210.0000, Val MAE: 1312.3944\n",
      "Epoch 5770, Train Loss: 4787704.5000, Val MSE: 4800786.5000, Val MAE: 1310.5649\n",
      "Epoch 5780, Train Loss: 4786624.5000, Val MSE: 4799185.0000, Val MAE: 1310.8599\n",
      "Epoch 5790, Train Loss: 4785040.0000, Val MSE: 4797934.0000, Val MAE: 1311.0590\n",
      "Epoch 5800, Train Loss: 4783768.0000, Val MSE: 4796846.5000, Val MAE: 1310.8632\n",
      "Epoch 5810, Train Loss: 4782587.5000, Val MSE: 4795719.0000, Val MAE: 1310.6245\n",
      "Epoch 5820, Train Loss: 4781416.0000, Val MSE: 4794558.0000, Val MAE: 1310.4497\n",
      "Epoch 5830, Train Loss: 4780249.5000, Val MSE: 4793427.5000, Val MAE: 1310.1763\n",
      "Epoch 5840, Train Loss: 4779089.0000, Val MSE: 4792330.0000, Val MAE: 1309.8479\n",
      "Epoch 5850, Train Loss: 4777931.5000, Val MSE: 4791207.0000, Val MAE: 1309.6156\n",
      "Epoch 5860, Train Loss: 4776776.5000, Val MSE: 4790114.5000, Val MAE: 1309.3416\n",
      "Epoch 5870, Train Loss: 4775626.5000, Val MSE: 4789010.5000, Val MAE: 1309.1045\n",
      "Epoch 5880, Train Loss: 4774479.0000, Val MSE: 4787921.0000, Val MAE: 1308.8602\n",
      "Epoch 5890, Train Loss: 4773335.0000, Val MSE: 4786832.5000, Val MAE: 1308.6340\n",
      "Epoch 5900, Train Loss: 4772194.0000, Val MSE: 4785744.5000, Val MAE: 1308.4047\n",
      "Epoch 5910, Train Loss: 4771056.0000, Val MSE: 4784663.5000, Val MAE: 1308.1675\n",
      "Epoch 5920, Train Loss: 4769921.5000, Val MSE: 4783583.0000, Val MAE: 1307.9337\n",
      "Epoch 5930, Train Loss: 4768790.0000, Val MSE: 4782497.0000, Val MAE: 1307.7219\n",
      "Early stopped at epoch 5930, best Val MAE: 1305.6708\n"
     ]
    }
   ],
   "source": [
    "# 初始化\n",
    "fea_num = X_train2.shape[1]\n",
    "model = FM(latent_dim=8, fea_num=fea_num)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Early Stopping 参数\n",
    "patience = 20  # 连续多少次没有提升就停止\n",
    "best_mae = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_pred = model(X_train2)\n",
    "    loss = loss_fn(y_pred, y_train2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val2)\n",
    "            val_loss = loss_fn(val_pred, y_val2).item()\n",
    "            mae = mean_absolute_error(y_val2.numpy(), val_pred.numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val MSE: {val_loss:.4f}, Val MAE: {mae:.4f}\")\n",
    "\n",
    "        # Early Stopping 判断\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()  # 保存当前最优模型参数\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopped at epoch {epoch+1}, best Val MAE: {best_mae:.4f}\")\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aAM1ErMeatl0",
   "metadata": {
    "id": "aAM1ErMeatl0"
   },
   "source": [
    "## 4.4 Wide&Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8de664e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fd01e",
   "metadata": {},
   "source": [
    "### 4.4.1 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "Kj1zui8VaxbE",
   "metadata": {
    "id": "Kj1zui8VaxbE"
   },
   "outputs": [],
   "source": [
    "# target是'price'\n",
    "dense_cols = ['name','power', 'kilometer', 'v_0', 'v_1', 'v_2',\n",
    "       'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12',\n",
    "       'v_13', 'v_14', 'used_time_meanfill',\n",
    "       'brand_amount', 'brand_price_max', 'brand_price_median',\n",
    "       'brand_price_min', 'brand_price_sum', 'brand_price_std',\n",
    "       'brand_price_average']  \n",
    "sparse_cols =[\"model\", \"brand\", \"bodyType\", \"fuelType\",'gearbox','notRepairedDamage']  # 类别特征列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "efd6495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_for_tree.dropna(subset=dense_cols + sparse_cols + ['price']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6fece8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "scaler = StandardScaler()\n",
    "df[dense_cols] = scaler.fit_transform(df[dense_cols])\n",
    "\n",
    "sparse_feature_info = []\n",
    "for col in sparse_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    sparse_feature_info.append({'feat_num': df[col].nunique(), 'embed_dim': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "969e597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造特征与标签\n",
    "X_dense = df[dense_cols].values\n",
    "X_sparse = df[sparse_cols].values\n",
    "X = np.hstack([X_dense, X_sparse])\n",
    "y = df['price'].values.reshape(-1, 1)\n",
    "\n",
    "# 转换为 Tensor\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "feature_columns = [dense_cols, sparse_feature_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a621c6",
   "metadata": {},
   "source": [
    "### 4.4.2 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1c127ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear part\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(Linear, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=input_dim, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class Dnn(nn.Module):\n",
    "    \"\"\"\n",
    "    Dnn part\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        \"\"\"\n",
    "        hidden_units: 列表， 每个元素表示每一层的神经单元个数， 比如[256, 128, 64], 两层网络， 第一层神经单元128， 第二层64， 第一个维度是输入维度\n",
    "        dropout: 失活率\n",
    "        \"\"\"\n",
    "        super(Dnn, self).__init__()\n",
    "        \n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for linear in self.dnn_network:\n",
    "            x = linear(x)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8f60a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeep(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.):\n",
    "        super(WideDeep, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        \n",
    "        # embedding \n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim'])\n",
    "            for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        hidden_units.insert(0, len(self.dense_feature_cols) + len(self.sparse_feature_cols)*self.sparse_feature_cols[0]['embed_dim'])\n",
    "        self.dnn_network = Dnn(hidden_units, dropout=dnn_dropout)\n",
    "        self.linear = Linear(len(self.dense_feature_cols))\n",
    "        self.final_linear = nn.Linear(hidden_units[-1], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        dense_input, sparse_inputs = x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):]\n",
    "        sparse_inputs = sparse_inputs.long()\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embeds = torch.cat(sparse_embeds, axis=-1)\n",
    "        \n",
    "        dnn_input = torch.cat([sparse_embeds, dense_input], axis=-1)\n",
    "        \n",
    "        # Wide\n",
    "        wide_out = self.linear(dense_input)\n",
    "        \n",
    "        # Deep\n",
    "        deep_out = self.dnn_network(dnn_input)\n",
    "        deep_out = self.final_linear(deep_out)\n",
    "        \n",
    "        # out\n",
    "        outputs = 0.5 * (wide_out + deep_out)  # 直接输出预测值\n",
    "        \n",
    "        return outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "33849d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_widedeep(model, X_train, y_train, X_val, y_val, \n",
    "                   epochs=5000, lr=0.01, patience=20, print_every=10, \n",
    "                   model_save_path=\"best_widedeep_model.pt\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    best_epoch = -1\n",
    "    wait = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(X_val)\n",
    "                val_loss = loss_fn(val_pred, y_val).item()\n",
    "                val_mae = mean_absolute_error(y_val.numpy(), val_pred.numpy())\n",
    "\n",
    "                print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val MSE: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "                if val_mae < best_mae:\n",
    "                    best_mae = val_mae\n",
    "                    best_epoch = epoch + 1\n",
    "                    wait = 0\n",
    "                    best_model_state = model.state_dict()\n",
    "                else:\n",
    "                    wait += 1\n",
    "                    if wait >= patience:\n",
    "                        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\n Best Val MAE: {best_mae:.4f} at epoch {best_epoch}\")\n",
    "        torch.save(best_model_state, model_save_path)\n",
    "        print(f\" Model saved to {model_save_path}\")\n",
    "\n",
    "    return model, best_mae, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e68191f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=64, bias=True)\n",
      "      (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 10, Train Loss: 96362752.0000, Val MSE: 97561040.0000, Val MAE: 6223.3882\n",
      "Epoch 20, Train Loss: 94366448.0000, Val MSE: 95191184.0000, Val MAE: 6082.5635\n",
      "Epoch 30, Train Loss: 86144200.0000, Val MSE: 85908784.0000, Val MAE: 5483.7915\n",
      "Epoch 40, Train Loss: 65288856.0000, Val MSE: 63599608.0000, Val MAE: 4249.8022\n",
      "Epoch 50, Train Loss: 42992296.0000, Val MSE: 43065604.0000, Val MAE: 4248.5527\n",
      "Epoch 60, Train Loss: 37313908.0000, Val MSE: 36900324.0000, Val MAE: 4095.6543\n",
      "Epoch 70, Train Loss: 30153772.0000, Val MSE: 30381840.0000, Val MAE: 3135.4834\n",
      "Epoch 80, Train Loss: 24911578.0000, Val MSE: 25034634.0000, Val MAE: 2882.8823\n",
      "Epoch 90, Train Loss: 20614322.0000, Val MSE: 20737050.0000, Val MAE: 2660.1006\n",
      "Epoch 100, Train Loss: 17040360.0000, Val MSE: 17204992.0000, Val MAE: 2300.6057\n",
      "Epoch 110, Train Loss: 14393603.0000, Val MSE: 14559588.0000, Val MAE: 2107.7422\n",
      "Epoch 120, Train Loss: 12556616.0000, Val MSE: 12727921.0000, Val MAE: 1989.3699\n",
      "Epoch 130, Train Loss: 11334098.0000, Val MSE: 11514815.0000, Val MAE: 1901.6565\n",
      "Epoch 140, Train Loss: 10506455.0000, Val MSE: 10689012.0000, Val MAE: 1857.8925\n",
      "Epoch 150, Train Loss: 9893900.0000, Val MSE: 10079872.0000, Val MAE: 1818.8352\n",
      "Epoch 160, Train Loss: 9389888.0000, Val MSE: 9580163.0000, Val MAE: 1775.3789\n",
      "Epoch 170, Train Loss: 8940588.0000, Val MSE: 9133799.0000, Val MAE: 1728.6904\n",
      "Epoch 180, Train Loss: 8520475.0000, Val MSE: 8715038.0000, Val MAE: 1674.2906\n",
      "Epoch 190, Train Loss: 8118074.5000, Val MSE: 8312415.0000, Val MAE: 1614.1885\n",
      "Epoch 200, Train Loss: 7730131.0000, Val MSE: 7922551.0000, Val MAE: 1549.4631\n",
      "Epoch 210, Train Loss: 7358948.0000, Val MSE: 7548692.0000, Val MAE: 1482.1892\n",
      "Epoch 220, Train Loss: 7010846.5000, Val MSE: 7197374.0000, Val MAE: 1416.3715\n",
      "Epoch 230, Train Loss: 6692452.0000, Val MSE: 6875780.0000, Val MAE: 1355.1870\n",
      "Epoch 240, Train Loss: 6408816.5000, Val MSE: 6588855.5000, Val MAE: 1301.1804\n",
      "Epoch 250, Train Loss: 6161294.5000, Val MSE: 6336719.0000, Val MAE: 1256.0067\n",
      "Epoch 260, Train Loss: 5947404.0000, Val MSE: 6116826.5000, Val MAE: 1220.6486\n",
      "Epoch 270, Train Loss: 5762087.0000, Val MSE: 5924147.0000, Val MAE: 1193.3652\n",
      "Epoch 280, Train Loss: 5600024.0000, Val MSE: 5753878.5000, Val MAE: 1171.4258\n",
      "Epoch 290, Train Loss: 5456275.0000, Val MSE: 5601776.0000, Val MAE: 1152.9082\n",
      "Epoch 300, Train Loss: 5326854.5000, Val MSE: 5464871.0000, Val MAE: 1136.3901\n",
      "Epoch 310, Train Loss: 5208712.5000, Val MSE: 5340181.0000, Val MAE: 1121.5226\n",
      "Epoch 320, Train Loss: 5099856.0000, Val MSE: 5226072.0000, Val MAE: 1107.8676\n",
      "Epoch 330, Train Loss: 4998912.5000, Val MSE: 5120836.5000, Val MAE: 1095.2755\n",
      "Epoch 340, Train Loss: 4904325.0000, Val MSE: 5022617.0000, Val MAE: 1083.2965\n",
      "Epoch 350, Train Loss: 4815888.0000, Val MSE: 4930097.5000, Val MAE: 1071.5815\n",
      "Epoch 360, Train Loss: 4733441.0000, Val MSE: 4843943.0000, Val MAE: 1060.9912\n",
      "Epoch 370, Train Loss: 4656273.0000, Val MSE: 4763469.0000, Val MAE: 1050.7999\n",
      "Epoch 380, Train Loss: 4583882.0000, Val MSE: 4687559.0000, Val MAE: 1041.1295\n",
      "Epoch 390, Train Loss: 4515686.0000, Val MSE: 4616068.0000, Val MAE: 1031.8018\n",
      "Epoch 400, Train Loss: 4451373.0000, Val MSE: 4548667.5000, Val MAE: 1022.8801\n",
      "Epoch 410, Train Loss: 4390668.5000, Val MSE: 4484846.0000, Val MAE: 1014.5807\n",
      "Epoch 420, Train Loss: 4333210.5000, Val MSE: 4424374.5000, Val MAE: 1006.5785\n",
      "Epoch 430, Train Loss: 4278844.0000, Val MSE: 4367075.0000, Val MAE: 998.8721\n",
      "Epoch 440, Train Loss: 4227276.5000, Val MSE: 4312651.0000, Val MAE: 991.4938\n",
      "Epoch 450, Train Loss: 4178291.2500, Val MSE: 4261096.5000, Val MAE: 984.4614\n",
      "Epoch 460, Train Loss: 4131846.2500, Val MSE: 4212439.5000, Val MAE: 977.8033\n",
      "Epoch 470, Train Loss: 4087774.7500, Val MSE: 4166209.5000, Val MAE: 971.4742\n",
      "Epoch 480, Train Loss: 4045666.7500, Val MSE: 4122021.7500, Val MAE: 965.4445\n",
      "Epoch 490, Train Loss: 4005257.7500, Val MSE: 4079742.0000, Val MAE: 959.6296\n",
      "Epoch 500, Train Loss: 3966541.5000, Val MSE: 4038870.5000, Val MAE: 954.1493\n",
      "Epoch 510, Train Loss: 3929324.0000, Val MSE: 3999489.5000, Val MAE: 948.8620\n",
      "Epoch 520, Train Loss: 3893337.0000, Val MSE: 3961376.5000, Val MAE: 943.7570\n",
      "Epoch 530, Train Loss: 3858529.5000, Val MSE: 3924503.0000, Val MAE: 938.7209\n",
      "Epoch 540, Train Loss: 3824729.5000, Val MSE: 3888530.7500, Val MAE: 933.9832\n",
      "Epoch 550, Train Loss: 3791667.5000, Val MSE: 3853078.0000, Val MAE: 929.2410\n",
      "Epoch 560, Train Loss: 3759087.2500, Val MSE: 3818396.7500, Val MAE: 924.4392\n",
      "Epoch 570, Train Loss: 3726573.5000, Val MSE: 3784113.7500, Val MAE: 919.6630\n",
      "Epoch 580, Train Loss: 3694222.0000, Val MSE: 3749786.5000, Val MAE: 914.6755\n",
      "Epoch 590, Train Loss: 3662426.0000, Val MSE: 3715956.7500, Val MAE: 909.9252\n",
      "Epoch 600, Train Loss: 3631158.5000, Val MSE: 3682966.7500, Val MAE: 905.3299\n",
      "Epoch 610, Train Loss: 3600191.0000, Val MSE: 3650281.0000, Val MAE: 900.6036\n",
      "Epoch 620, Train Loss: 3569584.5000, Val MSE: 3618164.0000, Val MAE: 895.7885\n",
      "Epoch 630, Train Loss: 3539084.2500, Val MSE: 3586894.2500, Val MAE: 891.0903\n",
      "Epoch 640, Train Loss: 3508808.7500, Val MSE: 3556530.5000, Val MAE: 886.3585\n",
      "Epoch 650, Train Loss: 3478789.7500, Val MSE: 3525814.5000, Val MAE: 881.9191\n",
      "Epoch 660, Train Loss: 3448953.7500, Val MSE: 3494837.2500, Val MAE: 877.2753\n",
      "Epoch 670, Train Loss: 3419420.7500, Val MSE: 3464024.2500, Val MAE: 872.8003\n",
      "Epoch 680, Train Loss: 3390247.2500, Val MSE: 3433945.0000, Val MAE: 868.3385\n",
      "Epoch 690, Train Loss: 3361727.7500, Val MSE: 3404008.0000, Val MAE: 863.9003\n",
      "Epoch 700, Train Loss: 3333618.0000, Val MSE: 3374724.2500, Val MAE: 859.6339\n",
      "Epoch 710, Train Loss: 3305891.5000, Val MSE: 3345977.2500, Val MAE: 855.3534\n",
      "Epoch 720, Train Loss: 3278457.2500, Val MSE: 3317447.7500, Val MAE: 851.3729\n",
      "Epoch 730, Train Loss: 3250876.7500, Val MSE: 3288393.0000, Val MAE: 847.4440\n",
      "Epoch 740, Train Loss: 3222957.0000, Val MSE: 3259224.5000, Val MAE: 843.4716\n",
      "Epoch 750, Train Loss: 3195047.7500, Val MSE: 3229645.0000, Val MAE: 839.7443\n",
      "Epoch 760, Train Loss: 3165496.2500, Val MSE: 3200144.0000, Val MAE: 835.9535\n",
      "Epoch 770, Train Loss: 3136205.7500, Val MSE: 3173316.0000, Val MAE: 832.5101\n",
      "Epoch 780, Train Loss: 3107873.0000, Val MSE: 3145007.2500, Val MAE: 828.7114\n",
      "Epoch 790, Train Loss: 3080234.0000, Val MSE: 3116008.7500, Val MAE: 824.9205\n",
      "Epoch 800, Train Loss: 3052513.5000, Val MSE: 3086626.0000, Val MAE: 821.2141\n",
      "Epoch 810, Train Loss: 3023778.0000, Val MSE: 3053567.2500, Val MAE: 817.3902\n",
      "Epoch 820, Train Loss: 2991400.2500, Val MSE: 3017432.5000, Val MAE: 813.5049\n",
      "Epoch 830, Train Loss: 2950466.7500, Val MSE: 2973243.5000, Val MAE: 809.0408\n",
      "Epoch 840, Train Loss: 2909678.5000, Val MSE: 2930519.2500, Val MAE: 804.8571\n",
      "Epoch 850, Train Loss: 2870274.7500, Val MSE: 2887821.7500, Val MAE: 800.7172\n",
      "Epoch 860, Train Loss: 2831378.2500, Val MSE: 2848527.5000, Val MAE: 796.3653\n",
      "Epoch 870, Train Loss: 2796691.5000, Val MSE: 2814767.7500, Val MAE: 792.6701\n",
      "Epoch 880, Train Loss: 2763550.2500, Val MSE: 2780444.2500, Val MAE: 788.8152\n",
      "Epoch 890, Train Loss: 2731339.0000, Val MSE: 2749350.5000, Val MAE: 785.6887\n",
      "Epoch 900, Train Loss: 2699758.2500, Val MSE: 2718208.0000, Val MAE: 782.4316\n",
      "Epoch 910, Train Loss: 2668661.5000, Val MSE: 2688120.0000, Val MAE: 779.4031\n",
      "Epoch 920, Train Loss: 2638031.5000, Val MSE: 2657809.0000, Val MAE: 776.2122\n",
      "Epoch 930, Train Loss: 2608052.7500, Val MSE: 2627621.5000, Val MAE: 772.8046\n",
      "Epoch 940, Train Loss: 2578590.0000, Val MSE: 2598414.2500, Val MAE: 769.4191\n",
      "Epoch 950, Train Loss: 2549314.2500, Val MSE: 2570137.5000, Val MAE: 766.0657\n",
      "Epoch 960, Train Loss: 2520274.2500, Val MSE: 2542327.0000, Val MAE: 762.5859\n",
      "Epoch 970, Train Loss: 2491382.7500, Val MSE: 2514819.7500, Val MAE: 759.0713\n",
      "Epoch 980, Train Loss: 2462495.5000, Val MSE: 2487447.5000, Val MAE: 755.3339\n",
      "Epoch 990, Train Loss: 2433510.5000, Val MSE: 2460327.0000, Val MAE: 751.4855\n",
      "Epoch 1000, Train Loss: 2404490.5000, Val MSE: 2433212.7500, Val MAE: 747.5233\n",
      "Epoch 1010, Train Loss: 2375597.0000, Val MSE: 2406569.5000, Val MAE: 743.4966\n",
      "Epoch 1020, Train Loss: 2346733.2500, Val MSE: 2379889.7500, Val MAE: 739.3491\n",
      "Epoch 1030, Train Loss: 2318194.7500, Val MSE: 2353307.2500, Val MAE: 735.2697\n",
      "Epoch 1040, Train Loss: 2289837.2500, Val MSE: 2326953.5000, Val MAE: 731.1390\n",
      "Epoch 1050, Train Loss: 2261857.0000, Val MSE: 2301140.5000, Val MAE: 726.9522\n",
      "Epoch 1060, Train Loss: 2234565.7500, Val MSE: 2276240.2500, Val MAE: 722.7271\n",
      "Epoch 1070, Train Loss: 2207860.2500, Val MSE: 2252222.2500, Val MAE: 718.5283\n",
      "Epoch 1080, Train Loss: 2181735.2500, Val MSE: 2228447.0000, Val MAE: 714.4532\n",
      "Epoch 1090, Train Loss: 2156275.2500, Val MSE: 2205527.2500, Val MAE: 710.4393\n",
      "Epoch 1100, Train Loss: 2131442.2500, Val MSE: 2183271.7500, Val MAE: 706.4211\n",
      "Epoch 1110, Train Loss: 2107207.5000, Val MSE: 2161345.5000, Val MAE: 702.5872\n",
      "Epoch 1120, Train Loss: 2083523.0000, Val MSE: 2139848.2500, Val MAE: 698.9551\n",
      "Epoch 1130, Train Loss: 2060696.5000, Val MSE: 2118806.5000, Val MAE: 695.3831\n",
      "Epoch 1140, Train Loss: 2038644.1250, Val MSE: 2098681.2500, Val MAE: 691.8755\n",
      "Epoch 1150, Train Loss: 2017300.2500, Val MSE: 2079483.0000, Val MAE: 688.6558\n",
      "Epoch 1160, Train Loss: 1996778.7500, Val MSE: 2060771.2500, Val MAE: 685.5265\n",
      "Epoch 1170, Train Loss: 1977069.1250, Val MSE: 2042861.0000, Val MAE: 682.4138\n",
      "Epoch 1180, Train Loss: 1958294.2500, Val MSE: 2025391.8750, Val MAE: 679.4081\n",
      "Epoch 1190, Train Loss: 1940293.5000, Val MSE: 2008592.6250, Val MAE: 676.4985\n",
      "Epoch 1200, Train Loss: 1922919.7500, Val MSE: 1992329.8750, Val MAE: 673.7939\n",
      "Epoch 1210, Train Loss: 1906137.3750, Val MSE: 1976222.2500, Val MAE: 671.1508\n",
      "Epoch 1220, Train Loss: 1889952.7500, Val MSE: 1960582.7500, Val MAE: 668.7548\n",
      "Epoch 1230, Train Loss: 1874380.7500, Val MSE: 1944650.2500, Val MAE: 666.0544\n",
      "Epoch 1240, Train Loss: 1859125.1250, Val MSE: 1929242.1250, Val MAE: 663.5774\n",
      "Epoch 1250, Train Loss: 1844171.1250, Val MSE: 1914330.6250, Val MAE: 661.3194\n",
      "Epoch 1260, Train Loss: 1829749.1250, Val MSE: 1900089.6250, Val MAE: 659.3553\n",
      "Epoch 1270, Train Loss: 1814693.2500, Val MSE: 1884846.5000, Val MAE: 656.8775\n",
      "Epoch 1280, Train Loss: 1799687.1250, Val MSE: 1870858.3750, Val MAE: 654.9194\n",
      "Epoch 1290, Train Loss: 1784461.2500, Val MSE: 1856036.6250, Val MAE: 652.5437\n",
      "Epoch 1300, Train Loss: 1767122.3750, Val MSE: 1841321.5000, Val MAE: 650.2231\n",
      "Epoch 1310, Train Loss: 1747236.7500, Val MSE: 1827955.8750, Val MAE: 648.6371\n",
      "Epoch 1320, Train Loss: 1728670.1250, Val MSE: 1811246.5000, Val MAE: 646.6801\n",
      "Epoch 1330, Train Loss: 1710719.5000, Val MSE: 1797080.8750, Val MAE: 644.7595\n",
      "Epoch 1340, Train Loss: 1693827.7500, Val MSE: 1783777.3750, Val MAE: 642.4357\n",
      "Epoch 1350, Train Loss: 1677852.2500, Val MSE: 1769993.5000, Val MAE: 640.0877\n",
      "Epoch 1360, Train Loss: 1662487.0000, Val MSE: 1757197.3750, Val MAE: 637.7552\n",
      "Epoch 1370, Train Loss: 1647802.0000, Val MSE: 1744794.6250, Val MAE: 635.3732\n",
      "Epoch 1380, Train Loss: 1633866.0000, Val MSE: 1732863.2500, Val MAE: 632.9319\n",
      "Epoch 1390, Train Loss: 1620540.3750, Val MSE: 1721630.7500, Val MAE: 630.6503\n",
      "Epoch 1400, Train Loss: 1607658.2500, Val MSE: 1710663.3750, Val MAE: 628.4568\n",
      "Epoch 1410, Train Loss: 1595216.2500, Val MSE: 1700304.6250, Val MAE: 626.0850\n",
      "Epoch 1420, Train Loss: 1583439.8750, Val MSE: 1690177.6250, Val MAE: 623.5717\n",
      "Epoch 1430, Train Loss: 1572200.0000, Val MSE: 1680290.8750, Val MAE: 621.0713\n",
      "Epoch 1440, Train Loss: 1561536.5000, Val MSE: 1670707.0000, Val MAE: 618.7179\n",
      "Epoch 1450, Train Loss: 1551393.8750, Val MSE: 1661925.5000, Val MAE: 616.3207\n",
      "Epoch 1460, Train Loss: 1541724.3750, Val MSE: 1653515.8750, Val MAE: 614.0841\n",
      "Epoch 1470, Train Loss: 1532448.0000, Val MSE: 1645220.0000, Val MAE: 611.8953\n",
      "Epoch 1480, Train Loss: 1523527.8750, Val MSE: 1638367.8750, Val MAE: 609.6650\n",
      "Epoch 1490, Train Loss: 1514938.1250, Val MSE: 1631742.1250, Val MAE: 607.6077\n",
      "Epoch 1500, Train Loss: 1506576.8750, Val MSE: 1625292.2500, Val MAE: 605.6209\n",
      "Epoch 1510, Train Loss: 1498501.2500, Val MSE: 1618819.3750, Val MAE: 603.5520\n",
      "Epoch 1520, Train Loss: 1490713.7500, Val MSE: 1612422.6250, Val MAE: 601.7059\n",
      "Epoch 1530, Train Loss: 1483284.8750, Val MSE: 1606762.8750, Val MAE: 599.7252\n",
      "Epoch 1540, Train Loss: 1476146.5000, Val MSE: 1600975.3750, Val MAE: 597.8502\n",
      "Epoch 1550, Train Loss: 1469195.6250, Val MSE: 1595656.1250, Val MAE: 596.0698\n",
      "Epoch 1560, Train Loss: 1462481.8750, Val MSE: 1590753.7500, Val MAE: 594.3007\n",
      "Epoch 1570, Train Loss: 1456003.7500, Val MSE: 1586243.8750, Val MAE: 592.5317\n",
      "Epoch 1580, Train Loss: 1449790.7500, Val MSE: 1581871.6250, Val MAE: 591.0049\n",
      "Epoch 1590, Train Loss: 1443821.7500, Val MSE: 1577760.6250, Val MAE: 589.4298\n",
      "Epoch 1600, Train Loss: 1438016.5000, Val MSE: 1573914.5000, Val MAE: 587.9926\n",
      "Epoch 1610, Train Loss: 1432396.1250, Val MSE: 1569927.1250, Val MAE: 586.4766\n",
      "Epoch 1620, Train Loss: 1426970.7500, Val MSE: 1565787.7500, Val MAE: 584.9713\n",
      "Epoch 1630, Train Loss: 1421671.2500, Val MSE: 1561965.0000, Val MAE: 583.6059\n",
      "Epoch 1640, Train Loss: 1416517.2500, Val MSE: 1557878.6250, Val MAE: 582.1878\n",
      "Epoch 1650, Train Loss: 1411498.7500, Val MSE: 1554270.7500, Val MAE: 580.9688\n",
      "Epoch 1660, Train Loss: 1406585.3750, Val MSE: 1550889.7500, Val MAE: 579.7563\n",
      "Epoch 1670, Train Loss: 1401729.0000, Val MSE: 1547414.1250, Val MAE: 578.5783\n",
      "Epoch 1680, Train Loss: 1396987.6250, Val MSE: 1544748.7500, Val MAE: 577.4986\n",
      "Epoch 1690, Train Loss: 1392317.0000, Val MSE: 1541587.3750, Val MAE: 576.4885\n",
      "Epoch 1700, Train Loss: 1387770.8750, Val MSE: 1539092.3750, Val MAE: 575.2573\n",
      "Epoch 1710, Train Loss: 1383196.8750, Val MSE: 1536485.8750, Val MAE: 574.2610\n",
      "Epoch 1720, Train Loss: 1378699.0000, Val MSE: 1533722.8750, Val MAE: 573.2509\n",
      "Epoch 1730, Train Loss: 1374146.0000, Val MSE: 1531745.6250, Val MAE: 572.2007\n",
      "Epoch 1740, Train Loss: 1369761.6250, Val MSE: 1528345.0000, Val MAE: 571.2509\n",
      "Epoch 1750, Train Loss: 1365461.0000, Val MSE: 1526307.3750, Val MAE: 570.1293\n",
      "Epoch 1760, Train Loss: 1361245.7500, Val MSE: 1522490.5000, Val MAE: 569.2937\n",
      "Epoch 1770, Train Loss: 1356798.2500, Val MSE: 1520090.6250, Val MAE: 567.9872\n",
      "Epoch 1780, Train Loss: 1352811.3750, Val MSE: 1517940.7500, Val MAE: 567.2017\n",
      "Epoch 1790, Train Loss: 1348575.2500, Val MSE: 1514242.1250, Val MAE: 566.1276\n",
      "Epoch 1800, Train Loss: 1344600.1250, Val MSE: 1512483.3750, Val MAE: 565.0708\n",
      "Epoch 1810, Train Loss: 1340257.6250, Val MSE: 1509820.5000, Val MAE: 564.0511\n",
      "Epoch 1820, Train Loss: 1336097.0000, Val MSE: 1506814.5000, Val MAE: 563.2643\n",
      "Epoch 1830, Train Loss: 1332226.3750, Val MSE: 1505682.0000, Val MAE: 562.5532\n",
      "Epoch 1840, Train Loss: 1328142.0000, Val MSE: 1501588.1250, Val MAE: 561.4953\n",
      "Epoch 1850, Train Loss: 1324244.1250, Val MSE: 1500149.6250, Val MAE: 560.3270\n",
      "Epoch 1860, Train Loss: 1320120.1250, Val MSE: 1496911.2500, Val MAE: 559.4612\n",
      "Epoch 1870, Train Loss: 1316263.1250, Val MSE: 1494972.8750, Val MAE: 558.4692\n",
      "Epoch 1880, Train Loss: 1312437.1250, Val MSE: 1491669.0000, Val MAE: 557.7740\n",
      "Epoch 1890, Train Loss: 1308223.3750, Val MSE: 1489759.3750, Val MAE: 556.6320\n",
      "Epoch 1900, Train Loss: 1304238.1250, Val MSE: 1487410.5000, Val MAE: 555.7675\n",
      "Epoch 1910, Train Loss: 1300420.2500, Val MSE: 1484110.3750, Val MAE: 555.1079\n",
      "Epoch 1920, Train Loss: 1296787.1250, Val MSE: 1483120.0000, Val MAE: 554.3482\n",
      "Epoch 1930, Train Loss: 1293311.8750, Val MSE: 1479987.3750, Val MAE: 554.1173\n",
      "Epoch 1940, Train Loss: 1289062.3750, Val MSE: 1478709.3750, Val MAE: 552.7260\n",
      "Epoch 1950, Train Loss: 1285165.7500, Val MSE: 1475661.8750, Val MAE: 552.3779\n",
      "Epoch 1960, Train Loss: 1281687.3750, Val MSE: 1475509.3750, Val MAE: 551.9614\n",
      "Epoch 1970, Train Loss: 1277364.2500, Val MSE: 1471720.5000, Val MAE: 550.8561\n",
      "Epoch 1980, Train Loss: 1273413.5000, Val MSE: 1469612.1250, Val MAE: 550.2252\n",
      "Epoch 1990, Train Loss: 1269704.2500, Val MSE: 1467828.8750, Val MAE: 549.6223\n",
      "Epoch 2000, Train Loss: 1266091.0000, Val MSE: 1465108.0000, Val MAE: 549.1883\n",
      "Epoch 2010, Train Loss: 1262614.0000, Val MSE: 1464345.5000, Val MAE: 548.6339\n",
      "Epoch 2020, Train Loss: 1258901.8750, Val MSE: 1461345.3750, Val MAE: 547.9791\n",
      "Epoch 2030, Train Loss: 1255541.2500, Val MSE: 1460131.8750, Val MAE: 547.3701\n",
      "Epoch 2040, Train Loss: 1251963.3750, Val MSE: 1458308.0000, Val MAE: 547.0426\n",
      "Epoch 2050, Train Loss: 1248944.8750, Val MSE: 1458377.6250, Val MAE: 546.8004\n",
      "Epoch 2060, Train Loss: 1245663.3750, Val MSE: 1454420.6250, Val MAE: 546.4177\n",
      "Epoch 2070, Train Loss: 1242341.8750, Val MSE: 1454814.1250, Val MAE: 545.8507\n",
      "Epoch 2080, Train Loss: 1239087.2500, Val MSE: 1451382.5000, Val MAE: 545.5212\n",
      "Epoch 2090, Train Loss: 1235919.2500, Val MSE: 1451732.6250, Val MAE: 545.2212\n",
      "Epoch 2100, Train Loss: 1232830.7500, Val MSE: 1449197.7500, Val MAE: 545.1845\n",
      "Epoch 2110, Train Loss: 1229986.3750, Val MSE: 1449207.5000, Val MAE: 544.3574\n",
      "Epoch 2120, Train Loss: 1226880.0000, Val MSE: 1446173.6250, Val MAE: 544.3196\n",
      "Epoch 2130, Train Loss: 1223491.2500, Val MSE: 1446485.1250, Val MAE: 543.2250\n",
      "Epoch 2140, Train Loss: 1220762.1250, Val MSE: 1442815.6250, Val MAE: 543.1262\n",
      "Epoch 2150, Train Loss: 1218309.7500, Val MSE: 1443532.1250, Val MAE: 542.7469\n",
      "Epoch 2160, Train Loss: 1215291.6250, Val MSE: 1440271.0000, Val MAE: 542.1786\n",
      "Epoch 2170, Train Loss: 1212390.1250, Val MSE: 1439555.3750, Val MAE: 541.4346\n",
      "Epoch 2180, Train Loss: 1209193.7500, Val MSE: 1437694.5000, Val MAE: 540.9714\n",
      "Epoch 2190, Train Loss: 1206459.2500, Val MSE: 1436073.5000, Val MAE: 540.8455\n",
      "Epoch 2200, Train Loss: 1203849.5000, Val MSE: 1434878.1250, Val MAE: 540.3072\n",
      "Epoch 2210, Train Loss: 1201258.0000, Val MSE: 1433473.7500, Val MAE: 540.1262\n",
      "Epoch 2220, Train Loss: 1198694.2500, Val MSE: 1432569.7500, Val MAE: 539.7656\n",
      "Epoch 2230, Train Loss: 1196250.5000, Val MSE: 1431049.5000, Val MAE: 539.9223\n",
      "Epoch 2240, Train Loss: 1193875.7500, Val MSE: 1431542.1250, Val MAE: 539.7073\n",
      "Epoch 2250, Train Loss: 1190901.2500, Val MSE: 1428533.8750, Val MAE: 539.1579\n",
      "Epoch 2260, Train Loss: 1188341.6250, Val MSE: 1428569.0000, Val MAE: 538.8299\n",
      "Epoch 2270, Train Loss: 1186425.5000, Val MSE: 1427050.2500, Val MAE: 539.3927\n",
      "Epoch 2280, Train Loss: 1184385.8750, Val MSE: 1428381.5000, Val MAE: 539.1580\n",
      "Epoch 2290, Train Loss: 1181429.1250, Val MSE: 1424897.3750, Val MAE: 538.3764\n",
      "Epoch 2300, Train Loss: 1178524.5000, Val MSE: 1425479.5000, Val MAE: 537.8510\n",
      "Epoch 2310, Train Loss: 1177074.0000, Val MSE: 1423991.8750, Val MAE: 538.9031\n",
      "Epoch 2320, Train Loss: 1174204.1250, Val MSE: 1423775.7500, Val MAE: 537.2574\n",
      "Epoch 2330, Train Loss: 1171607.0000, Val MSE: 1423267.8750, Val MAE: 537.0942\n",
      "Epoch 2340, Train Loss: 1170022.5000, Val MSE: 1421427.8750, Val MAE: 537.3470\n",
      "Epoch 2350, Train Loss: 1167723.1250, Val MSE: 1422886.8750, Val MAE: 537.2195\n",
      "Epoch 2360, Train Loss: 1165871.1250, Val MSE: 1420098.8750, Val MAE: 536.8207\n",
      "Epoch 2370, Train Loss: 1163714.2500, Val MSE: 1421517.1250, Val MAE: 536.7269\n",
      "Epoch 2380, Train Loss: 1160983.2500, Val MSE: 1419374.3750, Val MAE: 536.0497\n",
      "Epoch 2390, Train Loss: 1158714.8750, Val MSE: 1419944.2500, Val MAE: 536.1177\n",
      "Epoch 2400, Train Loss: 1156615.3750, Val MSE: 1419768.8750, Val MAE: 536.0212\n",
      "Epoch 2410, Train Loss: 1154389.1250, Val MSE: 1419072.8750, Val MAE: 535.8057\n",
      "Epoch 2420, Train Loss: 1152359.8750, Val MSE: 1418262.7500, Val MAE: 535.9160\n",
      "Epoch 2430, Train Loss: 1150115.6250, Val MSE: 1418435.8750, Val MAE: 535.4858\n",
      "Epoch 2440, Train Loss: 1148101.3750, Val MSE: 1418333.3750, Val MAE: 535.4601\n",
      "Epoch 2450, Train Loss: 1145905.3750, Val MSE: 1417083.8750, Val MAE: 535.7484\n",
      "Epoch 2460, Train Loss: 1143453.2500, Val MSE: 1417942.1250, Val MAE: 535.6290\n",
      "Epoch 2470, Train Loss: 1141558.2500, Val MSE: 1415906.6250, Val MAE: 535.5042\n",
      "Epoch 2480, Train Loss: 1139883.7500, Val MSE: 1418335.3750, Val MAE: 535.7964\n",
      "Epoch 2490, Train Loss: 1137183.5000, Val MSE: 1415986.0000, Val MAE: 534.6920\n",
      "Epoch 2500, Train Loss: 1134656.1250, Val MSE: 1416005.7500, Val MAE: 534.7731\n",
      "Epoch 2510, Train Loss: 1132779.5000, Val MSE: 1416975.6250, Val MAE: 534.7650\n",
      "Epoch 2520, Train Loss: 1131199.3750, Val MSE: 1415342.1250, Val MAE: 534.6933\n",
      "Epoch 2530, Train Loss: 1129471.0000, Val MSE: 1417798.2500, Val MAE: 535.0312\n",
      "Epoch 2540, Train Loss: 1127778.3750, Val MSE: 1415661.5000, Val MAE: 534.3671\n",
      "Epoch 2550, Train Loss: 1126160.7500, Val MSE: 1418899.7500, Val MAE: 535.0624\n",
      "Epoch 2560, Train Loss: 1124425.7500, Val MSE: 1415694.8750, Val MAE: 534.3278\n",
      "Epoch 2570, Train Loss: 1122443.7500, Val MSE: 1417802.7500, Val MAE: 534.5542\n",
      "Epoch 2580, Train Loss: 1119807.8750, Val MSE: 1416377.6250, Val MAE: 533.8438\n",
      "Epoch 2590, Train Loss: 1118162.8750, Val MSE: 1414551.2500, Val MAE: 533.8715\n",
      "Epoch 2600, Train Loss: 1116990.7500, Val MSE: 1417595.3750, Val MAE: 534.3849\n",
      "Epoch 2610, Train Loss: 1115070.8750, Val MSE: 1414919.1250, Val MAE: 533.6406\n",
      "Epoch 2620, Train Loss: 1113226.7500, Val MSE: 1416650.8750, Val MAE: 533.6935\n",
      "Epoch 2630, Train Loss: 1111617.8750, Val MSE: 1414584.7500, Val MAE: 533.6577\n",
      "Epoch 2640, Train Loss: 1110292.2500, Val MSE: 1416914.2500, Val MAE: 534.0361\n",
      "Epoch 2650, Train Loss: 1109151.1250, Val MSE: 1413896.3750, Val MAE: 533.0280\n",
      "Epoch 2660, Train Loss: 1107153.8750, Val MSE: 1415429.3750, Val MAE: 533.2453\n",
      "Epoch 2670, Train Loss: 1106088.1250, Val MSE: 1413721.0000, Val MAE: 532.9383\n",
      "Epoch 2680, Train Loss: 1102902.6250, Val MSE: 1413523.3750, Val MAE: 532.4797\n",
      "Epoch 2690, Train Loss: 1101735.0000, Val MSE: 1415254.7500, Val MAE: 532.7813\n",
      "Epoch 2700, Train Loss: 1099669.6250, Val MSE: 1414119.0000, Val MAE: 532.4254\n",
      "Epoch 2710, Train Loss: 1098573.5000, Val MSE: 1413593.8750, Val MAE: 532.4926\n",
      "Epoch 2720, Train Loss: 1097544.0000, Val MSE: 1415313.8750, Val MAE: 532.7934\n",
      "Epoch 2730, Train Loss: 1095436.5000, Val MSE: 1412965.2500, Val MAE: 531.7978\n",
      "Epoch 2740, Train Loss: 1093722.2500, Val MSE: 1413707.5000, Val MAE: 531.7908\n",
      "Epoch 2750, Train Loss: 1091909.1250, Val MSE: 1415380.6250, Val MAE: 532.2819\n",
      "Epoch 2760, Train Loss: 1091212.7500, Val MSE: 1413060.7500, Val MAE: 531.5565\n",
      "Epoch 2770, Train Loss: 1090462.1250, Val MSE: 1414761.2500, Val MAE: 532.1672\n",
      "Epoch 2780, Train Loss: 1087961.1250, Val MSE: 1413342.0000, Val MAE: 531.3914\n",
      "Epoch 2790, Train Loss: 1085959.1250, Val MSE: 1413032.3750, Val MAE: 531.3666\n",
      "Epoch 2800, Train Loss: 1084770.0000, Val MSE: 1415665.2500, Val MAE: 532.0485\n",
      "Epoch 2810, Train Loss: 1083985.0000, Val MSE: 1413360.2500, Val MAE: 531.7808\n",
      "Epoch 2820, Train Loss: 1082709.6250, Val MSE: 1414515.6250, Val MAE: 531.6995\n",
      "Epoch 2830, Train Loss: 1080142.0000, Val MSE: 1413395.7500, Val MAE: 530.8960\n",
      "Epoch 2840, Train Loss: 1078931.7500, Val MSE: 1412825.2500, Val MAE: 530.9576\n",
      "Epoch 2850, Train Loss: 1078601.6250, Val MSE: 1415969.8750, Val MAE: 531.8423\n",
      "Epoch 2860, Train Loss: 1076864.2500, Val MSE: 1412969.6250, Val MAE: 530.5701\n",
      "Epoch 2870, Train Loss: 1074474.8750, Val MSE: 1413963.7500, Val MAE: 530.5320\n",
      "Epoch 2880, Train Loss: 1073114.5000, Val MSE: 1414165.6250, Val MAE: 530.3295\n",
      "Epoch 2890, Train Loss: 1071974.8750, Val MSE: 1413471.3750, Val MAE: 530.3857\n",
      "Epoch 2900, Train Loss: 1071679.8750, Val MSE: 1415768.2500, Val MAE: 531.1127\n",
      "Epoch 2910, Train Loss: 1070172.8750, Val MSE: 1412326.6250, Val MAE: 529.7112\n",
      "Epoch 2920, Train Loss: 1067658.8750, Val MSE: 1413410.0000, Val MAE: 529.5987\n",
      "Epoch 2930, Train Loss: 1066036.2500, Val MSE: 1413531.0000, Val MAE: 529.6462\n",
      "Epoch 2940, Train Loss: 1064672.7500, Val MSE: 1411970.5000, Val MAE: 529.1056\n",
      "Epoch 2950, Train Loss: 1063355.1250, Val MSE: 1413922.7500, Val MAE: 529.5526\n",
      "Epoch 2960, Train Loss: 1061905.3750, Val MSE: 1411410.1250, Val MAE: 528.9398\n",
      "Epoch 2970, Train Loss: 1061513.5000, Val MSE: 1414692.0000, Val MAE: 530.0691\n",
      "Epoch 2980, Train Loss: 1061456.7500, Val MSE: 1411089.3750, Val MAE: 528.6871\n",
      "Epoch 2990, Train Loss: 1057853.1250, Val MSE: 1411633.5000, Val MAE: 528.9549\n",
      "Epoch 3000, Train Loss: 1057931.7500, Val MSE: 1414314.6250, Val MAE: 529.7719\n",
      "Epoch 3010, Train Loss: 1055903.6250, Val MSE: 1411095.1250, Val MAE: 528.4955\n",
      "Epoch 3020, Train Loss: 1054383.0000, Val MSE: 1411240.8750, Val MAE: 528.4125\n",
      "Epoch 3030, Train Loss: 1053337.7500, Val MSE: 1412866.0000, Val MAE: 528.9530\n",
      "Epoch 3040, Train Loss: 1052594.7500, Val MSE: 1410265.2500, Val MAE: 528.2396\n",
      "Epoch 3050, Train Loss: 1050148.7500, Val MSE: 1410599.3750, Val MAE: 528.1091\n",
      "Epoch 3060, Train Loss: 1049283.7500, Val MSE: 1413399.0000, Val MAE: 529.2328\n",
      "Epoch 3070, Train Loss: 1048139.0000, Val MSE: 1409979.2500, Val MAE: 528.1201\n",
      "Epoch 3080, Train Loss: 1045869.1875, Val MSE: 1409411.7500, Val MAE: 528.0145\n",
      "Epoch 3090, Train Loss: 1045579.4375, Val MSE: 1412451.7500, Val MAE: 528.7259\n",
      "Epoch 3100, Train Loss: 1044570.8750, Val MSE: 1408897.1250, Val MAE: 527.9396\n",
      "Epoch 3110, Train Loss: 1042340.4375, Val MSE: 1409962.0000, Val MAE: 527.8711\n",
      "Epoch 3120, Train Loss: 1041416.8125, Val MSE: 1411278.3750, Val MAE: 528.4347\n",
      "Epoch 3130, Train Loss: 1039860.1250, Val MSE: 1408257.2500, Val MAE: 528.0137\n",
      "Epoch 3140, Train Loss: 1038709.1875, Val MSE: 1410174.6250, Val MAE: 527.9230\n",
      "Epoch 3150, Train Loss: 1036657.6875, Val MSE: 1408785.7500, Val MAE: 527.5343\n",
      "Epoch 3160, Train Loss: 1035367.0625, Val MSE: 1408112.8750, Val MAE: 527.4249\n",
      "Epoch 3170, Train Loss: 1035924.8125, Val MSE: 1411604.1250, Val MAE: 528.3207\n",
      "Epoch 3180, Train Loss: 1032532.6250, Val MSE: 1409107.3750, Val MAE: 527.3707\n",
      "Epoch 3190, Train Loss: 1031919.8125, Val MSE: 1407538.2500, Val MAE: 527.0952\n",
      "Epoch 3200, Train Loss: 1030368.9375, Val MSE: 1409657.1250, Val MAE: 527.3843\n",
      "Epoch 3210, Train Loss: 1028627.0000, Val MSE: 1407082.6250, Val MAE: 526.8646\n",
      "Epoch 3220, Train Loss: 1028802.3125, Val MSE: 1410964.6250, Val MAE: 527.6447\n",
      "Epoch 3230, Train Loss: 1025817.6250, Val MSE: 1408626.2500, Val MAE: 527.2972\n",
      "Epoch 3240, Train Loss: 1024822.2500, Val MSE: 1409341.0000, Val MAE: 527.1754\n",
      "Epoch 3250, Train Loss: 1024449.0625, Val MSE: 1409445.7500, Val MAE: 527.3553\n",
      "Epoch 3260, Train Loss: 1021957.2500, Val MSE: 1408441.6250, Val MAE: 527.0458\n",
      "Epoch 3270, Train Loss: 1020950.6250, Val MSE: 1411548.6250, Val MAE: 527.7835\n",
      "Epoch 3280, Train Loss: 1019936.3750, Val MSE: 1407364.6250, Val MAE: 526.7774\n",
      "Epoch 3290, Train Loss: 1019386.8750, Val MSE: 1411588.2500, Val MAE: 527.5475\n",
      "Epoch 3300, Train Loss: 1017812.8125, Val MSE: 1406698.5000, Val MAE: 526.6356\n",
      "Epoch 3310, Train Loss: 1015977.6875, Val MSE: 1409279.6250, Val MAE: 527.1386\n",
      "Epoch 3320, Train Loss: 1015671.7500, Val MSE: 1405481.3750, Val MAE: 526.2192\n",
      "Epoch 3330, Train Loss: 1014109.7500, Val MSE: 1409264.3750, Val MAE: 526.7656\n",
      "Epoch 3340, Train Loss: 1014015.3750, Val MSE: 1408050.3750, Val MAE: 527.3466\n",
      "Epoch 3350, Train Loss: 1011189.5000, Val MSE: 1407728.1250, Val MAE: 526.4286\n",
      "Epoch 3360, Train Loss: 1010368.6875, Val MSE: 1406523.6250, Val MAE: 526.0084\n",
      "Epoch 3370, Train Loss: 1009727.6875, Val MSE: 1407406.2500, Val MAE: 526.2646\n",
      "Epoch 3380, Train Loss: 1007616.6250, Val MSE: 1407949.1250, Val MAE: 526.1441\n",
      "Epoch 3390, Train Loss: 1006861.1875, Val MSE: 1404383.5000, Val MAE: 525.9680\n",
      "Epoch 3400, Train Loss: 1006792.9375, Val MSE: 1409612.3750, Val MAE: 526.5454\n",
      "Epoch 3410, Train Loss: 1005927.0000, Val MSE: 1404743.5000, Val MAE: 525.4258\n",
      "Epoch 3420, Train Loss: 1005669.1250, Val MSE: 1409543.8750, Val MAE: 526.6287\n",
      "Epoch 3430, Train Loss: 1003663.8125, Val MSE: 1404180.0000, Val MAE: 525.2633\n",
      "Epoch 3440, Train Loss: 1001591.0000, Val MSE: 1408510.6250, Val MAE: 525.9955\n",
      "Epoch 3450, Train Loss: 1001294.8750, Val MSE: 1403782.5000, Val MAE: 525.4742\n",
      "Epoch 3460, Train Loss: 1000166.8750, Val MSE: 1408359.0000, Val MAE: 526.2731\n",
      "Epoch 3470, Train Loss: 998690.0625, Val MSE: 1403056.1250, Val MAE: 525.1246\n",
      "Epoch 3480, Train Loss: 997959.9375, Val MSE: 1407943.2500, Val MAE: 525.9695\n",
      "Epoch 3490, Train Loss: 996179.5000, Val MSE: 1403783.7500, Val MAE: 525.0494\n",
      "Epoch 3500, Train Loss: 995177.1250, Val MSE: 1406936.6250, Val MAE: 525.7419\n",
      "Epoch 3510, Train Loss: 994777.6875, Val MSE: 1402914.8750, Val MAE: 524.9791\n",
      "Epoch 3520, Train Loss: 993109.0000, Val MSE: 1402424.7500, Val MAE: 524.6665\n",
      "Epoch 3530, Train Loss: 994612.6875, Val MSE: 1410671.0000, Val MAE: 526.8547\n",
      "Epoch 3540, Train Loss: 992928.2500, Val MSE: 1403432.1250, Val MAE: 524.9518\n",
      "Epoch 3550, Train Loss: 990114.3750, Val MSE: 1404383.7500, Val MAE: 524.8055\n",
      "Epoch 3560, Train Loss: 988983.7500, Val MSE: 1405607.3750, Val MAE: 525.0034\n",
      "Epoch 3570, Train Loss: 988612.6875, Val MSE: 1402065.2500, Val MAE: 524.1646\n",
      "Epoch 3580, Train Loss: 988307.2500, Val MSE: 1406330.7500, Val MAE: 525.2106\n",
      "Epoch 3590, Train Loss: 987170.5625, Val MSE: 1401854.1250, Val MAE: 524.3323\n",
      "Epoch 3600, Train Loss: 986636.6875, Val MSE: 1408494.6250, Val MAE: 525.8105\n",
      "Epoch 3610, Train Loss: 985958.3125, Val MSE: 1401968.3750, Val MAE: 524.1775\n",
      "Epoch 3620, Train Loss: 985611.5625, Val MSE: 1409415.5000, Val MAE: 525.8456\n",
      "Epoch 3630, Train Loss: 983777.5625, Val MSE: 1401920.5000, Val MAE: 523.9247\n",
      "Epoch 3640, Train Loss: 981321.7500, Val MSE: 1402760.0000, Val MAE: 523.9888\n",
      "Epoch 3650, Train Loss: 980880.3125, Val MSE: 1403734.7500, Val MAE: 524.6463\n",
      "Epoch 3660, Train Loss: 980487.3750, Val MSE: 1404086.7500, Val MAE: 523.9947\n",
      "Epoch 3670, Train Loss: 978381.1875, Val MSE: 1403387.8750, Val MAE: 524.0419\n",
      "Epoch 3680, Train Loss: 978099.3750, Val MSE: 1400062.7500, Val MAE: 523.5319\n",
      "Epoch 3690, Train Loss: 978776.9375, Val MSE: 1407396.1250, Val MAE: 524.8768\n",
      "Epoch 3700, Train Loss: 976974.0000, Val MSE: 1400592.3750, Val MAE: 523.1217\n",
      "Epoch 3710, Train Loss: 976451.1250, Val MSE: 1405383.5000, Val MAE: 524.0319\n",
      "Epoch 3720, Train Loss: 976223.1250, Val MSE: 1400085.6250, Val MAE: 523.2333\n",
      "Epoch 3730, Train Loss: 976184.6250, Val MSE: 1408153.1250, Val MAE: 524.5493\n",
      "Epoch 3740, Train Loss: 972980.6250, Val MSE: 1401789.6250, Val MAE: 523.0913\n",
      "Epoch 3750, Train Loss: 972074.5000, Val MSE: 1399623.7500, Val MAE: 523.2568\n",
      "Epoch 3760, Train Loss: 972877.8125, Val MSE: 1404581.5000, Val MAE: 523.8746\n",
      "Epoch 3770, Train Loss: 970460.1250, Val MSE: 1399661.1250, Val MAE: 522.9673\n",
      "Epoch 3780, Train Loss: 971515.0625, Val MSE: 1408423.5000, Val MAE: 524.7350\n",
      "Epoch 3790, Train Loss: 969614.5625, Val MSE: 1400596.7500, Val MAE: 522.9649\n",
      "Epoch 3800, Train Loss: 967245.1250, Val MSE: 1401623.5000, Val MAE: 523.0145\n",
      "Epoch 3810, Train Loss: 967706.5000, Val MSE: 1405616.1250, Val MAE: 523.8187\n",
      "Epoch 3820, Train Loss: 967371.1250, Val MSE: 1401134.7500, Val MAE: 522.7554\n",
      "Epoch 3830, Train Loss: 965187.5000, Val MSE: 1401154.8750, Val MAE: 522.8872\n",
      "Epoch 3840, Train Loss: 965516.3750, Val MSE: 1405811.0000, Val MAE: 523.6738\n",
      "Epoch 3850, Train Loss: 964009.6875, Val MSE: 1399924.1250, Val MAE: 522.8838\n",
      "Epoch 3860, Train Loss: 963688.5625, Val MSE: 1404761.8750, Val MAE: 524.0325\n",
      "Epoch 3870, Train Loss: 963771.0000, Val MSE: 1398906.6250, Val MAE: 522.7126\n",
      "Epoch 3880, Train Loss: 963991.1250, Val MSE: 1405026.7500, Val MAE: 523.8100\n",
      "Epoch 3890, Train Loss: 961318.4375, Val MSE: 1399754.8750, Val MAE: 522.8407\n",
      "Epoch 3900, Train Loss: 961120.6250, Val MSE: 1403948.7500, Val MAE: 523.2429\n",
      "Epoch 3910, Train Loss: 962509.6250, Val MSE: 1400064.2500, Val MAE: 522.4792\n",
      "Epoch 3920, Train Loss: 959062.5625, Val MSE: 1401416.5000, Val MAE: 522.7375\n",
      "Epoch 3930, Train Loss: 959497.0625, Val MSE: 1405578.5000, Val MAE: 523.6036\n",
      "Epoch 3940, Train Loss: 958340.8750, Val MSE: 1399370.0000, Val MAE: 522.5931\n",
      "Epoch 3950, Train Loss: 957591.1875, Val MSE: 1405290.5000, Val MAE: 523.5370\n",
      "Epoch 3960, Train Loss: 958218.5625, Val MSE: 1399030.0000, Val MAE: 522.7724\n",
      "Epoch 3970, Train Loss: 957084.5000, Val MSE: 1403906.1250, Val MAE: 523.3710\n",
      "Epoch 3980, Train Loss: 955605.1250, Val MSE: 1400915.5000, Val MAE: 523.8058\n",
      "Epoch 3990, Train Loss: 955970.5625, Val MSE: 1402605.3750, Val MAE: 523.7656\n",
      "Epoch 4000, Train Loss: 953106.2500, Val MSE: 1401800.2500, Val MAE: 523.1160\n",
      "Epoch 4010, Train Loss: 953304.7500, Val MSE: 1400228.3750, Val MAE: 523.4781\n",
      "Epoch 4020, Train Loss: 951584.6875, Val MSE: 1403440.8750, Val MAE: 523.6526\n",
      "Epoch 4030, Train Loss: 953014.0000, Val MSE: 1399785.8750, Val MAE: 522.4238\n",
      "Epoch 4040, Train Loss: 950818.1875, Val MSE: 1403016.6250, Val MAE: 523.5524\n",
      "Epoch 4050, Train Loss: 949661.2500, Val MSE: 1401788.1250, Val MAE: 523.6658\n",
      "Epoch 4060, Train Loss: 949945.5000, Val MSE: 1402207.0000, Val MAE: 523.1930\n",
      "Epoch 4070, Train Loss: 948269.2500, Val MSE: 1402964.5000, Val MAE: 523.6975\n",
      "Epoch 4080, Train Loss: 947557.8125, Val MSE: 1398956.5000, Val MAE: 522.8473\n",
      "Epoch 4090, Train Loss: 947310.5000, Val MSE: 1404071.1250, Val MAE: 523.6879\n",
      "Epoch 4100, Train Loss: 946835.0000, Val MSE: 1399177.2500, Val MAE: 522.7325\n",
      "Epoch 4110, Train Loss: 946031.5000, Val MSE: 1404651.8750, Val MAE: 523.7079\n",
      "Epoch 4120, Train Loss: 946516.5625, Val MSE: 1399227.1250, Val MAE: 522.6864\n",
      "Epoch 4130, Train Loss: 946310.3750, Val MSE: 1405749.5000, Val MAE: 524.0776\n",
      "Epoch 4140, Train Loss: 944913.8125, Val MSE: 1399919.8750, Val MAE: 522.9664\n",
      "Epoch 4150, Train Loss: 945714.4375, Val MSE: 1407595.8750, Val MAE: 524.1469\n",
      "Epoch 4160, Train Loss: 944065.3750, Val MSE: 1400808.0000, Val MAE: 522.7709\n",
      "Epoch 4170, Train Loss: 944218.1250, Val MSE: 1406024.6250, Val MAE: 523.8431\n",
      "Epoch 4180, Train Loss: 942073.4375, Val MSE: 1401543.6250, Val MAE: 522.8951\n",
      "Epoch 4190, Train Loss: 940702.0625, Val MSE: 1402894.7500, Val MAE: 523.1906\n",
      "Epoch 4200, Train Loss: 939612.5625, Val MSE: 1403501.8750, Val MAE: 523.4924\n",
      "Epoch 4210, Train Loss: 939089.2500, Val MSE: 1402357.5000, Val MAE: 523.1204\n",
      "Epoch 4220, Train Loss: 938551.4375, Val MSE: 1405469.6250, Val MAE: 523.8043\n",
      "Epoch 4230, Train Loss: 939747.6250, Val MSE: 1401969.1250, Val MAE: 523.1818\n",
      "Early stopping triggered at epoch 4230\n",
      "\n",
      " Best Val MAE: 522.4238 at epoch 4030\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd = WideDeep(feature_columns=feature_columns, hidden_units=[64, 32])\n",
    "print(model_wd)\n",
    "model_wd, best_mae, best_epoch = train_widedeep(model_wd, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3ff26926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 938501.6250, Val MSE: 1404555.3750, Val MAE: 523.7253\n",
      "Epoch 20, Train Loss: 937453.3750, Val MSE: 1402872.3750, Val MAE: 523.2666\n",
      "Epoch 30, Train Loss: 937095.2500, Val MSE: 1402648.1250, Val MAE: 523.1632\n",
      "Epoch 40, Train Loss: 936922.6875, Val MSE: 1402631.2500, Val MAE: 523.1617\n",
      "Epoch 50, Train Loss: 936769.1250, Val MSE: 1402405.5000, Val MAE: 523.2114\n",
      "Epoch 60, Train Loss: 936600.6875, Val MSE: 1402388.8750, Val MAE: 523.1848\n",
      "Epoch 70, Train Loss: 936446.0000, Val MSE: 1402293.6250, Val MAE: 523.1786\n",
      "Epoch 80, Train Loss: 936286.5625, Val MSE: 1402098.6250, Val MAE: 523.1752\n",
      "Epoch 90, Train Loss: 936178.1250, Val MSE: 1402137.3750, Val MAE: 523.1723\n",
      "Epoch 100, Train Loss: 935981.0625, Val MSE: 1402183.3750, Val MAE: 523.1968\n",
      "Epoch 110, Train Loss: 935837.4375, Val MSE: 1402086.8750, Val MAE: 523.2014\n",
      "Epoch 120, Train Loss: 935680.1875, Val MSE: 1402358.0000, Val MAE: 523.2276\n",
      "Epoch 130, Train Loss: 935493.8125, Val MSE: 1402123.3750, Val MAE: 523.2028\n",
      "Epoch 140, Train Loss: 935326.6875, Val MSE: 1402213.7500, Val MAE: 523.2172\n",
      "Epoch 150, Train Loss: 935183.2500, Val MSE: 1402081.7500, Val MAE: 523.1812\n",
      "Epoch 160, Train Loss: 935019.1250, Val MSE: 1402275.0000, Val MAE: 523.1953\n",
      "Epoch 170, Train Loss: 934821.0000, Val MSE: 1402555.7500, Val MAE: 523.2612\n",
      "Epoch 180, Train Loss: 934656.7500, Val MSE: 1402437.1250, Val MAE: 523.2252\n",
      "Epoch 190, Train Loss: 934481.8125, Val MSE: 1402214.3750, Val MAE: 523.1787\n",
      "Epoch 200, Train Loss: 934312.0625, Val MSE: 1402386.3750, Val MAE: 523.2353\n",
      "Epoch 210, Train Loss: 934132.2500, Val MSE: 1402689.0000, Val MAE: 523.3113\n",
      "Epoch 220, Train Loss: 933974.4375, Val MSE: 1402290.1250, Val MAE: 523.2071\n",
      "Epoch 230, Train Loss: 933824.6875, Val MSE: 1402571.0000, Val MAE: 523.2580\n",
      "Epoch 240, Train Loss: 933650.0000, Val MSE: 1402807.1250, Val MAE: 523.2301\n",
      "Early stopping triggered at epoch 240\n",
      "\n",
      " Best Val MAE: 523.1617 at epoch 40\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd, best_mae, best_epoch = train_widedeep(model_wd, X_train3, y_train3, X_val3, y_val3, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "32ff5cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of model_wd: 9396\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_wd.parameters())\n",
    "print(f\"Total Parameters of model_wd: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e273732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wd1 = WideDeep(feature_columns=feature_columns, hidden_units=[128, 64], dnn_dropout=0.2)\n",
    "print(model_wd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "891bef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 95985608.0000, Val MSE: 97044424.0000, Val MAE: 6193.2002\n",
      "Epoch 20, Train Loss: 90357280.0000, Val MSE: 90369104.0000, Val MAE: 5793.0161\n",
      "Epoch 30, Train Loss: 69250504.0000, Val MSE: 66967680.0000, Val MAE: 4424.4883\n",
      "Epoch 40, Train Loss: 39774936.0000, Val MSE: 39227536.0000, Val MAE: 4120.1191\n",
      "Epoch 50, Train Loss: 32751850.0000, Val MSE: 31344186.0000, Val MAE: 3712.2432\n",
      "Epoch 60, Train Loss: 25331636.0000, Val MSE: 24953260.0000, Val MAE: 2754.6462\n",
      "Epoch 70, Train Loss: 19802064.0000, Val MSE: 19321268.0000, Val MAE: 2562.2239\n",
      "Epoch 80, Train Loss: 16324344.0000, Val MSE: 15830661.0000, Val MAE: 2260.1426\n",
      "Epoch 90, Train Loss: 14002544.0000, Val MSE: 13557737.0000, Val MAE: 2023.2323\n",
      "Epoch 100, Train Loss: 12417179.0000, Val MSE: 11953113.0000, Val MAE: 1962.9917\n",
      "Epoch 110, Train Loss: 11401038.0000, Val MSE: 10940495.0000, Val MAE: 1890.2052\n",
      "Epoch 120, Train Loss: 10717095.0000, Val MSE: 10202178.0000, Val MAE: 1839.5500\n",
      "Epoch 130, Train Loss: 10029873.0000, Val MSE: 9588945.0000, Val MAE: 1782.4603\n",
      "Epoch 140, Train Loss: 9563275.0000, Val MSE: 9047572.0000, Val MAE: 1703.9686\n",
      "Epoch 150, Train Loss: 8922284.0000, Val MSE: 8529685.0000, Val MAE: 1619.5769\n",
      "Epoch 160, Train Loss: 8560263.0000, Val MSE: 8059247.0000, Val MAE: 1533.7611\n",
      "Epoch 170, Train Loss: 8102911.0000, Val MSE: 7631656.0000, Val MAE: 1462.5946\n",
      "Epoch 180, Train Loss: 7705358.5000, Val MSE: 7228975.5000, Val MAE: 1398.8999\n",
      "Epoch 190, Train Loss: 7362926.0000, Val MSE: 6848931.5000, Val MAE: 1333.6084\n",
      "Epoch 200, Train Loss: 7026330.0000, Val MSE: 6499968.0000, Val MAE: 1275.2288\n",
      "Epoch 210, Train Loss: 6759676.0000, Val MSE: 6199277.5000, Val MAE: 1226.7860\n",
      "Epoch 220, Train Loss: 6440980.5000, Val MSE: 5936434.5000, Val MAE: 1188.6934\n",
      "Epoch 230, Train Loss: 6244426.0000, Val MSE: 5704984.0000, Val MAE: 1156.9609\n",
      "Epoch 240, Train Loss: 6054396.0000, Val MSE: 5500420.5000, Val MAE: 1130.1790\n",
      "Epoch 250, Train Loss: 5918385.5000, Val MSE: 5326681.5000, Val MAE: 1105.7704\n",
      "Epoch 260, Train Loss: 5819228.0000, Val MSE: 5171214.5000, Val MAE: 1084.3292\n",
      "Epoch 270, Train Loss: 5650847.0000, Val MSE: 5031376.5000, Val MAE: 1065.4563\n",
      "Epoch 280, Train Loss: 5545937.0000, Val MSE: 4907624.0000, Val MAE: 1048.3983\n",
      "Epoch 290, Train Loss: 5393268.0000, Val MSE: 4791429.0000, Val MAE: 1033.4943\n",
      "Epoch 300, Train Loss: 5338480.5000, Val MSE: 4684749.0000, Val MAE: 1018.9467\n",
      "Epoch 310, Train Loss: 5154465.0000, Val MSE: 4588587.5000, Val MAE: 1005.5098\n",
      "Epoch 320, Train Loss: 5098883.0000, Val MSE: 4495891.5000, Val MAE: 993.8290\n",
      "Epoch 330, Train Loss: 5021632.0000, Val MSE: 4412123.5000, Val MAE: 982.0845\n",
      "Epoch 340, Train Loss: 5011274.5000, Val MSE: 4328154.5000, Val MAE: 971.8734\n",
      "Epoch 350, Train Loss: 4858957.5000, Val MSE: 4252573.5000, Val MAE: 960.5907\n",
      "Epoch 360, Train Loss: 4786039.0000, Val MSE: 4175826.7500, Val MAE: 949.9300\n",
      "Epoch 370, Train Loss: 4731518.5000, Val MSE: 4100130.2500, Val MAE: 939.5596\n",
      "Epoch 380, Train Loss: 4620982.0000, Val MSE: 3989565.0000, Val MAE: 927.6720\n",
      "Epoch 390, Train Loss: 4447961.0000, Val MSE: 3871185.7500, Val MAE: 914.7086\n",
      "Epoch 400, Train Loss: 4357443.0000, Val MSE: 3748205.2500, Val MAE: 899.0186\n",
      "Epoch 410, Train Loss: 4242717.5000, Val MSE: 3612208.7500, Val MAE: 884.2261\n",
      "Epoch 420, Train Loss: 4093620.2500, Val MSE: 3483797.7500, Val MAE: 869.3225\n",
      "Epoch 430, Train Loss: 3962858.0000, Val MSE: 3363301.2500, Val MAE: 854.9025\n",
      "Epoch 440, Train Loss: 3863421.5000, Val MSE: 3251685.7500, Val MAE: 843.5380\n",
      "Epoch 450, Train Loss: 3801545.5000, Val MSE: 3160108.5000, Val MAE: 830.3995\n",
      "Epoch 460, Train Loss: 3634576.7500, Val MSE: 3069839.7500, Val MAE: 820.9669\n",
      "Epoch 470, Train Loss: 3625775.5000, Val MSE: 2986289.0000, Val MAE: 813.1805\n",
      "Epoch 480, Train Loss: 3548171.7500, Val MSE: 2909972.2500, Val MAE: 806.2366\n",
      "Epoch 490, Train Loss: 3502914.0000, Val MSE: 2836684.0000, Val MAE: 798.5620\n",
      "Epoch 500, Train Loss: 3376816.7500, Val MSE: 2766917.0000, Val MAE: 791.7660\n",
      "Epoch 510, Train Loss: 3357821.0000, Val MSE: 2713600.7500, Val MAE: 787.1826\n",
      "Epoch 520, Train Loss: 3246167.7500, Val MSE: 2637218.5000, Val MAE: 778.4675\n",
      "Epoch 530, Train Loss: 3258172.0000, Val MSE: 2578654.5000, Val MAE: 773.5728\n",
      "Epoch 540, Train Loss: 3162902.5000, Val MSE: 2515018.2500, Val MAE: 765.7177\n",
      "Epoch 550, Train Loss: 3140299.2500, Val MSE: 2464070.0000, Val MAE: 759.9784\n",
      "Epoch 560, Train Loss: 3074127.5000, Val MSE: 2409581.7500, Val MAE: 754.0874\n",
      "Epoch 570, Train Loss: 2966743.0000, Val MSE: 2368634.5000, Val MAE: 748.0658\n",
      "Epoch 580, Train Loss: 2980622.5000, Val MSE: 2327105.0000, Val MAE: 742.9870\n",
      "Epoch 590, Train Loss: 2975475.5000, Val MSE: 2279943.5000, Val MAE: 736.1747\n",
      "Epoch 600, Train Loss: 2859608.5000, Val MSE: 2244829.5000, Val MAE: 732.2125\n",
      "Epoch 610, Train Loss: 2778553.0000, Val MSE: 2202056.2500, Val MAE: 725.5287\n",
      "Epoch 620, Train Loss: 2805026.7500, Val MSE: 2169205.2500, Val MAE: 721.9782\n",
      "Epoch 630, Train Loss: 2750444.2500, Val MSE: 2137579.2500, Val MAE: 718.1808\n",
      "Epoch 640, Train Loss: 2735804.7500, Val MSE: 2111956.5000, Val MAE: 713.6285\n",
      "Epoch 650, Train Loss: 2681076.7500, Val MSE: 2092897.0000, Val MAE: 713.5590\n",
      "Epoch 660, Train Loss: 2648256.5000, Val MSE: 2060619.7500, Val MAE: 706.2328\n",
      "Epoch 670, Train Loss: 2660027.5000, Val MSE: 2035217.6250, Val MAE: 702.6819\n",
      "Epoch 680, Train Loss: 2565204.5000, Val MSE: 2019163.1250, Val MAE: 700.7245\n",
      "Epoch 690, Train Loss: 2545176.5000, Val MSE: 2003333.7500, Val MAE: 698.3649\n",
      "Epoch 700, Train Loss: 2528077.7500, Val MSE: 1970299.2500, Val MAE: 693.8165\n",
      "Epoch 710, Train Loss: 2510275.2500, Val MSE: 1959497.7500, Val MAE: 691.3776\n",
      "Epoch 720, Train Loss: 2526954.5000, Val MSE: 1946434.0000, Val MAE: 690.1422\n",
      "Epoch 730, Train Loss: 2472245.2500, Val MSE: 1921201.7500, Val MAE: 684.5146\n",
      "Epoch 740, Train Loss: 2495732.2500, Val MSE: 1909232.1250, Val MAE: 683.2864\n",
      "Epoch 750, Train Loss: 2433774.7500, Val MSE: 1892093.3750, Val MAE: 678.9683\n",
      "Epoch 760, Train Loss: 2426592.7500, Val MSE: 1883836.8750, Val MAE: 679.1847\n",
      "Epoch 770, Train Loss: 2476948.5000, Val MSE: 1867459.6250, Val MAE: 675.2477\n",
      "Epoch 780, Train Loss: 2419768.7500, Val MSE: 1857182.0000, Val MAE: 672.3963\n",
      "Epoch 790, Train Loss: 2380508.7500, Val MSE: 1838859.7500, Val MAE: 670.7684\n",
      "Epoch 800, Train Loss: 2430462.0000, Val MSE: 1825326.1250, Val MAE: 667.9048\n",
      "Epoch 810, Train Loss: 2388860.2500, Val MSE: 1813541.0000, Val MAE: 666.2086\n",
      "Epoch 820, Train Loss: 2358163.0000, Val MSE: 1796962.7500, Val MAE: 663.5598\n",
      "Epoch 830, Train Loss: 2358777.5000, Val MSE: 1793313.2500, Val MAE: 662.9322\n",
      "Epoch 840, Train Loss: 2277694.7500, Val MSE: 1781392.2500, Val MAE: 659.4398\n",
      "Epoch 850, Train Loss: 2307087.5000, Val MSE: 1780726.1250, Val MAE: 659.9177\n",
      "Epoch 860, Train Loss: 2334604.0000, Val MSE: 1774043.0000, Val MAE: 659.2823\n",
      "Epoch 870, Train Loss: 2292718.7500, Val MSE: 1751177.5000, Val MAE: 654.3448\n",
      "Epoch 880, Train Loss: 2291674.0000, Val MSE: 1738932.5000, Val MAE: 652.0970\n",
      "Epoch 890, Train Loss: 2248026.7500, Val MSE: 1728291.0000, Val MAE: 648.7327\n",
      "Epoch 900, Train Loss: 2285520.0000, Val MSE: 1714195.3750, Val MAE: 644.4533\n",
      "Epoch 910, Train Loss: 2278611.0000, Val MSE: 1711001.0000, Val MAE: 645.9431\n",
      "Epoch 920, Train Loss: 2236933.0000, Val MSE: 1700711.1250, Val MAE: 643.0864\n",
      "Epoch 930, Train Loss: 2230516.7500, Val MSE: 1702087.3750, Val MAE: 643.6445\n",
      "Epoch 940, Train Loss: 2214142.5000, Val MSE: 1691848.7500, Val MAE: 639.3825\n",
      "Epoch 950, Train Loss: 2188852.0000, Val MSE: 1685698.5000, Val MAE: 636.9357\n",
      "Epoch 960, Train Loss: 2192784.5000, Val MSE: 1688256.7500, Val MAE: 640.1646\n",
      "Epoch 970, Train Loss: 2156437.5000, Val MSE: 1678355.1250, Val MAE: 637.1113\n",
      "Epoch 980, Train Loss: 2192942.7500, Val MSE: 1672440.5000, Val MAE: 638.1621\n",
      "Epoch 990, Train Loss: 2177923.0000, Val MSE: 1658686.7500, Val MAE: 631.8150\n",
      "Epoch 1000, Train Loss: 2154576.7500, Val MSE: 1646411.5000, Val MAE: 626.9540\n",
      "Epoch 1010, Train Loss: 2129075.5000, Val MSE: 1644688.2500, Val MAE: 626.8095\n",
      "Epoch 1020, Train Loss: 2123676.5000, Val MSE: 1630233.5000, Val MAE: 621.9975\n",
      "Epoch 1030, Train Loss: 2154069.0000, Val MSE: 1626160.1250, Val MAE: 620.9139\n",
      "Epoch 1040, Train Loss: 2096459.8750, Val MSE: 1618019.3750, Val MAE: 618.9460\n",
      "Epoch 1050, Train Loss: 2135225.5000, Val MSE: 1612430.8750, Val MAE: 618.1896\n",
      "Epoch 1060, Train Loss: 2115148.0000, Val MSE: 1602910.5000, Val MAE: 615.2403\n",
      "Epoch 1070, Train Loss: 2100655.5000, Val MSE: 1616738.8750, Val MAE: 622.0817\n",
      "Epoch 1080, Train Loss: 2101133.7500, Val MSE: 1597951.1250, Val MAE: 613.3618\n",
      "Epoch 1090, Train Loss: 2077428.0000, Val MSE: 1589875.1250, Val MAE: 610.4435\n",
      "Epoch 1100, Train Loss: 2093341.3750, Val MSE: 1587286.0000, Val MAE: 610.6191\n",
      "Epoch 1110, Train Loss: 2069296.5000, Val MSE: 1574543.0000, Val MAE: 607.0830\n",
      "Epoch 1120, Train Loss: 2063020.1250, Val MSE: 1614469.8750, Val MAE: 623.5371\n",
      "Epoch 1130, Train Loss: 2080839.2500, Val MSE: 1567630.7500, Val MAE: 604.3862\n",
      "Epoch 1140, Train Loss: 2059562.5000, Val MSE: 1577534.6250, Val MAE: 611.4816\n",
      "Epoch 1150, Train Loss: 2044238.5000, Val MSE: 1554321.1250, Val MAE: 600.0729\n",
      "Epoch 1160, Train Loss: 2008652.7500, Val MSE: 1571389.1250, Val MAE: 610.4040\n",
      "Epoch 1170, Train Loss: 2043500.3750, Val MSE: 1540922.8750, Val MAE: 596.4011\n",
      "Epoch 1180, Train Loss: 1965035.2500, Val MSE: 1549390.6250, Val MAE: 599.7631\n",
      "Epoch 1190, Train Loss: 2016568.7500, Val MSE: 1538064.7500, Val MAE: 595.9409\n",
      "Epoch 1200, Train Loss: 2025877.2500, Val MSE: 1559250.5000, Val MAE: 607.4957\n",
      "Epoch 1210, Train Loss: 2031752.7500, Val MSE: 1526275.6250, Val MAE: 591.9053\n",
      "Epoch 1220, Train Loss: 2035659.3750, Val MSE: 1517817.7500, Val MAE: 590.0326\n",
      "Epoch 1230, Train Loss: 1993769.6250, Val MSE: 1516045.5000, Val MAE: 590.8164\n",
      "Epoch 1240, Train Loss: 1993612.3750, Val MSE: 1514726.7500, Val MAE: 592.2797\n",
      "Epoch 1250, Train Loss: 1983500.3750, Val MSE: 1517493.8750, Val MAE: 591.5756\n",
      "Epoch 1260, Train Loss: 1992121.0000, Val MSE: 1517708.1250, Val MAE: 592.3879\n",
      "Epoch 1270, Train Loss: 1964836.7500, Val MSE: 1496224.7500, Val MAE: 582.8971\n",
      "Epoch 1280, Train Loss: 1988670.1250, Val MSE: 1511174.7500, Val MAE: 591.3161\n",
      "Epoch 1290, Train Loss: 1930431.0000, Val MSE: 1499135.3750, Val MAE: 583.5298\n",
      "Epoch 1300, Train Loss: 1977299.8750, Val MSE: 1496374.6250, Val MAE: 585.2938\n",
      "Epoch 1310, Train Loss: 1977883.7500, Val MSE: 1482659.1250, Val MAE: 578.7419\n",
      "Epoch 1320, Train Loss: 1945064.6250, Val MSE: 1484632.1250, Val MAE: 579.2327\n",
      "Epoch 1330, Train Loss: 1964306.6250, Val MSE: 1484873.7500, Val MAE: 579.2766\n",
      "Epoch 1340, Train Loss: 1933059.7500, Val MSE: 1483628.0000, Val MAE: 579.2328\n",
      "Epoch 1350, Train Loss: 1933025.3750, Val MSE: 1474822.0000, Val MAE: 576.2110\n",
      "Epoch 1360, Train Loss: 1906655.2500, Val MSE: 1488125.1250, Val MAE: 583.8356\n",
      "Epoch 1370, Train Loss: 1933082.0000, Val MSE: 1486672.8750, Val MAE: 585.6680\n",
      "Epoch 1380, Train Loss: 1937320.5000, Val MSE: 1476568.1250, Val MAE: 580.4240\n",
      "Epoch 1390, Train Loss: 1906807.0000, Val MSE: 1506612.2500, Val MAE: 591.5762\n",
      "Epoch 1400, Train Loss: 1882780.6250, Val MSE: 1457648.0000, Val MAE: 570.3680\n",
      "Epoch 1410, Train Loss: 1910928.5000, Val MSE: 1463415.1250, Val MAE: 571.0319\n",
      "Epoch 1420, Train Loss: 1906413.5000, Val MSE: 1467426.7500, Val MAE: 573.8550\n",
      "Epoch 1430, Train Loss: 1930242.5000, Val MSE: 1457058.7500, Val MAE: 569.2896\n",
      "Epoch 1440, Train Loss: 1913779.2500, Val MSE: 1464369.6250, Val MAE: 569.7836\n",
      "Epoch 1450, Train Loss: 1866965.1250, Val MSE: 1455742.7500, Val MAE: 568.7168\n",
      "Epoch 1460, Train Loss: 1866528.6250, Val MSE: 1450872.1250, Val MAE: 565.3888\n",
      "Epoch 1470, Train Loss: 1892251.3750, Val MSE: 1447617.1250, Val MAE: 565.6595\n",
      "Epoch 1480, Train Loss: 1855747.1250, Val MSE: 1452220.0000, Val MAE: 565.3954\n",
      "Epoch 1490, Train Loss: 1861782.0000, Val MSE: 1473811.1250, Val MAE: 577.0692\n",
      "Epoch 1500, Train Loss: 1869965.5000, Val MSE: 1449944.6250, Val MAE: 562.7960\n",
      "Epoch 1510, Train Loss: 1850929.8750, Val MSE: 1455819.2500, Val MAE: 569.1591\n",
      "Epoch 1520, Train Loss: 1863470.5000, Val MSE: 1444547.8750, Val MAE: 562.5897\n",
      "Epoch 1530, Train Loss: 1851271.2500, Val MSE: 1450931.8750, Val MAE: 567.1890\n",
      "Epoch 1540, Train Loss: 1837606.0000, Val MSE: 1437622.1250, Val MAE: 560.4991\n",
      "Epoch 1550, Train Loss: 1861801.6250, Val MSE: 1459088.1250, Val MAE: 570.3810\n",
      "Epoch 1560, Train Loss: 1884126.5000, Val MSE: 1449470.0000, Val MAE: 564.2682\n",
      "Epoch 1570, Train Loss: 1811934.7500, Val MSE: 1433841.6250, Val MAE: 558.9476\n",
      "Epoch 1580, Train Loss: 1826691.0000, Val MSE: 1434995.6250, Val MAE: 558.3698\n",
      "Epoch 1590, Train Loss: 1850275.7500, Val MSE: 1444772.5000, Val MAE: 561.8340\n",
      "Epoch 1600, Train Loss: 1851204.6250, Val MSE: 1426659.7500, Val MAE: 555.4069\n",
      "Epoch 1610, Train Loss: 1846148.1250, Val MSE: 1466563.1250, Val MAE: 570.4085\n",
      "Epoch 1620, Train Loss: 1805663.7500, Val MSE: 1435077.3750, Val MAE: 556.1221\n",
      "Epoch 1630, Train Loss: 1832779.2500, Val MSE: 1428622.5000, Val MAE: 555.2714\n",
      "Epoch 1640, Train Loss: 1833994.6250, Val MSE: 1427946.6250, Val MAE: 553.9000\n",
      "Epoch 1650, Train Loss: 1808786.8750, Val MSE: 1431981.1250, Val MAE: 554.4144\n",
      "Epoch 1660, Train Loss: 1830980.3750, Val MSE: 1428304.7500, Val MAE: 551.8801\n",
      "Epoch 1670, Train Loss: 1810853.1250, Val MSE: 1474325.1250, Val MAE: 576.1285\n",
      "Epoch 1680, Train Loss: 1791342.5000, Val MSE: 1426973.7500, Val MAE: 552.3125\n",
      "Epoch 1690, Train Loss: 1840266.8750, Val MSE: 1430724.6250, Val MAE: 551.5004\n",
      "Epoch 1700, Train Loss: 1792150.8750, Val MSE: 1448856.7500, Val MAE: 562.3283\n",
      "Epoch 1710, Train Loss: 1785095.0000, Val MSE: 1429240.2500, Val MAE: 551.0693\n",
      "Epoch 1720, Train Loss: 1801853.7500, Val MSE: 1432654.0000, Val MAE: 553.3317\n",
      "Epoch 1730, Train Loss: 1784914.7500, Val MSE: 1427256.5000, Val MAE: 552.2861\n",
      "Epoch 1740, Train Loss: 1813028.3750, Val MSE: 1489793.0000, Val MAE: 582.4976\n",
      "Epoch 1750, Train Loss: 1848000.8750, Val MSE: 1427048.1250, Val MAE: 550.5515\n",
      "Epoch 1760, Train Loss: 1778391.6250, Val MSE: 1441386.7500, Val MAE: 557.3434\n",
      "Epoch 1770, Train Loss: 1776127.8750, Val MSE: 1426106.6250, Val MAE: 548.0244\n",
      "Epoch 1780, Train Loss: 1795888.7500, Val MSE: 1422830.5000, Val MAE: 547.1337\n",
      "Epoch 1790, Train Loss: 1746587.0000, Val MSE: 1418469.2500, Val MAE: 545.1796\n",
      "Epoch 1800, Train Loss: 1753237.6250, Val MSE: 1426337.3750, Val MAE: 546.4407\n",
      "Epoch 1810, Train Loss: 1774390.6250, Val MSE: 1435051.2500, Val MAE: 554.2503\n",
      "Epoch 1820, Train Loss: 1780958.0000, Val MSE: 1419118.3750, Val MAE: 544.4844\n",
      "Epoch 1830, Train Loss: 1761058.8750, Val MSE: 1422135.0000, Val MAE: 544.7911\n",
      "Epoch 1840, Train Loss: 1805688.1250, Val MSE: 1485966.5000, Val MAE: 579.7343\n",
      "Epoch 1850, Train Loss: 1815074.7500, Val MSE: 1421791.8750, Val MAE: 543.8456\n",
      "Epoch 1860, Train Loss: 1775481.0000, Val MSE: 1428654.2500, Val MAE: 550.3710\n",
      "Epoch 1870, Train Loss: 1751553.0000, Val MSE: 1444384.8750, Val MAE: 555.7486\n",
      "Epoch 1880, Train Loss: 1790551.0000, Val MSE: 1423483.8750, Val MAE: 544.0432\n",
      "Epoch 1890, Train Loss: 1774170.1250, Val MSE: 1427343.5000, Val MAE: 543.4260\n",
      "Epoch 1900, Train Loss: 1755136.2500, Val MSE: 1427197.0000, Val MAE: 543.4634\n",
      "Epoch 1910, Train Loss: 1792046.0000, Val MSE: 1430113.0000, Val MAE: 545.1342\n",
      "Epoch 1920, Train Loss: 1751168.3750, Val MSE: 1445558.1250, Val MAE: 559.0164\n",
      "Epoch 1930, Train Loss: 1750695.3750, Val MSE: 1421676.6250, Val MAE: 543.6503\n",
      "Epoch 1940, Train Loss: 1762097.3750, Val MSE: 1421849.6250, Val MAE: 541.5546\n",
      "Epoch 1950, Train Loss: 1738214.6250, Val MSE: 1428066.1250, Val MAE: 544.9512\n",
      "Epoch 1960, Train Loss: 1765840.6250, Val MSE: 1433425.7500, Val MAE: 548.7128\n",
      "Epoch 1970, Train Loss: 1773523.7500, Val MSE: 1423870.1250, Val MAE: 542.9798\n",
      "Epoch 1980, Train Loss: 1700449.0000, Val MSE: 1438336.7500, Val MAE: 555.4759\n",
      "Epoch 1990, Train Loss: 1749526.3750, Val MSE: 1423464.8750, Val MAE: 542.0468\n",
      "Epoch 2000, Train Loss: 1747498.7500, Val MSE: 1417077.3750, Val MAE: 538.9105\n",
      "Epoch 2010, Train Loss: 1739419.0000, Val MSE: 1468097.2500, Val MAE: 559.0513\n",
      "Epoch 2020, Train Loss: 1718493.2500, Val MSE: 1424942.1250, Val MAE: 539.7298\n",
      "Epoch 2030, Train Loss: 1756990.6250, Val MSE: 1420101.1250, Val MAE: 539.8234\n",
      "Epoch 2040, Train Loss: 1755086.3750, Val MSE: 1433982.1250, Val MAE: 545.7320\n",
      "Epoch 2050, Train Loss: 1711112.2500, Val MSE: 1427182.2500, Val MAE: 541.7309\n",
      "Epoch 2060, Train Loss: 1732962.2500, Val MSE: 1424802.3750, Val MAE: 542.5309\n",
      "Epoch 2070, Train Loss: 1758467.7500, Val MSE: 1417610.7500, Val MAE: 537.6490\n",
      "Epoch 2080, Train Loss: 1764509.2500, Val MSE: 1443601.0000, Val MAE: 546.4968\n",
      "Epoch 2090, Train Loss: 1714921.3750, Val MSE: 1421899.0000, Val MAE: 538.5263\n",
      "Epoch 2100, Train Loss: 1754585.5000, Val MSE: 1457768.0000, Val MAE: 561.2377\n",
      "Epoch 2110, Train Loss: 1747241.2500, Val MSE: 1430055.5000, Val MAE: 540.0234\n",
      "Epoch 2120, Train Loss: 1717328.3750, Val MSE: 1429553.6250, Val MAE: 545.6757\n",
      "Epoch 2130, Train Loss: 1698825.1250, Val MSE: 1421718.0000, Val MAE: 539.0158\n",
      "Epoch 2140, Train Loss: 1748937.0000, Val MSE: 1434260.1250, Val MAE: 547.1727\n",
      "Epoch 2150, Train Loss: 1705131.3750, Val MSE: 1424587.7500, Val MAE: 538.5319\n",
      "Epoch 2160, Train Loss: 1704809.8750, Val MSE: 1424786.2500, Val MAE: 540.5071\n",
      "Epoch 2170, Train Loss: 1729132.1250, Val MSE: 1418506.1250, Val MAE: 536.1786\n",
      "Epoch 2180, Train Loss: 1732001.6250, Val MSE: 1422919.5000, Val MAE: 536.5590\n",
      "Epoch 2190, Train Loss: 1727331.3750, Val MSE: 1420915.1250, Val MAE: 536.7300\n",
      "Epoch 2200, Train Loss: 1720287.7500, Val MSE: 1436852.2500, Val MAE: 549.4812\n",
      "Epoch 2210, Train Loss: 1709610.7500, Val MSE: 1427903.2500, Val MAE: 538.1227\n",
      "Epoch 2220, Train Loss: 1736769.3750, Val MSE: 1428559.6250, Val MAE: 537.8254\n",
      "Epoch 2230, Train Loss: 1746348.5000, Val MSE: 1460166.7500, Val MAE: 557.9003\n",
      "Epoch 2240, Train Loss: 1744465.7500, Val MSE: 1427718.8750, Val MAE: 536.3312\n",
      "Epoch 2250, Train Loss: 1711464.6250, Val MSE: 1430432.7500, Val MAE: 537.3084\n",
      "Epoch 2260, Train Loss: 1692751.2500, Val MSE: 1427775.8750, Val MAE: 535.7551\n",
      "Epoch 2270, Train Loss: 1689438.8750, Val MSE: 1435258.6250, Val MAE: 542.3927\n",
      "Epoch 2280, Train Loss: 1699874.7500, Val MSE: 1417375.8750, Val MAE: 532.8230\n",
      "Epoch 2290, Train Loss: 1724210.7500, Val MSE: 1446969.6250, Val MAE: 548.6132\n",
      "Epoch 2300, Train Loss: 1695658.8750, Val MSE: 1420522.0000, Val MAE: 535.4070\n",
      "Epoch 2310, Train Loss: 1693013.6250, Val MSE: 1425488.7500, Val MAE: 536.2214\n",
      "Epoch 2320, Train Loss: 1707500.8750, Val MSE: 1425594.0000, Val MAE: 540.2382\n",
      "Epoch 2330, Train Loss: 1689148.5000, Val MSE: 1430300.8750, Val MAE: 537.5126\n",
      "Epoch 2340, Train Loss: 1691158.0000, Val MSE: 1419208.6250, Val MAE: 532.8366\n",
      "Epoch 2350, Train Loss: 1695195.6250, Val MSE: 1426428.7500, Val MAE: 538.7023\n",
      "Epoch 2360, Train Loss: 1705182.3750, Val MSE: 1423078.5000, Val MAE: 540.1498\n",
      "Epoch 2370, Train Loss: 1682171.3750, Val MSE: 1416763.1250, Val MAE: 533.1570\n",
      "Epoch 2380, Train Loss: 1676303.5000, Val MSE: 1417318.7500, Val MAE: 535.8588\n",
      "Epoch 2390, Train Loss: 1704545.7500, Val MSE: 1452665.6250, Val MAE: 556.2241\n",
      "Epoch 2400, Train Loss: 1707322.5000, Val MSE: 1419780.3750, Val MAE: 536.4757\n",
      "Epoch 2410, Train Loss: 1687081.2500, Val MSE: 1421594.1250, Val MAE: 533.6650\n",
      "Epoch 2420, Train Loss: 1716543.5000, Val MSE: 1437932.0000, Val MAE: 541.4628\n",
      "Epoch 2430, Train Loss: 1700349.5000, Val MSE: 1422347.0000, Val MAE: 534.8625\n",
      "Epoch 2440, Train Loss: 1688852.1250, Val MSE: 1422153.5000, Val MAE: 531.5430\n",
      "Epoch 2450, Train Loss: 1673136.8750, Val MSE: 1420913.2500, Val MAE: 534.7636\n",
      "Epoch 2460, Train Loss: 1668445.5000, Val MSE: 1432291.3750, Val MAE: 542.5697\n",
      "Epoch 2470, Train Loss: 1687662.1250, Val MSE: 1423165.0000, Val MAE: 535.0181\n",
      "Epoch 2480, Train Loss: 1685812.8750, Val MSE: 1415720.1250, Val MAE: 533.3099\n",
      "Epoch 2490, Train Loss: 1673870.6250, Val MSE: 1421885.7500, Val MAE: 535.4472\n",
      "Epoch 2500, Train Loss: 1697782.6250, Val MSE: 1420259.8750, Val MAE: 533.4599\n",
      "Epoch 2510, Train Loss: 1683698.3750, Val MSE: 1421147.2500, Val MAE: 537.8743\n",
      "Epoch 2520, Train Loss: 1671778.1250, Val MSE: 1418506.6250, Val MAE: 531.7272\n",
      "Epoch 2530, Train Loss: 1705195.1250, Val MSE: 1424966.2500, Val MAE: 532.6268\n",
      "Epoch 2540, Train Loss: 1727976.1250, Val MSE: 1447298.3750, Val MAE: 545.4562\n",
      "Epoch 2550, Train Loss: 1673266.8750, Val MSE: 1426541.8750, Val MAE: 535.4979\n",
      "Epoch 2560, Train Loss: 1666363.5000, Val MSE: 1434696.1250, Val MAE: 540.7366\n",
      "Epoch 2570, Train Loss: 1684783.3750, Val MSE: 1424770.6250, Val MAE: 531.4848\n",
      "Epoch 2580, Train Loss: 1672456.6250, Val MSE: 1413400.5000, Val MAE: 531.6049\n",
      "Epoch 2590, Train Loss: 1655910.0000, Val MSE: 1415737.0000, Val MAE: 533.8290\n",
      "Epoch 2600, Train Loss: 1682752.7500, Val MSE: 1417832.6250, Val MAE: 532.4069\n",
      "Epoch 2610, Train Loss: 1662129.0000, Val MSE: 1422600.6250, Val MAE: 535.1384\n",
      "Epoch 2620, Train Loss: 1653545.2500, Val MSE: 1435079.3750, Val MAE: 536.6679\n",
      "Epoch 2630, Train Loss: 1632843.5000, Val MSE: 1417182.7500, Val MAE: 528.2327\n",
      "Epoch 2640, Train Loss: 1638037.1250, Val MSE: 1419244.3750, Val MAE: 533.2599\n",
      "Epoch 2650, Train Loss: 1660639.7500, Val MSE: 1432488.3750, Val MAE: 539.3988\n",
      "Epoch 2660, Train Loss: 1680315.8750, Val MSE: 1428278.2500, Val MAE: 536.3007\n",
      "Epoch 2670, Train Loss: 1662401.1250, Val MSE: 1434315.1250, Val MAE: 538.8676\n",
      "Epoch 2680, Train Loss: 1704746.1250, Val MSE: 1423060.7500, Val MAE: 530.8525\n",
      "Epoch 2690, Train Loss: 1662543.8750, Val MSE: 1417682.1250, Val MAE: 528.3955\n",
      "Epoch 2700, Train Loss: 1688377.5000, Val MSE: 1415744.3750, Val MAE: 528.5176\n",
      "Epoch 2710, Train Loss: 1667036.3750, Val MSE: 1416670.1250, Val MAE: 527.1666\n",
      "Epoch 2720, Train Loss: 1663082.8750, Val MSE: 1421116.2500, Val MAE: 532.0535\n",
      "Epoch 2730, Train Loss: 1669467.7500, Val MSE: 1419898.2500, Val MAE: 529.1137\n",
      "Epoch 2740, Train Loss: 1673311.0000, Val MSE: 1424345.7500, Val MAE: 530.5189\n",
      "Epoch 2750, Train Loss: 1649031.3750, Val MSE: 1435353.3750, Val MAE: 537.2734\n",
      "Epoch 2760, Train Loss: 1671314.5000, Val MSE: 1427511.5000, Val MAE: 534.1218\n",
      "Epoch 2770, Train Loss: 1655538.5000, Val MSE: 1434129.8750, Val MAE: 532.8268\n",
      "Epoch 2780, Train Loss: 1647621.5000, Val MSE: 1451448.6250, Val MAE: 545.6465\n",
      "Epoch 2790, Train Loss: 1671126.3750, Val MSE: 1446586.8750, Val MAE: 543.9885\n",
      "Epoch 2800, Train Loss: 1651049.2500, Val MSE: 1418861.3750, Val MAE: 529.1854\n",
      "Epoch 2810, Train Loss: 1644249.8750, Val MSE: 1420175.2500, Val MAE: 529.9574\n",
      "Epoch 2820, Train Loss: 1696742.1250, Val MSE: 1493640.1250, Val MAE: 564.8218\n",
      "Epoch 2830, Train Loss: 1633788.7500, Val MSE: 1423574.1250, Val MAE: 530.7180\n",
      "Epoch 2840, Train Loss: 1652312.8750, Val MSE: 1432623.0000, Val MAE: 532.7953\n",
      "Epoch 2850, Train Loss: 1686662.3750, Val MSE: 1417946.5000, Val MAE: 526.7489\n",
      "Epoch 2860, Train Loss: 1671487.3750, Val MSE: 1428495.7500, Val MAE: 537.1904\n",
      "Epoch 2870, Train Loss: 1669207.5000, Val MSE: 1419655.7500, Val MAE: 532.9140\n",
      "Epoch 2880, Train Loss: 1649712.5000, Val MSE: 1424318.1250, Val MAE: 530.6692\n",
      "Epoch 2890, Train Loss: 1636247.1250, Val MSE: 1422688.0000, Val MAE: 530.5683\n",
      "Epoch 2900, Train Loss: 1634328.6250, Val MSE: 1423795.5000, Val MAE: 528.5429\n",
      "Epoch 2910, Train Loss: 1630559.3750, Val MSE: 1415325.1250, Val MAE: 527.1725\n",
      "Epoch 2920, Train Loss: 1652916.0000, Val MSE: 1429855.7500, Val MAE: 534.9592\n",
      "Epoch 2930, Train Loss: 1657268.0000, Val MSE: 1434706.2500, Val MAE: 537.7107\n",
      "Epoch 2940, Train Loss: 1668470.8750, Val MSE: 1418802.7500, Val MAE: 528.5396\n",
      "Epoch 2950, Train Loss: 1633491.7500, Val MSE: 1434467.3750, Val MAE: 534.2603\n",
      "Epoch 2960, Train Loss: 1649484.3750, Val MSE: 1417542.1250, Val MAE: 530.0527\n",
      "Epoch 2970, Train Loss: 1632274.1250, Val MSE: 1428033.7500, Val MAE: 539.4609\n",
      "Epoch 2980, Train Loss: 1666111.6250, Val MSE: 1420713.7500, Val MAE: 532.4924\n",
      "Epoch 2990, Train Loss: 1629124.8750, Val MSE: 1423087.6250, Val MAE: 531.3002\n",
      "Epoch 3000, Train Loss: 1609261.7500, Val MSE: 1419682.6250, Val MAE: 528.5217\n",
      "Epoch 3010, Train Loss: 1632432.2500, Val MSE: 1417560.2500, Val MAE: 527.6491\n",
      "Epoch 3020, Train Loss: 1622024.8750, Val MSE: 1430839.5000, Val MAE: 538.4462\n",
      "Epoch 3030, Train Loss: 1635912.2500, Val MSE: 1422111.1250, Val MAE: 529.4564\n",
      "Epoch 3040, Train Loss: 1616928.2500, Val MSE: 1431505.7500, Val MAE: 532.6605\n",
      "Epoch 3050, Train Loss: 1640395.3750, Val MSE: 1443022.0000, Val MAE: 540.6231\n",
      "Early stopping triggered at epoch 3050\n",
      "\n",
      " Best Val MAE: 526.7489 at epoch 2850\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd1, best_mae1, best_epoch1 = train_widedeep(model_wd1, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4aa4e713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1635457.1250, Val MSE: 1415179.1250, Val MAE: 525.4807\n",
      "Epoch 20, Train Loss: 1611024.6250, Val MSE: 1416935.5000, Val MAE: 525.6226\n",
      "Epoch 30, Train Loss: 1639264.8750, Val MSE: 1418170.3750, Val MAE: 524.9588\n",
      "Epoch 40, Train Loss: 1611973.6250, Val MSE: 1416203.6250, Val MAE: 525.2457\n",
      "Epoch 50, Train Loss: 1636460.8750, Val MSE: 1418749.8750, Val MAE: 526.0590\n",
      "Epoch 60, Train Loss: 1633196.6250, Val MSE: 1424082.6250, Val MAE: 529.8342\n",
      "Epoch 70, Train Loss: 1630365.8750, Val MSE: 1422330.6250, Val MAE: 527.3016\n",
      "Epoch 80, Train Loss: 1644329.0000, Val MSE: 1419943.2500, Val MAE: 526.7445\n",
      "Epoch 90, Train Loss: 1624146.2500, Val MSE: 1422862.0000, Val MAE: 528.3201\n",
      "Epoch 100, Train Loss: 1631389.2500, Val MSE: 1418801.5000, Val MAE: 527.1650\n",
      "Epoch 110, Train Loss: 1625355.5000, Val MSE: 1418742.1250, Val MAE: 525.8813\n",
      "Epoch 120, Train Loss: 1638322.6250, Val MSE: 1422979.3750, Val MAE: 528.6704\n",
      "Epoch 130, Train Loss: 1637380.1250, Val MSE: 1421429.1250, Val MAE: 528.0191\n",
      "Epoch 140, Train Loss: 1618745.1250, Val MSE: 1417278.0000, Val MAE: 525.5805\n",
      "Epoch 150, Train Loss: 1589007.2500, Val MSE: 1419647.2500, Val MAE: 526.9164\n",
      "Epoch 160, Train Loss: 1636542.2500, Val MSE: 1417670.7500, Val MAE: 526.1216\n",
      "Epoch 170, Train Loss: 1623468.7500, Val MSE: 1420128.6250, Val MAE: 526.5159\n",
      "Epoch 180, Train Loss: 1660230.1250, Val MSE: 1423567.6250, Val MAE: 528.9500\n",
      "Epoch 190, Train Loss: 1608389.2500, Val MSE: 1423684.3750, Val MAE: 528.1254\n",
      "Epoch 200, Train Loss: 1576490.0000, Val MSE: 1423814.8750, Val MAE: 527.5060\n",
      "Epoch 210, Train Loss: 1626502.1250, Val MSE: 1420635.8750, Val MAE: 525.7456\n",
      "Epoch 220, Train Loss: 1637524.0000, Val MSE: 1418229.6250, Val MAE: 525.0548\n",
      "Epoch 230, Train Loss: 1614510.2500, Val MSE: 1423644.3750, Val MAE: 527.6295\n",
      "Early stopping triggered at epoch 230\n",
      "\n",
      " Best Val MAE: 524.9588 at epoch 30\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd1, best_mae1, best_epoch1 = train_widedeep(model_wd1, X_train3, y_train3, X_val3, y_val3, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "95de3a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of wd1: 20404\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_wd1.parameters())\n",
    "print(f\"Total Parameters of wd1: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9e46c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wd1_nodrop = WideDeep(feature_columns=feature_columns, hidden_units=[128, 64])\n",
    "print(model_wd1_nodrop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bfc754ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 95997008.0000, Val MSE: 97058088.0000, Val MAE: 6194.7407\n",
      "Epoch 20, Train Loss: 90356680.0000, Val MSE: 90355704.0000, Val MAE: 5796.8975\n",
      "Epoch 30, Train Loss: 68954248.0000, Val MSE: 66671568.0000, Val MAE: 4389.8730\n",
      "Epoch 40, Train Loss: 38783204.0000, Val MSE: 38731536.0000, Val MAE: 4072.3005\n",
      "Epoch 50, Train Loss: 32251596.0000, Val MSE: 31462438.0000, Val MAE: 3730.0579\n",
      "Epoch 60, Train Loss: 25132842.0000, Val MSE: 25216786.0000, Val MAE: 2764.1189\n",
      "Epoch 70, Train Loss: 19771150.0000, Val MSE: 19856198.0000, Val MAE: 2596.1218\n",
      "Epoch 80, Train Loss: 16264573.0000, Val MSE: 16346772.0000, Val MAE: 2308.7495\n",
      "Epoch 90, Train Loss: 13704961.0000, Val MSE: 13873025.0000, Val MAE: 2047.6301\n",
      "Epoch 100, Train Loss: 11970539.0000, Val MSE: 12153305.0000, Val MAE: 1975.7126\n",
      "Epoch 110, Train Loss: 10826600.0000, Val MSE: 11021977.0000, Val MAE: 1888.9070\n",
      "Epoch 120, Train Loss: 10025091.0000, Val MSE: 10220716.0000, Val MAE: 1833.5134\n",
      "Epoch 130, Train Loss: 9387365.0000, Val MSE: 9579888.0000, Val MAE: 1777.9153\n",
      "Epoch 140, Train Loss: 8827277.0000, Val MSE: 9018307.0000, Val MAE: 1705.0538\n",
      "Epoch 150, Train Loss: 8311469.0000, Val MSE: 8499194.0000, Val MAE: 1628.0258\n",
      "Epoch 160, Train Loss: 7831674.5000, Val MSE: 8016736.5000, Val MAE: 1545.5559\n",
      "Epoch 170, Train Loss: 7389562.5000, Val MSE: 7571219.0000, Val MAE: 1467.1488\n",
      "Epoch 180, Train Loss: 6982783.0000, Val MSE: 7160834.5000, Val MAE: 1394.0526\n",
      "Epoch 190, Train Loss: 6608713.0000, Val MSE: 6783114.0000, Val MAE: 1326.5090\n",
      "Epoch 200, Train Loss: 6272975.5000, Val MSE: 6444181.5000, Val MAE: 1266.4637\n",
      "Epoch 210, Train Loss: 5981032.5000, Val MSE: 6148614.5000, Val MAE: 1217.2462\n",
      "Epoch 220, Train Loss: 5733172.5000, Val MSE: 5894478.0000, Val MAE: 1179.9880\n",
      "Epoch 230, Train Loss: 5523212.5000, Val MSE: 5675257.0000, Val MAE: 1152.4846\n",
      "Epoch 240, Train Loss: 5342181.0000, Val MSE: 5483911.0000, Val MAE: 1130.0990\n",
      "Epoch 250, Train Loss: 5183889.5000, Val MSE: 5315960.0000, Val MAE: 1110.8184\n",
      "Epoch 260, Train Loss: 5043839.5000, Val MSE: 5167333.0000, Val MAE: 1093.4615\n",
      "Epoch 270, Train Loss: 4918150.0000, Val MSE: 5034618.5000, Val MAE: 1077.7479\n",
      "Epoch 280, Train Loss: 4803955.0000, Val MSE: 4914679.5000, Val MAE: 1063.4082\n",
      "Epoch 290, Train Loss: 4698823.5000, Val MSE: 4804624.0000, Val MAE: 1049.3547\n",
      "Epoch 300, Train Loss: 4601544.0000, Val MSE: 4703101.0000, Val MAE: 1036.4965\n",
      "Epoch 310, Train Loss: 4511385.0000, Val MSE: 4608390.0000, Val MAE: 1024.2312\n",
      "Epoch 320, Train Loss: 4427413.0000, Val MSE: 4519918.5000, Val MAE: 1012.5877\n",
      "Epoch 330, Train Loss: 4348632.0000, Val MSE: 4436933.0000, Val MAE: 1001.1722\n",
      "Epoch 340, Train Loss: 4274434.5000, Val MSE: 4358841.0000, Val MAE: 990.6462\n",
      "Epoch 350, Train Loss: 4203946.0000, Val MSE: 4284985.5000, Val MAE: 980.3799\n",
      "Epoch 360, Train Loss: 4136454.0000, Val MSE: 4214531.5000, Val MAE: 970.1750\n",
      "Epoch 370, Train Loss: 4071478.7500, Val MSE: 4147036.7500, Val MAE: 960.2036\n",
      "Epoch 380, Train Loss: 4008396.2500, Val MSE: 4081793.2500, Val MAE: 950.3080\n",
      "Epoch 390, Train Loss: 3946509.2500, Val MSE: 4018485.7500, Val MAE: 940.9286\n",
      "Epoch 400, Train Loss: 3884609.7500, Val MSE: 3954772.5000, Val MAE: 931.5458\n",
      "Epoch 410, Train Loss: 3821885.7500, Val MSE: 3889228.0000, Val MAE: 921.8865\n",
      "Epoch 420, Train Loss: 3755562.0000, Val MSE: 3818461.2500, Val MAE: 912.0915\n",
      "Epoch 430, Train Loss: 3677895.5000, Val MSE: 3734073.2500, Val MAE: 901.9930\n",
      "Epoch 440, Train Loss: 3581120.7500, Val MSE: 3626284.0000, Val MAE: 890.6000\n",
      "Epoch 450, Train Loss: 3476813.5000, Val MSE: 3516189.5000, Val MAE: 877.3838\n",
      "Epoch 460, Train Loss: 3372221.0000, Val MSE: 3406229.7500, Val MAE: 865.4984\n",
      "Epoch 470, Train Loss: 3274101.5000, Val MSE: 3306561.2500, Val MAE: 851.6417\n",
      "Epoch 480, Train Loss: 3184880.0000, Val MSE: 3215334.5000, Val MAE: 839.6193\n",
      "Epoch 490, Train Loss: 3099823.7500, Val MSE: 3130183.7500, Val MAE: 828.1718\n",
      "Epoch 500, Train Loss: 3018389.0000, Val MSE: 3046881.5000, Val MAE: 817.7819\n",
      "Epoch 510, Train Loss: 2940273.7500, Val MSE: 2964557.7500, Val MAE: 808.1961\n",
      "Epoch 520, Train Loss: 2865899.7500, Val MSE: 2885650.0000, Val MAE: 799.3590\n",
      "Epoch 530, Train Loss: 2794062.0000, Val MSE: 2809527.7500, Val MAE: 791.0158\n",
      "Epoch 540, Train Loss: 2725107.5000, Val MSE: 2737227.5000, Val MAE: 782.9321\n",
      "Epoch 550, Train Loss: 2658691.5000, Val MSE: 2667951.5000, Val MAE: 774.9205\n",
      "Epoch 560, Train Loss: 2594588.2500, Val MSE: 2602653.0000, Val MAE: 767.3812\n",
      "Epoch 570, Train Loss: 2533676.5000, Val MSE: 2540913.7500, Val MAE: 760.5324\n",
      "Epoch 580, Train Loss: 2475142.0000, Val MSE: 2481675.2500, Val MAE: 753.5505\n",
      "Epoch 590, Train Loss: 2418304.5000, Val MSE: 2425073.2500, Val MAE: 746.7202\n",
      "Epoch 600, Train Loss: 2361979.2500, Val MSE: 2370889.5000, Val MAE: 740.2484\n",
      "Epoch 610, Train Loss: 2305386.2500, Val MSE: 2317976.0000, Val MAE: 733.5079\n",
      "Epoch 620, Train Loss: 2249141.5000, Val MSE: 2263830.5000, Val MAE: 727.0674\n",
      "Epoch 630, Train Loss: 2193906.7500, Val MSE: 2213307.2500, Val MAE: 720.4159\n",
      "Epoch 640, Train Loss: 2140922.7500, Val MSE: 2166751.7500, Val MAE: 714.3651\n",
      "Epoch 650, Train Loss: 2090304.5000, Val MSE: 2122087.5000, Val MAE: 708.5029\n",
      "Epoch 660, Train Loss: 2041630.8750, Val MSE: 2079036.2500, Val MAE: 702.4175\n",
      "Epoch 670, Train Loss: 1996504.0000, Val MSE: 2039055.3750, Val MAE: 696.8890\n",
      "Epoch 680, Train Loss: 1955054.1250, Val MSE: 2003193.2500, Val MAE: 691.1877\n",
      "Epoch 690, Train Loss: 1917218.1250, Val MSE: 1970013.3750, Val MAE: 685.6399\n",
      "Epoch 700, Train Loss: 1882503.6250, Val MSE: 1938957.7500, Val MAE: 680.0546\n",
      "Epoch 710, Train Loss: 1850944.8750, Val MSE: 1911180.8750, Val MAE: 676.2448\n",
      "Epoch 720, Train Loss: 1822048.1250, Val MSE: 1886344.7500, Val MAE: 670.9035\n",
      "Epoch 730, Train Loss: 1795052.6250, Val MSE: 1863633.6250, Val MAE: 668.1174\n",
      "Epoch 740, Train Loss: 1769279.3750, Val MSE: 1840861.0000, Val MAE: 663.8649\n",
      "Epoch 750, Train Loss: 1746411.1250, Val MSE: 1820798.1250, Val MAE: 660.2433\n",
      "Epoch 760, Train Loss: 1725117.0000, Val MSE: 1801889.1250, Val MAE: 657.1235\n",
      "Epoch 770, Train Loss: 1705483.1250, Val MSE: 1784829.5000, Val MAE: 653.8862\n",
      "Epoch 780, Train Loss: 1687040.8750, Val MSE: 1769204.0000, Val MAE: 651.4315\n",
      "Epoch 790, Train Loss: 1669550.5000, Val MSE: 1754611.3750, Val MAE: 648.6922\n",
      "Epoch 800, Train Loss: 1653207.2500, Val MSE: 1741200.1250, Val MAE: 646.3764\n",
      "Epoch 810, Train Loss: 1637538.2500, Val MSE: 1728540.8750, Val MAE: 643.3387\n",
      "Epoch 820, Train Loss: 1623332.0000, Val MSE: 1717003.2500, Val MAE: 640.2990\n",
      "Epoch 830, Train Loss: 1610060.2500, Val MSE: 1706192.6250, Val MAE: 637.8437\n",
      "Epoch 840, Train Loss: 1596896.1250, Val MSE: 1694622.2500, Val MAE: 636.6422\n",
      "Epoch 850, Train Loss: 1584548.2500, Val MSE: 1683980.6250, Val MAE: 633.7479\n",
      "Epoch 860, Train Loss: 1573194.5000, Val MSE: 1674331.3750, Val MAE: 630.8856\n",
      "Epoch 870, Train Loss: 1561677.0000, Val MSE: 1664262.7500, Val MAE: 629.7003\n",
      "Epoch 880, Train Loss: 1550719.7500, Val MSE: 1655479.1250, Val MAE: 626.8642\n",
      "Epoch 890, Train Loss: 1540248.2500, Val MSE: 1647304.2500, Val MAE: 624.5665\n",
      "Epoch 900, Train Loss: 1529581.6250, Val MSE: 1639386.2500, Val MAE: 622.5723\n",
      "Epoch 910, Train Loss: 1520205.7500, Val MSE: 1631476.0000, Val MAE: 620.6868\n",
      "Epoch 920, Train Loss: 1510374.0000, Val MSE: 1624534.5000, Val MAE: 618.4136\n",
      "Epoch 930, Train Loss: 1499964.6250, Val MSE: 1615168.5000, Val MAE: 616.6235\n",
      "Epoch 940, Train Loss: 1490566.7500, Val MSE: 1607476.1250, Val MAE: 615.1021\n",
      "Epoch 950, Train Loss: 1481327.6250, Val MSE: 1600394.1250, Val MAE: 612.5620\n",
      "Epoch 960, Train Loss: 1472124.3750, Val MSE: 1593238.6250, Val MAE: 611.0358\n",
      "Epoch 970, Train Loss: 1464342.6250, Val MSE: 1587240.0000, Val MAE: 610.2607\n",
      "Epoch 980, Train Loss: 1455251.3750, Val MSE: 1581542.6250, Val MAE: 606.9809\n",
      "Epoch 990, Train Loss: 1446564.0000, Val MSE: 1574660.8750, Val MAE: 605.6509\n",
      "Epoch 1000, Train Loss: 1439117.1250, Val MSE: 1569197.1250, Val MAE: 604.4459\n",
      "Epoch 1010, Train Loss: 1432242.3750, Val MSE: 1566183.3750, Val MAE: 602.3198\n",
      "Epoch 1020, Train Loss: 1423627.2500, Val MSE: 1559069.6250, Val MAE: 601.6622\n",
      "Epoch 1030, Train Loss: 1416066.8750, Val MSE: 1553742.5000, Val MAE: 598.9985\n",
      "Epoch 1040, Train Loss: 1409568.8750, Val MSE: 1549381.5000, Val MAE: 597.3658\n",
      "Epoch 1050, Train Loss: 1402359.6250, Val MSE: 1544731.0000, Val MAE: 596.9189\n",
      "Epoch 1060, Train Loss: 1396572.2500, Val MSE: 1540150.5000, Val MAE: 595.6132\n",
      "Epoch 1070, Train Loss: 1389712.6250, Val MSE: 1536320.2500, Val MAE: 593.0430\n",
      "Epoch 1080, Train Loss: 1382764.7500, Val MSE: 1531802.3750, Val MAE: 592.9572\n",
      "Epoch 1090, Train Loss: 1376180.6250, Val MSE: 1526742.5000, Val MAE: 590.5564\n",
      "Epoch 1100, Train Loss: 1370498.5000, Val MSE: 1523845.2500, Val MAE: 588.6740\n",
      "Epoch 1110, Train Loss: 1363320.0000, Val MSE: 1518649.5000, Val MAE: 587.6163\n",
      "Epoch 1120, Train Loss: 1360910.0000, Val MSE: 1517746.3750, Val MAE: 589.1129\n",
      "Epoch 1130, Train Loss: 1352566.8750, Val MSE: 1512888.2500, Val MAE: 584.7463\n",
      "Epoch 1140, Train Loss: 1345414.7500, Val MSE: 1507309.6250, Val MAE: 583.8062\n",
      "Epoch 1150, Train Loss: 1340585.2500, Val MSE: 1504203.2500, Val MAE: 583.0332\n",
      "Epoch 1160, Train Loss: 1333902.1250, Val MSE: 1500253.3750, Val MAE: 580.4875\n",
      "Epoch 1170, Train Loss: 1331611.2500, Val MSE: 1499719.0000, Val MAE: 580.2732\n",
      "Epoch 1180, Train Loss: 1324286.5000, Val MSE: 1493840.0000, Val MAE: 579.8078\n",
      "Epoch 1190, Train Loss: 1317514.1250, Val MSE: 1489042.3750, Val MAE: 576.5803\n",
      "Epoch 1200, Train Loss: 1314480.7500, Val MSE: 1487043.6250, Val MAE: 575.8617\n",
      "Epoch 1210, Train Loss: 1308136.8750, Val MSE: 1482557.0000, Val MAE: 575.4626\n",
      "Epoch 1220, Train Loss: 1303284.3750, Val MSE: 1478584.8750, Val MAE: 573.6354\n",
      "Epoch 1230, Train Loss: 1298820.2500, Val MSE: 1477018.1250, Val MAE: 572.2791\n",
      "Epoch 1240, Train Loss: 1293810.2500, Val MSE: 1471681.1250, Val MAE: 570.4026\n",
      "Epoch 1250, Train Loss: 1289523.6250, Val MSE: 1469040.2500, Val MAE: 570.3839\n",
      "Epoch 1260, Train Loss: 1285047.7500, Val MSE: 1466700.3750, Val MAE: 568.8173\n",
      "Epoch 1270, Train Loss: 1278790.7500, Val MSE: 1461043.1250, Val MAE: 567.0726\n",
      "Epoch 1280, Train Loss: 1277402.0000, Val MSE: 1460368.7500, Val MAE: 568.3768\n",
      "Epoch 1290, Train Loss: 1269974.3750, Val MSE: 1454982.7500, Val MAE: 564.6172\n",
      "Epoch 1300, Train Loss: 1266472.6250, Val MSE: 1451964.2500, Val MAE: 563.6234\n",
      "Epoch 1310, Train Loss: 1261544.5000, Val MSE: 1449138.3750, Val MAE: 564.1152\n",
      "Epoch 1320, Train Loss: 1255124.7500, Val MSE: 1443713.1250, Val MAE: 561.0608\n",
      "Epoch 1330, Train Loss: 1252995.8750, Val MSE: 1443017.7500, Val MAE: 560.9622\n",
      "Epoch 1340, Train Loss: 1247409.3750, Val MSE: 1439516.2500, Val MAE: 560.8722\n",
      "Epoch 1350, Train Loss: 1241807.3750, Val MSE: 1434566.8750, Val MAE: 558.2187\n",
      "Epoch 1360, Train Loss: 1240462.1250, Val MSE: 1434611.2500, Val MAE: 558.4091\n",
      "Epoch 1370, Train Loss: 1233830.7500, Val MSE: 1429336.3750, Val MAE: 556.7780\n",
      "Epoch 1380, Train Loss: 1231178.1250, Val MSE: 1426609.0000, Val MAE: 556.0146\n",
      "Epoch 1390, Train Loss: 1227667.8750, Val MSE: 1426104.5000, Val MAE: 555.3736\n",
      "Epoch 1400, Train Loss: 1221842.2500, Val MSE: 1420860.7500, Val MAE: 553.3625\n",
      "Epoch 1410, Train Loss: 1220231.6250, Val MSE: 1420313.0000, Val MAE: 553.7733\n",
      "Epoch 1420, Train Loss: 1215355.1250, Val MSE: 1418282.3750, Val MAE: 552.1533\n",
      "Epoch 1430, Train Loss: 1212496.1250, Val MSE: 1415440.8750, Val MAE: 550.9781\n",
      "Epoch 1440, Train Loss: 1210529.7500, Val MSE: 1416591.2500, Val MAE: 552.4205\n",
      "Epoch 1450, Train Loss: 1204792.0000, Val MSE: 1413534.7500, Val MAE: 549.8706\n",
      "Epoch 1460, Train Loss: 1200903.7500, Val MSE: 1410512.5000, Val MAE: 548.6967\n",
      "Epoch 1470, Train Loss: 1200216.3750, Val MSE: 1412459.7500, Val MAE: 550.6213\n",
      "Epoch 1480, Train Loss: 1193977.7500, Val MSE: 1408350.7500, Val MAE: 547.4842\n",
      "Epoch 1490, Train Loss: 1192292.5000, Val MSE: 1407229.6250, Val MAE: 546.9478\n",
      "Epoch 1500, Train Loss: 1190027.3750, Val MSE: 1408135.2500, Val MAE: 548.3067\n",
      "Epoch 1510, Train Loss: 1184439.2500, Val MSE: 1404432.2500, Val MAE: 545.4852\n",
      "Epoch 1520, Train Loss: 1184830.1250, Val MSE: 1405831.5000, Val MAE: 546.0995\n",
      "Epoch 1530, Train Loss: 1179272.1250, Val MSE: 1403291.5000, Val MAE: 545.6505\n",
      "Epoch 1540, Train Loss: 1176774.3750, Val MSE: 1400727.3750, Val MAE: 544.2516\n",
      "Epoch 1550, Train Loss: 1175732.5000, Val MSE: 1402093.7500, Val MAE: 544.5047\n",
      "Epoch 1560, Train Loss: 1169736.8750, Val MSE: 1398450.1250, Val MAE: 543.2871\n",
      "Epoch 1570, Train Loss: 1168043.5000, Val MSE: 1397313.1250, Val MAE: 543.0753\n",
      "Epoch 1580, Train Loss: 1165493.2500, Val MSE: 1397523.0000, Val MAE: 542.5220\n",
      "Epoch 1590, Train Loss: 1160671.3750, Val MSE: 1394076.7500, Val MAE: 541.1631\n",
      "Epoch 1600, Train Loss: 1161522.0000, Val MSE: 1396322.0000, Val MAE: 543.3748\n",
      "Epoch 1610, Train Loss: 1155970.1250, Val MSE: 1392973.2500, Val MAE: 540.3602\n",
      "Epoch 1620, Train Loss: 1152667.5000, Val MSE: 1390387.0000, Val MAE: 539.3440\n",
      "Epoch 1630, Train Loss: 1152248.2500, Val MSE: 1392673.1250, Val MAE: 541.2035\n",
      "Epoch 1640, Train Loss: 1146748.6250, Val MSE: 1388772.6250, Val MAE: 538.3950\n",
      "Epoch 1650, Train Loss: 1148033.2500, Val MSE: 1391444.6250, Val MAE: 539.6288\n",
      "Epoch 1660, Train Loss: 1141506.8750, Val MSE: 1387686.2500, Val MAE: 537.8799\n",
      "Epoch 1670, Train Loss: 1142008.8750, Val MSE: 1389094.6250, Val MAE: 539.1360\n",
      "Epoch 1680, Train Loss: 1137365.5000, Val MSE: 1386968.2500, Val MAE: 536.9909\n",
      "Epoch 1690, Train Loss: 1136332.3750, Val MSE: 1386576.8750, Val MAE: 536.6140\n",
      "Epoch 1700, Train Loss: 1133701.8750, Val MSE: 1388286.3750, Val MAE: 538.1589\n",
      "Epoch 1710, Train Loss: 1129622.3750, Val MSE: 1384751.7500, Val MAE: 535.5800\n",
      "Epoch 1720, Train Loss: 1130687.5000, Val MSE: 1387187.2500, Val MAE: 536.3033\n",
      "Epoch 1730, Train Loss: 1125517.2500, Val MSE: 1386103.8750, Val MAE: 536.2914\n",
      "Epoch 1740, Train Loss: 1122709.7500, Val MSE: 1383736.6250, Val MAE: 534.7617\n",
      "Epoch 1750, Train Loss: 1122384.2500, Val MSE: 1385641.3750, Val MAE: 535.2489\n",
      "Epoch 1760, Train Loss: 1117173.5000, Val MSE: 1382491.7500, Val MAE: 533.8019\n",
      "Epoch 1770, Train Loss: 1118859.6250, Val MSE: 1386869.7500, Val MAE: 536.6456\n",
      "Epoch 1780, Train Loss: 1112498.7500, Val MSE: 1381908.2500, Val MAE: 533.1414\n",
      "Epoch 1790, Train Loss: 1114323.1250, Val MSE: 1384192.3750, Val MAE: 533.8428\n",
      "Epoch 1800, Train Loss: 1109999.8750, Val MSE: 1385029.5000, Val MAE: 534.7178\n",
      "Epoch 1810, Train Loss: 1105836.7500, Val MSE: 1381633.6250, Val MAE: 532.3455\n",
      "Epoch 1820, Train Loss: 1107127.8750, Val MSE: 1384232.5000, Val MAE: 533.2120\n",
      "Epoch 1830, Train Loss: 1101552.5000, Val MSE: 1382000.5000, Val MAE: 532.2441\n",
      "Epoch 1840, Train Loss: 1103097.8750, Val MSE: 1384500.5000, Val MAE: 533.7040\n",
      "Epoch 1850, Train Loss: 1098958.1250, Val MSE: 1382481.2500, Val MAE: 531.7284\n",
      "Epoch 1860, Train Loss: 1095810.2500, Val MSE: 1380255.7500, Val MAE: 530.6678\n",
      "Epoch 1870, Train Loss: 1098022.0000, Val MSE: 1386173.1250, Val MAE: 534.4490\n",
      "Epoch 1880, Train Loss: 1091405.8750, Val MSE: 1380328.0000, Val MAE: 530.1779\n",
      "Epoch 1890, Train Loss: 1091604.6250, Val MSE: 1380899.5000, Val MAE: 530.2412\n",
      "Epoch 1900, Train Loss: 1089728.0000, Val MSE: 1383903.8750, Val MAE: 532.3250\n",
      "Epoch 1910, Train Loss: 1085391.3750, Val MSE: 1379529.5000, Val MAE: 529.2261\n",
      "Epoch 1920, Train Loss: 1086646.2500, Val MSE: 1380950.0000, Val MAE: 529.7007\n",
      "Epoch 1930, Train Loss: 1082352.6250, Val MSE: 1381118.2500, Val MAE: 530.0270\n",
      "Epoch 1940, Train Loss: 1081800.5000, Val MSE: 1380698.3750, Val MAE: 529.7050\n",
      "Epoch 1950, Train Loss: 1080712.8750, Val MSE: 1380860.8750, Val MAE: 529.2521\n",
      "Epoch 1960, Train Loss: 1075987.2500, Val MSE: 1378679.7500, Val MAE: 528.1840\n",
      "Epoch 1970, Train Loss: 1077757.6250, Val MSE: 1381104.5000, Val MAE: 529.9933\n",
      "Epoch 1980, Train Loss: 1074534.8750, Val MSE: 1379938.3750, Val MAE: 528.3688\n",
      "Epoch 1990, Train Loss: 1069979.8750, Val MSE: 1378396.6250, Val MAE: 527.5129\n",
      "Epoch 2000, Train Loss: 1071811.8750, Val MSE: 1381456.0000, Val MAE: 529.5323\n",
      "Epoch 2010, Train Loss: 1067725.1250, Val MSE: 1379369.8750, Val MAE: 527.2871\n",
      "Epoch 2020, Train Loss: 1065327.1250, Val MSE: 1378444.0000, Val MAE: 526.5508\n",
      "Epoch 2030, Train Loss: 1066334.3750, Val MSE: 1383622.3750, Val MAE: 529.5603\n",
      "Epoch 2040, Train Loss: 1060851.6250, Val MSE: 1378611.8750, Val MAE: 526.1258\n",
      "Epoch 2050, Train Loss: 1064659.5000, Val MSE: 1383012.1250, Val MAE: 527.6918\n",
      "Epoch 2060, Train Loss: 1057821.6250, Val MSE: 1379938.2500, Val MAE: 526.9592\n",
      "Epoch 2070, Train Loss: 1058850.2500, Val MSE: 1381298.6250, Val MAE: 527.6018\n",
      "Epoch 2080, Train Loss: 1056711.8750, Val MSE: 1380654.0000, Val MAE: 526.3321\n",
      "Epoch 2090, Train Loss: 1052842.6250, Val MSE: 1378408.8750, Val MAE: 525.3177\n",
      "Epoch 2100, Train Loss: 1055282.8750, Val MSE: 1384422.3750, Val MAE: 528.8010\n",
      "Epoch 2110, Train Loss: 1049360.7500, Val MSE: 1378377.3750, Val MAE: 524.9410\n",
      "Epoch 2120, Train Loss: 1051687.1250, Val MSE: 1380272.8750, Val MAE: 525.5114\n",
      "Epoch 2130, Train Loss: 1048324.6250, Val MSE: 1381921.3750, Val MAE: 526.9927\n",
      "Epoch 2140, Train Loss: 1045410.3125, Val MSE: 1379161.6250, Val MAE: 524.8824\n",
      "Epoch 2150, Train Loss: 1047013.8750, Val MSE: 1381366.7500, Val MAE: 525.3572\n",
      "Epoch 2160, Train Loss: 1041980.3125, Val MSE: 1379820.7500, Val MAE: 524.9344\n",
      "Epoch 2170, Train Loss: 1044760.1250, Val MSE: 1383881.0000, Val MAE: 526.9083\n",
      "Epoch 2180, Train Loss: 1040254.8125, Val MSE: 1379995.1250, Val MAE: 524.2777\n",
      "Epoch 2190, Train Loss: 1038719.8750, Val MSE: 1379136.6250, Val MAE: 523.7780\n",
      "Epoch 2200, Train Loss: 1039675.2500, Val MSE: 1383582.2500, Val MAE: 526.5026\n",
      "Epoch 2210, Train Loss: 1034676.4375, Val MSE: 1378731.3750, Val MAE: 523.4868\n",
      "Epoch 2220, Train Loss: 1039287.0625, Val MSE: 1383033.3750, Val MAE: 525.2355\n",
      "Epoch 2230, Train Loss: 1033657.5625, Val MSE: 1382248.7500, Val MAE: 525.2797\n",
      "Epoch 2240, Train Loss: 1030807.0625, Val MSE: 1378694.0000, Val MAE: 523.1118\n",
      "Epoch 2250, Train Loss: 1033143.2500, Val MSE: 1380231.8750, Val MAE: 523.7484\n",
      "Epoch 2260, Train Loss: 1029261.6250, Val MSE: 1380937.6250, Val MAE: 524.4909\n",
      "Epoch 2270, Train Loss: 1027992.5625, Val MSE: 1379159.5000, Val MAE: 523.2305\n",
      "Epoch 2280, Train Loss: 1029427.3750, Val MSE: 1381029.3750, Val MAE: 523.8502\n",
      "Epoch 2290, Train Loss: 1024154.3125, Val MSE: 1379376.2500, Val MAE: 522.9917\n",
      "Epoch 2300, Train Loss: 1026690.7500, Val MSE: 1382811.5000, Val MAE: 524.8152\n",
      "Epoch 2310, Train Loss: 1023509.4375, Val MSE: 1380204.1250, Val MAE: 522.7801\n",
      "Epoch 2320, Train Loss: 1020616.1875, Val MSE: 1378420.6250, Val MAE: 521.8892\n",
      "Epoch 2330, Train Loss: 1023409.2500, Val MSE: 1384706.6250, Val MAE: 525.2654\n",
      "Epoch 2340, Train Loss: 1017922.5000, Val MSE: 1378938.6250, Val MAE: 521.6700\n",
      "Epoch 2350, Train Loss: 1021397.1875, Val MSE: 1381105.1250, Val MAE: 522.5015\n",
      "Epoch 2360, Train Loss: 1018603.6250, Val MSE: 1384231.7500, Val MAE: 524.4459\n",
      "Epoch 2370, Train Loss: 1014181.6250, Val MSE: 1378885.8750, Val MAE: 521.2911\n",
      "Epoch 2380, Train Loss: 1016618.3750, Val MSE: 1380822.8750, Val MAE: 521.8707\n",
      "Epoch 2390, Train Loss: 1012810.1875, Val MSE: 1381524.1250, Val MAE: 522.5197\n",
      "Epoch 2400, Train Loss: 1013122.5000, Val MSE: 1381456.6250, Val MAE: 522.2807\n",
      "Epoch 2410, Train Loss: 1012950.8750, Val MSE: 1381885.8750, Val MAE: 521.8569\n",
      "Epoch 2420, Train Loss: 1008326.2500, Val MSE: 1379409.0000, Val MAE: 520.7401\n",
      "Epoch 2430, Train Loss: 1012309.0000, Val MSE: 1386097.8750, Val MAE: 524.5306\n",
      "Epoch 2440, Train Loss: 1006125.2500, Val MSE: 1379308.1250, Val MAE: 520.3550\n",
      "Epoch 2450, Train Loss: 1008337.3125, Val MSE: 1380501.5000, Val MAE: 520.6712\n",
      "Epoch 2460, Train Loss: 1006135.4375, Val MSE: 1383492.2500, Val MAE: 522.7237\n",
      "Epoch 2470, Train Loss: 1002891.1875, Val MSE: 1379222.3750, Val MAE: 520.1770\n",
      "Epoch 2480, Train Loss: 1005953.3750, Val MSE: 1382410.8750, Val MAE: 521.2090\n",
      "Epoch 2490, Train Loss: 1000556.9375, Val MSE: 1380558.0000, Val MAE: 520.4469\n",
      "Epoch 2500, Train Loss: 1003207.4375, Val MSE: 1382788.7500, Val MAE: 521.8327\n",
      "Epoch 2510, Train Loss: 1000596.2500, Val MSE: 1380637.8750, Val MAE: 520.2294\n",
      "Epoch 2520, Train Loss: 997654.3750, Val MSE: 1378844.1250, Val MAE: 519.2211\n",
      "Epoch 2530, Train Loss: 1001442.6875, Val MSE: 1386508.6250, Val MAE: 523.3679\n",
      "Epoch 2540, Train Loss: 995257.2500, Val MSE: 1379278.7500, Val MAE: 519.0693\n",
      "Epoch 2550, Train Loss: 996984.4375, Val MSE: 1380074.6250, Val MAE: 519.3627\n",
      "Epoch 2560, Train Loss: 995353.4375, Val MSE: 1383705.3750, Val MAE: 521.2795\n",
      "Epoch 2570, Train Loss: 993217.3750, Val MSE: 1380404.8750, Val MAE: 519.3524\n",
      "Epoch 2580, Train Loss: 995452.3125, Val MSE: 1383004.8750, Val MAE: 520.1964\n",
      "Epoch 2590, Train Loss: 990245.3125, Val MSE: 1380342.5000, Val MAE: 519.0023\n",
      "Epoch 2600, Train Loss: 992679.0625, Val MSE: 1383339.6250, Val MAE: 520.6747\n",
      "Epoch 2610, Train Loss: 989613.1250, Val MSE: 1380907.8750, Val MAE: 518.7905\n",
      "Epoch 2620, Train Loss: 990982.0625, Val MSE: 1381521.1250, Val MAE: 518.9090\n",
      "Epoch 2630, Train Loss: 990353.3125, Val MSE: 1386315.2500, Val MAE: 521.8243\n",
      "Epoch 2640, Train Loss: 985554.8125, Val MSE: 1380430.1250, Val MAE: 518.3967\n",
      "Epoch 2650, Train Loss: 989419.3750, Val MSE: 1383173.8750, Val MAE: 519.5035\n",
      "Epoch 2660, Train Loss: 985404.6250, Val MSE: 1384381.1250, Val MAE: 520.4639\n",
      "Epoch 2670, Train Loss: 984035.5000, Val MSE: 1381782.2500, Val MAE: 518.8707\n",
      "Epoch 2680, Train Loss: 986754.5625, Val MSE: 1384606.7500, Val MAE: 520.0361\n",
      "Epoch 2690, Train Loss: 981047.8125, Val MSE: 1382074.6250, Val MAE: 518.8041\n",
      "Epoch 2700, Train Loss: 983928.9375, Val MSE: 1385029.5000, Val MAE: 520.2643\n",
      "Epoch 2710, Train Loss: 981104.8125, Val MSE: 1382812.3750, Val MAE: 518.8868\n",
      "Epoch 2720, Train Loss: 979251.5625, Val MSE: 1381438.6250, Val MAE: 518.1198\n",
      "Epoch 2730, Train Loss: 982432.0625, Val MSE: 1388321.3750, Val MAE: 521.9795\n",
      "Epoch 2740, Train Loss: 976863.1875, Val MSE: 1381916.6250, Val MAE: 518.1750\n",
      "Epoch 2750, Train Loss: 978360.0625, Val MSE: 1382519.8750, Val MAE: 518.4113\n",
      "Epoch 2760, Train Loss: 978938.6250, Val MSE: 1388232.7500, Val MAE: 521.2965\n",
      "Epoch 2770, Train Loss: 973996.8125, Val MSE: 1382423.7500, Val MAE: 518.0089\n",
      "Epoch 2780, Train Loss: 977923.7500, Val MSE: 1385677.5000, Val MAE: 519.2468\n",
      "Epoch 2790, Train Loss: 973400.4375, Val MSE: 1385581.1250, Val MAE: 519.4744\n",
      "Epoch 2800, Train Loss: 974201.5000, Val MSE: 1385908.2500, Val MAE: 518.9586\n",
      "Epoch 2810, Train Loss: 974679.8750, Val MSE: 1386886.8750, Val MAE: 519.4057\n",
      "Epoch 2820, Train Loss: 969721.4375, Val MSE: 1383678.5000, Val MAE: 518.1593\n",
      "Epoch 2830, Train Loss: 973446.1250, Val MSE: 1387635.7500, Val MAE: 519.9963\n",
      "Epoch 2840, Train Loss: 970128.6250, Val MSE: 1384647.8750, Val MAE: 518.5542\n",
      "Epoch 2850, Train Loss: 968141.0625, Val MSE: 1382765.7500, Val MAE: 517.5981\n",
      "Epoch 2860, Train Loss: 971074.5625, Val MSE: 1388989.1250, Val MAE: 520.9790\n",
      "Epoch 2870, Train Loss: 965455.9375, Val MSE: 1382099.8750, Val MAE: 517.5355\n",
      "Epoch 2880, Train Loss: 969259.3125, Val MSE: 1384343.8750, Val MAE: 518.5886\n",
      "Epoch 2890, Train Loss: 965801.3125, Val MSE: 1385636.2500, Val MAE: 519.5914\n",
      "Epoch 2900, Train Loss: 963546.3750, Val MSE: 1382234.8750, Val MAE: 517.6859\n",
      "Epoch 2910, Train Loss: 966924.2500, Val MSE: 1385657.0000, Val MAE: 519.1689\n",
      "Epoch 2920, Train Loss: 961257.1875, Val MSE: 1382211.3750, Val MAE: 517.7609\n",
      "Epoch 2930, Train Loss: 964390.5000, Val MSE: 1385562.8750, Val MAE: 519.2385\n",
      "Epoch 2940, Train Loss: 962038.6250, Val MSE: 1384433.3750, Val MAE: 518.3770\n",
      "Epoch 2950, Train Loss: 959127.8125, Val MSE: 1382257.0000, Val MAE: 517.3133\n",
      "Epoch 2960, Train Loss: 963636.4375, Val MSE: 1389408.7500, Val MAE: 520.6763\n",
      "Epoch 2970, Train Loss: 957924.8750, Val MSE: 1383855.5000, Val MAE: 517.6157\n",
      "Epoch 2980, Train Loss: 958054.6250, Val MSE: 1383705.2500, Val MAE: 517.3129\n",
      "Epoch 2990, Train Loss: 960881.6250, Val MSE: 1390630.3750, Val MAE: 520.7157\n",
      "Epoch 3000, Train Loss: 955434.1875, Val MSE: 1384993.2500, Val MAE: 517.6082\n",
      "Epoch 3010, Train Loss: 955499.0000, Val MSE: 1384459.6250, Val MAE: 517.2415\n",
      "Epoch 3020, Train Loss: 958112.4375, Val MSE: 1390872.3750, Val MAE: 520.4202\n",
      "Epoch 3030, Train Loss: 952574.1250, Val MSE: 1384458.1250, Val MAE: 517.0987\n",
      "Epoch 3040, Train Loss: 955355.6250, Val MSE: 1386512.2500, Val MAE: 517.6079\n",
      "Epoch 3050, Train Loss: 953507.7500, Val MSE: 1389436.3750, Val MAE: 519.2310\n",
      "Epoch 3060, Train Loss: 950537.0625, Val MSE: 1385430.6250, Val MAE: 517.0331\n",
      "Epoch 3070, Train Loss: 954465.6250, Val MSE: 1389361.6250, Val MAE: 518.3649\n",
      "Epoch 3080, Train Loss: 948789.0000, Val MSE: 1386546.7500, Val MAE: 517.3517\n",
      "Epoch 3090, Train Loss: 953008.8125, Val MSE: 1390762.5000, Val MAE: 519.1406\n",
      "Epoch 3100, Train Loss: 950529.8125, Val MSE: 1389388.5000, Val MAE: 518.1407\n",
      "Epoch 3110, Train Loss: 946454.4375, Val MSE: 1387250.2500, Val MAE: 517.0486\n",
      "Epoch 3120, Train Loss: 949917.5000, Val MSE: 1390828.7500, Val MAE: 518.6567\n",
      "Epoch 3130, Train Loss: 948322.1250, Val MSE: 1390084.5000, Val MAE: 517.9167\n",
      "Epoch 3140, Train Loss: 944292.5000, Val MSE: 1388319.0000, Val MAE: 516.8052\n",
      "Epoch 3150, Train Loss: 948912.8125, Val MSE: 1393891.3750, Val MAE: 519.4197\n",
      "Epoch 3160, Train Loss: 945201.4375, Val MSE: 1390833.8750, Val MAE: 517.5106\n",
      "Epoch 3170, Train Loss: 942746.1875, Val MSE: 1389328.7500, Val MAE: 516.6278\n",
      "Epoch 3180, Train Loss: 946880.9375, Val MSE: 1396101.6250, Val MAE: 519.9297\n",
      "Epoch 3190, Train Loss: 941333.1250, Val MSE: 1390277.3750, Val MAE: 516.7386\n",
      "Epoch 3200, Train Loss: 943255.8125, Val MSE: 1391532.5000, Val MAE: 516.9719\n",
      "Epoch 3210, Train Loss: 941739.5000, Val MSE: 1394541.1250, Val MAE: 518.6673\n",
      "Epoch 3220, Train Loss: 939755.5625, Val MSE: 1391539.8750, Val MAE: 516.8298\n",
      "Epoch 3230, Train Loss: 943382.7500, Val MSE: 1395399.0000, Val MAE: 517.9990\n",
      "Epoch 3240, Train Loss: 937965.9375, Val MSE: 1392954.8750, Val MAE: 517.3186\n",
      "Epoch 3250, Train Loss: 940191.3125, Val MSE: 1394757.2500, Val MAE: 517.8487\n",
      "Epoch 3260, Train Loss: 939830.6250, Val MSE: 1395039.7500, Val MAE: 517.3958\n",
      "Epoch 3270, Train Loss: 935469.1875, Val MSE: 1392274.3750, Val MAE: 516.3427\n",
      "Epoch 3280, Train Loss: 941097.9375, Val MSE: 1399879.0000, Val MAE: 519.8867\n",
      "Epoch 3290, Train Loss: 935081.7500, Val MSE: 1393797.2500, Val MAE: 516.5714\n",
      "Epoch 3300, Train Loss: 935176.3750, Val MSE: 1393651.1250, Val MAE: 516.2018\n",
      "Epoch 3310, Train Loss: 937381.6250, Val MSE: 1399274.7500, Val MAE: 519.0512\n",
      "Epoch 3320, Train Loss: 932062.5625, Val MSE: 1393776.1250, Val MAE: 516.0341\n",
      "Epoch 3330, Train Loss: 936734.4375, Val MSE: 1397591.1250, Val MAE: 517.0629\n",
      "Epoch 3340, Train Loss: 932077.3125, Val MSE: 1397324.0000, Val MAE: 517.5402\n",
      "Epoch 3350, Train Loss: 931891.5000, Val MSE: 1395857.3750, Val MAE: 516.5472\n",
      "Epoch 3360, Train Loss: 934641.0000, Val MSE: 1398401.5000, Val MAE: 517.0864\n",
      "Epoch 3370, Train Loss: 929089.2500, Val MSE: 1396297.3750, Val MAE: 516.5411\n",
      "Epoch 3380, Train Loss: 931438.8750, Val MSE: 1398754.6250, Val MAE: 517.3809\n",
      "Epoch 3390, Train Loss: 928976.1250, Val MSE: 1396835.6250, Val MAE: 516.0274\n",
      "Epoch 3400, Train Loss: 929262.1250, Val MSE: 1395991.3750, Val MAE: 515.6806\n",
      "Epoch 3410, Train Loss: 931047.0000, Val MSE: 1402032.2500, Val MAE: 518.6506\n",
      "Epoch 3420, Train Loss: 925676.0000, Val MSE: 1396005.5000, Val MAE: 515.3322\n",
      "Epoch 3430, Train Loss: 928669.8750, Val MSE: 1397560.6250, Val MAE: 515.8863\n",
      "Epoch 3440, Train Loss: 925898.1250, Val MSE: 1399643.1250, Val MAE: 516.9915\n",
      "Epoch 3450, Train Loss: 925616.8750, Val MSE: 1397935.1250, Val MAE: 515.9819\n",
      "Epoch 3460, Train Loss: 927865.8750, Val MSE: 1400417.2500, Val MAE: 516.5544\n",
      "Epoch 3470, Train Loss: 922487.9375, Val MSE: 1397829.1250, Val MAE: 515.4880\n",
      "Epoch 3480, Train Loss: 926431.7500, Val MSE: 1402104.3750, Val MAE: 517.4009\n",
      "Epoch 3490, Train Loss: 922296.1250, Val MSE: 1398336.1250, Val MAE: 515.2747\n",
      "Epoch 3500, Train Loss: 924124.8750, Val MSE: 1398758.7500, Val MAE: 515.3848\n",
      "Epoch 3510, Train Loss: 924318.6875, Val MSE: 1404364.6250, Val MAE: 518.2097\n",
      "Epoch 3520, Train Loss: 919371.1875, Val MSE: 1398197.5000, Val MAE: 514.9482\n",
      "Epoch 3530, Train Loss: 924185.3750, Val MSE: 1401839.1250, Val MAE: 516.1675\n",
      "Epoch 3540, Train Loss: 918882.7500, Val MSE: 1400827.3750, Val MAE: 516.0135\n",
      "Epoch 3550, Train Loss: 921408.9375, Val MSE: 1402346.8750, Val MAE: 516.6368\n",
      "Epoch 3560, Train Loss: 920236.6250, Val MSE: 1402048.3750, Val MAE: 515.9481\n",
      "Epoch 3570, Train Loss: 916851.0000, Val MSE: 1399178.6250, Val MAE: 514.9207\n",
      "Epoch 3580, Train Loss: 921712.2500, Val MSE: 1407374.8750, Val MAE: 518.6738\n",
      "Epoch 3590, Train Loss: 915440.6250, Val MSE: 1399811.2500, Val MAE: 514.8448\n",
      "Epoch 3600, Train Loss: 920069.8125, Val MSE: 1402894.8750, Val MAE: 515.8441\n",
      "Epoch 3610, Train Loss: 916831.6250, Val MSE: 1404833.0000, Val MAE: 517.1486\n",
      "Epoch 3620, Train Loss: 914415.7500, Val MSE: 1400698.1250, Val MAE: 515.1028\n",
      "Epoch 3630, Train Loss: 918654.1250, Val MSE: 1404944.2500, Val MAE: 516.3754\n",
      "Epoch 3640, Train Loss: 912792.5625, Val MSE: 1402257.0000, Val MAE: 515.5035\n",
      "Epoch 3650, Train Loss: 915778.1875, Val MSE: 1404281.3750, Val MAE: 516.5662\n",
      "Epoch 3660, Train Loss: 915184.1875, Val MSE: 1403797.5000, Val MAE: 515.8704\n",
      "Epoch 3670, Train Loss: 911046.3750, Val MSE: 1401097.3750, Val MAE: 514.9259\n",
      "Epoch 3680, Train Loss: 915900.0000, Val MSE: 1407247.0000, Val MAE: 517.7670\n",
      "Epoch 3690, Train Loss: 911058.6875, Val MSE: 1402027.3750, Val MAE: 514.9321\n",
      "Epoch 3700, Train Loss: 911809.9375, Val MSE: 1401820.3750, Val MAE: 514.7560\n",
      "Epoch 3710, Train Loss: 914170.1875, Val MSE: 1409100.8750, Val MAE: 518.4106\n",
      "Epoch 3720, Train Loss: 908592.5000, Val MSE: 1401912.1250, Val MAE: 514.6695\n",
      "Epoch 3730, Train Loss: 910894.8750, Val MSE: 1402480.1250, Val MAE: 514.6505\n",
      "Epoch 3740, Train Loss: 910290.5000, Val MSE: 1406811.3750, Val MAE: 516.9241\n",
      "Epoch 3750, Train Loss: 907349.8125, Val MSE: 1402623.8750, Val MAE: 514.7994\n",
      "Epoch 3760, Train Loss: 910715.2500, Val MSE: 1405784.8750, Val MAE: 515.7031\n",
      "Epoch 3770, Train Loss: 905847.5625, Val MSE: 1402562.5000, Val MAE: 514.6083\n",
      "Epoch 3780, Train Loss: 911762.0000, Val MSE: 1410161.1250, Val MAE: 518.0939\n",
      "Epoch 3790, Train Loss: 905704.8750, Val MSE: 1403367.2500, Val MAE: 514.5325\n",
      "Epoch 3800, Train Loss: 907152.0000, Val MSE: 1403796.8750, Val MAE: 514.5553\n",
      "Epoch 3810, Train Loss: 907757.0625, Val MSE: 1409857.7500, Val MAE: 517.5491\n",
      "Epoch 3820, Train Loss: 903282.2500, Val MSE: 1403999.0000, Val MAE: 514.4371\n",
      "Epoch 3830, Train Loss: 907555.6250, Val MSE: 1406806.2500, Val MAE: 515.3557\n",
      "Epoch 3840, Train Loss: 902277.2500, Val MSE: 1405491.8750, Val MAE: 514.9316\n",
      "Epoch 3850, Train Loss: 908321.1250, Val MSE: 1411979.8750, Val MAE: 517.8087\n",
      "Epoch 3860, Train Loss: 903194.7500, Val MSE: 1406628.1250, Val MAE: 514.8324\n",
      "Epoch 3870, Train Loss: 901634.5000, Val MSE: 1405488.8750, Val MAE: 514.2079\n",
      "Epoch 3880, Train Loss: 906666.8125, Val MSE: 1413949.3750, Val MAE: 518.2112\n",
      "Epoch 3890, Train Loss: 900397.6250, Val MSE: 1406534.0000, Val MAE: 514.3717\n",
      "Epoch 3900, Train Loss: 902078.5625, Val MSE: 1406633.7500, Val MAE: 514.3040\n",
      "Epoch 3910, Train Loss: 902786.0000, Val MSE: 1413175.7500, Val MAE: 517.3221\n",
      "Epoch 3920, Train Loss: 898111.0625, Val MSE: 1406555.2500, Val MAE: 514.1012\n",
      "Epoch 3930, Train Loss: 903677.7500, Val MSE: 1410519.0000, Val MAE: 515.3864\n",
      "Epoch 3940, Train Loss: 897786.3125, Val MSE: 1409668.8750, Val MAE: 515.2747\n",
      "Epoch 3950, Train Loss: 900276.8750, Val MSE: 1411033.3750, Val MAE: 515.8312\n",
      "Epoch 3960, Train Loss: 899663.6875, Val MSE: 1410150.2500, Val MAE: 514.8619\n",
      "Epoch 3970, Train Loss: 895800.6875, Val MSE: 1408378.7500, Val MAE: 514.2031\n",
      "Epoch 3980, Train Loss: 900290.0625, Val MSE: 1414760.2500, Val MAE: 517.0765\n",
      "Epoch 3990, Train Loss: 894793.2500, Val MSE: 1408235.1250, Val MAE: 513.9532\n",
      "Epoch 4000, Train Loss: 901283.3750, Val MSE: 1412782.1250, Val MAE: 515.4167\n",
      "Epoch 4010, Train Loss: 894930.1875, Val MSE: 1412563.0000, Val MAE: 515.5974\n",
      "Epoch 4020, Train Loss: 895865.7500, Val MSE: 1411881.8750, Val MAE: 515.1533\n",
      "Epoch 4030, Train Loss: 897407.6875, Val MSE: 1413003.3750, Val MAE: 515.1436\n",
      "Epoch 4040, Train Loss: 892431.3750, Val MSE: 1410717.5000, Val MAE: 514.3887\n",
      "Epoch 4050, Train Loss: 897566.8750, Val MSE: 1416571.3750, Val MAE: 516.8397\n",
      "Epoch 4060, Train Loss: 893450.3125, Val MSE: 1411886.5000, Val MAE: 514.4602\n",
      "Epoch 4070, Train Loss: 892468.6250, Val MSE: 1411283.1250, Val MAE: 514.0302\n",
      "Epoch 4080, Train Loss: 894191.2500, Val MSE: 1417891.7500, Val MAE: 516.8951\n",
      "Epoch 4090, Train Loss: 891200.8125, Val MSE: 1413076.5000, Val MAE: 514.5293\n",
      "Epoch 4100, Train Loss: 895315.3125, Val MSE: 1415827.0000, Val MAE: 515.2408\n",
      "Epoch 4110, Train Loss: 889421.8750, Val MSE: 1414540.2500, Val MAE: 514.7993\n",
      "Epoch 4120, Train Loss: 895216.1250, Val MSE: 1420511.3750, Val MAE: 516.9618\n",
      "Epoch 4130, Train Loss: 890775.6875, Val MSE: 1415310.2500, Val MAE: 514.6150\n",
      "Epoch 4140, Train Loss: 888482.3125, Val MSE: 1413748.8750, Val MAE: 513.8990\n",
      "Epoch 4150, Train Loss: 893705.1875, Val MSE: 1422470.3750, Val MAE: 517.5753\n",
      "Epoch 4160, Train Loss: 887353.9375, Val MSE: 1414993.3750, Val MAE: 514.1224\n",
      "Epoch 4170, Train Loss: 889832.1250, Val MSE: 1415598.2500, Val MAE: 514.3807\n",
      "Epoch 4180, Train Loss: 888407.3750, Val MSE: 1419757.6250, Val MAE: 516.2000\n",
      "Epoch 4190, Train Loss: 886582.5000, Val MSE: 1415974.8750, Val MAE: 514.3473\n",
      "Epoch 4200, Train Loss: 890628.3750, Val MSE: 1418920.7500, Val MAE: 515.1319\n",
      "Epoch 4210, Train Loss: 884499.3750, Val MSE: 1416722.7500, Val MAE: 514.3378\n",
      "Epoch 4220, Train Loss: 889563.7500, Val MSE: 1421510.3750, Val MAE: 516.1972\n",
      "Epoch 4230, Train Loss: 886301.9375, Val MSE: 1417725.6250, Val MAE: 514.6376\n",
      "Epoch 4240, Train Loss: 883486.3125, Val MSE: 1416022.3750, Val MAE: 513.6672\n",
      "Epoch 4250, Train Loss: 888162.9375, Val MSE: 1423534.7500, Val MAE: 516.5000\n",
      "Epoch 4260, Train Loss: 882450.8750, Val MSE: 1416605.7500, Val MAE: 513.7773\n",
      "Epoch 4270, Train Loss: 886488.3750, Val MSE: 1418499.5000, Val MAE: 514.4319\n",
      "Epoch 4280, Train Loss: 882114.7500, Val MSE: 1420109.0000, Val MAE: 514.8972\n",
      "Epoch 4290, Train Loss: 884845.8750, Val MSE: 1421153.8750, Val MAE: 515.4501\n",
      "Epoch 4300, Train Loss: 883381.9375, Val MSE: 1419701.7500, Val MAE: 514.4937\n",
      "Epoch 4310, Train Loss: 880449.3125, Val MSE: 1417832.6250, Val MAE: 513.6295\n",
      "Epoch 4320, Train Loss: 884508.9375, Val MSE: 1426500.8750, Val MAE: 516.9560\n",
      "Epoch 4330, Train Loss: 878768.3125, Val MSE: 1418464.1250, Val MAE: 513.6136\n",
      "Epoch 4340, Train Loss: 884860.9375, Val MSE: 1423059.1250, Val MAE: 515.0687\n",
      "Epoch 4350, Train Loss: 878476.8750, Val MSE: 1422311.1250, Val MAE: 514.8102\n",
      "Epoch 4360, Train Loss: 881425.5000, Val MSE: 1424052.1250, Val MAE: 515.3967\n",
      "Epoch 4370, Train Loss: 880731.4375, Val MSE: 1422862.1250, Val MAE: 514.4827\n",
      "Epoch 4380, Train Loss: 876591.8750, Val MSE: 1420902.5000, Val MAE: 513.6813\n",
      "Epoch 4390, Train Loss: 881861.8750, Val MSE: 1429857.8750, Val MAE: 516.9482\n",
      "Epoch 4400, Train Loss: 875393.9375, Val MSE: 1421550.3750, Val MAE: 513.7928\n",
      "Epoch 4410, Train Loss: 881443.1875, Val MSE: 1426063.1250, Val MAE: 515.2236\n",
      "Epoch 4420, Train Loss: 875193.9375, Val MSE: 1425613.6250, Val MAE: 514.7204\n",
      "Epoch 4430, Train Loss: 879265.8750, Val MSE: 1429170.0000, Val MAE: 515.7910\n",
      "Epoch 4440, Train Loss: 877375.0000, Val MSE: 1426435.7500, Val MAE: 514.9505\n",
      "Epoch 4450, Train Loss: 873530.2500, Val MSE: 1424727.3750, Val MAE: 513.8934\n",
      "Epoch 4460, Train Loss: 878367.4375, Val MSE: 1431963.2500, Val MAE: 516.4605\n",
      "Epoch 4470, Train Loss: 872456.5000, Val MSE: 1424715.0000, Val MAE: 513.8608\n",
      "Epoch 4480, Train Loss: 878896.9375, Val MSE: 1429708.3750, Val MAE: 515.3262\n",
      "Epoch 4490, Train Loss: 872095.0625, Val MSE: 1427876.7500, Val MAE: 514.6982\n",
      "Epoch 4500, Train Loss: 876521.6250, Val MSE: 1431887.3750, Val MAE: 515.7409\n",
      "Epoch 4510, Train Loss: 874442.1875, Val MSE: 1428783.1250, Val MAE: 514.9139\n",
      "Epoch 4520, Train Loss: 870512.0625, Val MSE: 1426652.2500, Val MAE: 513.7798\n",
      "Epoch 4530, Train Loss: 876717.9375, Val MSE: 1435577.0000, Val MAE: 516.5538\n",
      "Early stopping triggered at epoch 4530\n",
      "\n",
      " Best Val MAE: 513.6136 at epoch 4330\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd1_nodrop, best_mae1, best_epoch1 = train_widedeep(model_wd1_nodrop, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a11f4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 873301.2500, Val MSE: 1426944.5000, Val MAE: 513.4662\n",
      "Epoch 20, Train Loss: 870352.6875, Val MSE: 1427025.8750, Val MAE: 513.7136\n",
      "Epoch 30, Train Loss: 869720.8125, Val MSE: 1427471.5000, Val MAE: 513.9742\n",
      "Epoch 40, Train Loss: 869758.8750, Val MSE: 1427438.2500, Val MAE: 513.8398\n",
      "Epoch 50, Train Loss: 869524.0000, Val MSE: 1426988.3750, Val MAE: 513.6301\n",
      "Epoch 60, Train Loss: 869452.6875, Val MSE: 1427069.6250, Val MAE: 513.6627\n",
      "Epoch 70, Train Loss: 869360.1250, Val MSE: 1427195.7500, Val MAE: 513.6262\n",
      "Epoch 80, Train Loss: 869275.0000, Val MSE: 1427292.5000, Val MAE: 513.6423\n",
      "Epoch 90, Train Loss: 869188.8750, Val MSE: 1427391.1250, Val MAE: 513.6407\n",
      "Epoch 100, Train Loss: 869101.1875, Val MSE: 1427438.6250, Val MAE: 513.6287\n",
      "Epoch 110, Train Loss: 869010.0000, Val MSE: 1427691.7500, Val MAE: 513.6346\n",
      "Epoch 120, Train Loss: 868915.3750, Val MSE: 1427806.0000, Val MAE: 513.6356\n",
      "Epoch 130, Train Loss: 868820.3750, Val MSE: 1427964.8750, Val MAE: 513.6506\n",
      "Epoch 140, Train Loss: 868720.8750, Val MSE: 1428102.5000, Val MAE: 513.6528\n",
      "Epoch 150, Train Loss: 868617.1875, Val MSE: 1428333.3750, Val MAE: 513.6578\n",
      "Epoch 160, Train Loss: 868513.9375, Val MSE: 1428446.8750, Val MAE: 513.6644\n",
      "Epoch 170, Train Loss: 868407.1875, Val MSE: 1428641.6250, Val MAE: 513.6793\n",
      "Epoch 180, Train Loss: 868297.5625, Val MSE: 1428807.1250, Val MAE: 513.6878\n",
      "Epoch 190, Train Loss: 868187.1875, Val MSE: 1428980.6250, Val MAE: 513.6900\n",
      "Epoch 200, Train Loss: 868073.3125, Val MSE: 1429201.5000, Val MAE: 513.7004\n",
      "Epoch 210, Train Loss: 867957.4375, Val MSE: 1429442.2500, Val MAE: 513.7047\n",
      "Early stopping triggered at epoch 210\n",
      "\n",
      " Best Val MAE: 513.4662 at epoch 10\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd1_nodrop, best_mae1, best_epoch1 = train_widedeep(model_wd1_nodrop, X_train3, y_train3, X_val3, y_val3, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d5842",
   "metadata": {},
   "source": [
    "+ 非常浅的网络不适合加dropout,限制了模型的学习能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "1226da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of wd1_nodrop: 20404\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_wd1_nodrop.parameters())\n",
    "print(f\"Total Parameters of wd1_nodrop: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5ff25fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wd2 = WideDeep(feature_columns=feature_columns, hidden_units=[256, 128, 64, 32])\n",
    "print(model_wd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "aae1691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 87772504.0000, Val MSE: 83555472.0000, Val MAE: 5348.7754\n",
      "Epoch 20, Train Loss: 29929828.0000, Val MSE: 27354996.0000, Val MAE: 3126.0063\n",
      "Epoch 30, Train Loss: 16459073.0000, Val MSE: 17250048.0000, Val MAE: 2647.4678\n",
      "Epoch 40, Train Loss: 11501067.0000, Val MSE: 11160144.0000, Val MAE: 1906.4935\n",
      "Epoch 50, Train Loss: 9659401.0000, Val MSE: 9813983.0000, Val MAE: 1799.8405\n",
      "Epoch 60, Train Loss: 8148663.5000, Val MSE: 8273738.0000, Val MAE: 1594.5004\n",
      "Epoch 70, Train Loss: 7060142.5000, Val MSE: 7131939.5000, Val MAE: 1366.4861\n",
      "Epoch 80, Train Loss: 6268679.5000, Val MSE: 6357086.0000, Val MAE: 1241.5685\n",
      "Epoch 90, Train Loss: 5645878.5000, Val MSE: 5744636.5000, Val MAE: 1170.8228\n",
      "Epoch 100, Train Loss: 5152283.5000, Val MSE: 5234112.0000, Val MAE: 1109.7485\n",
      "Epoch 110, Train Loss: 4778727.5000, Val MSE: 4840065.0000, Val MAE: 1058.9479\n",
      "Epoch 120, Train Loss: 4489932.5000, Val MSE: 4531993.5000, Val MAE: 1020.7947\n",
      "Epoch 130, Train Loss: 4245915.5000, Val MSE: 4275928.5000, Val MAE: 982.2532\n",
      "Epoch 140, Train Loss: 4013304.0000, Val MSE: 4038524.2500, Val MAE: 946.8019\n",
      "Epoch 150, Train Loss: 3751650.7500, Val MSE: 3770052.0000, Val MAE: 908.8766\n",
      "Epoch 160, Train Loss: 3440565.2500, Val MSE: 3448852.5000, Val MAE: 872.7545\n",
      "Epoch 170, Train Loss: 3120922.5000, Val MSE: 3119703.0000, Val MAE: 851.2639\n",
      "Epoch 180, Train Loss: 2858104.0000, Val MSE: 2853687.7500, Val MAE: 818.3510\n",
      "Epoch 190, Train Loss: 2638485.0000, Val MSE: 2633441.2500, Val MAE: 790.5917\n",
      "Epoch 200, Train Loss: 2469237.7500, Val MSE: 2470135.7500, Val MAE: 766.4908\n",
      "Epoch 210, Train Loss: 2334716.7500, Val MSE: 2328217.5000, Val MAE: 754.5526\n",
      "Epoch 220, Train Loss: 2227478.7500, Val MSE: 2240469.2500, Val MAE: 737.7850\n",
      "Epoch 230, Train Loss: 2163417.5000, Val MSE: 2179444.0000, Val MAE: 739.5629\n",
      "Epoch 240, Train Loss: 2092556.6250, Val MSE: 2122779.7500, Val MAE: 721.6855\n",
      "Epoch 250, Train Loss: 2033822.7500, Val MSE: 2060181.5000, Val MAE: 717.5961\n",
      "Epoch 260, Train Loss: 1980485.5000, Val MSE: 2023408.0000, Val MAE: 706.9240\n",
      "Epoch 270, Train Loss: 1933832.8750, Val MSE: 1977708.7500, Val MAE: 703.2615\n",
      "Epoch 280, Train Loss: 1906375.8750, Val MSE: 1958554.1250, Val MAE: 696.9990\n",
      "Epoch 290, Train Loss: 1867241.1250, Val MSE: 1920381.2500, Val MAE: 694.2616\n",
      "Epoch 300, Train Loss: 1825320.2500, Val MSE: 1892322.1250, Val MAE: 684.7320\n",
      "Epoch 310, Train Loss: 1853171.2500, Val MSE: 1906623.8750, Val MAE: 689.6102\n",
      "Epoch 320, Train Loss: 1777983.7500, Val MSE: 1873046.8750, Val MAE: 682.7032\n",
      "Epoch 330, Train Loss: 1735938.2500, Val MSE: 1820796.6250, Val MAE: 671.4123\n",
      "Epoch 340, Train Loss: 1710069.0000, Val MSE: 1801797.2500, Val MAE: 670.1034\n",
      "Epoch 350, Train Loss: 1681586.8750, Val MSE: 1780449.2500, Val MAE: 663.6746\n",
      "Epoch 360, Train Loss: 1656918.8750, Val MSE: 1765910.6250, Val MAE: 661.6508\n",
      "Epoch 370, Train Loss: 1633335.2500, Val MSE: 1796816.6250, Val MAE: 670.6617\n",
      "Epoch 380, Train Loss: 1625875.8750, Val MSE: 1785030.3750, Val MAE: 668.2967\n",
      "Epoch 390, Train Loss: 1605043.8750, Val MSE: 1741806.6250, Val MAE: 654.0184\n",
      "Epoch 400, Train Loss: 1575639.8750, Val MSE: 1718387.6250, Val MAE: 647.4277\n",
      "Epoch 410, Train Loss: 1549853.2500, Val MSE: 1694281.2500, Val MAE: 641.7893\n",
      "Epoch 420, Train Loss: 1531136.1250, Val MSE: 1680366.5000, Val MAE: 638.8239\n",
      "Epoch 430, Train Loss: 1526690.0000, Val MSE: 1681974.0000, Val MAE: 643.8220\n",
      "Epoch 440, Train Loss: 1509598.5000, Val MSE: 1660550.6250, Val MAE: 634.9114\n",
      "Epoch 450, Train Loss: 1519956.7500, Val MSE: 1700592.6250, Val MAE: 646.8186\n",
      "Epoch 460, Train Loss: 1475688.6250, Val MSE: 1652240.1250, Val MAE: 635.6243\n",
      "Epoch 470, Train Loss: 1455518.0000, Val MSE: 1627717.0000, Val MAE: 624.5034\n",
      "Epoch 480, Train Loss: 1477852.0000, Val MSE: 1687043.6250, Val MAE: 643.8121\n",
      "Epoch 490, Train Loss: 1429366.8750, Val MSE: 1626600.7500, Val MAE: 628.1940\n",
      "Epoch 500, Train Loss: 1405025.5000, Val MSE: 1600415.7500, Val MAE: 615.3098\n",
      "Epoch 510, Train Loss: 1448523.8750, Val MSE: 1683896.0000, Val MAE: 644.6898\n",
      "Epoch 520, Train Loss: 1411861.7500, Val MSE: 1621969.0000, Val MAE: 631.4384\n",
      "Epoch 530, Train Loss: 1378497.1250, Val MSE: 1602679.8750, Val MAE: 616.8763\n",
      "Epoch 540, Train Loss: 1353040.0000, Val MSE: 1568243.2500, Val MAE: 605.2850\n",
      "Epoch 550, Train Loss: 1407142.6250, Val MSE: 1639797.0000, Val MAE: 641.6111\n",
      "Epoch 560, Train Loss: 1380885.2500, Val MSE: 1626902.0000, Val MAE: 626.3095\n",
      "Epoch 570, Train Loss: 1354043.5000, Val MSE: 1567290.8750, Val MAE: 611.2719\n",
      "Epoch 580, Train Loss: 1333173.8750, Val MSE: 1567368.8750, Val MAE: 606.4487\n",
      "Epoch 590, Train Loss: 1295821.3750, Val MSE: 1531370.7500, Val MAE: 595.3473\n",
      "Epoch 600, Train Loss: 1456898.3750, Val MSE: 1658909.2500, Val MAE: 654.5865\n",
      "Epoch 610, Train Loss: 1289223.5000, Val MSE: 1517826.2500, Val MAE: 589.8563\n",
      "Epoch 620, Train Loss: 1274251.2500, Val MSE: 1531293.8750, Val MAE: 594.5816\n",
      "Epoch 630, Train Loss: 1260868.2500, Val MSE: 1513412.1250, Val MAE: 591.6257\n",
      "Epoch 640, Train Loss: 1266710.7500, Val MSE: 1515952.3750, Val MAE: 593.5714\n",
      "Epoch 650, Train Loss: 1247619.6250, Val MSE: 1507158.5000, Val MAE: 590.0175\n",
      "Epoch 660, Train Loss: 1280257.5000, Val MSE: 1495507.3750, Val MAE: 585.4193\n",
      "Epoch 670, Train Loss: 1225712.5000, Val MSE: 1500729.2500, Val MAE: 588.0844\n",
      "Epoch 680, Train Loss: 1220059.6250, Val MSE: 1494751.2500, Val MAE: 581.4597\n",
      "Epoch 690, Train Loss: 1204219.1250, Val MSE: 1471460.1250, Val MAE: 574.1268\n",
      "Epoch 700, Train Loss: 1273562.1250, Val MSE: 1558709.3750, Val MAE: 615.6191\n",
      "Epoch 710, Train Loss: 1239592.7500, Val MSE: 1528405.6250, Val MAE: 594.4136\n",
      "Epoch 720, Train Loss: 1223492.7500, Val MSE: 1495282.6250, Val MAE: 589.5073\n",
      "Epoch 730, Train Loss: 1187427.7500, Val MSE: 1476863.2500, Val MAE: 575.8086\n",
      "Epoch 740, Train Loss: 1181283.1250, Val MSE: 1452838.3750, Val MAE: 567.7343\n",
      "Epoch 750, Train Loss: 1227753.2500, Val MSE: 1506403.2500, Val MAE: 595.7270\n",
      "Epoch 760, Train Loss: 1169303.1250, Val MSE: 1471968.2500, Val MAE: 574.3947\n",
      "Epoch 770, Train Loss: 1159976.7500, Val MSE: 1443115.6250, Val MAE: 564.1257\n",
      "Epoch 780, Train Loss: 1214598.5000, Val MSE: 1507602.0000, Val MAE: 596.8748\n",
      "Epoch 790, Train Loss: 1150571.6250, Val MSE: 1465605.2500, Val MAE: 572.1902\n",
      "Epoch 800, Train Loss: 1131047.6250, Val MSE: 1429452.8750, Val MAE: 559.6225\n",
      "Epoch 810, Train Loss: 1201961.8750, Val MSE: 1504029.8750, Val MAE: 595.8837\n",
      "Epoch 820, Train Loss: 1138679.8750, Val MSE: 1464224.2500, Val MAE: 571.6608\n",
      "Epoch 830, Train Loss: 1111047.1250, Val MSE: 1421477.0000, Val MAE: 556.5327\n",
      "Epoch 840, Train Loss: 1190195.8750, Val MSE: 1510854.1250, Val MAE: 598.1446\n",
      "Epoch 850, Train Loss: 1139179.7500, Val MSE: 1480827.3750, Val MAE: 576.8781\n",
      "Epoch 860, Train Loss: 1106301.6250, Val MSE: 1438483.2500, Val MAE: 566.1162\n",
      "Epoch 870, Train Loss: 1108575.1250, Val MSE: 1425999.1250, Val MAE: 560.2562\n",
      "Epoch 880, Train Loss: 1104784.2500, Val MSE: 1453965.1250, Val MAE: 566.4129\n",
      "Epoch 890, Train Loss: 1080766.5000, Val MSE: 1435833.6250, Val MAE: 565.2049\n",
      "Epoch 900, Train Loss: 1099347.7500, Val MSE: 1454362.8750, Val MAE: 565.9076\n",
      "Epoch 910, Train Loss: 1085804.3750, Val MSE: 1434417.7500, Val MAE: 563.0033\n",
      "Epoch 920, Train Loss: 1065436.6250, Val MSE: 1404058.1250, Val MAE: 548.7110\n",
      "Epoch 930, Train Loss: 1122581.8750, Val MSE: 1509289.3750, Val MAE: 583.4817\n",
      "Epoch 940, Train Loss: 1119981.8750, Val MSE: 1477260.8750, Val MAE: 581.5472\n",
      "Epoch 950, Train Loss: 1091635.8750, Val MSE: 1447738.5000, Val MAE: 563.0237\n",
      "Epoch 960, Train Loss: 1072600.2500, Val MSE: 1441468.2500, Val MAE: 563.3300\n",
      "Epoch 970, Train Loss: 1039237.8750, Val MSE: 1396874.2500, Val MAE: 543.1734\n",
      "Epoch 980, Train Loss: 1111185.6250, Val MSE: 1459051.5000, Val MAE: 566.3869\n",
      "Epoch 990, Train Loss: 1094062.0000, Val MSE: 1457606.2500, Val MAE: 569.2420\n",
      "Epoch 1000, Train Loss: 1121938.7500, Val MSE: 1458934.7500, Val MAE: 573.4553\n",
      "Epoch 1010, Train Loss: 1078787.5000, Val MSE: 1437111.5000, Val MAE: 555.7949\n",
      "Epoch 1020, Train Loss: 1058056.3750, Val MSE: 1439178.6250, Val MAE: 558.8588\n",
      "Epoch 1030, Train Loss: 1015036.2500, Val MSE: 1393998.2500, Val MAE: 538.7923\n",
      "Epoch 1040, Train Loss: 1136373.6250, Val MSE: 1542567.3750, Val MAE: 588.3605\n",
      "Epoch 1050, Train Loss: 1081200.7500, Val MSE: 1437845.6250, Val MAE: 557.7745\n",
      "Epoch 1060, Train Loss: 1039117.7500, Val MSE: 1416150.7500, Val MAE: 546.2972\n",
      "Epoch 1070, Train Loss: 1033308.8125, Val MSE: 1441124.0000, Val MAE: 557.6371\n",
      "Epoch 1080, Train Loss: 997958.1250, Val MSE: 1396065.6250, Val MAE: 536.9821\n",
      "Epoch 1090, Train Loss: 1019483.5625, Val MSE: 1398401.5000, Val MAE: 538.9977\n",
      "Epoch 1100, Train Loss: 1056703.2500, Val MSE: 1446699.8750, Val MAE: 558.1804\n",
      "Epoch 1110, Train Loss: 1021006.0625, Val MSE: 1440334.3750, Val MAE: 549.0017\n",
      "Epoch 1120, Train Loss: 985621.8125, Val MSE: 1406453.7500, Val MAE: 539.6733\n",
      "Epoch 1130, Train Loss: 999481.0000, Val MSE: 1395252.6250, Val MAE: 535.2350\n",
      "Epoch 1140, Train Loss: 1040040.3750, Val MSE: 1445126.0000, Val MAE: 549.7914\n",
      "Epoch 1150, Train Loss: 1025657.3750, Val MSE: 1456862.0000, Val MAE: 557.7963\n",
      "Epoch 1160, Train Loss: 979878.6250, Val MSE: 1408013.6250, Val MAE: 538.5319\n",
      "Epoch 1170, Train Loss: 980030.8125, Val MSE: 1392024.1250, Val MAE: 530.2940\n",
      "Epoch 1180, Train Loss: 1052755.8750, Val MSE: 1458148.6250, Val MAE: 558.8907\n",
      "Epoch 1190, Train Loss: 1020884.6250, Val MSE: 1467403.7500, Val MAE: 559.8207\n",
      "Epoch 1200, Train Loss: 983636.0625, Val MSE: 1436426.1250, Val MAE: 550.2148\n",
      "Epoch 1210, Train Loss: 962359.1250, Val MSE: 1394811.6250, Val MAE: 529.5258\n",
      "Epoch 1220, Train Loss: 980141.1875, Val MSE: 1410294.8750, Val MAE: 539.2143\n",
      "Epoch 1230, Train Loss: 1031975.8750, Val MSE: 1458123.7500, Val MAE: 554.9094\n",
      "Epoch 1240, Train Loss: 1009321.0000, Val MSE: 1466096.1250, Val MAE: 545.6719\n",
      "Epoch 1250, Train Loss: 978677.9375, Val MSE: 1455213.3750, Val MAE: 546.0555\n",
      "Epoch 1260, Train Loss: 957727.0625, Val MSE: 1411494.3750, Val MAE: 533.4335\n",
      "Epoch 1270, Train Loss: 944356.7500, Val MSE: 1406213.8750, Val MAE: 532.0688\n",
      "Epoch 1280, Train Loss: 987088.5000, Val MSE: 1424701.0000, Val MAE: 536.5508\n",
      "Epoch 1290, Train Loss: 1005101.1875, Val MSE: 1470182.6250, Val MAE: 558.4145\n",
      "Epoch 1300, Train Loss: 993128.5625, Val MSE: 1476758.2500, Val MAE: 562.3172\n",
      "Epoch 1310, Train Loss: 959662.7500, Val MSE: 1436963.3750, Val MAE: 536.2162\n",
      "Epoch 1320, Train Loss: 928819.7500, Val MSE: 1422257.2500, Val MAE: 532.2438\n",
      "Epoch 1330, Train Loss: 959536.5625, Val MSE: 1415447.3750, Val MAE: 531.6539\n",
      "Epoch 1340, Train Loss: 993060.8750, Val MSE: 1466883.6250, Val MAE: 540.0322\n",
      "Epoch 1350, Train Loss: 983525.4375, Val MSE: 1485130.6250, Val MAE: 550.4818\n",
      "Epoch 1360, Train Loss: 944739.6250, Val MSE: 1440071.7500, Val MAE: 537.0692\n",
      "Epoch 1370, Train Loss: 916926.6250, Val MSE: 1418736.7500, Val MAE: 533.7624\n",
      "Epoch 1380, Train Loss: 940375.4375, Val MSE: 1413794.1250, Val MAE: 527.0880\n",
      "Epoch 1390, Train Loss: 963082.8750, Val MSE: 1441818.6250, Val MAE: 541.7717\n",
      "Epoch 1400, Train Loss: 982877.1250, Val MSE: 1484521.0000, Val MAE: 557.4127\n",
      "Epoch 1410, Train Loss: 943030.8125, Val MSE: 1460859.6250, Val MAE: 536.4160\n",
      "Epoch 1420, Train Loss: 917748.7500, Val MSE: 1452935.7500, Val MAE: 535.1052\n",
      "Epoch 1430, Train Loss: 911781.0625, Val MSE: 1425311.8750, Val MAE: 526.4961\n",
      "Epoch 1440, Train Loss: 902722.1250, Val MSE: 1415225.5000, Val MAE: 525.2958\n",
      "Epoch 1450, Train Loss: 958522.1250, Val MSE: 1451474.3750, Val MAE: 537.2260\n",
      "Epoch 1460, Train Loss: 963093.4375, Val MSE: 1500093.0000, Val MAE: 556.0989\n",
      "Epoch 1470, Train Loss: 951048.8750, Val MSE: 1493715.5000, Val MAE: 558.8917\n",
      "Epoch 1480, Train Loss: 927875.3125, Val MSE: 1464630.1250, Val MAE: 536.2235\n",
      "Epoch 1490, Train Loss: 898275.3125, Val MSE: 1444186.3750, Val MAE: 529.7791\n",
      "Epoch 1500, Train Loss: 899366.2500, Val MSE: 1415998.5000, Val MAE: 521.6906\n",
      "Epoch 1510, Train Loss: 961330.6875, Val MSE: 1477502.8750, Val MAE: 535.5082\n",
      "Epoch 1520, Train Loss: 982527.1250, Val MSE: 1517959.5000, Val MAE: 555.0103\n",
      "Epoch 1530, Train Loss: 955898.2500, Val MSE: 1501737.3750, Val MAE: 552.5012\n",
      "Epoch 1540, Train Loss: 940310.3750, Val MSE: 1491253.1250, Val MAE: 556.0213\n",
      "Epoch 1550, Train Loss: 908036.3750, Val MSE: 1458961.2500, Val MAE: 529.9199\n",
      "Epoch 1560, Train Loss: 878591.5625, Val MSE: 1443266.1250, Val MAE: 526.6098\n",
      "Epoch 1570, Train Loss: 895076.6875, Val MSE: 1419731.5000, Val MAE: 520.1034\n",
      "Epoch 1580, Train Loss: 910076.0625, Val MSE: 1433799.7500, Val MAE: 521.4958\n",
      "Epoch 1590, Train Loss: 947034.3750, Val MSE: 1466302.6250, Val MAE: 534.6162\n",
      "Epoch 1600, Train Loss: 942010.6250, Val MSE: 1478921.7500, Val MAE: 551.4719\n",
      "Epoch 1610, Train Loss: 940682.1875, Val MSE: 1488718.6250, Val MAE: 551.8186\n",
      "Epoch 1620, Train Loss: 940998.5000, Val MSE: 1578060.3750, Val MAE: 606.1779\n",
      "Epoch 1630, Train Loss: 954960.6875, Val MSE: 1439211.5000, Val MAE: 529.1023\n",
      "Epoch 1640, Train Loss: 911431.0000, Val MSE: 1464638.1250, Val MAE: 537.1664\n",
      "Epoch 1650, Train Loss: 879471.5000, Val MSE: 1436973.8750, Val MAE: 527.2119\n",
      "Epoch 1660, Train Loss: 876224.1250, Val MSE: 1437890.0000, Val MAE: 523.2864\n",
      "Epoch 1670, Train Loss: 855886.3125, Val MSE: 1426682.6250, Val MAE: 518.3221\n",
      "Epoch 1680, Train Loss: 860084.3125, Val MSE: 1448686.0000, Val MAE: 524.8303\n",
      "Epoch 1690, Train Loss: 938315.6250, Val MSE: 1605357.2500, Val MAE: 573.0933\n",
      "Epoch 1700, Train Loss: 857396.2500, Val MSE: 1434469.3750, Val MAE: 521.6380\n",
      "Epoch 1710, Train Loss: 894761.6250, Val MSE: 1478823.7500, Val MAE: 537.0800\n",
      "Epoch 1720, Train Loss: 880245.1875, Val MSE: 1464653.7500, Val MAE: 528.0758\n",
      "Epoch 1730, Train Loss: 846664.5000, Val MSE: 1438307.7500, Val MAE: 519.9931\n",
      "Epoch 1740, Train Loss: 913006.1250, Val MSE: 1456249.2500, Val MAE: 529.3204\n",
      "Epoch 1750, Train Loss: 904519.2500, Val MSE: 1450581.0000, Val MAE: 525.2360\n",
      "Epoch 1760, Train Loss: 903892.8750, Val MSE: 1465833.0000, Val MAE: 531.0016\n",
      "Epoch 1770, Train Loss: 908264.7500, Val MSE: 1489417.8750, Val MAE: 538.1906\n",
      "Epoch 1780, Train Loss: 905734.1250, Val MSE: 1514834.8750, Val MAE: 547.6007\n",
      "Epoch 1790, Train Loss: 872380.8750, Val MSE: 1489440.7500, Val MAE: 532.3146\n",
      "Epoch 1800, Train Loss: 855568.9375, Val MSE: 1481038.0000, Val MAE: 532.8683\n",
      "Epoch 1810, Train Loss: 839673.8125, Val MSE: 1452669.5000, Val MAE: 522.6107\n",
      "Epoch 1820, Train Loss: 831623.0625, Val MSE: 1442383.7500, Val MAE: 519.5247\n",
      "Epoch 1830, Train Loss: 854086.5625, Val MSE: 1442541.2500, Val MAE: 519.5406\n",
      "Epoch 1840, Train Loss: 902778.6250, Val MSE: 1478119.0000, Val MAE: 533.4639\n",
      "Epoch 1850, Train Loss: 931643.0625, Val MSE: 1518955.6250, Val MAE: 545.8063\n",
      "Epoch 1860, Train Loss: 896525.6875, Val MSE: 1508937.3750, Val MAE: 537.9172\n",
      "Epoch 1870, Train Loss: 877605.0625, Val MSE: 1510948.5000, Val MAE: 542.3926\n",
      "Early stopping triggered at epoch 1870\n",
      "\n",
      " Best Val MAE: 518.3221 at epoch 1670\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd2, best_mae1, best_epoch = train_widedeep(model_wd2, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7be834c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 876004.5625, Val MSE: 1452000.6250, Val MAE: 520.7781\n",
      "Epoch 20, Train Loss: 834006.0000, Val MSE: 1439123.0000, Val MAE: 515.0938\n",
      "Epoch 30, Train Loss: 822383.3750, Val MSE: 1442598.6250, Val MAE: 515.8793\n",
      "Epoch 40, Train Loss: 822066.6875, Val MSE: 1445268.0000, Val MAE: 516.5697\n",
      "Epoch 50, Train Loss: 821073.0625, Val MSE: 1441859.1250, Val MAE: 515.2514\n",
      "Epoch 60, Train Loss: 820091.6875, Val MSE: 1441656.6250, Val MAE: 514.9666\n",
      "Epoch 70, Train Loss: 819304.6250, Val MSE: 1443406.0000, Val MAE: 515.4297\n",
      "Epoch 80, Train Loss: 818731.5625, Val MSE: 1443136.8750, Val MAE: 515.1852\n",
      "Epoch 90, Train Loss: 818161.6250, Val MSE: 1443910.2500, Val MAE: 515.3119\n",
      "Epoch 100, Train Loss: 817567.1250, Val MSE: 1444205.5000, Val MAE: 515.2816\n",
      "Epoch 110, Train Loss: 816971.5000, Val MSE: 1444724.8750, Val MAE: 515.2938\n",
      "Epoch 120, Train Loss: 816364.0625, Val MSE: 1445109.5000, Val MAE: 515.2855\n",
      "Epoch 130, Train Loss: 815737.4375, Val MSE: 1445631.8750, Val MAE: 515.2958\n",
      "Epoch 140, Train Loss: 815079.3125, Val MSE: 1445990.6250, Val MAE: 515.3184\n",
      "Epoch 150, Train Loss: 814421.0000, Val MSE: 1446650.6250, Val MAE: 515.3373\n",
      "Epoch 160, Train Loss: 813758.7500, Val MSE: 1447169.2500, Val MAE: 515.3494\n",
      "Epoch 170, Train Loss: 813084.9375, Val MSE: 1447759.7500, Val MAE: 515.3679\n",
      "Epoch 180, Train Loss: 812391.5000, Val MSE: 1448252.1250, Val MAE: 515.3745\n",
      "Epoch 190, Train Loss: 811694.4375, Val MSE: 1448821.3750, Val MAE: 515.3845\n",
      "Epoch 200, Train Loss: 810987.8750, Val MSE: 1449358.5000, Val MAE: 515.3874\n",
      "Epoch 210, Train Loss: 810268.8750, Val MSE: 1449939.1250, Val MAE: 515.4203\n",
      "Epoch 220, Train Loss: 809541.8750, Val MSE: 1450529.7500, Val MAE: 515.4352\n",
      "Epoch 230, Train Loss: 808814.3750, Val MSE: 1451048.0000, Val MAE: 515.4474\n",
      "Epoch 240, Train Loss: 808058.7500, Val MSE: 1451649.8750, Val MAE: 515.4684\n",
      "Epoch 250, Train Loss: 807282.5625, Val MSE: 1452088.5000, Val MAE: 515.4463\n",
      "Epoch 260, Train Loss: 806498.6250, Val MSE: 1452794.5000, Val MAE: 515.4481\n",
      "Early stopping triggered at epoch 260\n",
      "\n",
      " Best Val MAE: 514.9666 at epoch 60\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd2, best_mae1, best_epoch = train_widedeep(model_wd2, X_train3, y_train3, X_val3, y_val3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c497c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of wd1_nodrop: 65462\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_wd2.parameters())\n",
    "print(f\"Total Parameters of wd2: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6aca3ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wd3 = WideDeep(feature_columns=feature_columns, hidden_units=[256, 128, 64, 32], dnn_dropout=0.2)\n",
    "print(model_wd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a3ed7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 88452728.0000, Val MSE: 84597464.0000, Val MAE: 5412.2378\n",
      "Epoch 20, Train Loss: 34086436.0000, Val MSE: 30202922.0000, Val MAE: 3329.1758\n",
      "Epoch 30, Train Loss: 18777378.0000, Val MSE: 17709592.0000, Val MAE: 2696.7612\n",
      "Epoch 40, Train Loss: 13489098.0000, Val MSE: 11767142.0000, Val MAE: 1891.2024\n",
      "Epoch 50, Train Loss: 11184600.0000, Val MSE: 10094551.0000, Val MAE: 1823.9375\n",
      "Epoch 60, Train Loss: 9915435.0000, Val MSE: 8437068.0000, Val MAE: 1632.6195\n",
      "Epoch 70, Train Loss: 8708291.0000, Val MSE: 7277569.0000, Val MAE: 1333.8191\n",
      "Epoch 80, Train Loss: 8075561.5000, Val MSE: 6558897.5000, Val MAE: 1228.8312\n",
      "Epoch 90, Train Loss: 7412662.0000, Val MSE: 5938594.5000, Val MAE: 1154.3848\n",
      "Epoch 100, Train Loss: 6838251.5000, Val MSE: 5406131.0000, Val MAE: 1097.5103\n",
      "Epoch 110, Train Loss: 6407513.0000, Val MSE: 4946309.0000, Val MAE: 1049.1316\n",
      "Epoch 120, Train Loss: 6053463.5000, Val MSE: 4555592.5000, Val MAE: 1007.0927\n",
      "Epoch 130, Train Loss: 5794716.5000, Val MSE: 4236638.0000, Val MAE: 967.8806\n",
      "Epoch 140, Train Loss: 5493359.5000, Val MSE: 3970309.7500, Val MAE: 933.6633\n",
      "Epoch 150, Train Loss: 5389662.0000, Val MSE: 3732476.5000, Val MAE: 901.6160\n",
      "Epoch 160, Train Loss: 5132272.0000, Val MSE: 3481423.0000, Val MAE: 869.2059\n",
      "Epoch 170, Train Loss: 4896098.0000, Val MSE: 3259824.2500, Val MAE: 841.0615\n",
      "Epoch 180, Train Loss: 4651043.0000, Val MSE: 3009033.7500, Val MAE: 817.4217\n",
      "Epoch 190, Train Loss: 4429160.0000, Val MSE: 2779385.7500, Val MAE: 794.7452\n",
      "Epoch 200, Train Loss: 4245446.5000, Val MSE: 2587035.2500, Val MAE: 776.3070\n",
      "Epoch 210, Train Loss: 4137071.2500, Val MSE: 2503417.7500, Val MAE: 763.2426\n",
      "Epoch 220, Train Loss: 3946770.5000, Val MSE: 2399629.0000, Val MAE: 753.2579\n",
      "Epoch 230, Train Loss: 3905752.5000, Val MSE: 2241154.0000, Val MAE: 731.5921\n",
      "Epoch 240, Train Loss: 3872450.5000, Val MSE: 2207840.5000, Val MAE: 726.3502\n",
      "Epoch 250, Train Loss: 3722112.5000, Val MSE: 2146844.0000, Val MAE: 719.6992\n",
      "Epoch 260, Train Loss: 3680235.2500, Val MSE: 2040801.6250, Val MAE: 704.4686\n",
      "Epoch 270, Train Loss: 3607222.2500, Val MSE: 2026162.6250, Val MAE: 706.3177\n",
      "Epoch 280, Train Loss: 3603970.0000, Val MSE: 2036702.7500, Val MAE: 718.4561\n",
      "Epoch 290, Train Loss: 3493888.0000, Val MSE: 2025075.3750, Val MAE: 719.5887\n",
      "Epoch 300, Train Loss: 3494242.7500, Val MSE: 1914413.5000, Val MAE: 690.1835\n",
      "Epoch 310, Train Loss: 3570236.0000, Val MSE: 1873517.0000, Val MAE: 678.9468\n",
      "Epoch 320, Train Loss: 3440497.0000, Val MSE: 1883793.2500, Val MAE: 678.3009\n",
      "Epoch 330, Train Loss: 3442112.0000, Val MSE: 1947460.2500, Val MAE: 694.9038\n",
      "Epoch 340, Train Loss: 3417156.5000, Val MSE: 1803321.6250, Val MAE: 671.6737\n",
      "Epoch 350, Train Loss: 3408389.5000, Val MSE: 1856183.7500, Val MAE: 685.6608\n",
      "Epoch 360, Train Loss: 3310977.0000, Val MSE: 1789689.0000, Val MAE: 665.7367\n",
      "Epoch 370, Train Loss: 3306710.7500, Val MSE: 1834572.7500, Val MAE: 684.5363\n",
      "Epoch 380, Train Loss: 3288598.2500, Val MSE: 1807346.1250, Val MAE: 678.4414\n",
      "Epoch 390, Train Loss: 3278208.0000, Val MSE: 1770076.8750, Val MAE: 659.0310\n",
      "Epoch 400, Train Loss: 3240266.2500, Val MSE: 1765326.0000, Val MAE: 653.6302\n",
      "Epoch 410, Train Loss: 3210084.5000, Val MSE: 1744990.0000, Val MAE: 653.1253\n",
      "Epoch 420, Train Loss: 3213004.7500, Val MSE: 1700174.1250, Val MAE: 644.5758\n",
      "Epoch 430, Train Loss: 3266515.2500, Val MSE: 1701634.6250, Val MAE: 646.0558\n",
      "Epoch 440, Train Loss: 3332201.7500, Val MSE: 1681046.0000, Val MAE: 643.1887\n",
      "Epoch 450, Train Loss: 3182382.7500, Val MSE: 1838486.2500, Val MAE: 693.2117\n",
      "Epoch 460, Train Loss: 3129940.7500, Val MSE: 1676478.1250, Val MAE: 639.7395\n",
      "Epoch 470, Train Loss: 3039039.0000, Val MSE: 1912426.2500, Val MAE: 718.6681\n",
      "Epoch 480, Train Loss: 3160833.5000, Val MSE: 1666473.3750, Val MAE: 637.3476\n",
      "Epoch 490, Train Loss: 3118673.7500, Val MSE: 1852744.8750, Val MAE: 706.9197\n",
      "Epoch 500, Train Loss: 3095502.7500, Val MSE: 1631039.6250, Val MAE: 629.7068\n",
      "Epoch 510, Train Loss: 3074109.2500, Val MSE: 1713118.3750, Val MAE: 648.9709\n",
      "Epoch 520, Train Loss: 3117773.2500, Val MSE: 1618785.7500, Val MAE: 626.8289\n",
      "Epoch 530, Train Loss: 3135376.5000, Val MSE: 1861324.7500, Val MAE: 697.7520\n",
      "Epoch 540, Train Loss: 3057387.0000, Val MSE: 1604100.1250, Val MAE: 625.2195\n",
      "Epoch 550, Train Loss: 3009732.7500, Val MSE: 1665160.1250, Val MAE: 651.8480\n",
      "Epoch 560, Train Loss: 2969781.0000, Val MSE: 1598441.5000, Val MAE: 621.6734\n",
      "Epoch 570, Train Loss: 3053063.0000, Val MSE: 1650715.6250, Val MAE: 636.5154\n",
      "Epoch 580, Train Loss: 3024346.0000, Val MSE: 1635533.2500, Val MAE: 632.1548\n",
      "Epoch 590, Train Loss: 3060167.7500, Val MSE: 1583780.6250, Val MAE: 622.9410\n",
      "Epoch 600, Train Loss: 3118104.0000, Val MSE: 1576000.0000, Val MAE: 616.7318\n",
      "Epoch 610, Train Loss: 3056189.7500, Val MSE: 1569142.1250, Val MAE: 613.7892\n",
      "Epoch 620, Train Loss: 2956940.0000, Val MSE: 1697385.6250, Val MAE: 640.5710\n",
      "Epoch 630, Train Loss: 2964408.5000, Val MSE: 1621937.1250, Val MAE: 630.6524\n",
      "Epoch 640, Train Loss: 2954044.7500, Val MSE: 1579696.8750, Val MAE: 619.4473\n",
      "Epoch 650, Train Loss: 3031114.2500, Val MSE: 1633492.5000, Val MAE: 642.5214\n",
      "Epoch 660, Train Loss: 2962349.0000, Val MSE: 1549420.3750, Val MAE: 609.7371\n",
      "Epoch 670, Train Loss: 3023634.7500, Val MSE: 1649437.2500, Val MAE: 642.2307\n",
      "Epoch 680, Train Loss: 2931733.2500, Val MSE: 1598506.1250, Val MAE: 617.0050\n",
      "Epoch 690, Train Loss: 2919538.5000, Val MSE: 1630254.0000, Val MAE: 630.7582\n",
      "Epoch 700, Train Loss: 2872476.2500, Val MSE: 1561818.3750, Val MAE: 614.5599\n",
      "Epoch 710, Train Loss: 3016806.5000, Val MSE: 1571332.1250, Val MAE: 614.4564\n",
      "Epoch 720, Train Loss: 2859388.0000, Val MSE: 1548310.8750, Val MAE: 617.6078\n",
      "Epoch 730, Train Loss: 2863260.0000, Val MSE: 1573863.1250, Val MAE: 630.2852\n",
      "Epoch 740, Train Loss: 2934808.0000, Val MSE: 1581849.2500, Val MAE: 616.5393\n",
      "Epoch 750, Train Loss: 2909769.5000, Val MSE: 1631767.0000, Val MAE: 642.2587\n",
      "Epoch 760, Train Loss: 3079628.0000, Val MSE: 2015769.5000, Val MAE: 743.2408\n",
      "Epoch 770, Train Loss: 3017561.2500, Val MSE: 1520448.1250, Val MAE: 597.9207\n",
      "Epoch 780, Train Loss: 2864644.2500, Val MSE: 1521677.0000, Val MAE: 597.9360\n",
      "Epoch 790, Train Loss: 2838784.7500, Val MSE: 1541127.5000, Val MAE: 604.1900\n",
      "Epoch 800, Train Loss: 2820908.2500, Val MSE: 1518469.0000, Val MAE: 594.7786\n",
      "Epoch 810, Train Loss: 2895483.5000, Val MSE: 1559908.3750, Val MAE: 608.6817\n",
      "Epoch 820, Train Loss: 2873417.7500, Val MSE: 1518654.6250, Val MAE: 605.5620\n",
      "Epoch 830, Train Loss: 2805591.2500, Val MSE: 1569141.5000, Val MAE: 626.0715\n",
      "Epoch 840, Train Loss: 2841115.0000, Val MSE: 1539947.8750, Val MAE: 604.1636\n",
      "Epoch 850, Train Loss: 2850205.0000, Val MSE: 1507488.5000, Val MAE: 595.6569\n",
      "Epoch 860, Train Loss: 2775972.2500, Val MSE: 1603613.5000, Val MAE: 622.6169\n",
      "Epoch 870, Train Loss: 2790995.5000, Val MSE: 1611356.3750, Val MAE: 646.0176\n",
      "Epoch 880, Train Loss: 2864395.2500, Val MSE: 1493783.1250, Val MAE: 591.1087\n",
      "Epoch 890, Train Loss: 2852745.7500, Val MSE: 1495864.0000, Val MAE: 596.2394\n",
      "Epoch 900, Train Loss: 2820824.7500, Val MSE: 1499372.1250, Val MAE: 594.3181\n",
      "Epoch 910, Train Loss: 2792006.0000, Val MSE: 1612833.0000, Val MAE: 643.5800\n",
      "Epoch 920, Train Loss: 2804366.5000, Val MSE: 1843689.5000, Val MAE: 690.9733\n",
      "Epoch 930, Train Loss: 2826972.2500, Val MSE: 1473169.2500, Val MAE: 581.2433\n",
      "Epoch 940, Train Loss: 2825683.7500, Val MSE: 1500236.2500, Val MAE: 588.2935\n",
      "Epoch 950, Train Loss: 2682336.7500, Val MSE: 1602580.5000, Val MAE: 617.3854\n",
      "Epoch 960, Train Loss: 2775187.7500, Val MSE: 1471074.5000, Val MAE: 583.1118\n",
      "Epoch 970, Train Loss: 2727527.2500, Val MSE: 1462165.2500, Val MAE: 581.9172\n",
      "Epoch 980, Train Loss: 2784805.2500, Val MSE: 1464768.1250, Val MAE: 583.2419\n",
      "Epoch 990, Train Loss: 2768062.5000, Val MSE: 1618542.2500, Val MAE: 643.4202\n",
      "Epoch 1000, Train Loss: 2691492.0000, Val MSE: 1466659.6250, Val MAE: 581.3244\n",
      "Epoch 1010, Train Loss: 2710059.5000, Val MSE: 1499556.5000, Val MAE: 594.4203\n",
      "Epoch 1020, Train Loss: 2754578.7500, Val MSE: 1537780.3750, Val MAE: 604.9014\n",
      "Epoch 1030, Train Loss: 2736201.0000, Val MSE: 1495847.3750, Val MAE: 607.5066\n",
      "Epoch 1040, Train Loss: 2680742.2500, Val MSE: 1647097.7500, Val MAE: 628.7474\n",
      "Epoch 1050, Train Loss: 2748351.0000, Val MSE: 1536191.8750, Val MAE: 613.8529\n",
      "Epoch 1060, Train Loss: 2750875.0000, Val MSE: 1526270.2500, Val MAE: 605.4528\n",
      "Epoch 1070, Train Loss: 2711228.7500, Val MSE: 1517429.2500, Val MAE: 602.7281\n",
      "Epoch 1080, Train Loss: 2720334.5000, Val MSE: 1573222.0000, Val MAE: 625.9658\n",
      "Epoch 1090, Train Loss: 2719313.2500, Val MSE: 1611101.1250, Val MAE: 618.5341\n",
      "Epoch 1100, Train Loss: 2804589.0000, Val MSE: 1567743.2500, Val MAE: 628.2633\n",
      "Epoch 1110, Train Loss: 2845222.2500, Val MSE: 1822354.8750, Val MAE: 680.6382\n",
      "Epoch 1120, Train Loss: 2745900.0000, Val MSE: 1489570.3750, Val MAE: 590.5537\n",
      "Epoch 1130, Train Loss: 2665147.0000, Val MSE: 1451606.8750, Val MAE: 567.9772\n",
      "Epoch 1140, Train Loss: 2702978.0000, Val MSE: 1458880.5000, Val MAE: 586.2766\n",
      "Epoch 1150, Train Loss: 2685924.5000, Val MSE: 1444976.6250, Val MAE: 565.5607\n",
      "Epoch 1160, Train Loss: 2666964.0000, Val MSE: 1483304.5000, Val MAE: 584.1229\n",
      "Epoch 1170, Train Loss: 2635667.0000, Val MSE: 1477752.2500, Val MAE: 587.7288\n",
      "Epoch 1180, Train Loss: 2736551.7500, Val MSE: 1471578.2500, Val MAE: 570.9768\n",
      "Epoch 1190, Train Loss: 2782335.5000, Val MSE: 1447732.2500, Val MAE: 567.3304\n",
      "Epoch 1200, Train Loss: 2871351.5000, Val MSE: 1506251.1250, Val MAE: 582.6211\n",
      "Epoch 1210, Train Loss: 2812631.2500, Val MSE: 1434754.0000, Val MAE: 563.1025\n",
      "Epoch 1220, Train Loss: 2720863.2500, Val MSE: 1453689.2500, Val MAE: 575.8666\n",
      "Epoch 1230, Train Loss: 2658940.0000, Val MSE: 1464762.2500, Val MAE: 571.5663\n",
      "Epoch 1240, Train Loss: 2729066.5000, Val MSE: 1512676.8750, Val MAE: 603.6286\n",
      "Epoch 1250, Train Loss: 2681410.2500, Val MSE: 1478138.1250, Val MAE: 574.1169\n",
      "Epoch 1260, Train Loss: 2649228.5000, Val MSE: 1429242.3750, Val MAE: 560.9690\n",
      "Epoch 1270, Train Loss: 2605689.5000, Val MSE: 1469588.0000, Val MAE: 580.4089\n",
      "Epoch 1280, Train Loss: 2734469.2500, Val MSE: 1460340.6250, Val MAE: 570.3795\n",
      "Epoch 1290, Train Loss: 2691968.2500, Val MSE: 1443821.7500, Val MAE: 564.1821\n",
      "Epoch 1300, Train Loss: 2658864.7500, Val MSE: 1447643.1250, Val MAE: 568.9829\n",
      "Epoch 1310, Train Loss: 2585745.5000, Val MSE: 1433474.1250, Val MAE: 564.6927\n",
      "Epoch 1320, Train Loss: 2666298.7500, Val MSE: 1458041.8750, Val MAE: 571.3698\n",
      "Epoch 1330, Train Loss: 2671150.0000, Val MSE: 1449109.7500, Val MAE: 562.4279\n",
      "Epoch 1340, Train Loss: 2674343.5000, Val MSE: 1534386.2500, Val MAE: 598.6343\n",
      "Epoch 1350, Train Loss: 2582575.2500, Val MSE: 1524771.2500, Val MAE: 601.7045\n",
      "Epoch 1360, Train Loss: 2663177.7500, Val MSE: 1466898.8750, Val MAE: 578.8462\n",
      "Epoch 1370, Train Loss: 2632644.5000, Val MSE: 1435351.6250, Val MAE: 559.1722\n",
      "Epoch 1380, Train Loss: 2693837.0000, Val MSE: 1443954.5000, Val MAE: 555.8481\n",
      "Epoch 1390, Train Loss: 2691982.7500, Val MSE: 1581033.1250, Val MAE: 605.4667\n",
      "Epoch 1400, Train Loss: 2671552.7500, Val MSE: 1433219.0000, Val MAE: 555.4910\n",
      "Epoch 1410, Train Loss: 2625953.7500, Val MSE: 1458697.6250, Val MAE: 570.1734\n",
      "Epoch 1420, Train Loss: 2617886.7500, Val MSE: 1523243.7500, Val MAE: 588.0237\n",
      "Epoch 1430, Train Loss: 2787606.7500, Val MSE: 1434005.6250, Val MAE: 559.6733\n",
      "Epoch 1440, Train Loss: 2605476.7500, Val MSE: 1445024.7500, Val MAE: 553.9963\n",
      "Epoch 1450, Train Loss: 2614669.0000, Val MSE: 1444508.7500, Val MAE: 555.8595\n",
      "Epoch 1460, Train Loss: 2642334.5000, Val MSE: 1463616.3750, Val MAE: 562.0974\n",
      "Epoch 1470, Train Loss: 2608450.0000, Val MSE: 1444278.0000, Val MAE: 555.4698\n",
      "Epoch 1480, Train Loss: 2802356.7500, Val MSE: 1443775.7500, Val MAE: 570.1781\n",
      "Epoch 1490, Train Loss: 2669259.7500, Val MSE: 1469897.2500, Val MAE: 561.2523\n",
      "Epoch 1500, Train Loss: 2644976.0000, Val MSE: 1428674.6250, Val MAE: 552.2529\n",
      "Epoch 1510, Train Loss: 2626599.7500, Val MSE: 1471360.6250, Val MAE: 565.7750\n",
      "Epoch 1520, Train Loss: 2616139.2500, Val MSE: 1465014.8750, Val MAE: 573.0300\n",
      "Epoch 1530, Train Loss: 2626970.7500, Val MSE: 1428839.7500, Val MAE: 549.0789\n",
      "Epoch 1540, Train Loss: 2569777.5000, Val MSE: 1493652.8750, Val MAE: 589.1234\n",
      "Epoch 1550, Train Loss: 2551598.0000, Val MSE: 1518740.3750, Val MAE: 583.6879\n",
      "Epoch 1560, Train Loss: 2591380.5000, Val MSE: 1598912.5000, Val MAE: 597.8286\n",
      "Epoch 1570, Train Loss: 2549356.5000, Val MSE: 1494349.6250, Val MAE: 578.6121\n",
      "Epoch 1580, Train Loss: 2568279.5000, Val MSE: 1464001.5000, Val MAE: 557.8370\n",
      "Epoch 1590, Train Loss: 2560182.5000, Val MSE: 1438564.0000, Val MAE: 558.5280\n",
      "Epoch 1600, Train Loss: 2590267.7500, Val MSE: 1444314.2500, Val MAE: 553.7005\n",
      "Epoch 1610, Train Loss: 2627731.0000, Val MSE: 1477090.1250, Val MAE: 567.6766\n",
      "Epoch 1620, Train Loss: 2649829.0000, Val MSE: 1583667.0000, Val MAE: 598.3017\n",
      "Epoch 1630, Train Loss: 2555694.7500, Val MSE: 1432660.7500, Val MAE: 545.7033\n",
      "Epoch 1640, Train Loss: 2718820.0000, Val MSE: 1654915.7500, Val MAE: 616.3749\n",
      "Epoch 1650, Train Loss: 2565430.7500, Val MSE: 1569663.0000, Val MAE: 618.5159\n",
      "Epoch 1660, Train Loss: 2596910.7500, Val MSE: 1463586.7500, Val MAE: 559.1455\n",
      "Epoch 1670, Train Loss: 2656101.5000, Val MSE: 1478588.0000, Val MAE: 564.2442\n",
      "Epoch 1680, Train Loss: 2695921.0000, Val MSE: 1526324.7500, Val MAE: 567.2833\n",
      "Epoch 1690, Train Loss: 2705284.7500, Val MSE: 1437044.8750, Val MAE: 552.2315\n",
      "Epoch 1700, Train Loss: 2633064.5000, Val MSE: 1547887.0000, Val MAE: 576.1634\n",
      "Epoch 1710, Train Loss: 2589011.5000, Val MSE: 1502435.5000, Val MAE: 571.2820\n",
      "Epoch 1720, Train Loss: 2536388.5000, Val MSE: 1425721.5000, Val MAE: 541.4649\n",
      "Epoch 1730, Train Loss: 2652350.2500, Val MSE: 1681259.1250, Val MAE: 643.2687\n",
      "Epoch 1740, Train Loss: 2635204.7500, Val MSE: 1516332.2500, Val MAE: 579.7944\n",
      "Epoch 1750, Train Loss: 2543982.2500, Val MSE: 1453458.2500, Val MAE: 556.0400\n",
      "Epoch 1760, Train Loss: 2583668.5000, Val MSE: 1449611.3750, Val MAE: 551.2742\n",
      "Epoch 1770, Train Loss: 2584231.0000, Val MSE: 1463791.6250, Val MAE: 562.2903\n",
      "Epoch 1780, Train Loss: 2572165.2500, Val MSE: 1480300.0000, Val MAE: 565.6361\n",
      "Epoch 1790, Train Loss: 2532860.2500, Val MSE: 1572347.2500, Val MAE: 577.6083\n",
      "Epoch 1800, Train Loss: 2565910.7500, Val MSE: 1637947.7500, Val MAE: 620.5385\n",
      "Epoch 1810, Train Loss: 2532918.5000, Val MSE: 1438004.3750, Val MAE: 550.2376\n",
      "Epoch 1820, Train Loss: 2669971.0000, Val MSE: 1547171.5000, Val MAE: 573.5172\n",
      "Epoch 1830, Train Loss: 2517508.7500, Val MSE: 1510470.2500, Val MAE: 584.5458\n",
      "Epoch 1840, Train Loss: 2597228.0000, Val MSE: 1446889.2500, Val MAE: 546.3674\n",
      "Epoch 1850, Train Loss: 2597059.5000, Val MSE: 1441570.5000, Val MAE: 541.7355\n",
      "Epoch 1860, Train Loss: 2535094.5000, Val MSE: 1519404.8750, Val MAE: 564.6742\n",
      "Epoch 1870, Train Loss: 2675656.7500, Val MSE: 1491650.5000, Val MAE: 553.3017\n",
      "Epoch 1880, Train Loss: 2626544.5000, Val MSE: 1460086.7500, Val MAE: 548.1789\n",
      "Epoch 1890, Train Loss: 2687940.2500, Val MSE: 1728711.7500, Val MAE: 619.2280\n",
      "Epoch 1900, Train Loss: 2590881.0000, Val MSE: 1803902.2500, Val MAE: 649.4106\n",
      "Epoch 1910, Train Loss: 2595243.5000, Val MSE: 1529434.2500, Val MAE: 574.2627\n",
      "Epoch 1920, Train Loss: 2538448.7500, Val MSE: 1428158.8750, Val MAE: 538.3425\n",
      "Epoch 1930, Train Loss: 2623328.2500, Val MSE: 1458502.7500, Val MAE: 550.6394\n",
      "Epoch 1940, Train Loss: 2498785.2500, Val MSE: 1461975.0000, Val MAE: 554.7431\n",
      "Epoch 1950, Train Loss: 2506011.0000, Val MSE: 1452711.7500, Val MAE: 551.9609\n",
      "Epoch 1960, Train Loss: 2536313.7500, Val MSE: 1453273.2500, Val MAE: 545.9888\n",
      "Epoch 1970, Train Loss: 2576217.7500, Val MSE: 1468995.0000, Val MAE: 550.9212\n",
      "Epoch 1980, Train Loss: 2820738.5000, Val MSE: 2053943.6250, Val MAE: 701.4935\n",
      "Epoch 1990, Train Loss: 2597663.7500, Val MSE: 1459316.6250, Val MAE: 553.7266\n",
      "Epoch 2000, Train Loss: 2647160.2500, Val MSE: 1464429.2500, Val MAE: 544.3340\n",
      "Epoch 2010, Train Loss: 2538620.0000, Val MSE: 1454164.0000, Val MAE: 547.6954\n",
      "Epoch 2020, Train Loss: 2548175.2500, Val MSE: 1457784.1250, Val MAE: 545.0905\n",
      "Epoch 2030, Train Loss: 2526362.2500, Val MSE: 1498359.8750, Val MAE: 552.3788\n",
      "Epoch 2040, Train Loss: 2731396.0000, Val MSE: 1474719.7500, Val MAE: 540.9243\n",
      "Epoch 2050, Train Loss: 2468063.5000, Val MSE: 1471690.3750, Val MAE: 551.9549\n",
      "Epoch 2060, Train Loss: 2555095.7500, Val MSE: 1591426.5000, Val MAE: 605.2048\n",
      "Epoch 2070, Train Loss: 2571328.0000, Val MSE: 1450011.0000, Val MAE: 539.1245\n",
      "Epoch 2080, Train Loss: 2571827.0000, Val MSE: 1469523.3750, Val MAE: 547.2625\n",
      "Epoch 2090, Train Loss: 2492076.2500, Val MSE: 1481758.7500, Val MAE: 555.2125\n",
      "Epoch 2100, Train Loss: 2540197.7500, Val MSE: 1499240.7500, Val MAE: 547.5399\n",
      "Epoch 2110, Train Loss: 2549090.7500, Val MSE: 1522671.0000, Val MAE: 572.5741\n",
      "Epoch 2120, Train Loss: 2529481.2500, Val MSE: 1647660.3750, Val MAE: 643.8283\n",
      "Early stopping triggered at epoch 2120\n",
      "\n",
      " Best Val MAE: 538.3425 at epoch 1920\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd3, best_mae, best_epoch = train_widedeep(model_wd3, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "43262ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 2554357.0000, Val MSE: 1461330.1250, Val MAE: 547.5745\n",
      "Epoch 20, Train Loss: 2477244.2500, Val MSE: 1450260.8750, Val MAE: 542.2523\n",
      "Epoch 30, Train Loss: 2502653.5000, Val MSE: 1454183.7500, Val MAE: 548.4410\n",
      "Epoch 40, Train Loss: 2437275.5000, Val MSE: 1459816.5000, Val MAE: 545.8008\n",
      "Epoch 50, Train Loss: 2501672.5000, Val MSE: 1467919.5000, Val MAE: 552.0473\n",
      "Epoch 60, Train Loss: 2496894.2500, Val MSE: 1466544.0000, Val MAE: 553.4422\n",
      "Epoch 70, Train Loss: 2437551.2500, Val MSE: 1472886.7500, Val MAE: 550.2590\n",
      "Epoch 80, Train Loss: 2507727.7500, Val MSE: 1469248.6250, Val MAE: 554.8820\n",
      "Epoch 90, Train Loss: 2508507.5000, Val MSE: 1467685.0000, Val MAE: 556.4601\n",
      "Epoch 100, Train Loss: 2452856.0000, Val MSE: 1473755.6250, Val MAE: 554.0693\n",
      "Epoch 110, Train Loss: 2504924.5000, Val MSE: 1453963.7500, Val MAE: 542.7256\n",
      "Epoch 120, Train Loss: 2509994.5000, Val MSE: 1459472.5000, Val MAE: 542.3437\n",
      "Epoch 130, Train Loss: 2439232.5000, Val MSE: 1474746.0000, Val MAE: 554.2344\n",
      "Epoch 140, Train Loss: 2509333.7500, Val MSE: 1457617.8750, Val MAE: 543.2180\n",
      "Epoch 150, Train Loss: 2564119.2500, Val MSE: 1480052.8750, Val MAE: 557.4625\n",
      "Epoch 160, Train Loss: 2546920.0000, Val MSE: 1456564.3750, Val MAE: 544.4793\n",
      "Epoch 170, Train Loss: 2516669.0000, Val MSE: 1499596.6250, Val MAE: 559.9428\n",
      "Epoch 180, Train Loss: 2526205.5000, Val MSE: 1457394.8750, Val MAE: 543.4232\n",
      "Epoch 190, Train Loss: 2462718.2500, Val MSE: 1465875.2500, Val MAE: 549.3542\n",
      "Epoch 200, Train Loss: 2474262.0000, Val MSE: 1482210.6250, Val MAE: 553.4952\n",
      "Epoch 210, Train Loss: 2457130.0000, Val MSE: 1464940.6250, Val MAE: 543.3530\n",
      "Epoch 220, Train Loss: 2489644.2500, Val MSE: 1474145.5000, Val MAE: 551.6035\n",
      "Early stopping triggered at epoch 220\n",
      "\n",
      " Best Val MAE: 542.2523 at epoch 20\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd3, best_mae, best_epoch = train_widedeep(model_wd3, X_train3, y_train3, X_val3, y_val3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5cc655d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideDeep(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=512, bias=True)\n",
      "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (linear): Linear(\n",
      "    (linear): Linear(in_features=26, out_features=1, bias=True)\n",
      "  )\n",
      "  (final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_wd4 = WideDeep(feature_columns=feature_columns, hidden_units=[512, 256, 128, 64, 32])\n",
    "print(model_wd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "50346227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 40810032.0000, Val MSE: 55576220.0000, Val MAE: 6181.2246\n",
      "Epoch 20, Train Loss: 18494892.0000, Val MSE: 20474482.0000, Val MAE: 2993.4744\n",
      "Epoch 30, Train Loss: 11243357.0000, Val MSE: 12208355.0000, Val MAE: 2216.7725\n",
      "Epoch 40, Train Loss: 9397785.0000, Val MSE: 9250526.0000, Val MAE: 1879.9945\n",
      "Epoch 50, Train Loss: 7324315.0000, Val MSE: 7377548.5000, Val MAE: 1452.7081\n",
      "Epoch 60, Train Loss: 6373636.5000, Val MSE: 6536516.5000, Val MAE: 1219.6023\n",
      "Epoch 70, Train Loss: 5695797.0000, Val MSE: 5827099.0000, Val MAE: 1160.3042\n",
      "Epoch 80, Train Loss: 5188464.5000, Val MSE: 5298470.5000, Val MAE: 1115.3024\n",
      "Epoch 90, Train Loss: 4748326.0000, Val MSE: 4827710.0000, Val MAE: 1060.0585\n",
      "Epoch 100, Train Loss: 4359801.5000, Val MSE: 4413789.5000, Val MAE: 1011.2678\n",
      "Epoch 110, Train Loss: 4013563.5000, Val MSE: 4034664.7500, Val MAE: 965.5431\n",
      "Epoch 120, Train Loss: 3691833.7500, Val MSE: 3692180.7500, Val MAE: 916.4363\n",
      "Epoch 130, Train Loss: 3366675.5000, Val MSE: 3349025.0000, Val MAE: 875.5281\n",
      "Epoch 140, Train Loss: 3049490.0000, Val MSE: 3004047.5000, Val MAE: 838.4740\n",
      "Epoch 150, Train Loss: 2755602.0000, Val MSE: 2727750.5000, Val MAE: 803.4422\n",
      "Epoch 160, Train Loss: 2536165.7500, Val MSE: 2512225.0000, Val MAE: 794.5652\n",
      "Epoch 170, Train Loss: 2316328.2500, Val MSE: 2291858.0000, Val MAE: 751.9245\n",
      "Epoch 180, Train Loss: 2194834.2500, Val MSE: 2197097.5000, Val MAE: 734.3016\n",
      "Epoch 190, Train Loss: 2100403.2500, Val MSE: 2134488.5000, Val MAE: 755.9925\n",
      "Epoch 200, Train Loss: 1910737.6250, Val MSE: 1965107.8750, Val MAE: 708.5325\n",
      "Epoch 210, Train Loss: 1835399.1250, Val MSE: 1879671.6250, Val MAE: 684.6825\n",
      "Epoch 220, Train Loss: 1748849.8750, Val MSE: 1828983.5000, Val MAE: 675.1095\n",
      "Epoch 230, Train Loss: 1773775.1250, Val MSE: 1855831.5000, Val MAE: 682.8157\n",
      "Epoch 240, Train Loss: 1658290.3750, Val MSE: 1753079.5000, Val MAE: 661.4052\n",
      "Epoch 250, Train Loss: 1637084.8750, Val MSE: 1757625.8750, Val MAE: 660.2203\n",
      "Epoch 260, Train Loss: 1578372.7500, Val MSE: 1725466.3750, Val MAE: 661.3356\n",
      "Epoch 270, Train Loss: 1619109.7500, Val MSE: 1880937.7500, Val MAE: 700.8023\n",
      "Epoch 280, Train Loss: 1558928.1250, Val MSE: 1744154.7500, Val MAE: 659.8367\n",
      "Epoch 290, Train Loss: 1495551.6250, Val MSE: 1685044.7500, Val MAE: 642.7195\n",
      "Epoch 300, Train Loss: 1464744.1250, Val MSE: 1637389.8750, Val MAE: 635.6369\n",
      "Epoch 310, Train Loss: 1463847.0000, Val MSE: 1671800.3750, Val MAE: 641.1358\n",
      "Epoch 320, Train Loss: 1426124.6250, Val MSE: 1609155.0000, Val MAE: 624.9335\n",
      "Epoch 330, Train Loss: 1422071.6250, Val MSE: 1609023.5000, Val MAE: 629.2501\n",
      "Epoch 340, Train Loss: 1472359.8750, Val MSE: 1763075.1250, Val MAE: 670.7081\n",
      "Epoch 350, Train Loss: 1469164.7500, Val MSE: 1655620.5000, Val MAE: 655.7252\n",
      "Epoch 360, Train Loss: 1345648.3750, Val MSE: 1566020.5000, Val MAE: 613.0190\n",
      "Epoch 370, Train Loss: 1333409.7500, Val MSE: 1562286.3750, Val MAE: 613.8297\n",
      "Epoch 380, Train Loss: 1367052.8750, Val MSE: 1676968.2500, Val MAE: 646.6243\n",
      "Epoch 390, Train Loss: 1480597.3750, Val MSE: 1685429.5000, Val MAE: 673.4053\n",
      "Epoch 400, Train Loss: 1357895.5000, Val MSE: 1629171.6250, Val MAE: 651.6187\n",
      "Epoch 410, Train Loss: 1282813.6250, Val MSE: 1616233.0000, Val MAE: 649.3590\n",
      "Epoch 420, Train Loss: 1302046.6250, Val MSE: 1596354.5000, Val MAE: 627.2779\n",
      "Epoch 430, Train Loss: 1287449.3750, Val MSE: 1519768.3750, Val MAE: 599.2567\n",
      "Epoch 440, Train Loss: 1255358.6250, Val MSE: 1529910.7500, Val MAE: 603.2299\n",
      "Epoch 450, Train Loss: 1227149.0000, Val MSE: 1495334.0000, Val MAE: 590.5101\n",
      "Epoch 460, Train Loss: 1204538.0000, Val MSE: 1488852.6250, Val MAE: 590.4498\n",
      "Epoch 470, Train Loss: 1304405.2500, Val MSE: 1620494.5000, Val MAE: 646.5878\n",
      "Epoch 480, Train Loss: 1225527.8750, Val MSE: 1561592.8750, Val MAE: 611.0493\n",
      "Epoch 490, Train Loss: 1203606.3750, Val MSE: 1523694.2500, Val MAE: 607.0065\n",
      "Epoch 500, Train Loss: 1175951.8750, Val MSE: 1475591.6250, Val MAE: 585.1503\n",
      "Epoch 510, Train Loss: 1236281.7500, Val MSE: 1622921.0000, Val MAE: 630.5537\n",
      "Epoch 520, Train Loss: 1233861.5000, Val MSE: 1586487.3750, Val MAE: 632.5148\n",
      "Epoch 530, Train Loss: 1165498.1250, Val MSE: 1467528.2500, Val MAE: 579.0794\n",
      "Epoch 540, Train Loss: 1139722.3750, Val MSE: 1461396.7500, Val MAE: 578.7567\n",
      "Epoch 550, Train Loss: 1156811.7500, Val MSE: 1529393.1250, Val MAE: 600.3537\n",
      "Epoch 560, Train Loss: 1097206.2500, Val MSE: 1454374.7500, Val MAE: 577.1267\n",
      "Epoch 570, Train Loss: 1094462.7500, Val MSE: 1459578.2500, Val MAE: 574.6200\n",
      "Epoch 580, Train Loss: 1096476.1250, Val MSE: 1441976.1250, Val MAE: 567.7207\n",
      "Epoch 590, Train Loss: 1205461.8750, Val MSE: 1581359.2500, Val MAE: 622.3857\n",
      "Epoch 600, Train Loss: 1093890.5000, Val MSE: 1491917.6250, Val MAE: 582.3622\n",
      "Epoch 610, Train Loss: 1069766.5000, Val MSE: 1456332.5000, Val MAE: 576.2189\n",
      "Epoch 620, Train Loss: 1095027.8750, Val MSE: 1446126.6250, Val MAE: 570.8948\n",
      "Epoch 630, Train Loss: 1089662.6250, Val MSE: 1502045.8750, Val MAE: 576.8923\n",
      "Epoch 640, Train Loss: 1090377.8750, Val MSE: 1424718.5000, Val MAE: 559.5344\n",
      "Epoch 650, Train Loss: 1034124.6250, Val MSE: 1427433.5000, Val MAE: 559.5632\n",
      "Epoch 660, Train Loss: 1037724.6875, Val MSE: 1415920.6250, Val MAE: 554.2760\n",
      "Epoch 670, Train Loss: 1105016.1250, Val MSE: 1500437.3750, Val MAE: 597.5971\n",
      "Epoch 680, Train Loss: 1029473.3125, Val MSE: 1422917.8750, Val MAE: 554.3331\n",
      "Epoch 690, Train Loss: 1024909.5000, Val MSE: 1431096.7500, Val MAE: 554.3523\n",
      "Epoch 700, Train Loss: 1160519.5000, Val MSE: 1439931.8750, Val MAE: 569.1850\n",
      "Epoch 710, Train Loss: 1108181.7500, Val MSE: 1513024.7500, Val MAE: 606.4424\n",
      "Epoch 720, Train Loss: 1264767.2500, Val MSE: 1452461.0000, Val MAE: 571.2393\n",
      "Epoch 730, Train Loss: 1462555.3750, Val MSE: 1526213.7500, Val MAE: 599.2973\n",
      "Epoch 740, Train Loss: 1125606.0000, Val MSE: 1571012.6250, Val MAE: 624.0239\n",
      "Epoch 750, Train Loss: 1149912.2500, Val MSE: 1582080.7500, Val MAE: 607.0103\n",
      "Epoch 760, Train Loss: 1143863.7500, Val MSE: 1399903.0000, Val MAE: 552.9751\n",
      "Epoch 770, Train Loss: 1006112.1250, Val MSE: 1433965.3750, Val MAE: 569.9398\n",
      "Epoch 780, Train Loss: 986689.7500, Val MSE: 1409654.2500, Val MAE: 552.0175\n",
      "Epoch 790, Train Loss: 977296.0000, Val MSE: 1409269.2500, Val MAE: 547.2928\n",
      "Epoch 800, Train Loss: 985479.6875, Val MSE: 1398355.1250, Val MAE: 548.2723\n",
      "Epoch 810, Train Loss: 961750.3125, Val MSE: 1398962.2500, Val MAE: 544.2748\n",
      "Epoch 820, Train Loss: 950121.8125, Val MSE: 1393759.8750, Val MAE: 541.7619\n",
      "Epoch 830, Train Loss: 943188.0625, Val MSE: 1393936.2500, Val MAE: 541.2709\n",
      "Epoch 840, Train Loss: 950747.1875, Val MSE: 1408774.8750, Val MAE: 543.1453\n",
      "Epoch 850, Train Loss: 937298.2500, Val MSE: 1397034.2500, Val MAE: 539.7538\n",
      "Epoch 860, Train Loss: 1024198.5000, Val MSE: 1560501.1250, Val MAE: 586.9699\n",
      "Epoch 870, Train Loss: 964886.1250, Val MSE: 1459513.2500, Val MAE: 566.6422\n",
      "Epoch 880, Train Loss: 961901.6250, Val MSE: 1457947.6250, Val MAE: 561.1567\n",
      "Epoch 890, Train Loss: 915919.0000, Val MSE: 1396341.6250, Val MAE: 538.7048\n",
      "Epoch 900, Train Loss: 1037904.8750, Val MSE: 1501276.7500, Val MAE: 586.6281\n",
      "Epoch 910, Train Loss: 916645.3750, Val MSE: 1408292.3750, Val MAE: 540.0999\n",
      "Epoch 920, Train Loss: 1011293.1875, Val MSE: 1471654.5000, Val MAE: 567.1980\n",
      "Epoch 930, Train Loss: 975907.3750, Val MSE: 1463227.5000, Val MAE: 552.4038\n",
      "Epoch 940, Train Loss: 1021929.2500, Val MSE: 1441726.7500, Val MAE: 552.3918\n",
      "Epoch 950, Train Loss: 963721.8125, Val MSE: 1435064.5000, Val MAE: 557.3004\n",
      "Epoch 960, Train Loss: 1018001.3750, Val MSE: 1525201.1250, Val MAE: 568.3821\n",
      "Epoch 970, Train Loss: 972774.7500, Val MSE: 1522002.8750, Val MAE: 593.5445\n",
      "Epoch 980, Train Loss: 890613.3750, Val MSE: 1419250.3750, Val MAE: 548.1448\n",
      "Epoch 990, Train Loss: 1015061.0000, Val MSE: 1651880.8750, Val MAE: 648.9941\n",
      "Epoch 1000, Train Loss: 1098733.2500, Val MSE: 1461281.5000, Val MAE: 551.4569\n",
      "Epoch 1010, Train Loss: 908647.0625, Val MSE: 1452589.8750, Val MAE: 550.9532\n",
      "Epoch 1020, Train Loss: 1044191.0625, Val MSE: 1728612.6250, Val MAE: 663.4599\n",
      "Epoch 1030, Train Loss: 996344.6875, Val MSE: 1528572.8750, Val MAE: 554.7784\n",
      "Epoch 1040, Train Loss: 943918.8750, Val MSE: 1453201.8750, Val MAE: 553.2427\n",
      "Epoch 1050, Train Loss: 912142.6250, Val MSE: 1387129.6250, Val MAE: 536.2040\n",
      "Epoch 1060, Train Loss: 868916.0625, Val MSE: 1395018.5000, Val MAE: 531.4744\n",
      "Epoch 1070, Train Loss: 898732.8125, Val MSE: 1438742.1250, Val MAE: 552.3519\n",
      "Epoch 1080, Train Loss: 1006614.1875, Val MSE: 1464381.2500, Val MAE: 557.0251\n",
      "Epoch 1090, Train Loss: 913502.7500, Val MSE: 1421599.1250, Val MAE: 540.2736\n",
      "Epoch 1100, Train Loss: 946342.4375, Val MSE: 1484421.1250, Val MAE: 563.0649\n",
      "Epoch 1110, Train Loss: 876760.0625, Val MSE: 1451643.5000, Val MAE: 551.3610\n",
      "Epoch 1120, Train Loss: 900970.3125, Val MSE: 1408742.2500, Val MAE: 532.6216\n",
      "Epoch 1130, Train Loss: 870292.4375, Val MSE: 1405258.1250, Val MAE: 531.2124\n",
      "Epoch 1140, Train Loss: 916569.3750, Val MSE: 1456850.2500, Val MAE: 564.7265\n",
      "Epoch 1150, Train Loss: 895301.1250, Val MSE: 1496756.5000, Val MAE: 547.9039\n",
      "Epoch 1160, Train Loss: 872464.6250, Val MSE: 1416194.0000, Val MAE: 534.9816\n",
      "Epoch 1170, Train Loss: 1034479.5000, Val MSE: 1500149.3750, Val MAE: 569.0604\n",
      "Epoch 1180, Train Loss: 914294.6250, Val MSE: 1447711.2500, Val MAE: 539.1082\n",
      "Epoch 1190, Train Loss: 879108.0625, Val MSE: 1443831.8750, Val MAE: 555.7031\n",
      "Epoch 1200, Train Loss: 930897.1250, Val MSE: 1575481.7500, Val MAE: 566.1404\n",
      "Epoch 1210, Train Loss: 913308.1250, Val MSE: 1531714.7500, Val MAE: 595.4094\n",
      "Epoch 1220, Train Loss: 1630358.3750, Val MSE: 2421656.2500, Val MAE: 808.1639\n",
      "Epoch 1230, Train Loss: 2762826.5000, Val MSE: 2373535.2500, Val MAE: 730.5952\n",
      "Epoch 1240, Train Loss: 1554009.8750, Val MSE: 2222969.5000, Val MAE: 763.7703\n",
      "Epoch 1250, Train Loss: 1261549.6250, Val MSE: 1559757.1250, Val MAE: 608.9775\n",
      "Epoch 1260, Train Loss: 1094041.2500, Val MSE: 1421814.0000, Val MAE: 553.9568\n",
      "Epoch 1270, Train Loss: 979394.7500, Val MSE: 1417376.5000, Val MAE: 552.6519\n",
      "Epoch 1280, Train Loss: 936850.7500, Val MSE: 1394095.2500, Val MAE: 537.0529\n",
      "Epoch 1290, Train Loss: 907583.6250, Val MSE: 1382111.7500, Val MAE: 530.6401\n",
      "Epoch 1300, Train Loss: 885418.3750, Val MSE: 1379418.8750, Val MAE: 527.0105\n",
      "Epoch 1310, Train Loss: 869444.6250, Val MSE: 1383546.3750, Val MAE: 525.4318\n",
      "Epoch 1320, Train Loss: 856812.6250, Val MSE: 1383805.7500, Val MAE: 524.0912\n",
      "Epoch 1330, Train Loss: 846718.3750, Val MSE: 1386094.8750, Val MAE: 523.4538\n",
      "Epoch 1340, Train Loss: 837897.5625, Val MSE: 1387168.6250, Val MAE: 522.9296\n",
      "Epoch 1350, Train Loss: 830091.4375, Val MSE: 1389208.6250, Val MAE: 522.5515\n",
      "Epoch 1360, Train Loss: 823185.8750, Val MSE: 1391819.5000, Val MAE: 522.4665\n",
      "Epoch 1370, Train Loss: 816589.9375, Val MSE: 1393413.6250, Val MAE: 522.3381\n",
      "Epoch 1380, Train Loss: 811101.8125, Val MSE: 1395426.8750, Val MAE: 521.9103\n",
      "Epoch 1390, Train Loss: 805268.0625, Val MSE: 1398087.7500, Val MAE: 522.0938\n",
      "Epoch 1400, Train Loss: 801567.6250, Val MSE: 1405686.7500, Val MAE: 523.2297\n",
      "Epoch 1410, Train Loss: 796802.4375, Val MSE: 1402745.5000, Val MAE: 521.8124\n",
      "Epoch 1420, Train Loss: 792112.8750, Val MSE: 1413079.6250, Val MAE: 523.6295\n",
      "Epoch 1430, Train Loss: 786496.5000, Val MSE: 1408720.1250, Val MAE: 522.2889\n",
      "Epoch 1440, Train Loss: 791475.6875, Val MSE: 1414444.6250, Val MAE: 523.0656\n",
      "Epoch 1450, Train Loss: 783251.2500, Val MSE: 1430186.6250, Val MAE: 526.9151\n",
      "Epoch 1460, Train Loss: 795728.4375, Val MSE: 1430676.6250, Val MAE: 526.6653\n",
      "Epoch 1470, Train Loss: 855575.8125, Val MSE: 1521890.1250, Val MAE: 551.4918\n",
      "Epoch 1480, Train Loss: 823885.6875, Val MSE: 1497029.5000, Val MAE: 547.9328\n",
      "Epoch 1490, Train Loss: 770379.7500, Val MSE: 1424495.0000, Val MAE: 524.7200\n",
      "Epoch 1500, Train Loss: 798138.5000, Val MSE: 1426670.0000, Val MAE: 523.5601\n",
      "Epoch 1510, Train Loss: 863011.8750, Val MSE: 1553493.3750, Val MAE: 563.3941\n",
      "Epoch 1520, Train Loss: 775338.3750, Val MSE: 1439789.1250, Val MAE: 527.2306\n",
      "Epoch 1530, Train Loss: 804395.1250, Val MSE: 1428565.7500, Val MAE: 523.1933\n",
      "Epoch 1540, Train Loss: 867971.1875, Val MSE: 1570924.8750, Val MAE: 570.0222\n",
      "Epoch 1550, Train Loss: 774644.2500, Val MSE: 1449429.2500, Val MAE: 529.2816\n",
      "Epoch 1560, Train Loss: 783888.5000, Val MSE: 1426822.3750, Val MAE: 521.8073\n",
      "Epoch 1570, Train Loss: 886206.8750, Val MSE: 1569383.3750, Val MAE: 574.5393\n",
      "Epoch 1580, Train Loss: 778205.0625, Val MSE: 1470050.0000, Val MAE: 536.9149\n",
      "Epoch 1590, Train Loss: 769262.8125, Val MSE: 1428230.8750, Val MAE: 521.5717\n",
      "Epoch 1600, Train Loss: 897927.9375, Val MSE: 1595405.3750, Val MAE: 585.2666\n",
      "Epoch 1610, Train Loss: 773168.6875, Val MSE: 1472141.1250, Val MAE: 537.0207\n",
      "Epoch 1620, Train Loss: 776036.7500, Val MSE: 1434943.0000, Val MAE: 522.1088\n",
      "Epoch 1630, Train Loss: 886693.7500, Val MSE: 1608163.1250, Val MAE: 590.8954\n",
      "Epoch 1640, Train Loss: 764706.3750, Val MSE: 1475282.8750, Val MAE: 539.4290\n",
      "Epoch 1650, Train Loss: 777274.7500, Val MSE: 1445011.8750, Val MAE: 523.0597\n",
      "Epoch 1660, Train Loss: 745045.1250, Val MSE: 1489422.2500, Val MAE: 536.6769\n",
      "Epoch 1670, Train Loss: 743953.8750, Val MSE: 1463134.3750, Val MAE: 542.3218\n",
      "Epoch 1680, Train Loss: 739347.7500, Val MSE: 1449648.2500, Val MAE: 532.8627\n",
      "Epoch 1690, Train Loss: 858231.0625, Val MSE: 1626496.7500, Val MAE: 589.3135\n",
      "Epoch 1700, Train Loss: 733034.7500, Val MSE: 1458670.7500, Val MAE: 529.4301\n",
      "Epoch 1710, Train Loss: 874055.1250, Val MSE: 1526669.3750, Val MAE: 551.0761\n",
      "Epoch 1720, Train Loss: 785907.1875, Val MSE: 1538878.8750, Val MAE: 547.0217\n",
      "Epoch 1730, Train Loss: 724377.8750, Val MSE: 1468253.8750, Val MAE: 529.7089\n",
      "Epoch 1740, Train Loss: 852439.0000, Val MSE: 1613221.7500, Val MAE: 573.3270\n",
      "Epoch 1750, Train Loss: 747069.1250, Val MSE: 1504086.1250, Val MAE: 535.6064\n",
      "Epoch 1760, Train Loss: 779617.3750, Val MSE: 1528219.6250, Val MAE: 544.3534\n",
      "Epoch 1770, Train Loss: 708829.9375, Val MSE: 1458794.2500, Val MAE: 527.4414\n",
      "Epoch 1780, Train Loss: 962646.6875, Val MSE: 1820784.3750, Val MAE: 653.2607\n",
      "Epoch 1790, Train Loss: 902400.9375, Val MSE: 1548523.2500, Val MAE: 545.7466\n",
      "Early stopping triggered at epoch 1790\n",
      "\n",
      " Best Val MAE: 521.5717 at epoch 1590\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd4, best_mae, best_epoch = train_widedeep(model_wd4, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "351b60fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 810916.0000, Val MSE: 1467394.5000, Val MAE: 524.6793\n",
      "Epoch 20, Train Loss: 727725.1250, Val MSE: 1453646.7500, Val MAE: 523.0399\n",
      "Epoch 30, Train Loss: 707531.3125, Val MSE: 1455748.7500, Val MAE: 526.5969\n",
      "Epoch 40, Train Loss: 701223.7500, Val MSE: 1461475.7500, Val MAE: 526.0409\n",
      "Epoch 50, Train Loss: 697725.5000, Val MSE: 1463386.8750, Val MAE: 522.9225\n",
      "Epoch 60, Train Loss: 696483.3125, Val MSE: 1460734.7500, Val MAE: 522.4268\n",
      "Epoch 70, Train Loss: 695171.1875, Val MSE: 1461113.0000, Val MAE: 522.5841\n",
      "Epoch 80, Train Loss: 694125.3125, Val MSE: 1463672.6250, Val MAE: 522.7336\n",
      "Epoch 90, Train Loss: 693174.0000, Val MSE: 1465217.3750, Val MAE: 523.0026\n",
      "Epoch 100, Train Loss: 692272.2500, Val MSE: 1466114.0000, Val MAE: 523.0999\n",
      "Epoch 110, Train Loss: 691399.6250, Val MSE: 1468009.5000, Val MAE: 523.3466\n",
      "Epoch 120, Train Loss: 690523.7500, Val MSE: 1469382.3750, Val MAE: 523.5325\n",
      "Epoch 130, Train Loss: 689654.3125, Val MSE: 1471424.0000, Val MAE: 523.7420\n",
      "Epoch 140, Train Loss: 688784.8750, Val MSE: 1472885.1250, Val MAE: 523.9160\n",
      "Epoch 150, Train Loss: 687901.0000, Val MSE: 1473667.7500, Val MAE: 524.0320\n",
      "Epoch 160, Train Loss: 686991.3750, Val MSE: 1475607.6250, Val MAE: 524.2803\n",
      "Epoch 170, Train Loss: 686084.8750, Val MSE: 1476520.5000, Val MAE: 524.4091\n",
      "Epoch 180, Train Loss: 685180.4375, Val MSE: 1477777.6250, Val MAE: 524.5712\n",
      "Epoch 190, Train Loss: 684241.1875, Val MSE: 1479568.1250, Val MAE: 524.7475\n",
      "Epoch 200, Train Loss: 683292.5625, Val MSE: 1481126.2500, Val MAE: 524.9238\n",
      "Epoch 210, Train Loss: 682368.0625, Val MSE: 1482192.8750, Val MAE: 525.0306\n",
      "Epoch 220, Train Loss: 681457.8750, Val MSE: 1483340.5000, Val MAE: 525.1512\n",
      "Epoch 230, Train Loss: 680498.6875, Val MSE: 1484946.0000, Val MAE: 525.3605\n",
      "Epoch 240, Train Loss: 679535.1875, Val MSE: 1486182.7500, Val MAE: 525.4590\n",
      "Epoch 250, Train Loss: 678559.0000, Val MSE: 1488484.1250, Val MAE: 525.7349\n",
      "Epoch 260, Train Loss: 677627.3750, Val MSE: 1489477.5000, Val MAE: 525.8531\n",
      "Early stopping triggered at epoch 260\n",
      "\n",
      " Best Val MAE: 522.4268 at epoch 60\n",
      " Model saved to best_widedeep_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_wd4, best_mae, best_epoch = train_widedeep(model_wd4, X_train3, y_train3, X_val3, y_val3, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5ceeb0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of wd4: 215476\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_wd4.parameters())\n",
    "print(f\"Total Parameters of wd4: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_05WSsGta1zd",
   "metadata": {
    "id": "_05WSsGta1zd"
   },
   "source": [
    "## 4.5 DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2e64d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    \"\"\"FM part\"\"\"\n",
    "    def __init__(self, latent_dim, fea_num):\n",
    "        \"\"\"\n",
    "        latent_dim: 各个离散特征隐向量的维度\n",
    "        input_shape: 这个最后离散特征embedding之后的拼接和dense拼接的总特征个数\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        # 定义三个矩阵， 一个是全局偏置，一个是一阶权重矩阵， 一个是二阶交叉矩阵，注意这里的参数由于是可学习参数，需要用nn.Parameter进行定义\n",
    "        self.w0 = nn.Parameter(torch.zeros([1,]))\n",
    "        self.w1 = nn.Parameter(torch.rand([fea_num, 1]))\n",
    "        self.w2 = nn.Parameter(torch.rand([fea_num, latent_dim]))\n",
    "        \n",
    "    def forward(self, inputs):   \n",
    "        # 一阶交叉\n",
    "        first_order = self.w0 + torch.mm(inputs, self.w1)      # (samples_num, 1)\n",
    "        # 二阶交叉  这个用FM的最终化简公式\n",
    "        second_order = 1/2 * torch.sum(\n",
    "            torch.pow(torch.mm(inputs, self.w2), 2) - torch.mm(torch.pow(inputs,2), torch.pow(self.w2, 2)),\n",
    "            dim = 1,\n",
    "            keepdim = True\n",
    "        )         # (samples_num, 1)\n",
    "        \n",
    "        return first_order + second_order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0be51009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn(nn.Module):\n",
    "    \"\"\"Dnn part\"\"\"\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        \"\"\"\n",
    "        hidden_units: 列表， 每个元素表示每一层的神经单元个数， 比如[256, 128, 64], 两层网络， 第一层神经单元128， 第二层64， 第一个维度是输入维度\n",
    "        dropout = 0.\n",
    "        \"\"\"\n",
    "        super(Dnn, self).__init__()\n",
    "        \n",
    "        self.dnn_network = nn.ModuleList([nn.Linear(layer[0], layer[1]) for layer in list(zip(hidden_units[:-1], hidden_units[1:]))])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        for linear in self.dnn_network:\n",
    "            x = linear(x)\n",
    "            x = F.relu(x)    \n",
    "        x = self.dropout(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9f0c208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.):\n",
    "        \"\"\"\n",
    "        DeepFM:\n",
    "        :param feature_columns: 特征信息， 这个传入的是fea_cols\n",
    "        :param hidden_units: 隐藏单元个数， 一个列表的形式， 列表的长度代表层数， 每个元素代表每一层神经元个数\n",
    "        \"\"\"\n",
    "        super(DeepFM, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        \n",
    "        # embedding\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim'])\n",
    "            for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        # 这里要注意Pytorch的linear和tf的dense的不同之处， 前者的linear需要输入特征和输出特征维度， 而传入的hidden_units的第一个是第一层隐藏的神经单元个数，这里需要加个输入维度\n",
    "        self.fea_num = len(self.dense_feature_cols) + len(self.sparse_feature_cols)*self.sparse_feature_cols[0]['embed_dim']\n",
    "        hidden_units.insert(0, self.fea_num)\n",
    "        \n",
    "        self.fm = FM(self.sparse_feature_cols[0]['embed_dim'], self.fea_num)     \n",
    "        self.dnn_network = Dnn(hidden_units, dnn_dropout)\n",
    "        self.nn_final_linear = nn.Linear(hidden_units[-1], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):]\n",
    "        sparse_inputs = sparse_inputs.long()       # 转成long类型才能作为nn.embedding的输入\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embeds = torch.cat(sparse_embeds, dim=-1)\n",
    "        \n",
    "        # 把离散特征和连续特征进行拼接作为FM和DNN的输入\n",
    "        x = torch.cat([sparse_embeds, dense_inputs], dim=-1)\n",
    "        # Wide\n",
    "        wide_outputs = self.fm(x)\n",
    "        # deep\n",
    "        deep_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "        \n",
    "        # 模型的最后输出\n",
    "        outputs = wide_outputs + deep_outputs\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8154d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepfm(model, X_train, y_train, X_val, y_val, \n",
    "                 epochs=5000, lr=0.01, patience=20, print_every=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    wait = 0\n",
    "    best_model_state = None\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(X_val)\n",
    "                val_loss = loss_fn(val_pred, y_val).item()\n",
    "                val_mae = mean_absolute_error(y_val.numpy(), val_pred.numpy())\n",
    "\n",
    "                if val_mae < best_mae:\n",
    "                    best_mae = val_mae\n",
    "                    best_epoch = epoch + 1\n",
    "                    wait = 0\n",
    "                    best_model_state = model.state_dict()\n",
    "                else:\n",
    "                    wait += 1\n",
    "                    if wait >= patience:\n",
    "                        print(f\" Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "                print(f\"Epoch {epoch+1}, Train Loss: {loss.item():.4f}, Val MSE: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\n Best Val MAE: {best_mae:.4f} at epoch {best_epoch}\")\n",
    "        torch.save(best_model_state, \"best_deepfm_model.pt\")\n",
    "        print(\" Model saved to best_deepfm_model.pt\")\n",
    "\n",
    "    return model, best_mae, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ced24fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFM(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (fm): FM()\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (nn_final_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 10, Train Loss: 90109448.0000, Val MSE: 90330376.0000, Val MAE: 5918.4883\n",
      "Epoch 20, Train Loss: 73573264.0000, Val MSE: 71879608.0000, Val MAE: 4927.5908\n",
      "Epoch 30, Train Loss: 40486808.0000, Val MSE: 38233016.0000, Val MAE: 3529.5757\n",
      "Epoch 40, Train Loss: 29643602.0000, Val MSE: 28443432.0000, Val MAE: 3703.3804\n",
      "Epoch 50, Train Loss: 18871776.0000, Val MSE: 18776796.0000, Val MAE: 2326.3110\n",
      "Epoch 60, Train Loss: 13714627.0000, Val MSE: 13712823.0000, Val MAE: 2067.8545\n",
      "Epoch 70, Train Loss: 11381341.0000, Val MSE: 11472545.0000, Val MAE: 1920.0220\n",
      "Epoch 80, Train Loss: 10029783.0000, Val MSE: 10196617.0000, Val MAE: 1783.1345\n",
      "Epoch 90, Train Loss: 9154638.0000, Val MSE: 9318139.0000, Val MAE: 1767.0719\n",
      "Epoch 100, Train Loss: 8469687.0000, Val MSE: 8627349.0000, Val MAE: 1679.4996\n",
      "Epoch 110, Train Loss: 7863569.0000, Val MSE: 8008593.0000, Val MAE: 1599.0780\n",
      "Epoch 120, Train Loss: 7300253.5000, Val MSE: 7434025.5000, Val MAE: 1498.3846\n",
      "Epoch 130, Train Loss: 6782707.5000, Val MSE: 6905775.5000, Val MAE: 1402.6343\n",
      "Epoch 140, Train Loss: 6318296.5000, Val MSE: 6434326.0000, Val MAE: 1319.8160\n",
      "Epoch 150, Train Loss: 5926878.5000, Val MSE: 6038748.0000, Val MAE: 1253.5989\n",
      "Epoch 160, Train Loss: 5606054.0000, Val MSE: 5712748.0000, Val MAE: 1205.6436\n",
      "Epoch 170, Train Loss: 5342847.0000, Val MSE: 5441074.0000, Val MAE: 1167.1334\n",
      "Epoch 180, Train Loss: 5127011.5000, Val MSE: 5213889.0000, Val MAE: 1135.0961\n",
      "Epoch 190, Train Loss: 4946434.0000, Val MSE: 5022511.0000, Val MAE: 1109.0999\n",
      "Epoch 200, Train Loss: 4791292.5000, Val MSE: 4858345.0000, Val MAE: 1087.0182\n",
      "Epoch 210, Train Loss: 4655016.0000, Val MSE: 4714803.0000, Val MAE: 1066.9806\n",
      "Epoch 220, Train Loss: 4534434.5000, Val MSE: 4588546.5000, Val MAE: 1049.7627\n",
      "Epoch 230, Train Loss: 4425766.0000, Val MSE: 4475300.0000, Val MAE: 1034.3501\n",
      "Epoch 240, Train Loss: 4326789.5000, Val MSE: 4372862.0000, Val MAE: 1020.2955\n",
      "Epoch 250, Train Loss: 4235979.0000, Val MSE: 4279814.5000, Val MAE: 1007.2474\n",
      "Epoch 260, Train Loss: 4151793.7500, Val MSE: 4193853.7500, Val MAE: 995.0610\n",
      "Epoch 270, Train Loss: 4072357.5000, Val MSE: 4114195.0000, Val MAE: 983.3680\n",
      "Epoch 280, Train Loss: 3996437.7500, Val MSE: 4038451.7500, Val MAE: 972.2444\n",
      "Epoch 290, Train Loss: 3922466.5000, Val MSE: 3964922.2500, Val MAE: 961.1345\n",
      "Epoch 300, Train Loss: 3848663.2500, Val MSE: 3890301.5000, Val MAE: 950.5717\n",
      "Epoch 310, Train Loss: 3767651.0000, Val MSE: 3806215.0000, Val MAE: 940.0344\n",
      "Epoch 320, Train Loss: 3668504.0000, Val MSE: 3700047.0000, Val MAE: 926.1624\n",
      "Epoch 330, Train Loss: 3565577.5000, Val MSE: 3596701.0000, Val MAE: 912.2170\n",
      "Epoch 340, Train Loss: 3456008.5000, Val MSE: 3481343.7500, Val MAE: 898.8370\n",
      "Epoch 350, Train Loss: 3338558.2500, Val MSE: 3355442.0000, Val MAE: 884.0490\n",
      "Epoch 360, Train Loss: 3222901.5000, Val MSE: 3236847.7500, Val MAE: 868.4922\n",
      "Epoch 370, Train Loss: 3112997.7500, Val MSE: 3127005.7500, Val MAE: 853.1232\n",
      "Epoch 380, Train Loss: 3007722.5000, Val MSE: 3019636.5000, Val MAE: 838.9858\n",
      "Epoch 390, Train Loss: 2905682.7500, Val MSE: 2913257.0000, Val MAE: 825.5231\n",
      "Epoch 400, Train Loss: 2812437.5000, Val MSE: 2816027.5000, Val MAE: 813.5668\n",
      "Epoch 410, Train Loss: 2724984.2500, Val MSE: 2725920.2500, Val MAE: 802.0815\n",
      "Epoch 420, Train Loss: 2642429.5000, Val MSE: 2642430.7500, Val MAE: 791.7688\n",
      "Epoch 430, Train Loss: 2562491.2500, Val MSE: 2558387.7500, Val MAE: 780.9443\n",
      "Epoch 440, Train Loss: 2485790.0000, Val MSE: 2479876.5000, Val MAE: 771.0964\n",
      "Epoch 450, Train Loss: 2412131.0000, Val MSE: 2405521.7500, Val MAE: 761.7729\n",
      "Epoch 460, Train Loss: 2342024.7500, Val MSE: 2338255.0000, Val MAE: 753.2632\n",
      "Epoch 470, Train Loss: 2275780.2500, Val MSE: 2276164.7500, Val MAE: 745.3582\n",
      "Epoch 480, Train Loss: 2214015.2500, Val MSE: 2218392.7500, Val MAE: 737.3919\n",
      "Epoch 490, Train Loss: 2157411.0000, Val MSE: 2167622.0000, Val MAE: 730.4307\n",
      "Epoch 500, Train Loss: 2105698.5000, Val MSE: 2122563.7500, Val MAE: 724.4103\n",
      "Epoch 510, Train Loss: 2058320.3750, Val MSE: 2080588.3750, Val MAE: 718.7098\n",
      "Epoch 520, Train Loss: 2015135.8750, Val MSE: 2042004.2500, Val MAE: 713.3295\n",
      "Epoch 530, Train Loss: 1975514.6250, Val MSE: 2006356.6250, Val MAE: 707.7355\n",
      "Epoch 540, Train Loss: 1939375.5000, Val MSE: 1974576.7500, Val MAE: 702.4930\n",
      "Epoch 550, Train Loss: 1906230.1250, Val MSE: 1946206.8750, Val MAE: 697.7543\n",
      "Epoch 560, Train Loss: 1875201.3750, Val MSE: 1919890.0000, Val MAE: 693.2835\n",
      "Epoch 570, Train Loss: 1845696.1250, Val MSE: 1895602.6250, Val MAE: 688.7466\n",
      "Epoch 580, Train Loss: 1817840.3750, Val MSE: 1873827.2500, Val MAE: 684.3431\n",
      "Epoch 590, Train Loss: 1791854.5000, Val MSE: 1853187.0000, Val MAE: 680.9258\n",
      "Epoch 600, Train Loss: 1767551.3750, Val MSE: 1835372.7500, Val MAE: 676.9465\n",
      "Epoch 610, Train Loss: 1744403.1250, Val MSE: 1818133.1250, Val MAE: 673.0869\n",
      "Epoch 620, Train Loss: 1722771.3750, Val MSE: 1803154.5000, Val MAE: 669.5232\n",
      "Epoch 630, Train Loss: 1702494.0000, Val MSE: 1787946.6250, Val MAE: 666.2614\n",
      "Epoch 640, Train Loss: 1683159.3750, Val MSE: 1773417.2500, Val MAE: 662.4833\n",
      "Epoch 650, Train Loss: 1664646.7500, Val MSE: 1758112.7500, Val MAE: 659.7028\n",
      "Epoch 660, Train Loss: 1646404.7500, Val MSE: 1743598.3750, Val MAE: 655.3376\n",
      "Epoch 670, Train Loss: 1630000.5000, Val MSE: 1731457.1250, Val MAE: 651.7887\n",
      "Epoch 680, Train Loss: 1612178.3750, Val MSE: 1717079.2500, Val MAE: 648.8599\n",
      "Epoch 690, Train Loss: 1596156.6250, Val MSE: 1704998.2500, Val MAE: 644.6475\n",
      "Epoch 700, Train Loss: 1579826.8750, Val MSE: 1691785.7500, Val MAE: 641.9300\n",
      "Epoch 710, Train Loss: 1564731.1250, Val MSE: 1679532.6250, Val MAE: 638.5562\n",
      "Epoch 720, Train Loss: 1550339.7500, Val MSE: 1669148.1250, Val MAE: 634.8748\n",
      "Epoch 730, Train Loss: 1534897.5000, Val MSE: 1657543.6250, Val MAE: 631.8644\n",
      "Epoch 740, Train Loss: 1522800.1250, Val MSE: 1649456.7500, Val MAE: 630.6174\n",
      "Epoch 750, Train Loss: 1507272.1250, Val MSE: 1639218.7500, Val MAE: 625.7189\n",
      "Epoch 760, Train Loss: 1493444.5000, Val MSE: 1630364.8750, Val MAE: 623.2849\n",
      "Epoch 770, Train Loss: 1480868.6250, Val MSE: 1621249.0000, Val MAE: 620.8810\n",
      "Epoch 780, Train Loss: 1468975.7500, Val MSE: 1614878.2500, Val MAE: 617.8083\n",
      "Epoch 790, Train Loss: 1454391.0000, Val MSE: 1605063.0000, Val MAE: 615.3077\n",
      "Epoch 800, Train Loss: 1443744.7500, Val MSE: 1598798.2500, Val MAE: 613.3017\n",
      "Epoch 810, Train Loss: 1433420.6250, Val MSE: 1595738.1250, Val MAE: 610.6795\n",
      "Epoch 820, Train Loss: 1420140.2500, Val MSE: 1585360.0000, Val MAE: 608.8694\n",
      "Epoch 830, Train Loss: 1408539.6250, Val MSE: 1577250.1250, Val MAE: 604.7483\n",
      "Epoch 840, Train Loss: 1397786.1250, Val MSE: 1569591.5000, Val MAE: 602.0783\n",
      "Epoch 850, Train Loss: 1390005.3750, Val MSE: 1565848.1250, Val MAE: 600.3521\n",
      "Epoch 860, Train Loss: 1377061.0000, Val MSE: 1555660.0000, Val MAE: 597.8854\n",
      "Epoch 870, Train Loss: 1370841.7500, Val MSE: 1551493.1250, Val MAE: 596.9693\n",
      "Epoch 880, Train Loss: 1359495.6250, Val MSE: 1545142.3750, Val MAE: 593.1732\n",
      "Epoch 890, Train Loss: 1348760.2500, Val MSE: 1537360.5000, Val MAE: 590.9209\n",
      "Epoch 900, Train Loss: 1344389.8750, Val MSE: 1536103.1250, Val MAE: 591.7689\n",
      "Epoch 910, Train Loss: 1333047.3750, Val MSE: 1529474.5000, Val MAE: 587.2719\n",
      "Epoch 920, Train Loss: 1322546.7500, Val MSE: 1521545.2500, Val MAE: 585.2763\n",
      "Epoch 930, Train Loss: 1320953.7500, Val MSE: 1523696.3750, Val MAE: 587.9749\n",
      "Epoch 940, Train Loss: 1308624.7500, Val MSE: 1514191.0000, Val MAE: 582.1265\n",
      "Epoch 950, Train Loss: 1298810.0000, Val MSE: 1506630.5000, Val MAE: 581.1734\n",
      "Epoch 960, Train Loss: 1290536.3750, Val MSE: 1500476.5000, Val MAE: 578.2855\n",
      "Epoch 970, Train Loss: 1285115.6250, Val MSE: 1497512.7500, Val MAE: 576.7261\n",
      "Epoch 980, Train Loss: 1276021.0000, Val MSE: 1490795.7500, Val MAE: 575.0662\n",
      "Epoch 990, Train Loss: 1273336.2500, Val MSE: 1493211.6250, Val MAE: 577.9839\n",
      "Epoch 1000, Train Loss: 1264649.5000, Val MSE: 1486474.6250, Val MAE: 573.1909\n",
      "Epoch 1010, Train Loss: 1259458.2500, Val MSE: 1479396.0000, Val MAE: 572.6163\n",
      "Epoch 1020, Train Loss: 1249979.2500, Val MSE: 1471807.6250, Val MAE: 569.0877\n",
      "Epoch 1030, Train Loss: 1243560.6250, Val MSE: 1467818.5000, Val MAE: 568.3799\n",
      "Epoch 1040, Train Loss: 1237333.1250, Val MSE: 1463503.2500, Val MAE: 566.4478\n",
      "Epoch 1050, Train Loss: 1234856.8750, Val MSE: 1460704.8750, Val MAE: 565.5928\n",
      "Epoch 1060, Train Loss: 1227512.3750, Val MSE: 1457684.1250, Val MAE: 566.2654\n",
      "Epoch 1070, Train Loss: 1219173.0000, Val MSE: 1450004.5000, Val MAE: 562.8950\n",
      "Epoch 1080, Train Loss: 1219730.7500, Val MSE: 1452128.6250, Val MAE: 562.9672\n",
      "Epoch 1090, Train Loss: 1209058.0000, Val MSE: 1444463.1250, Val MAE: 561.8096\n",
      "Epoch 1100, Train Loss: 1203766.7500, Val MSE: 1438446.1250, Val MAE: 559.3941\n",
      "Epoch 1110, Train Loss: 1201974.7500, Val MSE: 1438255.1250, Val MAE: 558.7009\n",
      "Epoch 1120, Train Loss: 1192800.7500, Val MSE: 1431024.8750, Val MAE: 557.0300\n",
      "Epoch 1130, Train Loss: 1195289.0000, Val MSE: 1434946.2500, Val MAE: 559.7980\n",
      "Epoch 1140, Train Loss: 1185332.0000, Val MSE: 1425971.3750, Val MAE: 554.9841\n",
      "Epoch 1150, Train Loss: 1178498.7500, Val MSE: 1419961.3750, Val MAE: 553.5903\n",
      "Epoch 1160, Train Loss: 1178801.8750, Val MSE: 1422046.8750, Val MAE: 555.4272\n",
      "Epoch 1170, Train Loss: 1169341.3750, Val MSE: 1413259.7500, Val MAE: 551.3970\n",
      "Epoch 1180, Train Loss: 1170541.1250, Val MSE: 1413003.5000, Val MAE: 551.4316\n",
      "Epoch 1190, Train Loss: 1163811.0000, Val MSE: 1411607.3750, Val MAE: 552.1754\n",
      "Epoch 1200, Train Loss: 1156195.0000, Val MSE: 1403916.0000, Val MAE: 548.8289\n",
      "Epoch 1210, Train Loss: 1158664.3750, Val MSE: 1407254.5000, Val MAE: 549.7882\n",
      "Epoch 1220, Train Loss: 1149246.2500, Val MSE: 1401548.7500, Val MAE: 548.6637\n",
      "Epoch 1230, Train Loss: 1146822.5000, Val MSE: 1398022.0000, Val MAE: 547.4560\n",
      "Epoch 1240, Train Loss: 1145955.2500, Val MSE: 1398687.8750, Val MAE: 547.1769\n",
      "Epoch 1250, Train Loss: 1138218.1250, Val MSE: 1395252.3750, Val MAE: 546.4872\n",
      "Epoch 1260, Train Loss: 1135336.6250, Val MSE: 1392934.5000, Val MAE: 545.5897\n",
      "Epoch 1270, Train Loss: 1131975.2500, Val MSE: 1392179.1250, Val MAE: 544.7535\n",
      "Epoch 1280, Train Loss: 1128821.8750, Val MSE: 1387913.1250, Val MAE: 543.4520\n",
      "Epoch 1290, Train Loss: 1123686.0000, Val MSE: 1386887.0000, Val MAE: 543.0950\n",
      "Epoch 1300, Train Loss: 1119959.5000, Val MSE: 1385196.0000, Val MAE: 542.3176\n",
      "Epoch 1310, Train Loss: 1117930.5000, Val MSE: 1388240.2500, Val MAE: 543.7845\n",
      "Epoch 1320, Train Loss: 1111305.6250, Val MSE: 1382277.3750, Val MAE: 541.1756\n",
      "Epoch 1330, Train Loss: 1117920.3750, Val MSE: 1389780.3750, Val MAE: 543.9332\n",
      "Epoch 1340, Train Loss: 1106936.6250, Val MSE: 1385093.3750, Val MAE: 542.7260\n",
      "Epoch 1350, Train Loss: 1101608.8750, Val MSE: 1379187.1250, Val MAE: 539.8699\n",
      "Epoch 1360, Train Loss: 1098993.0000, Val MSE: 1378009.1250, Val MAE: 539.4090\n",
      "Epoch 1370, Train Loss: 1099056.8750, Val MSE: 1384427.2500, Val MAE: 542.1549\n",
      "Epoch 1380, Train Loss: 1092098.3750, Val MSE: 1376524.8750, Val MAE: 538.6664\n",
      "Epoch 1390, Train Loss: 1092560.1250, Val MSE: 1377530.8750, Val MAE: 538.7205\n",
      "Epoch 1400, Train Loss: 1087789.6250, Val MSE: 1378971.5000, Val MAE: 539.6427\n",
      "Epoch 1410, Train Loss: 1086184.3750, Val MSE: 1378102.6250, Val MAE: 538.7704\n",
      "Epoch 1420, Train Loss: 1084287.5000, Val MSE: 1377168.1250, Val MAE: 538.1439\n",
      "Epoch 1430, Train Loss: 1076903.2500, Val MSE: 1373880.1250, Val MAE: 536.8057\n",
      "Epoch 1440, Train Loss: 1083289.3750, Val MSE: 1382956.3750, Val MAE: 540.7583\n",
      "Epoch 1450, Train Loss: 1073487.0000, Val MSE: 1373288.8750, Val MAE: 536.2687\n",
      "Epoch 1460, Train Loss: 1070473.8750, Val MSE: 1370495.0000, Val MAE: 535.1927\n",
      "Epoch 1470, Train Loss: 1073252.2500, Val MSE: 1378057.0000, Val MAE: 538.6113\n",
      "Epoch 1480, Train Loss: 1064100.7500, Val MSE: 1368864.7500, Val MAE: 534.4537\n",
      "Epoch 1490, Train Loss: 1068287.7500, Val MSE: 1371870.5000, Val MAE: 535.3519\n",
      "Epoch 1500, Train Loss: 1061869.5000, Val MSE: 1373751.1250, Val MAE: 536.3557\n",
      "Epoch 1510, Train Loss: 1057263.3750, Val MSE: 1368092.8750, Val MAE: 533.8971\n",
      "Epoch 1520, Train Loss: 1060072.7500, Val MSE: 1371810.0000, Val MAE: 534.6959\n",
      "Epoch 1530, Train Loss: 1051770.2500, Val MSE: 1366982.1250, Val MAE: 533.1601\n",
      "Epoch 1540, Train Loss: 1056558.6250, Val MSE: 1374674.0000, Val MAE: 536.3429\n",
      "Epoch 1550, Train Loss: 1047570.0625, Val MSE: 1365622.0000, Val MAE: 532.3264\n",
      "Epoch 1560, Train Loss: 1054383.5000, Val MSE: 1371084.5000, Val MAE: 534.0017\n",
      "Epoch 1570, Train Loss: 1046083.0000, Val MSE: 1370475.7500, Val MAE: 534.5490\n",
      "Epoch 1580, Train Loss: 1041305.2500, Val MSE: 1364353.6250, Val MAE: 531.8928\n",
      "Epoch 1590, Train Loss: 1044795.1875, Val MSE: 1368494.1250, Val MAE: 532.8399\n",
      "Epoch 1600, Train Loss: 1036526.2500, Val MSE: 1364714.5000, Val MAE: 531.7808\n",
      "Epoch 1610, Train Loss: 1043270.5625, Val MSE: 1374103.5000, Val MAE: 535.3337\n",
      "Epoch 1620, Train Loss: 1035037.1875, Val MSE: 1366237.5000, Val MAE: 531.4828\n",
      "Epoch 1630, Train Loss: 1030919.2500, Val MSE: 1364195.0000, Val MAE: 530.8311\n",
      "Epoch 1640, Train Loss: 1034153.2500, Val MSE: 1371866.0000, Val MAE: 533.5614\n",
      "Epoch 1650, Train Loss: 1026802.3125, Val MSE: 1365190.1250, Val MAE: 530.5124\n",
      "Epoch 1660, Train Loss: 1035501.2500, Val MSE: 1372311.3750, Val MAE: 532.3792\n",
      "Epoch 1670, Train Loss: 1027375.6250, Val MSE: 1372429.3750, Val MAE: 533.1557\n",
      "Epoch 1680, Train Loss: 1020545.8125, Val MSE: 1364399.2500, Val MAE: 529.7561\n",
      "Epoch 1690, Train Loss: 1024446.5000, Val MSE: 1367273.0000, Val MAE: 530.4161\n",
      "Epoch 1700, Train Loss: 1019130.6875, Val MSE: 1369027.8750, Val MAE: 531.4348\n",
      "Epoch 1710, Train Loss: 1017916.9375, Val MSE: 1366941.7500, Val MAE: 530.5675\n",
      "Epoch 1720, Train Loss: 1017030.0000, Val MSE: 1367084.0000, Val MAE: 530.0129\n",
      "Epoch 1730, Train Loss: 1012055.4375, Val MSE: 1363616.6250, Val MAE: 528.8767\n",
      "Epoch 1740, Train Loss: 1015087.5000, Val MSE: 1370687.3750, Val MAE: 531.5377\n",
      "Epoch 1750, Train Loss: 1007707.1250, Val MSE: 1363659.8750, Val MAE: 528.6442\n",
      "Epoch 1760, Train Loss: 1014700.4375, Val MSE: 1368494.1250, Val MAE: 529.9660\n",
      "Epoch 1770, Train Loss: 1007234.8125, Val MSE: 1370152.7500, Val MAE: 530.8951\n",
      "Epoch 1780, Train Loss: 1003070.4375, Val MSE: 1365224.1250, Val MAE: 528.7762\n",
      "Epoch 1790, Train Loss: 1007901.3125, Val MSE: 1370213.5000, Val MAE: 529.8748\n",
      "Epoch 1800, Train Loss: 998232.5000, Val MSE: 1365955.6250, Val MAE: 528.7499\n",
      "Epoch 1810, Train Loss: 1004547.6250, Val MSE: 1372555.8750, Val MAE: 531.0538\n",
      "Epoch 1820, Train Loss: 999140.6250, Val MSE: 1368002.3750, Val MAE: 528.9417\n",
      "Epoch 1830, Train Loss: 993321.3125, Val MSE: 1364821.6250, Val MAE: 528.0651\n",
      "Epoch 1840, Train Loss: 999706.1250, Val MSE: 1373832.5000, Val MAE: 531.0231\n",
      "Epoch 1850, Train Loss: 991506.6875, Val MSE: 1365589.7500, Val MAE: 527.8015\n",
      "Epoch 1860, Train Loss: 991825.8125, Val MSE: 1365587.2500, Val MAE: 527.6252\n",
      "Epoch 1870, Train Loss: 992695.0000, Val MSE: 1374742.5000, Val MAE: 530.7686\n",
      "Epoch 1880, Train Loss: 985257.6250, Val MSE: 1365379.7500, Val MAE: 527.2252\n",
      "Epoch 1890, Train Loss: 989722.9375, Val MSE: 1367800.3750, Val MAE: 527.7474\n",
      "Epoch 1900, Train Loss: 984702.2500, Val MSE: 1370730.5000, Val MAE: 529.1890\n",
      "Epoch 1910, Train Loss: 984187.0625, Val MSE: 1367906.2500, Val MAE: 527.9974\n",
      "Epoch 1920, Train Loss: 986095.1875, Val MSE: 1370063.7500, Val MAE: 528.0214\n",
      "Epoch 1930, Train Loss: 977583.1875, Val MSE: 1366694.5000, Val MAE: 527.3467\n",
      "Epoch 1940, Train Loss: 983636.8125, Val MSE: 1373842.0000, Val MAE: 529.8189\n",
      "Epoch 1950, Train Loss: 975768.1875, Val MSE: 1366412.7500, Val MAE: 526.8240\n",
      "Epoch 1960, Train Loss: 980275.5000, Val MSE: 1367858.1250, Val MAE: 527.1514\n",
      "Epoch 1970, Train Loss: 979857.2500, Val MSE: 1375453.5000, Val MAE: 530.2534\n",
      "Epoch 1980, Train Loss: 971485.8750, Val MSE: 1366256.3750, Val MAE: 526.2990\n",
      "Epoch 1990, Train Loss: 973060.1250, Val MSE: 1366778.2500, Val MAE: 526.4182\n",
      "Epoch 2000, Train Loss: 971474.0000, Val MSE: 1372785.3750, Val MAE: 528.8442\n",
      "Epoch 2010, Train Loss: 968410.1875, Val MSE: 1366978.1250, Val MAE: 526.5421\n",
      "Epoch 2020, Train Loss: 974516.8125, Val MSE: 1372307.1250, Val MAE: 527.4714\n",
      "Epoch 2030, Train Loss: 965920.9375, Val MSE: 1372254.0000, Val MAE: 528.0656\n",
      "Epoch 2040, Train Loss: 964376.7500, Val MSE: 1368255.1250, Val MAE: 526.3217\n",
      "Epoch 2050, Train Loss: 971340.4375, Val MSE: 1373871.3750, Val MAE: 527.3774\n",
      "Epoch 2060, Train Loss: 961612.3750, Val MSE: 1373342.3750, Val MAE: 527.6965\n",
      "Epoch 2070, Train Loss: 958947.9375, Val MSE: 1368947.0000, Val MAE: 525.8401\n",
      "Epoch 2080, Train Loss: 965979.1250, Val MSE: 1375289.0000, Val MAE: 527.2438\n",
      "Epoch 2090, Train Loss: 955643.2500, Val MSE: 1371481.5000, Val MAE: 526.4099\n",
      "Epoch 2100, Train Loss: 959559.8750, Val MSE: 1374359.1250, Val MAE: 527.2582\n",
      "Epoch 2110, Train Loss: 954790.5000, Val MSE: 1370382.6250, Val MAE: 525.5604\n",
      "Epoch 2120, Train Loss: 954577.6875, Val MSE: 1369019.2500, Val MAE: 524.9836\n",
      "Epoch 2130, Train Loss: 960669.1875, Val MSE: 1381646.5000, Val MAE: 529.2494\n",
      "Epoch 2140, Train Loss: 951563.3750, Val MSE: 1371963.0000, Val MAE: 525.3511\n",
      "Epoch 2150, Train Loss: 947932.7500, Val MSE: 1369549.6250, Val MAE: 524.5839\n",
      "Epoch 2160, Train Loss: 955019.7500, Val MSE: 1382680.5000, Val MAE: 528.7343\n",
      "Epoch 2170, Train Loss: 944265.0000, Val MSE: 1369822.1250, Val MAE: 524.3477\n",
      "Epoch 2180, Train Loss: 948018.3125, Val MSE: 1371212.5000, Val MAE: 524.5268\n",
      "Epoch 2190, Train Loss: 950265.6875, Val MSE: 1381436.8750, Val MAE: 528.0563\n",
      "Epoch 2200, Train Loss: 940204.6875, Val MSE: 1370513.0000, Val MAE: 523.9868\n",
      "Epoch 2210, Train Loss: 947232.8125, Val MSE: 1374193.2500, Val MAE: 524.8926\n",
      "Epoch 2220, Train Loss: 947268.8125, Val MSE: 1384938.3750, Val MAE: 528.2103\n",
      "Epoch 2230, Train Loss: 937950.9375, Val MSE: 1374253.8750, Val MAE: 524.2816\n",
      "Epoch 2240, Train Loss: 935403.6875, Val MSE: 1372867.7500, Val MAE: 523.7585\n",
      "Epoch 2250, Train Loss: 943356.5000, Val MSE: 1383699.3750, Val MAE: 527.2271\n",
      "Epoch 2260, Train Loss: 934784.3125, Val MSE: 1377044.5000, Val MAE: 524.3510\n",
      "Epoch 2270, Train Loss: 931679.4375, Val MSE: 1374976.1250, Val MAE: 523.7264\n",
      "Epoch 2280, Train Loss: 938729.0625, Val MSE: 1384656.5000, Val MAE: 526.7511\n",
      "Epoch 2290, Train Loss: 930988.8125, Val MSE: 1378208.5000, Val MAE: 524.2106\n",
      "Epoch 2300, Train Loss: 929137.2500, Val MSE: 1376409.0000, Val MAE: 523.4841\n",
      "Epoch 2310, Train Loss: 934659.3750, Val MSE: 1387517.7500, Val MAE: 526.8968\n",
      "Epoch 2320, Train Loss: 924704.9375, Val MSE: 1377010.0000, Val MAE: 523.4680\n",
      "Epoch 2330, Train Loss: 931933.0000, Val MSE: 1381873.8750, Val MAE: 524.5034\n",
      "Epoch 2340, Train Loss: 928228.4375, Val MSE: 1386981.5000, Val MAE: 526.1412\n",
      "Epoch 2350, Train Loss: 920840.7500, Val MSE: 1377982.0000, Val MAE: 523.0814\n",
      "Epoch 2360, Train Loss: 927389.0625, Val MSE: 1383002.0000, Val MAE: 523.9020\n",
      "Epoch 2370, Train Loss: 922921.8125, Val MSE: 1386701.2500, Val MAE: 525.4537\n",
      "Epoch 2380, Train Loss: 917928.2500, Val MSE: 1379688.2500, Val MAE: 522.9499\n",
      "Epoch 2390, Train Loss: 924501.0625, Val MSE: 1386309.3750, Val MAE: 524.1180\n",
      "Epoch 2400, Train Loss: 915869.7500, Val MSE: 1383272.6250, Val MAE: 523.7048\n",
      "Epoch 2410, Train Loss: 922496.1875, Val MSE: 1387846.0000, Val MAE: 524.9823\n",
      "Epoch 2420, Train Loss: 919446.8125, Val MSE: 1387866.3750, Val MAE: 524.1044\n",
      "Epoch 2430, Train Loss: 911497.3125, Val MSE: 1382475.3750, Val MAE: 522.9244\n",
      "Epoch 2440, Train Loss: 918064.5000, Val MSE: 1388925.1250, Val MAE: 524.7166\n",
      "Epoch 2450, Train Loss: 912642.6875, Val MSE: 1385401.1250, Val MAE: 522.9892\n",
      "Epoch 2460, Train Loss: 911635.4375, Val MSE: 1383225.7500, Val MAE: 522.2829\n",
      "Epoch 2470, Train Loss: 916865.6250, Val MSE: 1394896.8750, Val MAE: 526.2368\n",
      "Epoch 2480, Train Loss: 906181.3125, Val MSE: 1383678.0000, Val MAE: 522.1528\n",
      "Epoch 2490, Train Loss: 911228.3125, Val MSE: 1386478.6250, Val MAE: 522.6896\n",
      "Epoch 2500, Train Loss: 908372.8750, Val MSE: 1391804.3750, Val MAE: 524.6357\n",
      "Epoch 2510, Train Loss: 904435.9375, Val MSE: 1385282.6250, Val MAE: 522.3814\n",
      "Epoch 2520, Train Loss: 912154.4375, Val MSE: 1391670.8750, Val MAE: 523.5813\n",
      "Epoch 2530, Train Loss: 903477.5000, Val MSE: 1391925.8750, Val MAE: 524.0228\n",
      "Epoch 2540, Train Loss: 901211.3125, Val MSE: 1387129.3750, Val MAE: 522.4269\n",
      "Epoch 2550, Train Loss: 906691.2500, Val MSE: 1393649.2500, Val MAE: 523.5852\n",
      "Epoch 2560, Train Loss: 897401.1875, Val MSE: 1386956.3750, Val MAE: 522.3193\n",
      "Epoch 2570, Train Loss: 905648.0000, Val MSE: 1395777.2500, Val MAE: 524.7165\n",
      "Epoch 2580, Train Loss: 899313.2500, Val MSE: 1390769.5000, Val MAE: 522.6048\n",
      "Epoch 2590, Train Loss: 896019.7500, Val MSE: 1386581.3750, Val MAE: 521.7617\n",
      "Epoch 2600, Train Loss: 904493.1875, Val MSE: 1400724.7500, Val MAE: 525.9226\n",
      "Epoch 2610, Train Loss: 893024.2500, Val MSE: 1387414.1250, Val MAE: 521.6754\n",
      "Epoch 2620, Train Loss: 896446.4375, Val MSE: 1388213.5000, Val MAE: 521.7196\n",
      "Epoch 2630, Train Loss: 895977.9375, Val MSE: 1396135.3750, Val MAE: 524.3417\n",
      "Epoch 2640, Train Loss: 890364.6875, Val MSE: 1387826.1250, Val MAE: 521.7855\n",
      "Epoch 2650, Train Loss: 897738.0000, Val MSE: 1395162.6250, Val MAE: 522.9816\n",
      "Epoch 2660, Train Loss: 887401.7500, Val MSE: 1389406.0000, Val MAE: 522.0123\n",
      "Epoch 2670, Train Loss: 895263.1875, Val MSE: 1395703.5000, Val MAE: 523.8392\n",
      "Epoch 2680, Train Loss: 892140.5000, Val MSE: 1393895.7500, Val MAE: 522.3911\n",
      "Epoch 2690, Train Loss: 884367.8750, Val MSE: 1389139.6250, Val MAE: 521.6194\n",
      "Epoch 2700, Train Loss: 895156.8750, Val MSE: 1401542.3750, Val MAE: 525.2214\n",
      "Epoch 2710, Train Loss: 883868.5625, Val MSE: 1389895.3750, Val MAE: 521.2974\n",
      "Epoch 2720, Train Loss: 889084.5000, Val MSE: 1391626.3750, Val MAE: 521.5992\n",
      "Epoch 2730, Train Loss: 886877.6875, Val MSE: 1399493.0000, Val MAE: 524.3309\n",
      "Epoch 2740, Train Loss: 880355.9375, Val MSE: 1389527.7500, Val MAE: 521.1399\n",
      "Epoch 2750, Train Loss: 891406.5625, Val MSE: 1398752.3750, Val MAE: 522.7892\n",
      "Epoch 2760, Train Loss: 880995.3750, Val MSE: 1396854.8750, Val MAE: 523.0528\n",
      "Epoch 2770, Train Loss: 877911.2500, Val MSE: 1391204.0000, Val MAE: 521.0455\n",
      "Epoch 2780, Train Loss: 885494.8125, Val MSE: 1397589.5000, Val MAE: 522.0344\n",
      "Epoch 2790, Train Loss: 875489.7500, Val MSE: 1392774.1250, Val MAE: 521.3243\n",
      "Epoch 2800, Train Loss: 886332.3125, Val MSE: 1402568.0000, Val MAE: 524.0984\n",
      "Epoch 2810, Train Loss: 878799.2500, Val MSE: 1396222.6250, Val MAE: 521.3578\n",
      "Epoch 2820, Train Loss: 872855.1250, Val MSE: 1391515.7500, Val MAE: 520.4258\n",
      "Epoch 2830, Train Loss: 882487.6250, Val MSE: 1405249.7500, Val MAE: 524.3126\n",
      "Epoch 2840, Train Loss: 871688.8750, Val MSE: 1392694.5000, Val MAE: 520.2430\n",
      "Epoch 2850, Train Loss: 877047.7500, Val MSE: 1394651.5000, Val MAE: 520.6569\n",
      "Epoch 2860, Train Loss: 877624.2500, Val MSE: 1404725.1250, Val MAE: 523.6973\n",
      "Epoch 2870, Train Loss: 868296.1875, Val MSE: 1392739.0000, Val MAE: 519.9169\n",
      "Epoch 2880, Train Loss: 879054.8750, Val MSE: 1399608.2500, Val MAE: 521.3323\n",
      "Epoch 2890, Train Loss: 871810.2500, Val MSE: 1402714.6250, Val MAE: 522.7314\n",
      "Epoch 2900, Train Loss: 866228.1250, Val MSE: 1393600.5000, Val MAE: 519.9775\n",
      "Epoch 2910, Train Loss: 874489.8750, Val MSE: 1399945.3750, Val MAE: 521.2984\n",
      "Epoch 2920, Train Loss: 864819.8125, Val MSE: 1396894.7500, Val MAE: 520.7819\n",
      "Epoch 2930, Train Loss: 872636.0000, Val MSE: 1402033.2500, Val MAE: 522.3802\n",
      "Epoch 2940, Train Loss: 869805.8125, Val MSE: 1400273.0000, Val MAE: 520.8880\n",
      "Epoch 2950, Train Loss: 861329.8125, Val MSE: 1395051.2500, Val MAE: 520.0161\n",
      "Epoch 2960, Train Loss: 871612.3125, Val MSE: 1406757.1250, Val MAE: 523.2100\n",
      "Epoch 2970, Train Loss: 861874.1875, Val MSE: 1395460.7500, Val MAE: 519.7206\n",
      "Epoch 2980, Train Loss: 864186.2500, Val MSE: 1395352.7500, Val MAE: 519.5234\n",
      "Epoch 2990, Train Loss: 864092.0000, Val MSE: 1404455.5000, Val MAE: 522.2739\n",
      "Epoch 3000, Train Loss: 858216.4375, Val MSE: 1395489.1250, Val MAE: 519.5289\n",
      "Epoch 3010, Train Loss: 866774.6250, Val MSE: 1403095.0000, Val MAE: 521.0431\n",
      "Epoch 3020, Train Loss: 855630.0000, Val MSE: 1397444.2500, Val MAE: 519.8628\n",
      "Epoch 3030, Train Loss: 861854.1250, Val MSE: 1402585.7500, Val MAE: 521.1959\n",
      "Epoch 3040, Train Loss: 859771.3750, Val MSE: 1400043.1250, Val MAE: 519.8467\n",
      "Epoch 3050, Train Loss: 853775.9375, Val MSE: 1395758.8750, Val MAE: 518.9001\n",
      "Epoch 3060, Train Loss: 862273.9375, Val MSE: 1410820.1250, Val MAE: 523.3164\n",
      "Epoch 3070, Train Loss: 851404.2500, Val MSE: 1396544.6250, Val MAE: 518.8655\n",
      "Epoch 3080, Train Loss: 860264.6875, Val MSE: 1401917.1250, Val MAE: 519.7250\n",
      "Epoch 3090, Train Loss: 854617.0625, Val MSE: 1406090.1250, Val MAE: 521.5839\n",
      "Epoch 3100, Train Loss: 852259.1250, Val MSE: 1401038.7500, Val MAE: 519.8232\n",
      "Epoch 3110, Train Loss: 859850.5000, Val MSE: 1408218.3750, Val MAE: 520.8691\n",
      "Epoch 3120, Train Loss: 848056.8750, Val MSE: 1402673.5000, Val MAE: 519.9048\n",
      "Epoch 3130, Train Loss: 852379.0000, Val MSE: 1405085.7500, Val MAE: 520.4752\n",
      "Epoch 3140, Train Loss: 853981.0625, Val MSE: 1406683.8750, Val MAE: 520.0914\n",
      "Epoch 3150, Train Loss: 845163.3750, Val MSE: 1401847.3750, Val MAE: 519.1536\n",
      "Epoch 3160, Train Loss: 857280.1875, Val MSE: 1416362.0000, Val MAE: 523.0234\n",
      "Epoch 3170, Train Loss: 845437.2500, Val MSE: 1403650.2500, Val MAE: 519.1300\n",
      "Epoch 3180, Train Loss: 848064.9375, Val MSE: 1403551.2500, Val MAE: 519.0474\n",
      "Epoch 3190, Train Loss: 851100.3125, Val MSE: 1414754.2500, Val MAE: 522.2363\n",
      "Epoch 3200, Train Loss: 841531.3750, Val MSE: 1403321.6250, Val MAE: 518.8694\n",
      "Epoch 3210, Train Loss: 852195.1875, Val MSE: 1410983.0000, Val MAE: 520.3596\n",
      "Epoch 3220, Train Loss: 841488.0625, Val MSE: 1407769.2500, Val MAE: 520.1258\n",
      "Epoch 3230, Train Loss: 846435.0000, Val MSE: 1409806.1250, Val MAE: 520.5546\n",
      "Epoch 3240, Train Loss: 847904.6875, Val MSE: 1411366.6250, Val MAE: 520.2255\n",
      "Epoch 3250, Train Loss: 837937.8125, Val MSE: 1405904.5000, Val MAE: 519.2863\n",
      "Epoch 3260, Train Loss: 849461.0000, Val MSE: 1417896.0000, Val MAE: 522.4545\n",
      " Early stopping at epoch 3270\n",
      "\n",
      " Best Val MAE: 518.8655 at epoch 3070\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "# 构建一个隐藏层 - input：128， output - 64\n",
    "model = DeepFM(feature_columns, hidden_units=[128, 64]) \n",
    "print(model)\n",
    "model, best_mae, best_epoch = train_deepfm(model, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8072aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 844405.7500, Val MSE: 1410355.2500, Val MAE: 520.1620\n",
      "Epoch 20, Train Loss: 838756.5000, Val MSE: 1407496.7500, Val MAE: 519.3470\n",
      "Epoch 30, Train Loss: 836813.1250, Val MSE: 1406190.7500, Val MAE: 519.0114\n",
      "Epoch 40, Train Loss: 836042.6250, Val MSE: 1405631.2500, Val MAE: 518.8778\n",
      "Epoch 50, Train Loss: 835977.0625, Val MSE: 1405886.7500, Val MAE: 518.8994\n",
      "Epoch 60, Train Loss: 835747.8750, Val MSE: 1406435.6250, Val MAE: 519.0162\n",
      "Epoch 70, Train Loss: 835609.2500, Val MSE: 1406338.7500, Val MAE: 519.0024\n",
      "Epoch 80, Train Loss: 835458.0625, Val MSE: 1406541.2500, Val MAE: 519.0065\n",
      "Epoch 90, Train Loss: 835313.8125, Val MSE: 1406710.3750, Val MAE: 519.0289\n",
      "Epoch 100, Train Loss: 835165.6250, Val MSE: 1406785.0000, Val MAE: 519.0264\n",
      "Epoch 110, Train Loss: 835014.7500, Val MSE: 1406952.8750, Val MAE: 519.0397\n",
      "Epoch 120, Train Loss: 834861.6250, Val MSE: 1407054.7500, Val MAE: 519.0387\n",
      "Epoch 130, Train Loss: 834703.3750, Val MSE: 1407157.8750, Val MAE: 519.0424\n",
      "Epoch 140, Train Loss: 834543.0000, Val MSE: 1407247.6250, Val MAE: 519.0555\n",
      "Epoch 150, Train Loss: 834378.3125, Val MSE: 1407396.6250, Val MAE: 519.0628\n",
      "Epoch 160, Train Loss: 834210.1250, Val MSE: 1407488.6250, Val MAE: 519.0657\n",
      "Epoch 170, Train Loss: 834038.5000, Val MSE: 1407684.5000, Val MAE: 519.0804\n",
      "Epoch 180, Train Loss: 833864.6875, Val MSE: 1407810.2500, Val MAE: 519.0856\n",
      "Epoch 190, Train Loss: 833688.1250, Val MSE: 1407937.7500, Val MAE: 519.0963\n",
      "Epoch 200, Train Loss: 833511.6250, Val MSE: 1408091.8750, Val MAE: 519.1035\n",
      "Epoch 210, Train Loss: 833329.4375, Val MSE: 1408224.1250, Val MAE: 519.1244\n",
      "Epoch 220, Train Loss: 833145.5000, Val MSE: 1408208.5000, Val MAE: 519.1202\n",
      "Epoch 230, Train Loss: 832960.9375, Val MSE: 1408286.0000, Val MAE: 519.1260\n",
      " Early stopping at epoch 240\n",
      "\n",
      " Best Val MAE: 518.8778 at epoch 40\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model, best_mae, best_epoch = train_deepfm(model, X_train3, y_train3, X_val3, y_val3, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3eb60978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of DeepFM: 21044\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters of DeepFM: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d5570",
   "metadata": {},
   "source": [
    "### 4.5.1 在DeepFM框架中使用更深的DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5c5a26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFM(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (fm): FM()\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (nn_final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_deepfm = DeepFM(feature_columns, hidden_units=[256, 128, 64, 32]) \n",
    "print(model_deepfm)  # 展示模块结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1eecf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 86039888.0000, Val MSE: 82082424.0000, Val MAE: 5305.2559\n",
      "Epoch 20, Train Loss: 30728582.0000, Val MSE: 28577824.0000, Val MAE: 3211.7571\n",
      "Epoch 30, Train Loss: 16368136.0000, Val MSE: 17078356.0000, Val MAE: 2629.5061\n",
      "Epoch 40, Train Loss: 10625552.0000, Val MSE: 10251597.0000, Val MAE: 1826.9589\n",
      "Epoch 50, Train Loss: 9128634.0000, Val MSE: 9191116.0000, Val MAE: 1751.2620\n",
      "Epoch 60, Train Loss: 7665145.5000, Val MSE: 7753115.5000, Val MAE: 1554.8774\n",
      "Epoch 70, Train Loss: 6655914.0000, Val MSE: 6703562.5000, Val MAE: 1322.0989\n",
      "Epoch 80, Train Loss: 5927920.5000, Val MSE: 5962115.5000, Val MAE: 1215.4592\n",
      "Epoch 90, Train Loss: 5354696.5000, Val MSE: 5389503.0000, Val MAE: 1146.3243\n",
      "Epoch 100, Train Loss: 4931348.5000, Val MSE: 4959119.0000, Val MAE: 1088.2024\n",
      "Epoch 110, Train Loss: 4620699.0000, Val MSE: 4634200.5000, Val MAE: 1043.7594\n",
      "Epoch 120, Train Loss: 4381707.5000, Val MSE: 4389413.5000, Val MAE: 1009.0343\n",
      "Epoch 130, Train Loss: 4175577.0000, Val MSE: 4188744.7500, Val MAE: 977.9069\n",
      "Epoch 140, Train Loss: 3983747.5000, Val MSE: 3999875.0000, Val MAE: 948.2733\n",
      "Epoch 150, Train Loss: 3789138.0000, Val MSE: 3808041.5000, Val MAE: 918.2683\n",
      "Epoch 160, Train Loss: 3582483.7500, Val MSE: 3602376.2500, Val MAE: 891.8224\n",
      "Epoch 170, Train Loss: 3350019.5000, Val MSE: 3361087.5000, Val MAE: 869.1597\n",
      "Epoch 180, Train Loss: 3106357.7500, Val MSE: 3105930.0000, Val MAE: 853.9470\n",
      "Epoch 190, Train Loss: 2882390.5000, Val MSE: 2883141.7500, Val MAE: 832.5237\n",
      "Epoch 200, Train Loss: 2683336.0000, Val MSE: 2669685.0000, Val MAE: 807.8823\n",
      "Epoch 210, Train Loss: 2499728.5000, Val MSE: 2487204.7500, Val MAE: 776.6912\n",
      "Epoch 220, Train Loss: 2348428.0000, Val MSE: 2352283.2500, Val MAE: 753.0076\n",
      "Epoch 230, Train Loss: 2204352.5000, Val MSE: 2212321.7500, Val MAE: 733.3301\n",
      "Epoch 240, Train Loss: 2096293.1250, Val MSE: 2106882.2500, Val MAE: 719.3753\n",
      "Epoch 250, Train Loss: 2050031.2500, Val MSE: 2038663.8750, Val MAE: 717.1105\n",
      "Epoch 260, Train Loss: 1957676.8750, Val MSE: 1977565.2500, Val MAE: 707.6455\n",
      "Epoch 270, Train Loss: 1878241.2500, Val MSE: 1916993.0000, Val MAE: 692.9227\n",
      "Epoch 280, Train Loss: 1829403.8750, Val MSE: 1878665.5000, Val MAE: 681.7669\n",
      "Epoch 290, Train Loss: 1783911.8750, Val MSE: 1837205.3750, Val MAE: 674.5105\n",
      "Epoch 300, Train Loss: 1767522.0000, Val MSE: 1860274.8750, Val MAE: 685.2936\n",
      "Epoch 310, Train Loss: 1734288.6250, Val MSE: 1776048.7500, Val MAE: 668.7667\n",
      "Epoch 320, Train Loss: 1685482.5000, Val MSE: 1751593.2500, Val MAE: 664.3748\n",
      "Epoch 330, Train Loss: 1639054.1250, Val MSE: 1726751.6250, Val MAE: 658.7057\n",
      "Epoch 340, Train Loss: 1613634.3750, Val MSE: 1712266.3750, Val MAE: 650.5118\n",
      "Epoch 350, Train Loss: 1580483.6250, Val MSE: 1684925.5000, Val MAE: 644.9014\n",
      "Epoch 360, Train Loss: 1572968.6250, Val MSE: 1700506.8750, Val MAE: 660.4819\n",
      "Epoch 370, Train Loss: 1625849.0000, Val MSE: 1666893.8750, Val MAE: 640.2002\n",
      "Epoch 380, Train Loss: 1530087.7500, Val MSE: 1673022.5000, Val MAE: 654.4131\n",
      "Epoch 390, Train Loss: 1506189.1250, Val MSE: 1628413.0000, Val MAE: 633.0392\n",
      "Epoch 400, Train Loss: 1477672.2500, Val MSE: 1620462.0000, Val MAE: 629.9542\n",
      "Epoch 410, Train Loss: 1459113.0000, Val MSE: 1606256.1250, Val MAE: 626.6290\n",
      "Epoch 420, Train Loss: 1442693.6250, Val MSE: 1594736.1250, Val MAE: 624.8649\n",
      "Epoch 430, Train Loss: 1424636.5000, Val MSE: 1585228.0000, Val MAE: 620.9628\n",
      "Epoch 440, Train Loss: 1434289.6250, Val MSE: 1614988.1250, Val MAE: 631.2963\n",
      "Epoch 450, Train Loss: 1392025.6250, Val MSE: 1565518.8750, Val MAE: 617.1603\n",
      "Epoch 460, Train Loss: 1397511.0000, Val MSE: 1565868.5000, Val MAE: 619.9728\n",
      "Epoch 470, Train Loss: 1385510.0000, Val MSE: 1585438.3750, Val MAE: 623.1006\n",
      "Epoch 480, Train Loss: 1350281.7500, Val MSE: 1540274.2500, Val MAE: 609.4953\n",
      "Epoch 490, Train Loss: 1341568.5000, Val MSE: 1533205.2500, Val MAE: 606.9247\n",
      "Epoch 500, Train Loss: 1368690.1250, Val MSE: 1589194.2500, Val MAE: 625.2833\n",
      "Epoch 510, Train Loss: 1316528.0000, Val MSE: 1530475.8750, Val MAE: 608.0804\n",
      "Epoch 520, Train Loss: 1318705.2500, Val MSE: 1523528.6250, Val MAE: 605.4406\n",
      "Epoch 530, Train Loss: 1309141.8750, Val MSE: 1547390.0000, Val MAE: 610.4862\n",
      "Epoch 540, Train Loss: 1278422.5000, Val MSE: 1510199.6250, Val MAE: 599.6266\n",
      "Epoch 550, Train Loss: 1281166.3750, Val MSE: 1529411.1250, Val MAE: 603.5745\n",
      "Epoch 560, Train Loss: 1265953.1250, Val MSE: 1507661.1250, Val MAE: 599.6327\n",
      "Epoch 570, Train Loss: 1257398.6250, Val MSE: 1495504.7500, Val MAE: 594.1484\n",
      "Epoch 580, Train Loss: 1236536.5000, Val MSE: 1487027.6250, Val MAE: 588.3706\n",
      "Epoch 590, Train Loss: 1478537.0000, Val MSE: 1654547.3750, Val MAE: 645.3469\n",
      "Epoch 600, Train Loss: 1309152.5000, Val MSE: 1543667.5000, Val MAE: 608.7252\n",
      "Epoch 610, Train Loss: 1245414.2500, Val MSE: 1490591.6250, Val MAE: 589.0748\n",
      "Epoch 620, Train Loss: 1218118.1250, Val MSE: 1481374.5000, Val MAE: 585.9432\n",
      "Epoch 630, Train Loss: 1194060.7500, Val MSE: 1470834.8750, Val MAE: 581.2632\n",
      "Epoch 640, Train Loss: 1187973.6250, Val MSE: 1467174.0000, Val MAE: 580.7198\n",
      "Epoch 650, Train Loss: 1175741.8750, Val MSE: 1458676.1250, Val MAE: 576.5365\n",
      "Epoch 660, Train Loss: 1173485.0000, Val MSE: 1467990.1250, Val MAE: 579.3409\n",
      "Epoch 670, Train Loss: 1181588.1250, Val MSE: 1465720.1250, Val MAE: 580.7106\n",
      "Epoch 680, Train Loss: 1190399.2500, Val MSE: 1450843.3750, Val MAE: 572.7625\n",
      "Epoch 690, Train Loss: 1170336.5000, Val MSE: 1450790.0000, Val MAE: 572.5659\n",
      "Epoch 700, Train Loss: 1152429.1250, Val MSE: 1455166.6250, Val MAE: 573.0455\n",
      "Epoch 710, Train Loss: 1135391.5000, Val MSE: 1442656.3750, Val MAE: 567.7908\n",
      "Epoch 720, Train Loss: 1130853.5000, Val MSE: 1445711.5000, Val MAE: 567.9840\n",
      "Epoch 730, Train Loss: 1122104.1250, Val MSE: 1443887.5000, Val MAE: 566.7765\n",
      "Epoch 740, Train Loss: 1264894.7500, Val MSE: 1571323.1250, Val MAE: 613.8134\n",
      "Epoch 750, Train Loss: 1125294.3750, Val MSE: 1432108.1250, Val MAE: 562.8271\n",
      "Epoch 760, Train Loss: 1101629.7500, Val MSE: 1439982.2500, Val MAE: 565.6675\n",
      "Epoch 770, Train Loss: 1093608.3750, Val MSE: 1429026.8750, Val MAE: 560.2119\n",
      "Epoch 780, Train Loss: 1133075.5000, Val MSE: 1474933.1250, Val MAE: 578.5568\n",
      "Epoch 790, Train Loss: 1081461.7500, Val MSE: 1423248.5000, Val MAE: 557.1242\n",
      "Epoch 800, Train Loss: 1181064.0000, Val MSE: 1539787.7500, Val MAE: 607.4457\n",
      "Epoch 810, Train Loss: 1115060.7500, Val MSE: 1476926.5000, Val MAE: 578.0137\n",
      "Epoch 820, Train Loss: 1095667.0000, Val MSE: 1451888.2500, Val MAE: 570.0097\n",
      "Epoch 830, Train Loss: 1062507.0000, Val MSE: 1421478.5000, Val MAE: 554.6541\n",
      "Epoch 840, Train Loss: 1143703.0000, Val MSE: 1505543.2500, Val MAE: 586.8799\n",
      "Epoch 850, Train Loss: 1089243.8750, Val MSE: 1462779.1250, Val MAE: 573.1409\n",
      "Epoch 860, Train Loss: 1045036.6250, Val MSE: 1414049.8750, Val MAE: 549.8472\n",
      "Epoch 870, Train Loss: 1125870.6250, Val MSE: 1513021.7500, Val MAE: 587.9532\n",
      "Epoch 880, Train Loss: 1061541.0000, Val MSE: 1450686.1250, Val MAE: 566.6799\n",
      "Epoch 890, Train Loss: 1031658.3750, Val MSE: 1409518.2500, Val MAE: 546.9271\n",
      "Epoch 900, Train Loss: 1091854.1250, Val MSE: 1475440.8750, Val MAE: 573.3426\n",
      "Epoch 910, Train Loss: 1025628.2500, Val MSE: 1415484.1250, Val MAE: 549.0439\n",
      "Epoch 920, Train Loss: 1114466.6250, Val MSE: 1488711.6250, Val MAE: 581.1149\n",
      "Epoch 930, Train Loss: 1041460.8125, Val MSE: 1438840.6250, Val MAE: 557.6826\n",
      "Epoch 940, Train Loss: 1020353.1250, Val MSE: 1406743.5000, Val MAE: 543.4410\n",
      "Epoch 950, Train Loss: 1050133.7500, Val MSE: 1465692.5000, Val MAE: 569.1385\n",
      "Epoch 960, Train Loss: 1005563.7500, Val MSE: 1411576.8750, Val MAE: 545.2382\n",
      "Epoch 970, Train Loss: 1012409.1875, Val MSE: 1427667.8750, Val MAE: 551.7476\n",
      "Epoch 980, Train Loss: 1002007.7500, Val MSE: 1409376.8750, Val MAE: 542.0439\n",
      "Epoch 990, Train Loss: 1014691.6250, Val MSE: 1414485.8750, Val MAE: 543.7177\n",
      "Epoch 1000, Train Loss: 990146.1875, Val MSE: 1399733.1250, Val MAE: 536.5497\n",
      "Epoch 1010, Train Loss: 1160450.8750, Val MSE: 1693423.2500, Val MAE: 629.5867\n",
      "Epoch 1020, Train Loss: 1092881.8750, Val MSE: 1411794.2500, Val MAE: 544.2233\n",
      "Epoch 1030, Train Loss: 1061386.5000, Val MSE: 1443776.5000, Val MAE: 557.3028\n",
      "Epoch 1040, Train Loss: 998972.8750, Val MSE: 1426511.7500, Val MAE: 548.4246\n",
      "Epoch 1050, Train Loss: 981510.6875, Val MSE: 1395880.7500, Val MAE: 533.3737\n",
      "Epoch 1060, Train Loss: 971929.7500, Val MSE: 1396920.0000, Val MAE: 532.8304\n",
      "Epoch 1070, Train Loss: 980382.0000, Val MSE: 1405723.7500, Val MAE: 537.0900\n",
      "Epoch 1080, Train Loss: 999457.7500, Val MSE: 1432612.5000, Val MAE: 547.7246\n",
      "Epoch 1090, Train Loss: 999778.8750, Val MSE: 1397440.8750, Val MAE: 533.8317\n",
      "Epoch 1100, Train Loss: 968069.3750, Val MSE: 1395189.0000, Val MAE: 531.4760\n",
      "Epoch 1110, Train Loss: 973719.7500, Val MSE: 1401511.2500, Val MAE: 534.5533\n",
      "Epoch 1120, Train Loss: 977085.9375, Val MSE: 1432176.3750, Val MAE: 546.3989\n",
      "Epoch 1130, Train Loss: 989470.9375, Val MSE: 1406435.8750, Val MAE: 536.3953\n",
      "Epoch 1140, Train Loss: 990617.3125, Val MSE: 1415739.5000, Val MAE: 540.0328\n",
      "Epoch 1150, Train Loss: 981880.8125, Val MSE: 1438199.3750, Val MAE: 548.4722\n",
      "Epoch 1160, Train Loss: 954905.0625, Val MSE: 1398944.2500, Val MAE: 531.9856\n",
      "Epoch 1170, Train Loss: 974149.2500, Val MSE: 1439485.1250, Val MAE: 547.8738\n",
      "Epoch 1180, Train Loss: 941813.3750, Val MSE: 1397896.2500, Val MAE: 531.3013\n",
      "Epoch 1190, Train Loss: 941997.4375, Val MSE: 1404961.8750, Val MAE: 534.4571\n",
      "Epoch 1200, Train Loss: 935140.3125, Val MSE: 1399770.6250, Val MAE: 531.2227\n",
      "Epoch 1210, Train Loss: 956674.7500, Val MSE: 1414862.1250, Val MAE: 537.5126\n",
      "Epoch 1220, Train Loss: 927609.1875, Val MSE: 1389907.8750, Val MAE: 526.4338\n",
      "Epoch 1230, Train Loss: 1070634.7500, Val MSE: 1629943.0000, Val MAE: 604.5010\n",
      "Epoch 1240, Train Loss: 1089338.3750, Val MSE: 1469862.5000, Val MAE: 564.7325\n",
      "Epoch 1250, Train Loss: 945194.7500, Val MSE: 1444512.2500, Val MAE: 548.3660\n",
      "Epoch 1260, Train Loss: 939606.6875, Val MSE: 1389361.5000, Val MAE: 527.0592\n",
      "Epoch 1270, Train Loss: 918222.7500, Val MSE: 1388290.2500, Val MAE: 524.7052\n",
      "Epoch 1280, Train Loss: 923266.1875, Val MSE: 1392355.6250, Val MAE: 526.2802\n",
      "Epoch 1290, Train Loss: 911357.3125, Val MSE: 1391183.3750, Val MAE: 524.9119\n",
      "Epoch 1300, Train Loss: 1082319.0000, Val MSE: 1612651.8750, Val MAE: 603.9026\n",
      "Epoch 1310, Train Loss: 1026796.3750, Val MSE: 1462562.0000, Val MAE: 553.1475\n",
      "Epoch 1320, Train Loss: 907306.3125, Val MSE: 1391426.1250, Val MAE: 525.5808\n",
      "Epoch 1330, Train Loss: 917381.6875, Val MSE: 1413217.8750, Val MAE: 533.3937\n",
      "Epoch 1340, Train Loss: 903998.0000, Val MSE: 1392802.1250, Val MAE: 525.0257\n",
      "Epoch 1350, Train Loss: 936325.6250, Val MSE: 1423222.8750, Val MAE: 536.4444\n",
      "Epoch 1360, Train Loss: 901700.3125, Val MSE: 1392210.7500, Val MAE: 523.9470\n",
      "Epoch 1370, Train Loss: 909881.4375, Val MSE: 1415764.6250, Val MAE: 532.6332\n",
      "Epoch 1380, Train Loss: 908831.8125, Val MSE: 1402451.6250, Val MAE: 528.1256\n",
      "Epoch 1390, Train Loss: 972087.0625, Val MSE: 1450274.8750, Val MAE: 545.3665\n",
      "Epoch 1400, Train Loss: 892771.3125, Val MSE: 1391675.7500, Val MAE: 522.4630\n",
      "Epoch 1410, Train Loss: 887544.6250, Val MSE: 1398560.0000, Val MAE: 524.8917\n",
      "Epoch 1420, Train Loss: 888319.1250, Val MSE: 1398208.5000, Val MAE: 523.7903\n",
      "Epoch 1430, Train Loss: 892240.5000, Val MSE: 1410590.3750, Val MAE: 528.4171\n",
      "Epoch 1440, Train Loss: 952269.0625, Val MSE: 1403800.6250, Val MAE: 527.2309\n",
      "Epoch 1450, Train Loss: 878625.9375, Val MSE: 1398443.8750, Val MAE: 523.5381\n",
      "Epoch 1460, Train Loss: 876636.3125, Val MSE: 1406356.6250, Val MAE: 525.1578\n",
      "Epoch 1470, Train Loss: 891200.6250, Val MSE: 1413804.5000, Val MAE: 527.2479\n",
      "Epoch 1480, Train Loss: 883827.1875, Val MSE: 1416473.8750, Val MAE: 528.2794\n",
      "Epoch 1490, Train Loss: 942798.6250, Val MSE: 1411084.3750, Val MAE: 528.1943\n",
      "Epoch 1500, Train Loss: 875794.6250, Val MSE: 1398476.0000, Val MAE: 520.9489\n",
      "Epoch 1510, Train Loss: 872050.6250, Val MSE: 1400395.5000, Val MAE: 520.8878\n",
      "Epoch 1520, Train Loss: 914907.6250, Val MSE: 1461899.7500, Val MAE: 543.5739\n",
      "Epoch 1530, Train Loss: 862640.0000, Val MSE: 1403068.7500, Val MAE: 521.0059\n",
      "Epoch 1540, Train Loss: 969047.7500, Val MSE: 1549835.1250, Val MAE: 568.1169\n",
      "Epoch 1550, Train Loss: 929732.7500, Val MSE: 1492216.3750, Val MAE: 555.4413\n",
      "Epoch 1560, Train Loss: 894148.2500, Val MSE: 1437605.3750, Val MAE: 534.2733\n",
      "Epoch 1570, Train Loss: 864108.1250, Val MSE: 1425628.0000, Val MAE: 528.2216\n",
      "Epoch 1580, Train Loss: 919771.2500, Val MSE: 1460071.8750, Val MAE: 541.8422\n",
      "Epoch 1590, Train Loss: 873239.8125, Val MSE: 1433684.5000, Val MAE: 531.0963\n",
      "Epoch 1600, Train Loss: 884383.7500, Val MSE: 1409528.0000, Val MAE: 523.0791\n",
      "Epoch 1610, Train Loss: 922850.0625, Val MSE: 1468976.3750, Val MAE: 544.0872\n",
      "Epoch 1620, Train Loss: 882099.0625, Val MSE: 1446940.5000, Val MAE: 534.9856\n",
      "Epoch 1630, Train Loss: 850154.6250, Val MSE: 1406297.0000, Val MAE: 519.6742\n",
      "Epoch 1640, Train Loss: 941754.6250, Val MSE: 1526483.5000, Val MAE: 561.4558\n",
      "Epoch 1650, Train Loss: 862653.5625, Val MSE: 1440660.7500, Val MAE: 532.4041\n",
      "Epoch 1660, Train Loss: 840265.8125, Val MSE: 1409769.1250, Val MAE: 520.1992\n",
      "Epoch 1670, Train Loss: 915412.6250, Val MSE: 1487467.1250, Val MAE: 548.2571\n",
      "Epoch 1680, Train Loss: 847409.1250, Val MSE: 1427119.1250, Val MAE: 525.8738\n",
      "Epoch 1690, Train Loss: 894250.9375, Val MSE: 1432548.5000, Val MAE: 528.9731\n",
      "Epoch 1700, Train Loss: 913247.4375, Val MSE: 1487193.7500, Val MAE: 546.4197\n",
      "Epoch 1710, Train Loss: 863281.2500, Val MSE: 1451179.8750, Val MAE: 533.4111\n",
      "Epoch 1720, Train Loss: 836715.0625, Val MSE: 1413257.0000, Val MAE: 519.4337\n",
      "Epoch 1730, Train Loss: 917871.4375, Val MSE: 1522322.1250, Val MAE: 556.7083\n",
      "Epoch 1740, Train Loss: 839821.3125, Val MSE: 1438139.5000, Val MAE: 528.6002\n",
      "Epoch 1750, Train Loss: 834328.1250, Val MSE: 1415653.3750, Val MAE: 519.3723\n",
      "Epoch 1760, Train Loss: 898771.3750, Val MSE: 1493966.7500, Val MAE: 545.5310\n",
      "Epoch 1770, Train Loss: 832612.2500, Val MSE: 1434304.2500, Val MAE: 525.4224\n",
      "Epoch 1780, Train Loss: 886971.8125, Val MSE: 1451604.2500, Val MAE: 531.8907\n",
      "Epoch 1790, Train Loss: 900987.6250, Val MSE: 1511064.5000, Val MAE: 550.7322\n",
      "Epoch 1800, Train Loss: 833845.3125, Val MSE: 1444277.2500, Val MAE: 527.7468\n",
      "Epoch 1810, Train Loss: 840080.8125, Val MSE: 1428399.0000, Val MAE: 521.9713\n",
      "Epoch 1820, Train Loss: 883881.0000, Val MSE: 1516999.6250, Val MAE: 550.3961\n",
      "Epoch 1830, Train Loss: 813236.6250, Val MSE: 1429775.5000, Val MAE: 521.6486\n",
      "Epoch 1840, Train Loss: 846322.4375, Val MSE: 1434410.5000, Val MAE: 523.5262\n",
      "Epoch 1850, Train Loss: 879341.9375, Val MSE: 1504272.7500, Val MAE: 544.7447\n",
      "Epoch 1860, Train Loss: 816129.4375, Val MSE: 1440918.6250, Val MAE: 524.1186\n",
      "Epoch 1870, Train Loss: 875143.0000, Val MSE: 1463919.8750, Val MAE: 532.9054\n",
      "Epoch 1880, Train Loss: 889500.3125, Val MSE: 1530243.7500, Val MAE: 551.8086\n",
      "Epoch 1890, Train Loss: 820224.0000, Val MSE: 1455185.2500, Val MAE: 527.6093\n",
      "Epoch 1900, Train Loss: 815038.7500, Val MSE: 1431124.7500, Val MAE: 519.7242\n",
      "Epoch 1910, Train Loss: 883494.2500, Val MSE: 1533531.0000, Val MAE: 552.1893\n",
      "Epoch 1920, Train Loss: 804586.1875, Val MSE: 1445549.0000, Val MAE: 523.4517\n",
      "Epoch 1930, Train Loss: 839462.1875, Val MSE: 1447843.5000, Val MAE: 524.9364\n",
      "Epoch 1940, Train Loss: 875899.1875, Val MSE: 1529550.3750, Val MAE: 549.3226\n",
      " Early stopping at epoch 1950\n",
      "\n",
      " Best Val MAE: 519.3723 at epoch 1750\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm, best_mae_deepfm, best_epoch_deepfm = train_deepfm(model_deepfm, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "863225a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of model_deepfm: 65588\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_deepfm.parameters())\n",
    "print(f\"Total Parameters of model_deepfm: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0cceaf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 886791.6250, Val MSE: 1504203.8750, Val MAE: 545.0732\n",
      "Epoch 20, Train Loss: 822496.1250, Val MSE: 1471376.0000, Val MAE: 532.9175\n",
      "Epoch 30, Train Loss: 801741.5625, Val MSE: 1453838.1250, Val MAE: 525.0746\n",
      "Epoch 40, Train Loss: 796019.9375, Val MSE: 1445429.1250, Val MAE: 521.6674\n",
      "Epoch 50, Train Loss: 793281.6875, Val MSE: 1441382.0000, Val MAE: 520.0952\n",
      "Epoch 60, Train Loss: 791404.5625, Val MSE: 1439659.6250, Val MAE: 519.5133\n",
      "Epoch 70, Train Loss: 790993.5000, Val MSE: 1440244.8750, Val MAE: 519.6014\n",
      "Epoch 80, Train Loss: 790438.8125, Val MSE: 1441805.1250, Val MAE: 519.8516\n",
      "Epoch 90, Train Loss: 789994.8125, Val MSE: 1442160.6250, Val MAE: 519.8688\n",
      "Epoch 100, Train Loss: 789533.3750, Val MSE: 1442973.8750, Val MAE: 519.9457\n",
      "Epoch 110, Train Loss: 789073.0000, Val MSE: 1443738.7500, Val MAE: 520.0164\n",
      "Epoch 120, Train Loss: 788599.9375, Val MSE: 1444600.3750, Val MAE: 520.1008\n",
      "Epoch 130, Train Loss: 788090.1875, Val MSE: 1445486.7500, Val MAE: 520.1766\n",
      "Epoch 140, Train Loss: 787496.0000, Val MSE: 1446443.2500, Val MAE: 520.2572\n",
      "Epoch 150, Train Loss: 786904.1875, Val MSE: 1447559.1250, Val MAE: 520.3469\n",
      "Epoch 160, Train Loss: 786333.8750, Val MSE: 1448379.6250, Val MAE: 520.4216\n",
      "Epoch 170, Train Loss: 785786.1875, Val MSE: 1449351.0000, Val MAE: 520.5301\n",
      "Epoch 180, Train Loss: 785263.9375, Val MSE: 1449898.7500, Val MAE: 520.5604\n",
      "Epoch 190, Train Loss: 784739.7500, Val MSE: 1450340.6250, Val MAE: 520.6041\n",
      "Epoch 200, Train Loss: 784208.8750, Val MSE: 1451096.1250, Val MAE: 520.6938\n",
      "Epoch 210, Train Loss: 783671.0625, Val MSE: 1451807.5000, Val MAE: 520.7676\n",
      "Epoch 220, Train Loss: 783126.2500, Val MSE: 1452476.2500, Val MAE: 520.8459\n",
      "Epoch 230, Train Loss: 782561.3125, Val MSE: 1453194.8750, Val MAE: 520.9042\n",
      "Epoch 240, Train Loss: 781997.3125, Val MSE: 1453904.7500, Val MAE: 520.9811\n",
      "Epoch 250, Train Loss: 781434.8750, Val MSE: 1454507.8750, Val MAE: 521.0419\n",
      " Early stopping at epoch 260\n",
      "\n",
      " Best Val MAE: 519.5133 at epoch 60\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm, best_mae_deepfm, best_epoch_deepfm = train_deepfm(model_deepfm, X_train3, y_train3, X_val3, y_val3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "060b2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFM(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (fm): FM()\n",
      "  (dnn_network): Dnn(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Linear(in_features=74, out_features=76, bias=True)\n",
      "      (1): Linear(in_features=76, out_features=128, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (nn_final_linear): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_deepfm2 = DeepFM(feature_columns, hidden_units=[76, 128, 64, 32]) \n",
    "print(model_deepfm2)  # 展示模块结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "29b99c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 88688432.0000, Val MSE: 86062848.0000, Val MAE: 5607.5527\n",
      "Epoch 20, Train Loss: 38753816.0000, Val MSE: 31360612.0000, Val MAE: 4081.1804\n",
      "Epoch 30, Train Loss: 16468002.0000, Val MSE: 15582346.0000, Val MAE: 2210.7068\n",
      "Epoch 40, Train Loss: 11817496.0000, Val MSE: 12190727.0000, Val MAE: 1810.2205\n",
      "Epoch 50, Train Loss: 9531456.0000, Val MSE: 9467339.0000, Val MAE: 1782.9420\n",
      "Epoch 60, Train Loss: 8278911.5000, Val MSE: 8397846.0000, Val MAE: 1641.4955\n",
      "Epoch 70, Train Loss: 7271726.0000, Val MSE: 7344532.0000, Val MAE: 1422.3682\n",
      "Epoch 80, Train Loss: 6453917.0000, Val MSE: 6546094.0000, Val MAE: 1272.9242\n",
      "Epoch 90, Train Loss: 5844432.0000, Val MSE: 5950134.5000, Val MAE: 1200.5922\n",
      "Epoch 100, Train Loss: 5351142.0000, Val MSE: 5434975.0000, Val MAE: 1141.6875\n",
      "Epoch 110, Train Loss: 4957636.0000, Val MSE: 5026897.5000, Val MAE: 1095.1891\n",
      "Epoch 120, Train Loss: 4637274.5000, Val MSE: 4693335.5000, Val MAE: 1056.2797\n",
      "Epoch 130, Train Loss: 4368856.0000, Val MSE: 4411646.5000, Val MAE: 1019.3229\n",
      "Epoch 140, Train Loss: 4124724.2500, Val MSE: 4156972.7500, Val MAE: 983.2214\n",
      "Epoch 150, Train Loss: 3884579.2500, Val MSE: 3906826.2500, Val MAE: 949.6957\n",
      "Epoch 160, Train Loss: 3615107.0000, Val MSE: 3624330.7500, Val MAE: 917.9091\n",
      "Epoch 170, Train Loss: 3312432.7500, Val MSE: 3303565.5000, Val MAE: 884.1072\n",
      "Epoch 180, Train Loss: 2997528.0000, Val MSE: 2973010.5000, Val MAE: 852.2536\n",
      "Epoch 190, Train Loss: 2728014.7500, Val MSE: 2710020.5000, Val MAE: 817.6458\n",
      "Epoch 200, Train Loss: 2487631.5000, Val MSE: 2488153.5000, Val MAE: 789.8259\n",
      "Epoch 210, Train Loss: 2309675.0000, Val MSE: 2312426.5000, Val MAE: 778.9894\n",
      "Epoch 220, Train Loss: 2167912.5000, Val MSE: 2186509.5000, Val MAE: 752.9439\n",
      "Epoch 230, Train Loss: 2046788.1250, Val MSE: 2072497.8750, Val MAE: 741.1072\n",
      "Epoch 240, Train Loss: 1973068.1250, Val MSE: 2014934.3750, Val MAE: 730.0851\n",
      "Epoch 250, Train Loss: 1897733.3750, Val MSE: 1944734.7500, Val MAE: 721.9955\n",
      "Epoch 260, Train Loss: 1846535.1250, Val MSE: 1905614.8750, Val MAE: 711.0450\n",
      "Epoch 270, Train Loss: 1796247.6250, Val MSE: 1864294.1250, Val MAE: 707.5803\n",
      "Epoch 280, Train Loss: 1754850.1250, Val MSE: 1832861.5000, Val MAE: 696.8568\n",
      "Epoch 290, Train Loss: 1728976.1250, Val MSE: 1817630.8750, Val MAE: 698.4161\n",
      "Epoch 300, Train Loss: 1700236.5000, Val MSE: 1798040.5000, Val MAE: 688.7733\n",
      "Epoch 310, Train Loss: 1667643.6250, Val MSE: 1770582.5000, Val MAE: 684.6793\n",
      "Epoch 320, Train Loss: 1694401.5000, Val MSE: 1815187.3750, Val MAE: 708.3438\n",
      "Epoch 330, Train Loss: 1629435.2500, Val MSE: 1740531.2500, Val MAE: 678.3964\n",
      "Epoch 340, Train Loss: 1610751.5000, Val MSE: 1732332.5000, Val MAE: 674.7988\n",
      "Epoch 350, Train Loss: 1584224.6250, Val MSE: 1722979.6250, Val MAE: 672.3348\n",
      "Epoch 360, Train Loss: 1565559.2500, Val MSE: 1709784.6250, Val MAE: 671.3184\n",
      "Epoch 370, Train Loss: 1550223.7500, Val MSE: 1702370.3750, Val MAE: 669.9561\n",
      "Epoch 380, Train Loss: 1564715.6250, Val MSE: 1721282.8750, Val MAE: 680.4629\n",
      "Epoch 390, Train Loss: 1527845.0000, Val MSE: 1700099.6250, Val MAE: 666.7305\n",
      "Epoch 400, Train Loss: 1500220.3750, Val MSE: 1676304.0000, Val MAE: 663.7069\n",
      "Epoch 410, Train Loss: 1492389.8750, Val MSE: 1669455.6250, Val MAE: 662.3270\n",
      "Epoch 420, Train Loss: 1466955.7500, Val MSE: 1656187.1250, Val MAE: 655.0485\n",
      "Epoch 430, Train Loss: 1513960.7500, Val MSE: 1682151.7500, Val MAE: 661.6731\n",
      "Epoch 440, Train Loss: 1438446.6250, Val MSE: 1651279.7500, Val MAE: 653.0414\n",
      "Epoch 450, Train Loss: 1433255.1250, Val MSE: 1636403.7500, Val MAE: 651.6111\n",
      "Epoch 460, Train Loss: 1410117.2500, Val MSE: 1624076.0000, Val MAE: 645.0692\n",
      "Epoch 470, Train Loss: 1401398.7500, Val MSE: 1624595.7500, Val MAE: 647.7704\n",
      "Epoch 480, Train Loss: 1405782.2500, Val MSE: 1631900.5000, Val MAE: 651.9539\n",
      "Epoch 490, Train Loss: 1366894.6250, Val MSE: 1601943.6250, Val MAE: 637.0289\n",
      "Epoch 500, Train Loss: 1422573.7500, Val MSE: 1670306.7500, Val MAE: 657.2399\n",
      "Epoch 510, Train Loss: 1369063.5000, Val MSE: 1599640.7500, Val MAE: 640.0909\n",
      "Epoch 520, Train Loss: 1337496.8750, Val MSE: 1582027.3750, Val MAE: 628.7256\n",
      "Epoch 530, Train Loss: 1330778.0000, Val MSE: 1585849.6250, Val MAE: 633.9669\n",
      "Epoch 540, Train Loss: 1302698.2500, Val MSE: 1563716.8750, Val MAE: 622.0262\n",
      "Epoch 550, Train Loss: 1319007.8750, Val MSE: 1608586.8750, Val MAE: 635.1473\n",
      "Epoch 560, Train Loss: 1333847.8750, Val MSE: 1620824.2500, Val MAE: 648.7719\n",
      "Epoch 570, Train Loss: 1272041.7500, Val MSE: 1555324.0000, Val MAE: 620.5055\n",
      "Epoch 580, Train Loss: 1269197.0000, Val MSE: 1540582.2500, Val MAE: 611.6534\n",
      "Epoch 590, Train Loss: 1252029.5000, Val MSE: 1534137.8750, Val MAE: 609.1529\n",
      "Epoch 600, Train Loss: 1242430.8750, Val MSE: 1528490.6250, Val MAE: 607.6200\n",
      "Epoch 610, Train Loss: 1241287.3750, Val MSE: 1532025.5000, Val MAE: 610.4108\n",
      "Epoch 620, Train Loss: 1266562.6250, Val MSE: 1560195.0000, Val MAE: 622.6857\n",
      "Epoch 630, Train Loss: 1222360.2500, Val MSE: 1518954.2500, Val MAE: 602.2575\n",
      "Epoch 640, Train Loss: 1226658.7500, Val MSE: 1518358.0000, Val MAE: 601.9097\n",
      "Epoch 650, Train Loss: 1214446.8750, Val MSE: 1522610.7500, Val MAE: 606.6679\n",
      "Epoch 660, Train Loss: 1225986.6250, Val MSE: 1515974.8750, Val MAE: 603.5983\n",
      "Epoch 670, Train Loss: 1209236.3750, Val MSE: 1507912.8750, Val MAE: 597.2524\n",
      "Epoch 680, Train Loss: 1200527.7500, Val MSE: 1515760.7500, Val MAE: 603.1740\n",
      "Epoch 690, Train Loss: 1176565.8750, Val MSE: 1491689.7500, Val MAE: 590.4194\n",
      "Epoch 700, Train Loss: 1190146.2500, Val MSE: 1520247.2500, Val MAE: 598.8093\n",
      "Epoch 710, Train Loss: 1164840.6250, Val MSE: 1499601.7500, Val MAE: 593.9735\n",
      "Epoch 720, Train Loss: 1183490.8750, Val MSE: 1508426.1250, Val MAE: 594.3552\n",
      "Epoch 730, Train Loss: 1162707.6250, Val MSE: 1487965.0000, Val MAE: 587.3138\n",
      "Epoch 740, Train Loss: 1154453.2500, Val MSE: 1484091.5000, Val MAE: 582.9475\n",
      "Epoch 750, Train Loss: 1143954.2500, Val MSE: 1483973.3750, Val MAE: 582.5991\n",
      "Epoch 760, Train Loss: 1190084.0000, Val MSE: 1535946.7500, Val MAE: 606.8083\n",
      "Epoch 770, Train Loss: 1141487.3750, Val MSE: 1487698.5000, Val MAE: 581.7288\n",
      "Epoch 780, Train Loss: 1129541.6250, Val MSE: 1471707.0000, Val MAE: 574.8743\n",
      "Epoch 790, Train Loss: 1196124.7500, Val MSE: 1540832.1250, Val MAE: 606.5727\n",
      "Epoch 800, Train Loss: 1145961.5000, Val MSE: 1491676.3750, Val MAE: 580.5906\n",
      "Epoch 810, Train Loss: 1126475.7500, Val MSE: 1484486.1250, Val MAE: 580.0931\n",
      "Epoch 820, Train Loss: 1111826.6250, Val MSE: 1465863.5000, Val MAE: 570.6084\n",
      "Epoch 830, Train Loss: 1121158.7500, Val MSE: 1484465.6250, Val MAE: 575.8853\n",
      "Epoch 840, Train Loss: 1115069.7500, Val MSE: 1459477.8750, Val MAE: 567.5531\n",
      "Epoch 850, Train Loss: 1101147.0000, Val MSE: 1466359.5000, Val MAE: 568.7544\n",
      "Epoch 860, Train Loss: 1098780.2500, Val MSE: 1468711.5000, Val MAE: 570.7640\n",
      "Epoch 870, Train Loss: 1090116.5000, Val MSE: 1455093.7500, Val MAE: 563.5024\n",
      "Epoch 880, Train Loss: 1105378.8750, Val MSE: 1475979.1250, Val MAE: 571.0471\n",
      "Epoch 890, Train Loss: 1093618.3750, Val MSE: 1454887.6250, Val MAE: 561.7101\n",
      "Epoch 900, Train Loss: 1111892.1250, Val MSE: 1492439.1250, Val MAE: 579.7962\n",
      "Epoch 910, Train Loss: 1075738.0000, Val MSE: 1452592.7500, Val MAE: 559.0301\n",
      "Epoch 920, Train Loss: 1134781.1250, Val MSE: 1517253.5000, Val MAE: 586.4663\n",
      "Epoch 930, Train Loss: 1089935.5000, Val MSE: 1485116.0000, Val MAE: 572.0358\n",
      "Epoch 940, Train Loss: 1067753.2500, Val MSE: 1455702.0000, Val MAE: 558.0656\n",
      "Epoch 950, Train Loss: 1081593.0000, Val MSE: 1464780.6250, Val MAE: 561.3815\n",
      "Epoch 960, Train Loss: 1059987.5000, Val MSE: 1453297.3750, Val MAE: 554.8657\n",
      "Epoch 970, Train Loss: 1084222.5000, Val MSE: 1504728.5000, Val MAE: 575.8096\n",
      "Epoch 980, Train Loss: 1061935.7500, Val MSE: 1484970.6250, Val MAE: 568.8660\n",
      "Epoch 990, Train Loss: 1083687.0000, Val MSE: 1464256.7500, Val MAE: 559.7979\n",
      "Epoch 1000, Train Loss: 1052041.8750, Val MSE: 1460712.0000, Val MAE: 555.6483\n",
      "Epoch 1010, Train Loss: 1054088.1250, Val MSE: 1453213.8750, Val MAE: 553.7859\n",
      "Epoch 1020, Train Loss: 1047842.9375, Val MSE: 1454830.1250, Val MAE: 552.0885\n",
      "Epoch 1030, Train Loss: 1048167.6875, Val MSE: 1456757.5000, Val MAE: 552.3229\n",
      "Epoch 1040, Train Loss: 1048569.8750, Val MSE: 1463295.2500, Val MAE: 554.0496\n",
      "Epoch 1050, Train Loss: 1083273.0000, Val MSE: 1491605.2500, Val MAE: 566.5968\n",
      "Epoch 1060, Train Loss: 1049504.1250, Val MSE: 1462132.2500, Val MAE: 556.8855\n",
      "Epoch 1070, Train Loss: 1037042.3750, Val MSE: 1447429.2500, Val MAE: 547.6078\n",
      "Epoch 1080, Train Loss: 1061124.8750, Val MSE: 1483350.3750, Val MAE: 560.7626\n",
      "Epoch 1090, Train Loss: 1033920.3750, Val MSE: 1450694.5000, Val MAE: 546.8954\n",
      "Epoch 1100, Train Loss: 1041810.9375, Val MSE: 1464244.0000, Val MAE: 554.9502\n",
      "Epoch 1110, Train Loss: 1044863.6250, Val MSE: 1449436.7500, Val MAE: 549.0437\n",
      "Epoch 1120, Train Loss: 1055953.1250, Val MSE: 1470284.3750, Val MAE: 554.2972\n",
      "Epoch 1130, Train Loss: 1038462.3125, Val MSE: 1460789.7500, Val MAE: 553.6448\n",
      "Epoch 1140, Train Loss: 1019143.0000, Val MSE: 1443357.1250, Val MAE: 543.4217\n",
      "Epoch 1150, Train Loss: 1049189.0000, Val MSE: 1491749.7500, Val MAE: 565.9467\n",
      "Epoch 1160, Train Loss: 1015043.2500, Val MSE: 1441191.7500, Val MAE: 541.7249\n",
      "Epoch 1170, Train Loss: 1027244.8750, Val MSE: 1444601.6250, Val MAE: 542.5044\n",
      "Epoch 1180, Train Loss: 1033453.1250, Val MSE: 1470827.6250, Val MAE: 555.6098\n",
      "Epoch 1190, Train Loss: 1009987.3125, Val MSE: 1445009.8750, Val MAE: 541.6524\n",
      "Epoch 1200, Train Loss: 1007637.2500, Val MSE: 1445213.2500, Val MAE: 543.9028\n",
      "Epoch 1210, Train Loss: 1118534.5000, Val MSE: 1579038.6250, Val MAE: 607.8685\n",
      "Epoch 1220, Train Loss: 1046885.5000, Val MSE: 1484651.0000, Val MAE: 551.1215\n",
      "Epoch 1230, Train Loss: 1021638.6250, Val MSE: 1457666.8750, Val MAE: 551.0357\n",
      "Epoch 1240, Train Loss: 1006551.4375, Val MSE: 1445659.5000, Val MAE: 539.6147\n",
      "Epoch 1250, Train Loss: 997344.1250, Val MSE: 1446528.8750, Val MAE: 540.0480\n",
      "Epoch 1260, Train Loss: 1044374.8125, Val MSE: 1484395.7500, Val MAE: 559.8488\n",
      "Epoch 1270, Train Loss: 1022873.4375, Val MSE: 1473516.8750, Val MAE: 549.0425\n",
      "Epoch 1280, Train Loss: 992486.3125, Val MSE: 1450902.6250, Val MAE: 543.0684\n",
      "Epoch 1290, Train Loss: 999935.0625, Val MSE: 1446145.1250, Val MAE: 541.2213\n",
      "Epoch 1300, Train Loss: 1021364.3125, Val MSE: 1470196.1250, Val MAE: 553.0362\n",
      "Epoch 1310, Train Loss: 988600.8125, Val MSE: 1440346.5000, Val MAE: 538.2749\n",
      "Epoch 1320, Train Loss: 1001121.5000, Val MSE: 1463378.0000, Val MAE: 541.5256\n",
      "Epoch 1330, Train Loss: 1047254.8125, Val MSE: 1483880.3750, Val MAE: 552.2338\n",
      "Epoch 1340, Train Loss: 1017785.8125, Val MSE: 1466078.8750, Val MAE: 549.8060\n",
      "Epoch 1350, Train Loss: 1004268.5000, Val MSE: 1477797.8750, Val MAE: 548.1656\n",
      "Epoch 1360, Train Loss: 982117.3125, Val MSE: 1443679.2500, Val MAE: 535.1198\n",
      "Epoch 1370, Train Loss: 988369.1875, Val MSE: 1443468.2500, Val MAE: 538.1052\n",
      "Epoch 1380, Train Loss: 982230.2500, Val MSE: 1444123.8750, Val MAE: 538.0659\n",
      "Epoch 1390, Train Loss: 1041765.6875, Val MSE: 1519613.5000, Val MAE: 563.4736\n",
      "Epoch 1400, Train Loss: 1004470.0000, Val MSE: 1491497.1250, Val MAE: 557.5197\n",
      "Epoch 1410, Train Loss: 979681.0000, Val MSE: 1450595.2500, Val MAE: 541.7753\n",
      "Epoch 1420, Train Loss: 966857.5000, Val MSE: 1446082.8750, Val MAE: 534.1767\n",
      "Epoch 1430, Train Loss: 991089.4375, Val MSE: 1471409.2500, Val MAE: 548.0203\n",
      "Epoch 1440, Train Loss: 964889.2500, Val MSE: 1442069.6250, Val MAE: 534.4841\n",
      "Epoch 1450, Train Loss: 994142.1250, Val MSE: 1476122.6250, Val MAE: 551.5761\n",
      "Epoch 1460, Train Loss: 969098.0625, Val MSE: 1442407.8750, Val MAE: 533.8412\n",
      "Epoch 1470, Train Loss: 995233.0625, Val MSE: 1472547.6250, Val MAE: 542.1838\n",
      "Epoch 1480, Train Loss: 966970.1875, Val MSE: 1449532.0000, Val MAE: 535.4434\n",
      "Epoch 1490, Train Loss: 991786.5625, Val MSE: 1453978.2500, Val MAE: 537.8871\n",
      "Epoch 1500, Train Loss: 997330.6875, Val MSE: 1485847.8750, Val MAE: 549.1802\n",
      "Epoch 1510, Train Loss: 969523.5625, Val MSE: 1455888.2500, Val MAE: 536.8953\n",
      "Epoch 1520, Train Loss: 956942.5625, Val MSE: 1444978.1250, Val MAE: 532.1042\n",
      "Epoch 1530, Train Loss: 982108.4375, Val MSE: 1475548.7500, Val MAE: 549.9198\n",
      "Epoch 1540, Train Loss: 961611.1875, Val MSE: 1453550.8750, Val MAE: 533.4645\n",
      "Epoch 1550, Train Loss: 970847.5625, Val MSE: 1450569.3750, Val MAE: 538.2126\n",
      "Epoch 1560, Train Loss: 1009982.0625, Val MSE: 1497335.5000, Val MAE: 551.8500\n",
      "Epoch 1570, Train Loss: 977136.8125, Val MSE: 1467029.0000, Val MAE: 539.9296\n",
      "Epoch 1580, Train Loss: 952558.5000, Val MSE: 1458796.0000, Val MAE: 533.5521\n",
      "Epoch 1590, Train Loss: 955926.8750, Val MSE: 1451116.0000, Val MAE: 536.8532\n",
      "Epoch 1600, Train Loss: 973961.4375, Val MSE: 1468537.2500, Val MAE: 543.7744\n",
      "Epoch 1610, Train Loss: 942555.5000, Val MSE: 1443328.2500, Val MAE: 530.1279\n",
      "Epoch 1620, Train Loss: 951922.9375, Val MSE: 1446029.1250, Val MAE: 530.2045\n",
      "Epoch 1630, Train Loss: 1038744.4375, Val MSE: 1508589.5000, Val MAE: 567.0716\n",
      "Epoch 1640, Train Loss: 981870.1875, Val MSE: 1474584.7500, Val MAE: 546.9078\n",
      "Epoch 1650, Train Loss: 968577.3125, Val MSE: 1466095.3750, Val MAE: 532.4203\n",
      "Epoch 1660, Train Loss: 967317.8125, Val MSE: 1466704.7500, Val MAE: 534.0327\n",
      "Epoch 1670, Train Loss: 952950.4375, Val MSE: 1454220.7500, Val MAE: 531.3041\n",
      "Epoch 1680, Train Loss: 940848.8750, Val MSE: 1445503.8750, Val MAE: 529.4011\n",
      "Epoch 1690, Train Loss: 938459.5625, Val MSE: 1449424.2500, Val MAE: 532.1574\n",
      "Epoch 1700, Train Loss: 994252.4375, Val MSE: 1503827.3750, Val MAE: 547.5842\n",
      "Epoch 1710, Train Loss: 947098.0000, Val MSE: 1477016.6250, Val MAE: 543.3575\n",
      "Epoch 1720, Train Loss: 944618.0000, Val MSE: 1456797.3750, Val MAE: 530.7928\n",
      "Epoch 1730, Train Loss: 952770.5625, Val MSE: 1460601.0000, Val MAE: 530.3456\n",
      "Epoch 1740, Train Loss: 932660.5625, Val MSE: 1456205.2500, Val MAE: 530.7209\n",
      "Epoch 1750, Train Loss: 979135.2500, Val MSE: 1509433.3750, Val MAE: 561.6788\n",
      "Epoch 1760, Train Loss: 940114.1875, Val MSE: 1457027.2500, Val MAE: 532.0718\n",
      "Epoch 1770, Train Loss: 961269.5000, Val MSE: 1466290.5000, Val MAE: 534.7653\n",
      "Epoch 1780, Train Loss: 926213.6250, Val MSE: 1459319.5000, Val MAE: 534.7788\n",
      "Epoch 1790, Train Loss: 930017.4375, Val MSE: 1465051.6250, Val MAE: 529.8687\n",
      "Epoch 1800, Train Loss: 967844.5625, Val MSE: 1497762.1250, Val MAE: 557.4333\n",
      "Epoch 1810, Train Loss: 934097.5625, Val MSE: 1462014.6250, Val MAE: 537.5197\n",
      "Epoch 1820, Train Loss: 957817.5625, Val MSE: 1481023.5000, Val MAE: 543.9296\n",
      "Epoch 1830, Train Loss: 922798.0000, Val MSE: 1461606.0000, Val MAE: 528.9618\n",
      "Epoch 1840, Train Loss: 965453.7500, Val MSE: 1496919.2500, Val MAE: 551.5687\n",
      "Epoch 1850, Train Loss: 929893.6875, Val MSE: 1461763.3750, Val MAE: 534.0872\n",
      "Epoch 1860, Train Loss: 930715.5625, Val MSE: 1483740.7500, Val MAE: 537.8641\n",
      "Epoch 1870, Train Loss: 951031.1875, Val MSE: 1466962.3750, Val MAE: 535.0319\n",
      "Epoch 1880, Train Loss: 946972.5000, Val MSE: 1476248.5000, Val MAE: 529.8985\n",
      "Epoch 1890, Train Loss: 934011.7500, Val MSE: 1476864.8750, Val MAE: 536.0452\n",
      "Epoch 1900, Train Loss: 932918.4375, Val MSE: 1482787.8750, Val MAE: 533.5859\n",
      "Epoch 1910, Train Loss: 912796.6250, Val MSE: 1460941.8750, Val MAE: 527.2110\n",
      "Epoch 1920, Train Loss: 929843.1250, Val MSE: 1467806.7500, Val MAE: 533.3561\n",
      "Epoch 1930, Train Loss: 932194.4375, Val MSE: 1468197.8750, Val MAE: 535.7712\n",
      "Epoch 1940, Train Loss: 960438.5625, Val MSE: 1508865.7500, Val MAE: 540.7025\n",
      "Epoch 1950, Train Loss: 928249.6875, Val MSE: 1478499.1250, Val MAE: 530.8829\n",
      "Epoch 1960, Train Loss: 910052.5625, Val MSE: 1460575.2500, Val MAE: 526.9935\n",
      "Epoch 1970, Train Loss: 959036.2500, Val MSE: 1507242.5000, Val MAE: 544.2369\n",
      "Epoch 1980, Train Loss: 926854.9375, Val MSE: 1481610.7500, Val MAE: 535.7649\n",
      "Epoch 1990, Train Loss: 914537.8750, Val MSE: 1469168.0000, Val MAE: 527.8270\n",
      "Epoch 2000, Train Loss: 904610.0625, Val MSE: 1467998.0000, Val MAE: 527.2647\n",
      "Epoch 2010, Train Loss: 940976.3125, Val MSE: 1511600.5000, Val MAE: 558.4490\n",
      "Epoch 2020, Train Loss: 925482.5625, Val MSE: 1488155.2500, Val MAE: 536.1234\n",
      "Epoch 2030, Train Loss: 950975.8750, Val MSE: 1533381.7500, Val MAE: 554.4844\n",
      "Epoch 2040, Train Loss: 920448.4375, Val MSE: 1481309.0000, Val MAE: 529.9704\n",
      "Epoch 2050, Train Loss: 912812.5000, Val MSE: 1476211.0000, Val MAE: 534.4426\n",
      "Epoch 2060, Train Loss: 915882.8125, Val MSE: 1479699.3750, Val MAE: 530.5843\n",
      "Epoch 2070, Train Loss: 974837.0625, Val MSE: 1534154.7500, Val MAE: 547.3243\n",
      "Epoch 2080, Train Loss: 929121.1875, Val MSE: 1496691.3750, Val MAE: 536.6585\n",
      "Epoch 2090, Train Loss: 896695.6875, Val MSE: 1469832.0000, Val MAE: 529.5699\n",
      "Epoch 2100, Train Loss: 923073.7500, Val MSE: 1480992.5000, Val MAE: 531.0919\n",
      "Epoch 2110, Train Loss: 919611.5625, Val MSE: 1489927.1250, Val MAE: 543.0490\n",
      "Epoch 2120, Train Loss: 900771.6875, Val MSE: 1464782.6250, Val MAE: 525.0283\n",
      "Epoch 2130, Train Loss: 922033.6250, Val MSE: 1503781.7500, Val MAE: 544.0789\n",
      "Epoch 2140, Train Loss: 924115.6250, Val MSE: 1490714.0000, Val MAE: 529.6888\n",
      "Epoch 2150, Train Loss: 908272.7500, Val MSE: 1477312.6250, Val MAE: 526.2194\n",
      "Epoch 2160, Train Loss: 966961.3750, Val MSE: 1532828.2500, Val MAE: 549.5518\n",
      "Epoch 2170, Train Loss: 940739.2500, Val MSE: 1517234.0000, Val MAE: 542.0380\n",
      "Epoch 2180, Train Loss: 906081.0625, Val MSE: 1483723.2500, Val MAE: 530.9174\n",
      "Epoch 2190, Train Loss: 889613.8125, Val MSE: 1471871.2500, Val MAE: 525.5782\n",
      "Epoch 2200, Train Loss: 908159.2500, Val MSE: 1487008.5000, Val MAE: 537.3263\n",
      "Epoch 2210, Train Loss: 919569.8750, Val MSE: 1494753.6250, Val MAE: 537.8533\n",
      "Epoch 2220, Train Loss: 887164.9375, Val MSE: 1470321.8750, Val MAE: 525.6383\n",
      "Epoch 2230, Train Loss: 887630.0000, Val MSE: 1472487.3750, Val MAE: 526.3038\n",
      "Epoch 2240, Train Loss: 911637.1250, Val MSE: 1496291.7500, Val MAE: 534.1475\n",
      "Epoch 2250, Train Loss: 917653.5000, Val MSE: 1488478.2500, Val MAE: 532.2788\n",
      "Epoch 2260, Train Loss: 924534.4375, Val MSE: 1518748.3750, Val MAE: 535.6114\n",
      "Epoch 2270, Train Loss: 907564.5625, Val MSE: 1486509.0000, Val MAE: 527.4494\n",
      "Epoch 2280, Train Loss: 895124.0000, Val MSE: 1480631.2500, Val MAE: 525.4928\n",
      "Epoch 2290, Train Loss: 893673.6250, Val MSE: 1488810.3750, Val MAE: 530.1404\n",
      "Epoch 2300, Train Loss: 959148.1875, Val MSE: 1565417.8750, Val MAE: 564.5253\n",
      "Epoch 2310, Train Loss: 910314.2500, Val MSE: 1503468.8750, Val MAE: 532.9780\n",
      " Early stopping at epoch 2320\n",
      "\n",
      " Best Val MAE: 525.0283 at epoch 2120\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm2, best_mae_deepfm2, best_epoch_deepfm2 = train_deepfm(model_deepfm2, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a2bad85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 920299.5000, Val MSE: 1482195.2500, Val MAE: 525.3903\n",
      "Epoch 20, Train Loss: 889751.6250, Val MSE: 1477088.2500, Val MAE: 526.0520\n",
      "Epoch 30, Train Loss: 881165.3750, Val MSE: 1473635.3750, Val MAE: 525.1306\n",
      "Epoch 40, Train Loss: 879221.6250, Val MSE: 1471230.8750, Val MAE: 524.2709\n",
      "Epoch 50, Train Loss: 877883.2500, Val MSE: 1470595.7500, Val MAE: 523.4177\n",
      "Epoch 60, Train Loss: 877027.1875, Val MSE: 1471376.2500, Val MAE: 523.5495\n",
      "Epoch 70, Train Loss: 876638.5625, Val MSE: 1472281.5000, Val MAE: 523.7560\n",
      "Epoch 80, Train Loss: 876324.6250, Val MSE: 1471942.1250, Val MAE: 523.6357\n",
      "Epoch 90, Train Loss: 876070.8125, Val MSE: 1472808.8750, Val MAE: 523.7380\n",
      "Epoch 100, Train Loss: 875815.8750, Val MSE: 1473191.7500, Val MAE: 523.7947\n",
      "Epoch 110, Train Loss: 875582.5000, Val MSE: 1473491.8750, Val MAE: 523.8481\n",
      "Epoch 120, Train Loss: 875345.0000, Val MSE: 1473989.2500, Val MAE: 523.8934\n",
      "Epoch 130, Train Loss: 875112.5625, Val MSE: 1474397.5000, Val MAE: 523.9607\n",
      "Epoch 140, Train Loss: 874877.8750, Val MSE: 1474819.5000, Val MAE: 523.9871\n",
      "Epoch 150, Train Loss: 874646.7500, Val MSE: 1475450.7500, Val MAE: 524.0647\n",
      "Epoch 160, Train Loss: 874402.5625, Val MSE: 1475710.7500, Val MAE: 524.0905\n",
      "Epoch 170, Train Loss: 874167.8125, Val MSE: 1476151.0000, Val MAE: 524.1472\n",
      "Epoch 180, Train Loss: 873921.1250, Val MSE: 1476428.0000, Val MAE: 524.1877\n",
      "Epoch 190, Train Loss: 873671.5625, Val MSE: 1476853.0000, Val MAE: 524.2584\n",
      "Epoch 200, Train Loss: 873430.5000, Val MSE: 1477241.6250, Val MAE: 524.3199\n",
      "Epoch 210, Train Loss: 873188.6875, Val MSE: 1477669.2500, Val MAE: 524.3533\n",
      "Epoch 220, Train Loss: 872928.2500, Val MSE: 1478001.6250, Val MAE: 524.4017\n",
      "Epoch 230, Train Loss: 872673.6875, Val MSE: 1478575.8750, Val MAE: 524.4672\n",
      "Epoch 240, Train Loss: 872411.3125, Val MSE: 1478790.0000, Val MAE: 524.5057\n",
      " Early stopping at epoch 250\n",
      "\n",
      " Best Val MAE: 523.4177 at epoch 50\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm2, best_mae_deepfm2, best_epoch_deepfm2 = train_deepfm(model_deepfm2, X_train3, y_train3, X_val3, y_val3, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9e19cfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of model_deepfm2: 29048\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_deepfm2.parameters())\n",
    "print(f\"Total Parameters of model_deepfm2: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226cdd8",
   "metadata": {},
   "source": [
    "### 4.5.2 使用增强版DNN, 每一个隐藏层都包含完整的BatchNormalization+ReLU+Dropout(FC block)机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "55f9be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dnn1(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout=0.):\n",
    "        super(Dnn1, self).__init__()\n",
    "        self.dnn_network = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(layer[0], layer[1]),\n",
    "                nn.BatchNorm1d(layer[1]),     # 加入 BatchNorm（可选）\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "            for layer in zip(hidden_units[:-1], hidden_units[1:])\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for block in self.dnn_network:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e4b92e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM1(nn.Module):\n",
    "    def __init__(self, feature_columns, hidden_units, dnn_dropout=0.5):\n",
    "        \"\"\"\n",
    "        DeepFM:\n",
    "        :param feature_columns: 特征信息， 这个传入的是fea_cols\n",
    "        :param hidden_units: 隐藏单元个数， 一个列表的形式， 列表的长度代表层数， 每个元素代表每一层神经元个数\n",
    "        \"\"\"\n",
    "        super(DeepFM1, self).__init__()\n",
    "        self.dense_feature_cols, self.sparse_feature_cols = feature_columns\n",
    "        \n",
    "        # embedding\n",
    "        self.embed_layers = nn.ModuleDict({\n",
    "            'embed_' + str(i): nn.Embedding(num_embeddings=feat['feat_num'], embedding_dim=feat['embed_dim'])\n",
    "            for i, feat in enumerate(self.sparse_feature_cols)\n",
    "        })\n",
    "        \n",
    "        # 这里要注意Pytorch的linear和tf的dense的不同之处， 前者的linear需要输入特征和输出特征维度， 而传入的hidden_units的第一个是第一层隐藏的神经单元个数，这里需要加个输入维度\n",
    "        self.fea_num = len(self.dense_feature_cols) + len(self.sparse_feature_cols)*self.sparse_feature_cols[0]['embed_dim']\n",
    "        hidden_units.insert(0, self.fea_num)\n",
    "        \n",
    "        self.fm = FM(self.sparse_feature_cols[0]['embed_dim'], self.fea_num)     \n",
    "        self.dnn_network = Dnn1(hidden_units, dnn_dropout)\n",
    "        self.nn_final_linear = nn.Linear(hidden_units[-1], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        dense_inputs, sparse_inputs = x[:, :len(self.dense_feature_cols)], x[:, len(self.dense_feature_cols):]\n",
    "        sparse_inputs = sparse_inputs.long()       # 转成long类型才能作为nn.embedding的输入\n",
    "        sparse_embeds = [self.embed_layers['embed_'+str(i)](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])]\n",
    "        sparse_embeds = torch.cat(sparse_embeds, dim=-1)\n",
    "        \n",
    "        # 把离散特征和连续特征进行拼接作为FM和DNN的输入\n",
    "        x = torch.cat([sparse_embeds, dense_inputs], dim=-1)\n",
    "        # Wide\n",
    "        wide_outputs = self.fm(x)\n",
    "        # deep\n",
    "        deep_outputs = self.nn_final_linear(self.dnn_network(x))\n",
    "        \n",
    "        # 模型的最后输出\n",
    "        outputs = wide_outputs + deep_outputs\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "166d5b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFM1(\n",
      "  (embed_layers): ModuleDict(\n",
      "    (embed_0): Embedding(247, 8)\n",
      "    (embed_1): Embedding(40, 8)\n",
      "    (embed_2): Embedding(8, 8)\n",
      "    (embed_3): Embedding(7, 8)\n",
      "    (embed_4): Embedding(2, 8)\n",
      "    (embed_5): Embedding(3, 8)\n",
      "  )\n",
      "  (fm): FM()\n",
      "  (dnn_network): Dnn1(\n",
      "    (dnn_network): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=74, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.5, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (nn_final_linear): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 构建三个隐藏层\n",
    "model_deepfm1 = DeepFM1(feature_columns, hidden_units=[128, 64]) \n",
    "print(model_deepfm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b7722810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 93282632.0000, Val MSE: 93879640.0000, Val MAE: 6045.5498\n",
      "Epoch 20, Train Loss: 86390520.0000, Val MSE: 86423584.0000, Val MAE: 5637.5542\n",
      "Epoch 30, Train Loss: 74723744.0000, Val MSE: 74158896.0000, Val MAE: 4967.9927\n",
      "Epoch 40, Train Loss: 58449912.0000, Val MSE: 57357860.0000, Val MAE: 4159.8252\n",
      "Epoch 50, Train Loss: 41906760.0000, Val MSE: 41157148.0000, Val MAE: 3669.0586\n",
      "Epoch 60, Train Loss: 32540166.0000, Val MSE: 32534150.0000, Val MAE: 3684.2302\n",
      "Epoch 70, Train Loss: 26613326.0000, Val MSE: 26645496.0000, Val MAE: 3338.3992\n",
      "Epoch 80, Train Loss: 21720278.0000, Val MSE: 21979852.0000, Val MAE: 2838.6494\n",
      "Epoch 90, Train Loss: 18489206.0000, Val MSE: 18750038.0000, Val MAE: 2561.8296\n",
      "Epoch 100, Train Loss: 16053529.0000, Val MSE: 16400393.0000, Val MAE: 2412.7283\n",
      "Epoch 110, Train Loss: 14235786.0000, Val MSE: 14449586.0000, Val MAE: 2256.9233\n",
      "Epoch 120, Train Loss: 12819178.0000, Val MSE: 12977871.0000, Val MAE: 2100.1743\n",
      "Epoch 130, Train Loss: 11697108.0000, Val MSE: 11828643.0000, Val MAE: 1982.0027\n",
      "Epoch 140, Train Loss: 10783796.0000, Val MSE: 10919007.0000, Val MAE: 1893.3816\n",
      "Epoch 150, Train Loss: 10010980.0000, Val MSE: 10046461.0000, Val MAE: 1804.6173\n",
      "Epoch 160, Train Loss: 9339887.0000, Val MSE: 9331084.0000, Val MAE: 1729.3256\n",
      "Epoch 170, Train Loss: 8754838.0000, Val MSE: 8676755.0000, Val MAE: 1664.5385\n",
      "Epoch 180, Train Loss: 8231453.5000, Val MSE: 8152213.0000, Val MAE: 1606.5688\n",
      "Epoch 190, Train Loss: 7759117.0000, Val MSE: 7646088.0000, Val MAE: 1556.9883\n",
      "Epoch 200, Train Loss: 7316897.0000, Val MSE: 7288591.0000, Val MAE: 1514.3185\n",
      "Epoch 210, Train Loss: 6940733.0000, Val MSE: 6789255.0000, Val MAE: 1461.3889\n",
      "Epoch 220, Train Loss: 6570325.0000, Val MSE: 6486130.5000, Val MAE: 1424.8801\n",
      "Epoch 230, Train Loss: 6212555.0000, Val MSE: 6139570.0000, Val MAE: 1387.2355\n",
      "Epoch 240, Train Loss: 5899171.5000, Val MSE: 5848493.0000, Val MAE: 1349.1346\n",
      "Epoch 250, Train Loss: 5605412.5000, Val MSE: 5541094.0000, Val MAE: 1311.3761\n",
      "Epoch 260, Train Loss: 5340768.5000, Val MSE: 5359505.0000, Val MAE: 1291.8940\n",
      "Epoch 270, Train Loss: 5081492.0000, Val MSE: 5105002.5000, Val MAE: 1262.0647\n",
      "Epoch 280, Train Loss: 4813358.5000, Val MSE: 4945607.0000, Val MAE: 1236.4292\n",
      "Epoch 290, Train Loss: 4609127.5000, Val MSE: 4581166.0000, Val MAE: 1198.4061\n",
      "Epoch 300, Train Loss: 4398277.0000, Val MSE: 4298530.0000, Val MAE: 1162.7943\n",
      "Epoch 310, Train Loss: 4195871.5000, Val MSE: 4070714.7500, Val MAE: 1142.0089\n",
      "Epoch 320, Train Loss: 4019474.2500, Val MSE: 3993437.0000, Val MAE: 1116.9760\n",
      "Epoch 330, Train Loss: 3839167.5000, Val MSE: 3782070.7500, Val MAE: 1102.1127\n",
      "Epoch 340, Train Loss: 3681184.7500, Val MSE: 3589723.7500, Val MAE: 1066.6355\n",
      "Epoch 350, Train Loss: 3537675.2500, Val MSE: 3486773.5000, Val MAE: 1050.0846\n",
      "Epoch 360, Train Loss: 3405512.2500, Val MSE: 3446129.2500, Val MAE: 1038.9946\n",
      "Epoch 370, Train Loss: 3249245.0000, Val MSE: 3121819.0000, Val MAE: 1003.2395\n",
      "Epoch 380, Train Loss: 3137904.5000, Val MSE: 3091878.0000, Val MAE: 988.3331\n",
      "Epoch 390, Train Loss: 3032148.5000, Val MSE: 2959502.2500, Val MAE: 972.1827\n",
      "Epoch 400, Train Loss: 2917000.5000, Val MSE: 2791550.5000, Val MAE: 943.8279\n",
      "Epoch 410, Train Loss: 2830303.5000, Val MSE: 2725889.5000, Val MAE: 930.6342\n",
      "Epoch 420, Train Loss: 2756336.2500, Val MSE: 2721050.7500, Val MAE: 933.1533\n",
      "Epoch 430, Train Loss: 2692406.7500, Val MSE: 2533339.2500, Val MAE: 888.2218\n",
      "Epoch 440, Train Loss: 2613318.2500, Val MSE: 2525776.5000, Val MAE: 901.5109\n",
      "Epoch 450, Train Loss: 2510939.7500, Val MSE: 2457272.2500, Val MAE: 896.0632\n",
      "Epoch 460, Train Loss: 2492190.0000, Val MSE: 2337205.2500, Val MAE: 860.9638\n",
      "Epoch 470, Train Loss: 2455177.2500, Val MSE: 2338293.7500, Val MAE: 863.2274\n",
      "Epoch 480, Train Loss: 2422425.0000, Val MSE: 2253911.0000, Val MAE: 844.3385\n",
      "Epoch 490, Train Loss: 2329870.0000, Val MSE: 2204088.0000, Val MAE: 827.9666\n",
      "Epoch 500, Train Loss: 2311443.7500, Val MSE: 2193527.7500, Val MAE: 826.3983\n",
      "Epoch 510, Train Loss: 2256512.7500, Val MSE: 2175474.0000, Val MAE: 819.1407\n",
      "Epoch 520, Train Loss: 2222636.7500, Val MSE: 2078053.5000, Val MAE: 806.9774\n",
      "Epoch 530, Train Loss: 2218044.7500, Val MSE: 2122364.5000, Val MAE: 808.3952\n",
      "Epoch 540, Train Loss: 2179850.7500, Val MSE: 2079032.3750, Val MAE: 797.5909\n",
      "Epoch 550, Train Loss: 2156663.2500, Val MSE: 2024281.7500, Val MAE: 787.7698\n",
      "Epoch 560, Train Loss: 2126736.5000, Val MSE: 2000353.2500, Val MAE: 778.5266\n",
      "Epoch 570, Train Loss: 2110942.5000, Val MSE: 1977641.3750, Val MAE: 782.3962\n",
      "Epoch 580, Train Loss: 2104883.7500, Val MSE: 1964432.2500, Val MAE: 776.3998\n",
      "Epoch 590, Train Loss: 2039438.2500, Val MSE: 1955952.5000, Val MAE: 772.5597\n",
      "Epoch 600, Train Loss: 2080214.7500, Val MSE: 1909812.0000, Val MAE: 758.6525\n",
      "Epoch 610, Train Loss: 2056927.7500, Val MSE: 1936961.7500, Val MAE: 763.9304\n",
      "Epoch 620, Train Loss: 2026053.3750, Val MSE: 1913651.7500, Val MAE: 765.9545\n",
      "Epoch 630, Train Loss: 2017831.0000, Val MSE: 1947711.1250, Val MAE: 772.8746\n",
      "Epoch 640, Train Loss: 1999404.7500, Val MSE: 1896739.0000, Val MAE: 766.6204\n",
      "Epoch 650, Train Loss: 1986040.8750, Val MSE: 1899553.7500, Val MAE: 760.5157\n",
      "Epoch 660, Train Loss: 1970512.1250, Val MSE: 1874111.1250, Val MAE: 755.3968\n",
      "Epoch 670, Train Loss: 2007918.7500, Val MSE: 1848415.3750, Val MAE: 749.8946\n",
      "Epoch 680, Train Loss: 2010380.8750, Val MSE: 1857623.5000, Val MAE: 746.6876\n",
      "Epoch 690, Train Loss: 1967556.0000, Val MSE: 1858797.8750, Val MAE: 751.4362\n",
      "Epoch 700, Train Loss: 1950890.1250, Val MSE: 1869475.5000, Val MAE: 751.7074\n",
      "Epoch 710, Train Loss: 1933464.8750, Val MSE: 1876438.8750, Val MAE: 747.9803\n",
      "Epoch 720, Train Loss: 1983862.0000, Val MSE: 1851073.2500, Val MAE: 752.4580\n",
      "Epoch 730, Train Loss: 1953151.7500, Val MSE: 1823291.6250, Val MAE: 736.4374\n",
      "Epoch 740, Train Loss: 1907961.3750, Val MSE: 1823288.6250, Val MAE: 735.8483\n",
      "Epoch 750, Train Loss: 1949634.5000, Val MSE: 1798818.0000, Val MAE: 728.4125\n",
      "Epoch 760, Train Loss: 1922962.1250, Val MSE: 1838275.6250, Val MAE: 744.7402\n",
      "Epoch 770, Train Loss: 1906451.7500, Val MSE: 1810527.2500, Val MAE: 723.8373\n",
      "Epoch 780, Train Loss: 1936073.6250, Val MSE: 1812748.7500, Val MAE: 724.5544\n",
      "Epoch 790, Train Loss: 1950313.1250, Val MSE: 1805733.8750, Val MAE: 723.9750\n",
      "Epoch 800, Train Loss: 1909024.3750, Val MSE: 1836857.7500, Val MAE: 742.1456\n",
      "Epoch 810, Train Loss: 1918197.2500, Val MSE: 1814172.6250, Val MAE: 723.6528\n",
      "Epoch 820, Train Loss: 1874240.2500, Val MSE: 1817749.5000, Val MAE: 741.4213\n",
      "Epoch 830, Train Loss: 1922247.3750, Val MSE: 1810387.7500, Val MAE: 739.1519\n",
      "Epoch 840, Train Loss: 1931834.5000, Val MSE: 1796990.1250, Val MAE: 710.9928\n",
      "Epoch 850, Train Loss: 1874838.0000, Val MSE: 1777123.6250, Val MAE: 715.3462\n",
      "Epoch 860, Train Loss: 1859788.5000, Val MSE: 1799239.8750, Val MAE: 733.6273\n",
      "Epoch 870, Train Loss: 1900007.7500, Val MSE: 1776544.8750, Val MAE: 713.7306\n",
      "Epoch 880, Train Loss: 1857021.7500, Val MSE: 1819782.1250, Val MAE: 730.2261\n",
      "Epoch 890, Train Loss: 1902603.5000, Val MSE: 1783763.8750, Val MAE: 726.4979\n",
      "Epoch 900, Train Loss: 1875457.2500, Val MSE: 1819254.1250, Val MAE: 725.5499\n",
      "Epoch 910, Train Loss: 1855594.5000, Val MSE: 1772921.2500, Val MAE: 702.9694\n",
      "Epoch 920, Train Loss: 1867418.3750, Val MSE: 1760998.5000, Val MAE: 714.9917\n",
      "Epoch 930, Train Loss: 1887621.8750, Val MSE: 1759091.0000, Val MAE: 709.0221\n",
      "Epoch 940, Train Loss: 1849148.6250, Val MSE: 1771617.6250, Val MAE: 713.4949\n",
      "Epoch 950, Train Loss: 1878706.6250, Val MSE: 1768692.5000, Val MAE: 713.1604\n",
      "Epoch 960, Train Loss: 1879484.8750, Val MSE: 1744799.1250, Val MAE: 705.6888\n",
      "Epoch 970, Train Loss: 1865308.7500, Val MSE: 1750793.7500, Val MAE: 704.4837\n",
      "Epoch 980, Train Loss: 1858383.5000, Val MSE: 1772517.5000, Val MAE: 718.6633\n",
      "Epoch 990, Train Loss: 1848487.5000, Val MSE: 1756304.8750, Val MAE: 712.3353\n",
      "Epoch 1000, Train Loss: 1875466.6250, Val MSE: 1772290.3750, Val MAE: 716.2661\n",
      "Epoch 1010, Train Loss: 1883271.8750, Val MSE: 1730216.2500, Val MAE: 699.2426\n",
      "Epoch 1020, Train Loss: 1844605.0000, Val MSE: 1734576.3750, Val MAE: 696.9373\n",
      "Epoch 1030, Train Loss: 1830315.3750, Val MSE: 1724589.5000, Val MAE: 692.0977\n",
      "Epoch 1040, Train Loss: 1836997.5000, Val MSE: 1740483.5000, Val MAE: 696.4080\n",
      "Epoch 1050, Train Loss: 1872488.3750, Val MSE: 1772036.7500, Val MAE: 708.0519\n",
      "Epoch 1060, Train Loss: 1826269.6250, Val MSE: 1764469.7500, Val MAE: 704.1269\n",
      "Epoch 1070, Train Loss: 1896623.8750, Val MSE: 1741295.7500, Val MAE: 690.8219\n",
      "Epoch 1080, Train Loss: 1835516.5000, Val MSE: 1740723.1250, Val MAE: 695.3555\n",
      "Epoch 1090, Train Loss: 1841772.7500, Val MSE: 1743391.7500, Val MAE: 696.5347\n",
      "Epoch 1100, Train Loss: 1826120.2500, Val MSE: 1751597.8750, Val MAE: 698.7154\n",
      "Epoch 1110, Train Loss: 1844464.8750, Val MSE: 1710657.6250, Val MAE: 692.2341\n",
      "Epoch 1120, Train Loss: 1851108.7500, Val MSE: 1732103.8750, Val MAE: 688.0514\n",
      "Epoch 1130, Train Loss: 1810464.1250, Val MSE: 1729954.2500, Val MAE: 702.2253\n",
      "Epoch 1140, Train Loss: 1827579.0000, Val MSE: 1707849.1250, Val MAE: 681.2031\n",
      "Epoch 1150, Train Loss: 1800062.1250, Val MSE: 1730472.6250, Val MAE: 700.9681\n",
      "Epoch 1160, Train Loss: 1863910.3750, Val MSE: 1718893.3750, Val MAE: 689.6074\n",
      "Epoch 1170, Train Loss: 1822687.6250, Val MSE: 1724176.0000, Val MAE: 683.7430\n",
      "Epoch 1180, Train Loss: 1812598.8750, Val MSE: 1707014.2500, Val MAE: 688.0001\n",
      "Epoch 1190, Train Loss: 1813488.0000, Val MSE: 1700333.1250, Val MAE: 686.9113\n",
      "Epoch 1200, Train Loss: 1786450.1250, Val MSE: 1704472.3750, Val MAE: 682.1416\n",
      "Epoch 1210, Train Loss: 1821293.3750, Val MSE: 1723443.6250, Val MAE: 687.2952\n",
      "Epoch 1220, Train Loss: 1846156.7500, Val MSE: 1694061.7500, Val MAE: 683.4532\n",
      "Epoch 1230, Train Loss: 1788294.5000, Val MSE: 1710059.6250, Val MAE: 687.9588\n",
      "Epoch 1240, Train Loss: 1777844.5000, Val MSE: 1701807.5000, Val MAE: 683.8959\n",
      "Epoch 1250, Train Loss: 1787801.2500, Val MSE: 1711278.6250, Val MAE: 686.9821\n",
      "Epoch 1260, Train Loss: 1803188.1250, Val MSE: 1726348.6250, Val MAE: 700.0558\n",
      "Epoch 1270, Train Loss: 1815667.1250, Val MSE: 1692171.3750, Val MAE: 680.4736\n",
      "Epoch 1280, Train Loss: 1805393.8750, Val MSE: 1679968.1250, Val MAE: 677.3572\n",
      "Epoch 1290, Train Loss: 1803954.0000, Val MSE: 1700130.2500, Val MAE: 679.4107\n",
      "Epoch 1300, Train Loss: 1807682.1250, Val MSE: 1715733.2500, Val MAE: 684.3438\n",
      "Epoch 1310, Train Loss: 1759090.8750, Val MSE: 1709184.6250, Val MAE: 668.5219\n",
      "Epoch 1320, Train Loss: 1813167.1250, Val MSE: 1719917.2500, Val MAE: 686.4700\n",
      "Epoch 1330, Train Loss: 1783012.7500, Val MSE: 1705647.2500, Val MAE: 671.5496\n",
      "Epoch 1340, Train Loss: 1765503.6250, Val MSE: 1725846.8750, Val MAE: 701.6821\n",
      "Epoch 1350, Train Loss: 1800643.2500, Val MSE: 1725621.0000, Val MAE: 688.9733\n",
      "Epoch 1360, Train Loss: 1774477.3750, Val MSE: 1713803.3750, Val MAE: 688.9321\n",
      "Epoch 1370, Train Loss: 1767089.1250, Val MSE: 1678741.5000, Val MAE: 671.0221\n",
      "Epoch 1380, Train Loss: 1751423.0000, Val MSE: 1721562.6250, Val MAE: 673.4570\n",
      "Epoch 1390, Train Loss: 1806537.2500, Val MSE: 1719140.7500, Val MAE: 668.4077\n",
      "Epoch 1400, Train Loss: 1776069.0000, Val MSE: 1668986.1250, Val MAE: 666.6116\n",
      "Epoch 1410, Train Loss: 1760566.7500, Val MSE: 1687025.8750, Val MAE: 664.5068\n",
      "Epoch 1420, Train Loss: 1760082.1250, Val MSE: 1701369.5000, Val MAE: 667.5296\n",
      "Epoch 1430, Train Loss: 1743135.5000, Val MSE: 1706729.5000, Val MAE: 676.9558\n",
      "Epoch 1440, Train Loss: 1771502.8750, Val MSE: 1735972.3750, Val MAE: 688.6613\n",
      "Epoch 1450, Train Loss: 1767196.1250, Val MSE: 1689173.1250, Val MAE: 669.4352\n",
      "Epoch 1460, Train Loss: 1743242.7500, Val MSE: 1704648.2500, Val MAE: 675.4954\n",
      "Epoch 1470, Train Loss: 1779216.5000, Val MSE: 1699910.1250, Val MAE: 675.9305\n",
      "Epoch 1480, Train Loss: 1770965.5000, Val MSE: 1698598.7500, Val MAE: 678.9781\n",
      "Epoch 1490, Train Loss: 1795166.2500, Val MSE: 1711927.1250, Val MAE: 675.0659\n",
      "Epoch 1500, Train Loss: 1785908.0000, Val MSE: 1698105.3750, Val MAE: 668.4773\n",
      "Epoch 1510, Train Loss: 1743939.5000, Val MSE: 1684934.6250, Val MAE: 675.4327\n",
      "Epoch 1520, Train Loss: 1805525.0000, Val MSE: 1725502.5000, Val MAE: 674.4755\n",
      "Epoch 1530, Train Loss: 1783304.5000, Val MSE: 1701387.8750, Val MAE: 661.9736\n",
      "Epoch 1540, Train Loss: 1802044.3750, Val MSE: 1706844.6250, Val MAE: 660.0944\n",
      "Epoch 1550, Train Loss: 1777671.2500, Val MSE: 1698510.5000, Val MAE: 664.1996\n",
      "Epoch 1560, Train Loss: 1776217.3750, Val MSE: 1703332.8750, Val MAE: 673.2326\n",
      "Epoch 1570, Train Loss: 1729995.6250, Val MSE: 1680143.3750, Val MAE: 664.2535\n",
      "Epoch 1580, Train Loss: 1759589.8750, Val MSE: 1682472.1250, Val MAE: 671.2645\n",
      "Epoch 1590, Train Loss: 1724420.7500, Val MSE: 1690137.5000, Val MAE: 666.6178\n",
      "Epoch 1600, Train Loss: 1752705.1250, Val MSE: 1697583.7500, Val MAE: 665.4323\n",
      "Epoch 1610, Train Loss: 1755716.6250, Val MSE: 1692735.1250, Val MAE: 667.1965\n",
      "Epoch 1620, Train Loss: 1730676.2500, Val MSE: 1675187.6250, Val MAE: 659.7546\n",
      "Epoch 1630, Train Loss: 1742665.7500, Val MSE: 1679180.7500, Val MAE: 656.7878\n",
      "Epoch 1640, Train Loss: 1758326.5000, Val MSE: 1709594.8750, Val MAE: 665.8826\n",
      "Epoch 1650, Train Loss: 1778394.7500, Val MSE: 1667836.8750, Val MAE: 657.6327\n",
      "Epoch 1660, Train Loss: 1722497.7500, Val MSE: 1698361.8750, Val MAE: 658.4963\n",
      "Epoch 1670, Train Loss: 1739226.0000, Val MSE: 1664544.6250, Val MAE: 654.1703\n",
      "Epoch 1680, Train Loss: 1761838.5000, Val MSE: 1700442.1250, Val MAE: 663.1641\n",
      "Epoch 1690, Train Loss: 1739470.5000, Val MSE: 1700371.7500, Val MAE: 660.5289\n",
      "Epoch 1700, Train Loss: 1734465.5000, Val MSE: 1688811.8750, Val MAE: 671.6298\n",
      "Epoch 1710, Train Loss: 1736009.2500, Val MSE: 1707958.2500, Val MAE: 661.8017\n",
      "Epoch 1720, Train Loss: 1729283.6250, Val MSE: 1678290.1250, Val MAE: 653.6945\n",
      "Epoch 1730, Train Loss: 1713247.5000, Val MSE: 1721144.0000, Val MAE: 667.6581\n",
      "Epoch 1740, Train Loss: 1727744.8750, Val MSE: 1690694.3750, Val MAE: 660.2650\n",
      "Epoch 1750, Train Loss: 1766160.5000, Val MSE: 1698834.0000, Val MAE: 661.3318\n",
      "Epoch 1760, Train Loss: 1738096.5000, Val MSE: 1730279.0000, Val MAE: 657.4777\n",
      "Epoch 1770, Train Loss: 1719449.5000, Val MSE: 1709971.2500, Val MAE: 677.3890\n",
      "Epoch 1780, Train Loss: 1718475.3750, Val MSE: 1690848.1250, Val MAE: 670.2964\n",
      "Epoch 1790, Train Loss: 1718486.3750, Val MSE: 1702090.7500, Val MAE: 658.8703\n",
      "Epoch 1800, Train Loss: 1765346.6250, Val MSE: 1688271.5000, Val MAE: 651.9629\n",
      "Epoch 1810, Train Loss: 1715335.1250, Val MSE: 1723453.3750, Val MAE: 682.9238\n",
      "Epoch 1820, Train Loss: 1736457.1250, Val MSE: 1705250.1250, Val MAE: 676.7391\n",
      "Epoch 1830, Train Loss: 1738573.6250, Val MSE: 1688414.7500, Val MAE: 674.9537\n",
      "Epoch 1840, Train Loss: 1694604.0000, Val MSE: 1668074.7500, Val MAE: 661.0103\n",
      "Epoch 1850, Train Loss: 1711110.2500, Val MSE: 1686535.6250, Val MAE: 652.4089\n",
      "Epoch 1860, Train Loss: 1757937.1250, Val MSE: 1689822.2500, Val MAE: 651.5399\n",
      "Epoch 1870, Train Loss: 1730422.2500, Val MSE: 1729395.7500, Val MAE: 669.0706\n",
      "Epoch 1880, Train Loss: 1721290.1250, Val MSE: 1690505.3750, Val MAE: 658.7006\n",
      "Epoch 1890, Train Loss: 1712992.0000, Val MSE: 1704851.7500, Val MAE: 659.1884\n",
      "Epoch 1900, Train Loss: 1715459.2500, Val MSE: 1696024.0000, Val MAE: 652.3055\n",
      "Epoch 1910, Train Loss: 1745986.0000, Val MSE: 1703153.7500, Val MAE: 661.4316\n",
      "Epoch 1920, Train Loss: 1703861.5000, Val MSE: 1680800.5000, Val MAE: 648.2310\n",
      "Epoch 1930, Train Loss: 1713442.8750, Val MSE: 1681018.1250, Val MAE: 654.8924\n",
      "Epoch 1940, Train Loss: 1717823.8750, Val MSE: 1698498.6250, Val MAE: 654.9558\n",
      "Epoch 1950, Train Loss: 1704204.7500, Val MSE: 1694581.1250, Val MAE: 659.2108\n",
      "Epoch 1960, Train Loss: 1747513.6250, Val MSE: 1683054.6250, Val MAE: 655.0198\n",
      "Epoch 1970, Train Loss: 1736348.0000, Val MSE: 1699061.2500, Val MAE: 660.8364\n",
      "Epoch 1980, Train Loss: 1716585.1250, Val MSE: 1671217.3750, Val MAE: 654.2443\n",
      "Epoch 1990, Train Loss: 1712572.2500, Val MSE: 1670428.1250, Val MAE: 639.1894\n",
      "Epoch 2000, Train Loss: 1736872.0000, Val MSE: 1701873.8750, Val MAE: 654.7779\n",
      "Epoch 2010, Train Loss: 1727702.6250, Val MSE: 1670642.1250, Val MAE: 645.0220\n",
      "Epoch 2020, Train Loss: 1714742.8750, Val MSE: 1678329.2500, Val MAE: 652.7223\n",
      "Epoch 2030, Train Loss: 1707750.3750, Val MSE: 1665233.0000, Val MAE: 651.7502\n",
      "Epoch 2040, Train Loss: 1715013.8750, Val MSE: 1672464.1250, Val MAE: 644.6925\n",
      "Epoch 2050, Train Loss: 1684916.3750, Val MSE: 1697888.8750, Val MAE: 647.5911\n",
      "Epoch 2060, Train Loss: 1679999.1250, Val MSE: 1659408.5000, Val MAE: 644.0146\n",
      "Epoch 2070, Train Loss: 1663221.2500, Val MSE: 1696819.7500, Val MAE: 664.1725\n",
      "Epoch 2080, Train Loss: 1711667.6250, Val MSE: 1719148.5000, Val MAE: 660.9687\n",
      "Epoch 2090, Train Loss: 1700822.6250, Val MSE: 1693370.8750, Val MAE: 646.2977\n",
      "Epoch 2100, Train Loss: 1698708.2500, Val MSE: 1676124.8750, Val MAE: 645.3077\n",
      "Epoch 2110, Train Loss: 1710446.3750, Val MSE: 1712012.5000, Val MAE: 653.5347\n",
      "Epoch 2120, Train Loss: 1688602.0000, Val MSE: 1751303.8750, Val MAE: 683.7518\n",
      "Epoch 2130, Train Loss: 1720356.3750, Val MSE: 1687557.3750, Val MAE: 648.5674\n",
      "Epoch 2140, Train Loss: 1716308.5000, Val MSE: 1725627.1250, Val MAE: 664.1520\n",
      "Epoch 2150, Train Loss: 1709196.7500, Val MSE: 1701165.0000, Val MAE: 657.2966\n",
      "Epoch 2160, Train Loss: 1716886.6250, Val MSE: 1700317.7500, Val MAE: 643.8468\n",
      "Epoch 2170, Train Loss: 1681544.1250, Val MSE: 1676140.5000, Val MAE: 643.9990\n",
      "Epoch 2180, Train Loss: 1680143.6250, Val MSE: 1707592.3750, Val MAE: 663.4631\n",
      " Early stopping at epoch 2190\n",
      "\n",
      " Best Val MAE: 639.1894 at epoch 1990\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm1, best_mae_deepfm1, best_epoch_deepfm1 = train_deepfm(model_deepfm1, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f404bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1689280.8750, Val MSE: 1700130.8750, Val MAE: 649.6033\n",
      "Epoch 20, Train Loss: 1653346.8750, Val MSE: 1696381.5000, Val MAE: 647.3687\n",
      "Epoch 30, Train Loss: 1692299.6250, Val MSE: 1694213.8750, Val MAE: 645.5338\n",
      "Epoch 40, Train Loss: 1666252.5000, Val MSE: 1699875.2500, Val MAE: 649.7424\n",
      "Epoch 50, Train Loss: 1687248.6250, Val MSE: 1698171.1250, Val MAE: 652.4045\n",
      "Epoch 60, Train Loss: 1629981.3750, Val MSE: 1712072.8750, Val MAE: 656.2851\n",
      "Epoch 70, Train Loss: 1674660.7500, Val MSE: 1703476.3750, Val MAE: 645.3825\n",
      "Epoch 80, Train Loss: 1674918.7500, Val MSE: 1699224.6250, Val MAE: 642.8607\n",
      "Epoch 90, Train Loss: 1679873.1250, Val MSE: 1698079.2500, Val MAE: 646.8079\n",
      "Epoch 100, Train Loss: 1660038.8750, Val MSE: 1690743.8750, Val MAE: 647.9073\n",
      "Epoch 110, Train Loss: 1695495.7500, Val MSE: 1701368.1250, Val MAE: 646.7731\n",
      "Epoch 120, Train Loss: 1676721.5000, Val MSE: 1702007.2500, Val MAE: 650.6168\n",
      "Epoch 130, Train Loss: 1666318.8750, Val MSE: 1700477.1250, Val MAE: 648.1763\n",
      "Epoch 140, Train Loss: 1639231.7500, Val MSE: 1693481.5000, Val MAE: 642.8411\n",
      "Epoch 150, Train Loss: 1699825.6250, Val MSE: 1695947.1250, Val MAE: 645.8569\n",
      "Epoch 160, Train Loss: 1643304.6250, Val MSE: 1708204.7500, Val MAE: 645.3251\n",
      "Epoch 170, Train Loss: 1640155.2500, Val MSE: 1702761.7500, Val MAE: 643.5311\n",
      "Epoch 180, Train Loss: 1655421.6250, Val MSE: 1707913.2500, Val MAE: 650.2761\n",
      "Epoch 190, Train Loss: 1654565.6250, Val MSE: 1708417.5000, Val MAE: 653.9295\n",
      "Epoch 200, Train Loss: 1678904.0000, Val MSE: 1715183.2500, Val MAE: 650.8455\n",
      "Epoch 210, Train Loss: 1666885.5000, Val MSE: 1695182.1250, Val MAE: 643.0491\n",
      "Epoch 220, Train Loss: 1667422.8750, Val MSE: 1712400.3750, Val MAE: 651.8597\n",
      "Epoch 230, Train Loss: 1654412.3750, Val MSE: 1718500.0000, Val MAE: 653.1096\n",
      "Epoch 240, Train Loss: 1666280.5000, Val MSE: 1700802.3750, Val MAE: 643.9738\n",
      "Epoch 250, Train Loss: 1654437.2500, Val MSE: 1706626.8750, Val MAE: 643.7261\n",
      "Epoch 260, Train Loss: 1680823.8750, Val MSE: 1712554.3750, Val MAE: 651.0842\n",
      "Epoch 270, Train Loss: 1638742.3750, Val MSE: 1710145.3750, Val MAE: 646.5630\n",
      "Epoch 280, Train Loss: 1637026.2500, Val MSE: 1709047.2500, Val MAE: 646.4786\n",
      "Epoch 290, Train Loss: 1638200.7500, Val MSE: 1718762.3750, Val MAE: 652.2117\n",
      "Epoch 300, Train Loss: 1666968.2500, Val MSE: 1710864.7500, Val MAE: 646.6439\n",
      "Epoch 310, Train Loss: 1677733.8750, Val MSE: 1708756.7500, Val MAE: 643.8107\n",
      "Epoch 320, Train Loss: 1658091.5000, Val MSE: 1714009.5000, Val MAE: 642.9954\n",
      "Epoch 330, Train Loss: 1695736.5000, Val MSE: 1704182.0000, Val MAE: 641.6798\n",
      "Epoch 340, Train Loss: 1673933.7500, Val MSE: 1700708.6250, Val MAE: 647.3048\n",
      "Epoch 350, Train Loss: 1674366.3750, Val MSE: 1720026.0000, Val MAE: 649.0891\n",
      "Epoch 360, Train Loss: 1626042.3750, Val MSE: 1725274.1250, Val MAE: 649.5454\n",
      "Epoch 370, Train Loss: 1646898.3750, Val MSE: 1708471.3750, Val MAE: 644.3629\n",
      "Epoch 380, Train Loss: 1632099.2500, Val MSE: 1716923.0000, Val MAE: 647.4119\n",
      "Epoch 390, Train Loss: 1620348.1250, Val MSE: 1703524.0000, Val MAE: 643.8690\n",
      "Epoch 400, Train Loss: 1669511.1250, Val MSE: 1730811.7500, Val MAE: 649.5526\n",
      "Epoch 410, Train Loss: 1698197.2500, Val MSE: 1717597.5000, Val MAE: 642.3416\n",
      "Epoch 420, Train Loss: 1632228.7500, Val MSE: 1717271.1250, Val MAE: 646.6779\n",
      "Epoch 430, Train Loss: 1641058.7500, Val MSE: 1715912.3750, Val MAE: 647.4438\n",
      "Epoch 440, Train Loss: 1659440.5000, Val MSE: 1714034.1250, Val MAE: 645.5209\n",
      "Epoch 450, Train Loss: 1637775.3750, Val MSE: 1703888.6250, Val MAE: 647.8566\n",
      "Epoch 460, Train Loss: 1645525.7500, Val MSE: 1721633.0000, Val MAE: 649.4474\n",
      "Epoch 470, Train Loss: 1638169.7500, Val MSE: 1720204.1250, Val MAE: 647.3701\n",
      "Epoch 480, Train Loss: 1641073.3750, Val MSE: 1720106.0000, Val MAE: 646.1267\n",
      "Epoch 490, Train Loss: 1642974.7500, Val MSE: 1720409.5000, Val MAE: 644.4884\n",
      "Epoch 500, Train Loss: 1625930.8750, Val MSE: 1717525.1250, Val MAE: 645.0645\n",
      "Epoch 510, Train Loss: 1646537.2500, Val MSE: 1722679.0000, Val MAE: 649.7502\n",
      "Epoch 520, Train Loss: 1643229.7500, Val MSE: 1716365.1250, Val MAE: 643.3959\n",
      " Early stopping at epoch 530\n",
      "\n",
      " Best Val MAE: 641.6798 at epoch 330\n",
      " Model saved to best_deepfm_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_deepfm1, best_mae_deepfm1, best_epoch_deepfm1 = train_deepfm(model_deepfm1, X_train3, y_train3, X_val3, y_val3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8e9548d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters of model_deepfm1: 21428\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_deepfm1.parameters())\n",
    "print(f\"Total Parameters of model_deepfm1: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
